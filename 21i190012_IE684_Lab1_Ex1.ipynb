{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190012_IE684_Lab1_Ex1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVE0Xoa0Q5wE"
      },
      "source": [
        "$\\Large\\textbf{Welcome to IE 684 (Spring 2021-22)}$  \n",
        "\n",
        "$\\large\\textbf{Lab 1 Exercise 1. }$\n",
        "\n",
        "We will start with a procedure which helps to find a minimizer of the function $f(\\mathbf{x})=f(x_1,x_2)= (x_1+100)^2 + (x_2-25)^2$. \n",
        "\n",
        "Note that the gradient of $f(\\mathbf{x})$ is given by:\n",
        "\n",
        "$\n",
        "\\nabla f(\\mathbf{x}) = \\begin{bmatrix} \\frac{\\partial f(\\mathbf{x})}{\\partial x_1} \\\\ \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}\\end{bmatrix}. \n",
        "$\n",
        "\n",
        "We will use the following gradient descent type algorithm: \n",
        "\n",
        "\\begin{align}\n",
        "& \\textbf{Input:} \\text{ Starting point $x^0$, Stopping tolerance $\\tau$, Steplength $\\eta$}  \\\\\n",
        "& \\textbf{Initialize } k=0 \\\\ \n",
        "&\\textbf{While } \\| \\nabla f(\\mathbf{x}^k) \\|_2 > \\tau \\text{ do:}  \\\\   \n",
        "&\\quad \\quad \\mathbf{x}^{k+1} \\leftarrow \\mathbf{x}^k - \\eta \\nabla f(\\mathbf{x}^k)  \\\\ \n",
        "&\\quad \\quad k = {k+1} \\\\ \n",
        "&\\textbf{End While} \\\\\n",
        "&\\textbf{Output: } \\mathbf{x}^k\n",
        "\\end{align}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJq7tIgIRroP"
      },
      "source": [
        "#numpy package will be used for most of our lab exercises. Please have a look at https://numpy.org/doc/stable/ for numpy documentation\n",
        "#we will first import the numpy package and name it as np\n",
        "import numpy as np \n",
        "#Henceforth, we can lazily use np to denote the much longer numpy !! "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZjX2IwOR8_X"
      },
      "source": [
        "#Now we will define a function which will compute and return the function value \n",
        "def evalf(x):  \n",
        "  #Input: x is a numpy array of size 2 \n",
        "  assert type(x) is np.ndarray \n",
        "  assert len(x) == 2 #do not allow arbitrary arguments \n",
        "  #after checking if the argument is valid, we can compute the objective function value\n",
        "  return (x[0]+100)**2 + (x[1]-25)**2\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu_eWNWHTg64"
      },
      "source": [
        "#check whether you can pass arbitrary arguments to evalf \n",
        "#my_x = [1,3] #Note: my_x is a list of 2 elements, but not a numpy array\n",
        "#print('f(my_x) is:',evalf(my_x))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhgbIivdTshs",
        "outputId": "db27795f-fd71-4313-8ac5-017b5216060e"
      },
      "source": [
        "# First we will create a numpy array of size 2\n",
        "my_x = np.array([1,2])\n",
        "print('type of my_x',type(my_x), 'length of my_x:',len(my_x)) #verify if my_x is indeed a numpy array of size 2\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of my_x <class 'numpy.ndarray'> length of my_x: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Iky9aOT78d"
      },
      "source": [
        "#now call evalf (x) with my_x as argument and check if it works\n",
        "#print(evalf(my_x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6klpwtDra_I8"
      },
      "source": [
        "#Now we will define a function which will compute and return the gradient value as a numpy array \n",
        "def evalg(x):  \n",
        "  #Input: x is a numpy array of size 2 \n",
        "  assert type(x) is np.ndarray and len(x) == 2 #do not allow arbitrary arguments \n",
        "  #after checking if the argument is valid, we can compute the gradient value\n",
        "  return np.array([2*(x[0]+100),2*(x[1]-25)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCJdqivdpxx"
      },
      "source": [
        "def find_minimizer(start_x, tol, step_length):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 2 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  assert type(step_length) is float and step_length>=0 \n",
        "  x = start_x\n",
        "  g_x = evalg(x)\n",
        "  k = 0\n",
        "\n",
        "  #we can manage a list to store the function values, might be useful for plotting \n",
        "  fvals = [evalf(x)]\n",
        "  print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x) #compute gradient at new point\n",
        "\n",
        "    #append the current function value to the list containing function values\n",
        "    fvals.append(evalf(x))\n",
        "    print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x, fvals \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-kHCkbwe-M4",
        "outputId": "954483e6-7127-4ffc-fc05-f2cf37d9c65e"
      },
      "source": [
        "my_start_x = np.array([10,10])\n",
        "my_steplength = 0.1\n",
        "my_tol= 1e-3 #10^{-3} or 0.001\n",
        "opt_x, fvals_ret = find_minimizer(my_start_x, my_tol, my_steplength)\n",
        "print('Optimizer:',opt_x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0  x: [10 10]  f(x): 12325  grad at x: [220 -30]  gradient norm: 222.03603311174518\n",
            "iter: 1  x: [-12.  13.]  f(x): 7888.0  grad at x: [176. -24.]  gradient norm: 177.62882648939615\n",
            "iter: 2  x: [-29.6  15.4]  f(x): 5048.320000000001  grad at x: [140.8 -19.2]  gradient norm: 142.10306119151693\n",
            "iter: 3  x: [-43.68  17.32]  f(x): 3230.9247999999993  grad at x: [112.64 -15.36]  gradient norm: 113.68244895321352\n",
            "iter: 4  x: [-54.944  18.856]  f(x): 2067.791872  grad at x: [ 90.112 -12.288]  gradient norm: 90.94595916257082\n",
            "iter: 5  x: [-63.9552  20.0848]  f(x): 1323.3867980799996  grad at x: [72.0896 -9.8304]  gradient norm: 72.75676733005665\n",
            "iter: 6  x: [-71.16416  21.06784]  f(x): 846.9675507711995  grad at x: [57.67168 -7.86432]  gradient norm: 58.20541386404531\n",
            "iter: 7  x: [-76.931328  21.854272]  f(x): 542.0592324935676  grad at x: [46.137344 -6.291456]  gradient norm: 46.56433109123625\n",
            "iter: 8  x: [-81.5450624  22.4834176]  f(x): 346.9179087958833  grad at x: [36.9098752 -5.0331648]  gradient norm: 37.251464872989\n",
            "iter: 9  x: [-85.23604992  22.98673408]  f(x): 222.0274616293655  grad at x: [29.52790016 -4.02653184]  gradient norm: 29.80117189839121\n",
            "iter: 10  x: [-88.18883994  23.38938726]  f(x): 142.09757544279404  grad at x: [23.62232013 -3.22122547]  gradient norm: 23.840937518712977\n",
            "iter: 11  x: [-90.55107195  23.71150981]  f(x): 90.94244828338809  grad at x: [18.8978561  -2.57698038]  gradient norm: 19.072750014970374\n",
            "iter: 12  x: [-92.44085756  23.96920785]  f(x): 58.20316690136841  grad at x: [15.11828488 -2.0615843 ]  gradient norm: 15.258200011976303\n",
            "iter: 13  x: [-93.95268605  24.17536628]  f(x): 37.25002681687585  grad at x: [12.09462791 -1.64926744]  gradient norm: 12.206560009581054\n",
            "iter: 14  x: [-95.16214884  24.34029302]  f(x): 23.840017162800546  grad at x: [ 9.67570232 -1.31941395]  gradient norm: 9.765248007664843\n",
            "iter: 15  x: [-96.12971907  24.47223442]  f(x): 15.25761098419235  grad at x: [ 7.74056186 -1.05553116]  gradient norm: 7.812198406131874\n",
            "iter: 16  x: [-96.90377526  24.57778753]  f(x): 9.764871029883087  grad at x: [ 6.19244949 -0.84442493]  gradient norm: 6.249758724905495\n",
            "iter: 17  x: [-97.5230202   24.66223003]  f(x): 6.249517459125205  grad at x: [ 4.95395959 -0.67553994]  gradient norm: 4.999806979924407\n",
            "iter: 18  x: [-98.01841616  24.72978402]  f(x): 3.9996911738401533  grad at x: [ 3.96316767 -0.54043196]  gradient norm: 3.999845583939537\n",
            "iter: 19  x: [-98.41473293  24.78382722]  f(x): 2.559802351257707  grad at x: [ 3.17053414 -0.43234556]  gradient norm: 3.199876467151635\n",
            "iter: 20  x: [-98.73178634  24.82706177]  f(x): 1.6382735048049322  grad at x: [ 2.53642731 -0.34587645]  gradient norm: 2.5599011737213075\n",
            "iter: 21  x: [-98.98542908  24.86164942]  f(x): 1.0484950430751447  grad at x: [ 2.02914185 -0.27670116]  gradient norm: 2.0479209389770348\n",
            "iter: 22  x: [-99.18834326  24.88931954]  f(x): 0.6710368275680882  grad at x: [ 1.62331348 -0.22136093]  gradient norm: 1.6383367511816223\n",
            "iter: 23  x: [-99.35067461  24.91145563]  f(x): 0.42946356964356897  grad at x: [ 1.29865078 -0.17708874]  gradient norm: 1.3106694009452864\n",
            "iter: 24  x: [-99.48053969  24.9291645 ]  f(x): 0.27485668457188733  grad at x: [ 1.03892063 -0.14167099]  gradient norm: 1.0485355207562352\n",
            "iter: 25  x: [-99.58443175  24.9433316 ]  f(x): 0.1759082781260078  grad at x: [ 0.8311365 -0.1133368]  gradient norm: 0.8388284166049879\n",
            "iter: 26  x: [-99.6675454   24.95466528]  f(x): 0.11258129800064115  grad at x: [ 0.6649092  -0.09066944]  gradient norm: 0.6710627332839789\n",
            "iter: 27  x: [-99.73403632  24.96373223]  f(x): 0.07205203072040883  grad at x: [ 0.53192736 -0.07253555]  gradient norm: 0.5368501866271775\n",
            "iter: 28  x: [-99.78722906  24.97098578]  f(x): 0.04611329966106277  grad at x: [ 0.42554189 -0.05802844]  gradient norm: 0.4294801493017472\n",
            "iter: 29  x: [-99.82978324  24.97678862]  f(x): 0.02951251178308121  grad at x: [ 0.34043351 -0.04642275]  gradient norm: 0.3435841194414038\n",
            "iter: 30  x: [-99.8638266  24.9814309]  f(x): 0.018888007541173576  grad at x: [ 0.27234681 -0.0371382 ]  gradient norm: 0.2748672955531347\n",
            "iter: 31  x: [-99.89106128  24.98514472]  f(x): 0.01208832482635049  grad at x: [ 0.21787745 -0.02971056]  gradient norm: 0.21989383644250232\n",
            "iter: 32  x: [-99.91284902  24.98811578]  f(x): 0.007736527888864313  grad at x: [ 0.17430196 -0.02376845]  gradient norm: 0.17591506915400185\n",
            "iter: 33  x: [-99.93027922  24.99049262]  f(x): 0.004951377848873557  grad at x: [ 0.13944157 -0.01901476]  gradient norm: 0.14073205532320712\n",
            "iter: 34  x: [-99.94422337  24.9923941 ]  f(x): 0.0031688818232796997  grad at x: [ 0.11155325 -0.01521181]  gradient norm: 0.11258564425857677\n",
            "iter: 35  x: [-99.9553787   24.99391528]  f(x): 0.0020280843668995063  grad at x: [ 0.0892426  -0.01216945]  gradient norm: 0.09006851540687248\n",
            "iter: 36  x: [-99.96430296  24.99513222]  f(x): 0.0012979739948154952  grad at x: [ 0.07139408 -0.00973556]  gradient norm: 0.07205481232549274\n",
            "iter: 37  x: [-99.97144237  24.99610578]  f(x): 0.0008307033566815811  grad at x: [ 0.05711527 -0.00778845]  gradient norm: 0.05764384986038254\n",
            "iter: 38  x: [-99.97715389  24.99688462]  f(x): 0.000531650148276203  grad at x: [ 0.04569221 -0.00623076]  gradient norm: 0.04611507988830565\n",
            "iter: 39  x: [-99.98172312  24.9975077 ]  f(x): 0.000340256094896659  grad at x: [ 0.03655377 -0.0049846 ]  gradient norm: 0.036892063910638505\n",
            "iter: 40  x: [-99.98537849  24.99800616]  f(x): 0.00021776390073393917  grad at x: [ 0.02924302 -0.00398768]  gradient norm: 0.02951365112851605\n",
            "iter: 41  x: [-99.98830279  24.99840493]  f(x): 0.0001393688964697853  grad at x: [ 0.02339441 -0.00319015]  gradient norm: 0.02361092090281828\n",
            "iter: 42  x: [-99.99064223  24.99872394]  f(x): 8.919609374066622e-05  grad at x: [ 0.01871553 -0.00255212]  gradient norm: 0.01888873672225501\n",
            "iter: 43  x: [-99.99251379  24.99897915]  f(x): 5.7085499994068934e-05  grad at x: [ 0.01497242 -0.00204169]  gradient norm: 0.01511098937780964\n",
            "iter: 44  x: [-99.99401103  24.99918332]  f(x): 3.653471999613835e-05  grad at x: [ 0.01197794 -0.00163336]  gradient norm: 0.01208879150223683\n",
            "iter: 45  x: [-99.99520882  24.99934666]  f(x): 2.3382220797474075e-05  grad at x: [ 0.00958235 -0.00130668]  gradient norm: 0.0096710332017782\n",
            "iter: 46  x: [-99.99616706  24.99947733]  f(x): 1.4964621310382665e-05  grad at x: [ 0.00766588 -0.00104535]  gradient norm: 0.007736826561422368\n",
            "iter: 47  x: [-99.99693365  24.99958186]  f(x): 9.577357638678578e-06  grad at x: [ 0.0061327  -0.00083628]  gradient norm: 0.006189461249148775\n",
            "iter: 48  x: [-99.99754692  24.99966549]  f(x): 6.129508888739396e-06  grad at x: [ 0.00490616 -0.00066902]  gradient norm: 0.004951568999313004\n",
            "iter: 49  x: [-99.99803753  24.99973239]  f(x): 3.922885688770902e-06  grad at x: [ 0.00392493 -0.00053522]  gradient norm: 0.003961255199439138\n",
            "iter: 50  x: [-99.99843003  24.99978591]  f(x): 2.5106468407952244e-06  grad at x: [ 0.00313994 -0.00042817]  gradient norm: 0.003169004159539854\n",
            "iter: 51  x: [-99.99874402  24.99982873]  f(x): 1.6068139781229793e-06  grad at x: [ 0.00251196 -0.00034254]  gradient norm: 0.002535203327642956\n",
            "iter: 52  x: [-99.99899522  24.99986298]  f(x): 1.0283609459933846e-06  grad at x: [ 0.00200956 -0.00027403]  gradient norm: 0.0020281626621091167\n",
            "iter: 53  x: [-99.99919617  24.99989039]  f(x): 6.581510054452161e-07  grad at x: [ 0.00160765 -0.00021923]  gradient norm: 0.0016225301296989418\n",
            "iter: 54  x: [-99.99935694  24.99991231]  f(x): 4.212166434776276e-07  grad at x: [ 0.00128612 -0.00017538]  gradient norm: 0.001298024103747889\n",
            "iter: 55  x: [-99.99948555  24.99992985]  f(x): 2.6957865182860594e-07  grad at x: [ 0.0010289 -0.0001403]  gradient norm: 0.0010384192830039433\n",
            "iter: 56  x: [-99.99958844  24.99994388]  f(x): 1.7253033717248775e-07  grad at x: [ 0.00082312 -0.00011224]  gradient norm: 0.0008307354264084029\n",
            "Optimizer: [-99.99958844  24.99994388]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft_3BxMzfREx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "b9eff4b7-17db-42b5-8abd-2e5c04f9f425"
      },
      "source": [
        "#we will plot the function values and check the behavior\n",
        "import matplotlib.pyplot as plt #package useful for plotting\n",
        "plt.plot(fvals_ret)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('f(x)')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "${\\Large\\text{Do not forget to rename the file before submission.}}$"
      ],
      "metadata": {
        "id": "D2U-MGS6M0Cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hLIB_t-EkHRT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 2:\n",
        "\n",
        "Minimizer: [-99.99958844  24.99994388]\n",
        "\n",
        "f(x): 1.7253033717248775e-07"
      ],
      "metadata": {
        "id": "7ahXhTI2kAuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer(start_x, tol, step_length):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 2 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  assert type(step_length) is float and step_length>=0 \n",
        "  x = start_x\n",
        "  g_x = evalg(x)\n",
        "  k = 0\n",
        "\n",
        "  #we can manage a list to store the function values, might be useful for plotting \n",
        "  fvals = [evalf(x)]\n",
        "  #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x) #compute gradient at new point\n",
        "\n",
        "    #append the current function value to the list containing function values\n",
        "    fvals.append(evalf(x))\n",
        "    #print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return k, x, fvals "
      ],
      "metadata": {
        "id": "aqkWBOYilvKc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_iterations = []\n",
        "optimizer = []\n",
        "function_values = []\n",
        "tolerance = []\n",
        "for i in range(1,11):\n",
        "  my_tol = 10**-i\n",
        "  k, opt, fval = find_minimizer(my_start_x, my_tol, my_steplength)\n",
        "  tolerance.append(my_tol)\n",
        "  no_of_iterations.append(k)\n",
        "  optimizer.append(opt)\n",
        "  function_values.append(fval[-1])"
      ],
      "metadata": {
        "id": "YmHIo4htkFo_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print('For tolerance =',tolerance[i],'\\nNo. of iterations :',no_of_iterations[i],'\\nFinal Optimizer :',optimizer[i],'\\nFinal Function Value :',function_values[i],'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoBalTzmkZ5u",
        "outputId": "3b4717dd-b678-4840-ff98-53062bf58507"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For tolerance = 0.1 \n",
            "No. of iterations : 35 \n",
            "Final Optimizer : [-99.9553787   24.99391528] \n",
            "Final Function Value : 0.0020280843668995063 \n",
            "\n",
            "For tolerance = 0.01 \n",
            "No. of iterations : 45 \n",
            "Final Optimizer : [-99.99520882  24.99934666] \n",
            "Final Function Value : 2.3382220797474075e-05 \n",
            "\n",
            "For tolerance = 0.001 \n",
            "No. of iterations : 56 \n",
            "Final Optimizer : [-99.99958844  24.99994388] \n",
            "Final Function Value : 1.7253033717248775e-07 \n",
            "\n",
            "For tolerance = 0.0001 \n",
            "No. of iterations : 66 \n",
            "Final Optimizer : [-99.99995581  24.99999397] \n",
            "Final Function Value : 1.989139359193299e-09 \n",
            "\n",
            "For tolerance = 1e-05 \n",
            "No. of iterations : 76 \n",
            "Final Optimizer : [-99.99999526  24.99999935] \n",
            "Final Function Value : 2.293321544605827e-11 \n",
            "\n",
            "For tolerance = 1e-06 \n",
            "No. of iterations : 87 \n",
            "Final Optimizer : [-99.99999959  24.99999994] \n",
            "Final Function Value : 1.6921726745458407e-13 \n",
            "\n",
            "For tolerance = 1e-07 \n",
            "No. of iterations : 97 \n",
            "Final Optimizer : [-99.99999996  24.99999999] \n",
            "Final Function Value : 1.950942200128245e-15 \n",
            "\n",
            "For tolerance = 1e-08 \n",
            "No. of iterations : 107 \n",
            "Final Optimizer : [-100.   25.] \n",
            "Final Function Value : 2.249273021138356e-17 \n",
            "\n",
            "For tolerance = 1e-09 \n",
            "No. of iterations : 118 \n",
            "Final Optimizer : [-100.   25.] \n",
            "Final Function Value : 1.6597088735501767e-19 \n",
            "\n",
            "For tolerance = 1e-10 \n",
            "No. of iterations : 128 \n",
            "Final Optimizer : [-100.   25.] \n",
            "Final Function Value : 1.9135732950098918e-21 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 3:\n",
        "\n",
        "The values of No. of iterations, final optimizer, final function value are printed above for each value of tolerance.\n",
        "\n",
        "The required plot is plotted below.\n",
        "\n",
        "We can observe that as the tolerance value reduces the no. of iterations increase rapidly.\n",
        "\n",
        "We can also observe that the function value reduces as the tolerance reduces, and the value of the optimizer saturates after a point ."
      ],
      "metadata": {
        "id": "4W95Rsppfukd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tolerance, no_of_iterations)\n",
        "plt.xlabel('Tolerance')\n",
        "plt.ylabel('No. of iterations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "GwZwkdh4qEWZ",
        "outputId": "31de2bdc-152f-4fda-af6e-8a1bbdb52194"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'No. of iterations')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_length_values = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "my_tol = 1e-5\n",
        "no_of_iterations = []\n",
        "optimizer = []\n",
        "function_values = []\n",
        "tolerance = []\n",
        "for i in range(len(step_length_values)):\n",
        "  k, opt, fval = find_minimizer(my_start_x, my_tol, step_length_values[i])\n",
        "  no_of_iterations.append(k)\n",
        "  optimizer.append(opt)\n",
        "  function_values.append(fval[-1])"
      ],
      "metadata": {
        "id": "WavM34xqq99_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print('For step length =',step_length_values[i],'\\nNo. of iterations :',no_of_iterations[i],'\\nFinal Optimizer :',optimizer[i],'\\nFinal Function Value :',function_values[i],'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ4XidQ7upte",
        "outputId": "0dfd0073-e46d-433b-9177-0b8f51424cfd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For step length = 0.0001 \n",
            "No. of iterations : 84571 \n",
            "Final Optimizer : [-99.99999505  24.99999932] \n",
            "Final Function Value : 2.49936770204995e-11 \n",
            "\n",
            "For step length = 0.001 \n",
            "No. of iterations : 8450 \n",
            "Final Optimizer : [-99.99999505  24.99999933] \n",
            "Final Function Value : 2.494219709847674e-11 \n",
            "\n",
            "For step length = 0.01 \n",
            "No. of iterations : 838 \n",
            "Final Optimizer : [-99.99999512  24.99999933] \n",
            "Final Function Value : 2.4304673044883465e-11 \n",
            "\n",
            "For step length = 0.1 \n",
            "No. of iterations : 76 \n",
            "Final Optimizer : [-99.99999526  24.99999935] \n",
            "Final Function Value : 2.293321544605827e-11 \n",
            "\n",
            "For step length = 0.2 \n",
            "No. of iterations : 34 \n",
            "Final Optimizer : [-99.99999685  24.99999957] \n",
            "Final Function Value : 1.011747066175869e-11 \n",
            "\n",
            "For step length = 0.4 \n",
            "No. of iterations : 11 \n",
            "Final Optimizer : [-99.99999775  24.99999969] \n",
            "Final Function Value : 5.169479687800271e-12 \n",
            "\n",
            "For step length = 0.5 \n",
            "No. of iterations : 1 \n",
            "Final Optimizer : [-100.   25.] \n",
            "Final Function Value : 0.0 \n",
            "\n",
            "For step length = 0.6 \n",
            "No. of iterations : 11 \n",
            "Final Optimizer : [-100.00000225   25.00000031] \n",
            "Final Function Value : 5.169479687800271e-12 \n",
            "\n",
            "For step length = 0.7 \n",
            "No. of iterations : 19 \n",
            "Final Optimizer : [-100.00000302   25.00000041] \n",
            "Final Function Value : 9.312506683476372e-12 \n",
            "\n",
            "For step length = 0.8 \n",
            "No. of iterations : 34 \n",
            "Final Optimizer : [-99.99999685  24.99999957] \n",
            "Final Function Value : 1.011747066175869e-11 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 4:\n",
        "\n",
        "The values of No. of iterations, final optimizer, final function value are printed above for each value of step length.\n",
        "\n",
        "The required plot is plotted below.\n",
        "\n",
        "We can observe that as the step length value reduces the no. of iterations increase rapidly.\n",
        "\n",
        "We can also observe that the function value reduces as the step length reduces but negligibly, and that at step length = 0.5, the function attains a minimum of 0. The value of the optimizer negligibly fluctuates."
      ],
      "metadata": {
        "id": "qKm6UMp1igC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(step_length_values, no_of_iterations)\n",
        "plt.xlabel('Step Length')\n",
        "plt.ylabel('No. of iterations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "AydSkhhiuz8v",
        "outputId": "b5357cae-d1a8-4d16-9572-d6cde2918f7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'No. of iterations')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_x = [(10000, 10000),(500, 0),(0, 1000),(1, 1),(-500, -2)]\n",
        "my_tol = 1e-5\n",
        "step_length = 0.1\n",
        "no_of_iterations = []\n",
        "optimizer = []\n",
        "function_values = []\n",
        "for i in range(len(start_x)):\n",
        "  my_start_x = np.array(start_x[i])\n",
        "  k, opt, fval = find_minimizer(my_start_x, my_tol, step_length)\n",
        "  no_of_iterations.append(k)\n",
        "  optimizer.append(opt)\n",
        "  function_values.append(fval[-1])"
      ],
      "metadata": {
        "id": "VHXOnSpBu7yD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(start_x)):\n",
        "  print('For starting point :',start_x[i],'\\nNo. of iterations :',no_of_iterations[i],'\\nFinal Optimizer :',optimizer[i],'\\nFinal Function Value :',function_values[i],'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF6cPMXUvqfU",
        "outputId": "139affe8-212e-4f25-d443-a8f2fde39cdf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For starting point : (10000, 10000) \n",
            "No. of iterations : 98 \n",
            "Final Optimizer : [-99.99999679  25.00000317] \n",
            "Final Function Value : 2.0414342669998657e-11 \n",
            "\n",
            "For starting point : (500, 0) \n",
            "No. of iterations : 84 \n",
            "Final Optimizer : [-99.99999566  24.99999982] \n",
            "Final Function Value : 1.888746375147865e-11 \n",
            "\n",
            "For starting point : (0, 1000) \n",
            "No. of iterations : 86 \n",
            "Final Optimizer : [-99.99999954  25.00000452] \n",
            "Final Function Value : 2.060780080476227e-11 \n",
            "\n",
            "For starting point : (1, 1) \n",
            "No. of iterations : 76 \n",
            "Final Optimizer : [-99.99999564  24.99999896] \n",
            "Final Function Value : 2.0052840841640608e-11 \n",
            "\n",
            "For starting point : (-500, -2) \n",
            "No. of iterations : 82 \n",
            "Final Optimizer : [-100.00000452   24.99999969] \n",
            "Final Function Value : 2.055190630073527e-11 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 5:\n",
        "\n",
        "The values of No. of iterations, final optimizer, final function value are printed above for each starting value of x.\n",
        "\n",
        "We can observe that the closer the inital x is to the optimizer the less no. of iterations are required but the difference is not too much in comparison to the difference between the points.\n",
        "\n",
        "We can observe that we reach almost the same optimizer and final function value in each case."
      ],
      "metadata": {
        "id": "r0OZMufzjE21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X5pX27VByqN7"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}