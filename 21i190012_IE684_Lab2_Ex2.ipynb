{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190012_IE684_Lab2_Ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjJfkmtNB1yG"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evalf(x,n):\n",
        "  assert type(x) is np.ndarray and len(x) == n\n",
        "\n",
        "  sum = 0\n",
        "\n",
        "  for i in range(1,n+1):\n",
        "    sum += ((x[i-1]-2**i)**2)/(8**i)\n",
        "  return sum"
      ],
      "metadata": {
        "id": "kc6pJP2iB9b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evalf(np.array([1,1]),2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaQmptYYDTaZ",
        "outputId": "e8707a79-72b9-4988-eb72-0e768ec4c2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.265625"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg(x,n):\n",
        "  assert type(x) is np.ndarray and len(x) == n\n",
        "\n",
        "  arr = np.array([])\n",
        "\n",
        "  for i in range(1,n+1):\n",
        "    j = 2*(x[i-1]-2**i)/(8**i)\n",
        "    arr = np.concatenate((arr,np.array([j])),axis=0)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "FjZNksBODdSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evalg(np.array([1,1]),2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8OXX3W2EXlW",
        "outputId": "09c75b34-372f-4076-9450-714fc7aebeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.25   , -0.09375])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_exact(gradf, A, n):\n",
        "  assert type(gradf) is np.ndarray and len(gradf) ==  n\n",
        "  assert type(A) is np.ndarray and A.shape[0] == n and  A.shape[1] == n\n",
        "\n",
        "  t1 = np.matmul(gradf,gradf)/2\n",
        "  t2 = np.matmul(np.matmul(A,gradf),gradf)\n",
        "\n",
        "  step_length = t1/t2\n",
        "  \n",
        "  return step_length"
      ],
      "metadata": {
        "id": "VgcuOmVVEbH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_backtracking(x, gradf, alpha_start, rho, gamma, n):\n",
        "  assert type(x) is np.ndarray and len(x) == n\n",
        "  assert type(gradf) is np.ndarray and len(gradf) == n\n",
        "  \n",
        "  alpha = alpha_start\n",
        "\n",
        "  while evalf(x+alpha*(-gradf),n) > evalf(x,n) + gamma*alpha*np.matmul(gradf.transpose(),-gradf):\n",
        "    alpha = rho*alpha\n",
        "\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "RHSJ6vkiGXLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXACT_LINE_SEARCH = 1\n",
        "BACKTRACKING_LINE_SEARCH = 2\n",
        "CONSTANT_STEP_LENGTH = 3"
      ],
      "metadata": {
        "id": "ES7DpVAtHoXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer(start_x, tol, line_search_type, n, *args):\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == n\n",
        "  assert type(tol) is float and tol>=0\n",
        "  A = np.array([[1/8, 0,0],[0,1/64,0],[0,0,1/512]])\n",
        "  x = start_x\n",
        "  g_x = evalg(x,n)\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "    #print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\n",
        "\n",
        "  k = 0\n",
        "  #print('iter:',k, ' x:', x, ' f(x):', evalf(x,n), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact(g_x, A, n) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking(x,g_x, alpha_start,rho, gamma, n) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 0.1\n",
        "    else:  \n",
        "      raise ValueError('ReEnter Line Search Type')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x,n) #compute gradient at new point\n",
        "\n",
        "    #print('iter:',k, ' x:', x, ' f(x):', evalf(x,n), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x,evalf(x,n),k\n"
      ],
      "metadata": {
        "id": "-f4ZAzAwGjHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_start_x = np.array([10,10,10])\n",
        "my_tol= 1e-5"
      ],
      "metadata": {
        "id": "rpw6DuYLHdNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_opt,f_min,k = find_minimizer(my_start_x, my_tol, CONSTANT_STEP_LENGTH,3)\n",
        "print('Constant Step Length:','\\nOptimizer:',x_opt,'\\nMinimum Function Value:',f_min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiRca88x6waT",
        "outputId": "f35267da-8a7d-4374-fad3-3ddb8738415a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant Step Length: \n",
            "Optimizer: [2.         4.         8.00255956] \n",
            "Minimum Function Value: 1.279561039741878e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 2:\n",
        "\n",
        "Since no data for this question has been provided, I have taken the following values:\n",
        "\n",
        "start_x = [10,10,10]\n",
        "\n",
        "tolerance = $10^{-5}$\n",
        "\n",
        "step length = 0.1\n",
        "\n",
        "Using Constant Step Length :\n",
        "\n",
        "Optimizer: [2. , 4. , 8.00255956]\n",
        "\n",
        "Minimum Function Value: 1.279561039741878e-08"
      ],
      "metadata": {
        "id": "gTBvbPS4KSmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q3_start_x = np.array([1/64,1/8,1])\n",
        "q3_tol = 1e-10"
      ],
      "metadata": {
        "id": "dGI9Ba_5JP0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_opt,f_min,k = find_minimizer(q3_start_x, q3_tol, EXACT_LINE_SEARCH,3)\n",
        "print('Exact Line Search:','\\nOptimizer:',x_opt,'\\nMinimum Function Value:',f_min,'\\nNo. of iterations:',k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdtI4j007yI_",
        "outputId": "cca5eeac-1136-49c6-bdfe-02980f1ebe93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Line Search: \n",
            "Optimizer: [2.         4.         7.99999998] \n",
            "Minimum Function Value: 9.150071377581033e-19 \n",
            "No. of iterations: 269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_opt,f_min,k = find_minimizer(q3_start_x, q3_tol, BACKTRACKING_LINE_SEARCH,3,1,0.5,0.5)\n",
        "print('Backtracking Line Search:','\\nOptimizer:',x_opt,'\\nMinimum Function Value:',f_min,'\\nNo. of iterations:',k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct0KWyvM8FXO",
        "outputId": "cb601ff7-5bc7-4389-cf1c-3c618317fa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backtracking Line Search: \n",
            "Optimizer: [2.         4.         7.99999997] \n",
            "Minimum Function Value: 1.2748574165464873e-18 \n",
            "No. of iterations: 4964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 3:\n",
        "\n",
        "We can observe that Backtraining Line Search uses around 18 times more iterations than what Exact Line Search uses."
      ],
      "metadata": {
        "id": "FCQFVXkO8a1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer(start_x, tol, line_search_type, n, *args):\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == n\n",
        "  assert type(tol) is float and tol>=0\n",
        "  A = np.array([[1/8, 0,0,0],[0,1/64,0,0],[0,0,1/512,0],[0,0,0,1/4096]])\n",
        "  x = start_x\n",
        "  g_x = evalg(x,n)\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "    #print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\n",
        "\n",
        "  k = 0\n",
        "  #print('iter:',k, ' x:', x, ' f(x):', evalf(x,n), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact(g_x, A, n) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking(x,g_x, alpha_start,rho, gamma, n) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 0.1\n",
        "    else:  \n",
        "      raise ValueError('ReEnter Line Search Type')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x,n) #compute gradient at new point\n",
        "\n",
        "    #print('iter:',k, ' x:', x, ' f(x):', evalf(x,n), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x,evalf(x,n),k\n"
      ],
      "metadata": {
        "id": "6yVxuGRJ9rVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q4_start_x = np.array([1/512,1/64,1/8,1])\n",
        "q4_tol = 1e-10"
      ],
      "metadata": {
        "id": "uabgepvp8V8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_opt,f_min,k = find_minimizer(q4_start_x, q4_tol, EXACT_LINE_SEARCH,4)\n",
        "print('Exact Line Search:','\\nOptimizer:',x_opt,'\\nMinimum Function Value:',f_min,'\\nNo. of iterations:',k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-VnG3eq9JFR",
        "outputId": "b78cc570-e1f3-423d-9536-78862648e681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Line Search: \n",
            "Optimizer: [ 2.          4.          8.         15.99999981] \n",
            "Minimum Function Value: 8.8565993523583e-18 \n",
            "No. of iterations: 2013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_opt,f_min,k = find_minimizer(q4_start_x, q4_tol, BACKTRACKING_LINE_SEARCH,4,1,0.5,0.5)\n",
        "print('Backtracking Line Search:','\\nOptimizer:',x_opt,'\\nMinimum Function Value:',f_min,'\\nNo. of iterations:',k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqZV2pTE9Xtn",
        "outputId": "b051eff8-946b-4d08-e594-ce812e5be2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backtracking Line Search: \n",
            "Optimizer: [ 2.         4.         8.        15.9999998] \n",
            "Minimum Function Value: 1.0237544252113035e-17 \n",
            "No. of iterations: 37079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 4:\n",
        "\n",
        "We can gather similar observations here as in the case for N = 3. Backtracking Line Search uses significantly more iterations (around 18 times more)."
      ],
      "metadata": {
        "id": "1gK5TtFY9-xs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 5:\n",
        "\n",
        "Considering the case for N = 3 and N = 4, we can say that for N $>$ 4 too Backtracking Line Search takes significantly more no. of iterations than Exact Line Search."
      ],
      "metadata": {
        "id": "zjhVeIJn-aCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qHN8gJ2C977m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}