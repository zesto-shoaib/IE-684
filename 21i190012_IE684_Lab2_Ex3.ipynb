{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190012_IE684_Lab2_Ex3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AO3lXCpLfGz"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evalf(x):\n",
        "  assert type(x) is np.ndarray and len(x) == 2\n",
        "  return (512*(x[1]-x[0]**2)**2 + (4-x[0])**2)"
      ],
      "metadata": {
        "id": "XgD9UlvxLlHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg(x):\n",
        "  assert type(x) is np.ndarray and len(x) == 2\n",
        "  return np.array([-2048*x[0]*(x[1]-x[0]**2)+2*x[0]-8, 1024*(x[1]-x[0]**2)])"
      ],
      "metadata": {
        "id": "RFEoEJHoMsAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_exact(gradf, A):\n",
        "  assert type(gradf) is np.ndarray and len(gradf) ==  2\n",
        "  assert type(A) is np.ndarray and A.shape[0] == n and  A.shape[1] == 2\n",
        "\n",
        "  t1 = np.matmul(gradf,gradf)/2\n",
        "  t2 = np.matmul(np.matmul(A,gradf),gradf)\n",
        "\n",
        "  step_length = t1/t2\n",
        "  \n",
        "  return step_length"
      ],
      "metadata": {
        "id": "mX_4ZzO3NlPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_backtracking(x, gradf, alpha_start, rho, gamma):\n",
        "  assert type(x) is np.ndarray and len(x) == 2\n",
        "  assert type(gradf) is np.ndarray and len(gradf) == 2\n",
        "  \n",
        "  alpha = alpha_start\n",
        "\n",
        "  while evalf(x+alpha*(-gradf)) > evalf(x) + gamma*alpha*np.matmul(gradf.transpose(),-gradf):\n",
        "    alpha = rho*alpha\n",
        "\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "N3-wYFhhNuGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXACT_LINE_SEARCH = 1\n",
        "BACKTRACKING_LINE_SEARCH = 2\n",
        "CONSTANT_STEP_LENGTH = 3"
      ],
      "metadata": {
        "id": "lj2GZJyIOHu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_minimizer(start_x, tol, line_search_type, *args):\n",
        "  #Input: start_x is a numpy array of size 2, tol denotes the tolerance and is a positive float value\n",
        "  assert type(start_x) is np.ndarray and len(start_x) == 2 #do not allow arbitrary arguments \n",
        "  assert type(tol) is float and tol>=0 \n",
        "  # construct a suitable A matrix for the quadratic function \n",
        "  A = np.array([[1, 0],[0,1]])\n",
        "  x = start_x\n",
        "  g_x = evalg(x)\n",
        "\n",
        "  #initialization for backtracking line search\n",
        "  if(line_search_type == BACKTRACKING_LINE_SEARCH):\n",
        "    alpha_start = args[0]\n",
        "    rho = args[1]\n",
        "    gamma = args[2]\n",
        "    #print('Params for Backtracking LS: alpha start:', alpha_start, 'rho:', rho,' gamma:', gamma)\n",
        "\n",
        "  k = 0\n",
        "  print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "\n",
        "  while (np.linalg.norm(g_x) > tol): #continue as long as the norm of gradient is not close to zero upto a tolerance tol\n",
        "  \n",
        "    if line_search_type == EXACT_LINE_SEARCH:\n",
        "      step_length = compute_steplength_exact(g_x, A) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('EXACT LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == BACKTRACKING_LINE_SEARCH:\n",
        "      step_length = compute_steplength_backtracking(x,g_x, alpha_start,rho, gamma) #call the new function you wrote to compute the steplength\n",
        "      #raise ValueError('BACKTRACKING LINE SEARCH NOT YET IMPLEMENTED')\n",
        "    elif line_search_type == CONSTANT_STEP_LENGTH: #do a gradient descent with constant step length\n",
        "      step_length = 1e-6\n",
        "    else:  \n",
        "      raise ValueError('Line search type unknown. Please check!')\n",
        "    \n",
        "    #implement the gradient descent steps here   \n",
        "    x = np.subtract(x, np.multiply(step_length,g_x)) #update x = x - step_length*g_x\n",
        "    k += 1 #increment iteration\n",
        "    g_x = evalg(x) #compute gradient at new point\n",
        "\n",
        "    print('iter:',k, ' x:', x, ' f(x):', evalf(x), ' grad at x:', g_x, ' gradient norm:', np.linalg.norm(g_x))\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "6vEe83BtN0Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_start_x = np.array([4,4])\n",
        "my_tol = 1e-5\n",
        "\n",
        "x_opt = find_minimizer(my_start_x, my_tol, BACKTRACKING_LINE_SEARCH,1.0,0.5,0.5)"
      ],
      "metadata": {
        "id": "5ecbFij1OCWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b597ede-6958-4a23-8c9d-e13ed7b56130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "iter: 932680  x: [ 3.99995641 15.99965125]  f(x): 1.9003932468978503e-09  grad at x: [-2.66002317e-06 -1.05658310e-05]  gradient norm: 1.0895526935109392e-05\n",
            "iter: 932681  x: [ 3.99995641 15.99965126]  f(x): 1.900333374437544e-09  grad at x: [ 8.30572162e-05 -2.12799532e-05]  gradient norm: 8.573994153150024e-05\n",
            "iter: 932682  x: [ 3.99995641 15.99965126]  f(x): 1.9002772588738616e-09  grad at x: [-2.66068029e-06 -1.05654162e-05]  gradient norm: 1.0895285208503258e-05\n",
            "iter: 932683  x: [ 3.99995641 15.99965127]  f(x): 1.9002174509570115e-09  grad at x: [ 8.31019473e-05 -2.12852119e-05]  gradient norm: 8.57845784333741e-05\n",
            "iter: 932684  x: [ 3.99995641 15.99965127]  f(x): 1.9001612779326727e-09  grad at x: [-2.66135204e-06 -1.05649997e-05]  gradient norm: 1.0895045342857082e-05\n",
            "iter: 932685  x: [ 3.99995641 15.99965128]  f(x): 1.900101535714066e-09  grad at x: [ 8.31475806e-05 -2.12905834e-05]  gradient norm: 8.583011768927084e-05\n",
            "iter: 932686  x: [ 3.99995641 15.99965128]  f(x): 1.9000453040727772e-09  grad at x: [-2.66200932e-06 -1.05645850e-05]  gradient norm: 1.0894803757074314e-05\n",
            "iter: 932687  x: [ 3.99995641 15.99965129]  f(x): 1.8999856264204987e-09  grad at x: [ 8.31922970e-05 -2.12958403e-05]  gradient norm: 8.58747407340481e-05\n",
            "iter: 932688  x: [ 3.99995641 15.99965129]  f(x): 1.899929337276268e-09  grad at x: [-2.66269579e-06 -1.05641666e-05]  gradient norm: 1.089456582702262e-05\n",
            "iter: 932689  x: [ 3.99995642 15.9996513 ]  f(x): 1.8998697266984933e-09  grad at x: [ 8.32389197e-05 -2.13013354e-05]  gradient norm: 8.592127001664514e-05\n",
            "iter: 932690  x: [ 3.99995641 15.9996513 ]  f(x): 1.8998133775803524e-09  grad at x: [-2.66338234e-06 -1.05637482e-05]  gradient norm: 1.0894327970855663e-05\n",
            "iter: 932691  x: [ 3.99995642 15.99965131]  f(x): 1.899753834071907e-09  grad at x: [ 8.32855277e-05 -2.13068288e-05]  gradient norm: 8.596778512380577e-05\n",
            "iter: 932692  x: [ 3.99995642 15.99965131]  f(x): 1.8996974249647584e-09  grad at x: [-2.66405442e-06 -1.05633317e-05]  gradient norm: 1.089408839380258e-05\n",
            "iter: 932693  x: [ 3.99995642 15.99965132]  f(x): 1.8996379473174368e-09  grad at x: [ 8.33311898e-05 -2.13122039e-05]  gradient norm: 8.601335491265634e-05\n",
            "iter: 932694  x: [ 3.99995642 15.99965132]  f(x): 1.8995814794291595e-09  grad at x: [-2.66471203e-06 -1.05629169e-05]  gradient norm: 1.0893847093080121e-05\n",
            "iter: 932695  x: [ 3.99995642 15.99965133]  f(x): 1.899522066508518e-09  grad at x: [ 8.33759350e-05 -2.13174644e-05]  gradient norm: 8.605800845318908e-05\n",
            "iter: 932696  x: [ 3.99995642 15.99965133]  f(x): 1.8994655409357074e-09  grad at x: [-2.66538427e-06 -1.05625004e-05]  gradient norm: 1.0893607659040664e-05\n",
            "iter: 932697  x: [ 3.99995642 15.99965134]  f(x): 1.8994061940139605e-09  grad at x: [ 8.34216260e-05 -2.13228432e-05]  gradient norm: 8.610360804007304e-05\n",
            "iter: 932698  x: [ 3.99995642 15.99965134]  f(x): 1.8993496095415502e-09  grad at x: [-2.66605659e-06 -1.05620838e-05]  gradient norm: 1.0893368296932377e-05\n",
            "iter: 932699  x: [ 3.99995642 15.99965135]  f(x): 1.8992903285742893e-09  grad at x: [ 8.34672878e-05 -2.13282183e-05]  gradient norm: 8.61491788837283e-05\n",
            "iter: 932700  x: [ 3.99995642 15.99965135]  f(x): 1.8992336852264176e-09  grad at x: [-2.66671444e-06 -1.05616691e-05]  gradient norm: 1.0893127208211957e-05\n",
            "iter: 932701  x: [ 3.99995642 15.99965137]  f(x): 1.8991744691143816e-09  grad at x: [ 8.35120618e-05 -2.13334824e-05]  gradient norm: 8.619386255124672e-05\n",
            "iter: 932702  x: [ 3.99995642 15.99965137]  f(x): 1.8991177679911685e-09  grad at x: [-2.66738692e-06 -1.05612526e-05]  gradient norm: 1.0892887989235244e-05\n",
            "iter: 932703  x: [ 3.99995642 15.99965138]  f(x): 1.8990586179706653e-09  grad at x: [ 8.35577671e-05 -2.13388630e-05]  gradient norm: 8.623947774110865e-05\n",
            "iter: 932704  x: [ 3.99995642 15.99965138]  f(x): 1.8990018578155345e-09  grad at x: [-2.66805949e-06 -1.05608360e-05]  gradient norm: 1.0892648842466356e-05\n",
            "iter: 932705  x: [ 3.99995643 15.99965139]  f(x): 1.8989427739558666e-09  grad at x: [ 8.36034869e-05 -2.13442454e-05]  gradient norm: 8.628510783232002e-05\n",
            "iter: 932706  x: [ 3.99995642 15.99965139]  f(x): 1.8988859547191376e-09  grad at x: [-2.66874668e-06 -1.05604176e-05]  gradient norm: 1.0892411569510758e-05\n",
            "iter: 932707  x: [ 3.99995643 15.9996514 ]  f(x): 1.898826938183377e-09  grad at x: [ 8.36501088e-05 -2.13497406e-05]  gradient norm: 8.633164037679663e-05\n",
            "iter: 932708  x: [ 3.99995643 15.9996514 ]  f(x): 1.8987700587004686e-09  grad at x: [-2.66941941e-06 -1.05600011e-05]  gradient norm: 1.0892172568007337e-05\n",
            "iter: 932709  x: [ 3.99995643 15.99965141]  f(x): 1.898711108351048e-09  grad at x: [ 8.36958139e-05 -2.13551211e-05]  gradient norm: 8.637725662978066e-05\n",
            "iter: 932710  x: [ 3.99995643 15.99965141]  f(x): 1.898654169759203e-09  grad at x: [-2.67007767e-06 -1.05595864e-05]  gradient norm: 1.0891931834516942e-05\n",
            "iter: 932711  x: [ 3.99995643 15.99965142]  f(x): 1.898595284455882e-09  grad at x: [ 8.37406166e-05 -2.13603889e-05]  gradient norm: 8.64219711144182e-05\n",
            "iter: 932712  x: [ 3.99995643 15.99965142]  f(x): 1.898538287877446e-09  grad at x: [-2.67076511e-06 -1.05591680e-05]  gradient norm: 1.0891694781169618e-05\n",
            "iter: 932713  x: [ 3.99995643 15.99965143]  f(x): 1.8984794700692803e-09  grad at x: [ 8.37872820e-05 -2.13658896e-05]  gradient norm: 8.646854838460366e-05\n",
            "iter: 932714  x: [ 3.99995643 15.99965143]  f(x): 1.8984224130724444e-09  grad at x: [-2.67143808e-06 -1.05587515e-05]  gradient norm: 1.089145599587476e-05\n",
            "iter: 932715  x: [ 3.99995643 15.99965144]  f(x): 1.8983636615448154e-09  grad at x: [ 8.38329868e-05 -2.13712701e-05]  gradient norm: 8.651416568674258e-05\n",
            "iter: 932716  x: [ 3.99995643 15.99965144]  f(x): 1.898306545343874e-09  grad at x: [-2.67209658e-06 -1.05583367e-05]  gradient norm: 1.0891215476062887e-05\n",
            "iter: 932717  x: [ 3.99995643 15.99965145]  f(x): 1.8982478589919044e-09  grad at x: [ 8.38778184e-05 -2.13765416e-05]  gradient norm: 8.655891029532108e-05\n",
            "iter: 932718  x: [ 3.99995643 15.99965145]  f(x): 1.8981906846925974e-09  grad at x: [-2.67276971e-06 -1.05579202e-05]  gradient norm: 1.0890976834215154e-05\n",
            "iter: 932719  x: [ 3.99995644 15.99965146]  f(x): 1.898132064720596e-09  grad at x: [ 8.39235522e-05 -2.13819258e-05]  gradient norm: 8.660455738707314e-05\n",
            "iter: 932720  x: [ 3.99995643 15.99965146]  f(x): 1.8980748310983503e-09  grad at x: [-2.67344293e-06 -1.05575036e-05]  gradient norm: 1.0890738264733852e-05\n",
            "iter: 932721  x: [ 3.99995644 15.99965147]  f(x): 1.8980162775377426e-09  grad at x: [ 8.39692859e-05 -2.13873100e-05]  gradient norm: 8.665020482560458e-05\n",
            "iter: 932722  x: [ 3.99995644 15.99965147]  f(x): 1.8979589845807496e-09  grad at x: [-2.67413077e-06 -1.05570853e-05]  gradient norm: 1.089050157729081e-05\n",
            "iter: 932723  x: [ 3.99995644 15.99965148]  f(x): 1.8979004987129826e-09  grad at x: [ 8.40159799e-05 -2.13928142e-05]  gradient norm: 8.669681297920452e-05\n",
            "iter: 932724  x: [ 3.99995644 15.99965148]  f(x): 1.897843145138285e-09  grad at x: [-2.67480415e-06 -1.05566687e-05]  gradient norm: 1.0890263153392876e-05\n",
            "iter: 932725  x: [ 3.99995644 15.99965149]  f(x): 1.897784725782763e-09  grad at x: [ 8.40617425e-05 -2.13982021e-05]  gradient norm: 8.674249022124969e-05\n",
            "iter: 932726  x: [ 3.99995644 15.99965149]  f(x): 1.897727312770632e-09  grad at x: [-2.67546306e-06 -1.05562540e-05]  gradient norm: 1.0890022989596582e-05\n",
            "iter: 932727  x: [ 3.99995644 15.9996515 ]  f(x): 1.8976689587074584e-09  grad at x: [ 8.41065446e-05 -2.14034699e-05]  gradient norm: 8.678720742270784e-05\n",
            "iter: 932728  x: [ 3.99995644 15.9996515 ]  f(x): 1.897611487478653e-09  grad at x: [-2.67613659e-06 -1.05558374e-05]  gradient norm: 1.0889784709343278e-05\n",
            "iter: 932729  x: [ 3.99995644 15.99965151]  f(x): 1.897553199989327e-09  grad at x: [ 8.41523216e-05 -2.14088595e-05]  gradient norm: 8.683289989905072e-05\n",
            "iter: 932730  x: [ 3.99995644 15.99965151]  f(x): 1.8974956692233366e-09  grad at x: [-2.67682477e-06 -1.05554191e-05]  gradient norm: 1.0889548315025879e-05\n",
            "iter: 932731  x: [ 3.99995644 15.99965152]  f(x): 1.8974374495933423e-09  grad at x: [ 8.41990299e-05 -2.14143656e-05]  gradient norm: 8.687952401963059e-05\n",
            "iter: 932732  x: [ 3.99995644 15.99965153]  f(x): 1.8973798580617993e-09  grad at x: [-2.67751302e-06 -1.05550007e-05]  gradient norm: 1.0889311995450856e-05\n",
            "iter: 932733  x: [ 3.99995644 15.99965154]  f(x): 1.8973217062858827e-09  grad at x: [ 8.42457236e-05 -2.14198699e-05]  gradient norm: 8.692613394871291e-05\n",
            "iter: 932734  x: [ 3.99995644 15.99965154]  f(x): 1.8972640539737783e-09  grad at x: [-2.67818680e-06 -1.05545842e-05]  gradient norm: 1.0889073934018447e-05\n",
            "iter: 932735  x: [ 3.99995645 15.99965155]  f(x): 1.897205968905515e-09  grad at x: [ 8.42915149e-05 -2.14252614e-05]  gradient norm: 8.697184202322563e-05\n",
            "iter: 932736  x: [ 3.99995644 15.99965155]  f(x): 1.8971482569401997e-09  grad at x: [-2.67886067e-06 -1.05541676e-05]  gradient norm: 1.0888835945111487e-05\n",
            "iter: 932737  x: [ 3.99995645 15.99965156]  f(x): 1.8970902386110967e-09  grad at x: [ 8.43373061e-05 -2.14306529e-05]  gradient norm: 8.70175504435689e-05\n",
            "iter: 932738  x: [ 3.99995645 15.99965156]  f(x): 1.8970324669806796e-09  grad at x: [-2.67954916e-06 -1.05537492e-05]  gradient norm: 1.0888599846516074e-05\n",
            "iter: 932739  x: [ 3.99995645 15.99965157]  f(x): 1.8969745166020977e-09  grad at x: [ 8.43840141e-05 -2.14361589e-05]  gradient norm: 8.706417598494964e-05\n",
            "iter: 932740  x: [ 3.99995645 15.99965157]  f(x): 1.896916684093703e-09  grad at x: [-2.68022319e-06 -1.05533327e-05]  gradient norm: 1.0888362003511218e-05\n",
            "iter: 932741  x: [ 3.99995645 15.99965157]  f(x): 1.8968732687513934e-09  grad at x: [ 4.08747982e-05 -1.59974425e-05]  gradient norm: 4.389381843195557e-05\n",
            "iter: 932742  x: [ 3.99995645 15.99965157]  f(x): 1.89685789475919e-09  grad at x: [-1.99999916e-06 -1.06381904e-05]  gradient norm: 1.0824559612114393e-05\n",
            "iter: 932743  x: [ 3.99995646 15.99965161]  f(x): 1.8966248426771523e-09  grad at x: [ 1.69585888e-04 -3.20847066e-05]  gradient norm: 0.0001725943275707829\n",
            "iter: 932744  x: [ 3.99995645 15.99965161]  f(x): 1.8964550519511213e-09  grad at x: [ 8.27869315e-05 -2.12350424e-05]  gradient norm: 8.546697049063914e-05\n",
            "iter: 932745  x: [ 3.99995645 15.99965162]  f(x): 1.8963992892100964e-09  grad at x: [-2.65507099e-06 -1.05549916e-05]  gradient norm: 1.08838067667834e-05\n",
            "iter: 932746  x: [ 3.99995646 15.99965163]  f(x): 1.896339365327842e-09  grad at x: [ 8.28319509e-05 -2.12403374e-05]  gradient norm: 8.551189406284257e-05\n",
            "iter: 932747  x: [ 3.99995645 15.99965163]  f(x): 1.896283544965591e-09  grad at x: [-2.65573091e-06 -1.05545769e-05]  gradient norm: 1.0883565576822477e-05\n",
            "iter: 932748  x: [ 3.99995646 15.99965164]  f(x): 1.896223685640744e-09  grad at x: [ 8.28768393e-05 -2.12456162e-05]  gradient norm: 8.5556687052398e-05\n",
            "iter: 932749  x: [ 3.99995646 15.99965164]  f(x): 1.8961678077927203e-09  grad at x: [-2.65640546e-06 -1.05541603e-05]  gradient norm: 1.0883326245131185e-05\n",
            "iter: 932750  x: [ 3.99995646 15.99965165]  f(x): 1.8961080142527084e-09  grad at x: [ 8.29226590e-05 -2.12510113e-05]  gradient norm: 8.56024114736496e-05\n",
            "iter: 932751  x: [ 3.99995646 15.99965165]  f(x): 1.896052077671233e-09  grad at x: [-2.65708009e-06 -1.05537438e-05]  gradient norm: 1.0883086985446e-05\n",
            "iter: 932752  x: [ 3.99995646 15.99965166]  f(x): 1.8959923499844504e-09  grad at x: [ 8.29685076e-05 -2.12564100e-05]  gradient norm: 8.564816535525476e-05\n",
            "iter: 932753  x: [ 3.99995646 15.99965166]  f(x): 1.8959363546195544e-09  grad at x: [-2.65774025e-06 -1.05533290e-05]  gradient norm: 1.0882846008346355e-05\n",
            "iter: 932754  x: [ 3.99995646 15.99965167]  f(x): 1.8958766915813487e-09  grad at x: [ 8.30134104e-05 -2.12616906e-05]  gradient norm: 8.569297395030629e-05\n",
            "iter: 932755  x: [ 3.99995646 15.99965167]  f(x): 1.8958206386186126e-09  grad at x: [-2.65840049e-06 -1.05529143e-05]  gradient norm: 1.0882605101506189e-05\n",
            "iter: 932756  x: [ 3.99995646 15.99965168]  f(x): 1.8957610402970436e-09  grad at x: [ 8.30583275e-05 -2.12669729e-05]  gradient norm: 8.57377974382328e-05\n",
            "iter: 932757  x: [ 3.99995646 15.99965168]  f(x): 1.8957049296680874e-09  grad at x: [-2.65906082e-06 -1.05524996e-05]  gradient norm: 1.0882364264727855e-05\n",
            "iter: 932758  x: [ 3.99995646 15.99965169]  f(x): 1.8956453961312407e-09  grad at x: [ 8.31032592e-05 -2.12722571e-05]  gradient norm: 8.57826358187552e-05\n",
            "iter: 932759  x: [ 3.99995646 15.99965169]  f(x): 1.8955892278063246e-09  grad at x: [-2.65972122e-06 -1.05520849e-05]  gradient norm: 1.08821234986818e-05\n",
            "iter: 932760  x: [ 3.99995646 15.9996517 ]  f(x): 1.89552975904672e-09  grad at x: [ 8.31481762e-05 -2.12775394e-05]  gradient norm: 8.582745999612835e-05\n",
            "iter: 932761  x: [ 3.99995646 15.9996517 ]  f(x): 1.8954735329955122e-09  grad at x: [-2.66041081e-06 -1.05516665e-05]  gradient norm: 1.088188639087416e-05\n",
            "iter: 932762  x: [ 3.99995647 15.99965171]  f(x): 1.895414131445502e-09  grad at x: [ 8.31949558e-05 -2.12830546e-05]  gradient norm: 8.587414678756509e-05\n",
            "iter: 932763  x: [ 3.99995646 15.99965171]  f(x): 1.89535784525289e-09  grad at x: [-2.66108593e-06 -1.05512499e-05]  gradient norm: 1.0881647562341075e-05\n",
            "iter: 932764  x: [ 3.99995647 15.99965172]  f(x): 1.895298509780645e-09  grad at x: [ 8.32408331e-05 -2.12884570e-05]  gradient norm: 8.591993190824839e-05\n",
            "iter: 932765  x: [ 3.99995647 15.99965172]  f(x): 1.895242164578134e-09  grad at x: [-2.66174657e-06 -1.05508352e-05]  gradient norm: 1.08814070105012e-05\n",
            "iter: 932766  x: [ 3.99995647 15.99965173]  f(x): 1.8951828939751193e-09  grad at x: [ 8.32857644e-05 -2.12937412e-05]  gradient norm: 8.596477168773425e-05\n",
            "iter: 932767  x: [ 3.99995647 15.99965173]  f(x): 1.8951264909521772e-09  grad at x: [-2.66240730e-06 -1.05504205e-05]  gradient norm: 1.0881166529037755e-05\n",
            "iter: 932768  x: [ 3.99995647 15.99965174]  f(x): 1.8950672852865486e-09  grad at x: [ 8.33307102e-05 -2.12990271e-05]  gradient norm: 8.600962635736305e-05\n",
            "iter: 932769  x: [ 3.99995647 15.99965174]  f(x): 1.8950108243934395e-09  grad at x: [-2.66305356e-06 -1.05500076e-05]  gradient norm: 1.088092432011886e-05\n",
            "iter: 932770  x: [ 3.99995647 15.99965175]  f(x): 1.894951682491935e-09  grad at x: [ 8.33747246e-05 -2.13041967e-05]  gradient norm: 8.605355020047651e-05\n",
            "iter: 932771  x: [ 3.99995647 15.99965175]  f(x): 1.894895164884039e-09  grad at x: [-2.6637290e-06 -1.0549591e-05]  gradient norm: 1.0880685777317712e-05\n",
            "iter: 932772  x: [ 3.99995647 15.99965176]  f(x): 1.8948360891841937e-09  grad at x: [ 8.34206016e-05 -2.13095991e-05]  gradient norm: 8.609933672126748e-05\n",
            "iter: 932773  x: [ 3.99995647 15.99965176]  f(x): 1.8947795124224713e-09  grad at x: [-2.66440453e-06 -1.05491745e-05]  gradient norm: 1.0880447307174125e-05\n",
            "iter: 932774  x: [ 3.99995647 15.99965177]  f(x): 1.8947205030308427e-09  grad at x: [ 8.34665221e-05 -2.13150070e-05]  gradient norm: 8.61451672481703e-05\n",
            "iter: 932775  x: [ 3.99995647 15.99965177]  f(x): 1.894663867028336e-09  grad at x: [-2.66509468e-06 -1.05487561e-05]  gradient norm: 1.0880210710379413e-05\n",
            "iter: 932776  x: [ 3.99995648 15.99965178]  f(x): 1.8946049251072026e-09  grad at x: [ 8.35133303e-05 -2.13205258e-05]  gradient norm: 8.619188567607617e-05\n",
            "iter: 932777  x: [ 3.99995647 15.99965179]  f(x): 1.8945482287001262e-09  grad at x: [-2.66577037e-06 -1.05483396e-05]  gradient norm: 1.0879972386406084e-05\n",
            "iter: 932778  x: [ 3.99995648 15.9996518 ]  f(x): 1.894489353113321e-09  grad at x: [ 8.35592361e-05 -2.13259318e-05]  gradient norm: 8.623770237238627e-05\n",
            "iter: 932779  x: [ 3.99995648 15.9996518 ]  f(x): 1.8944325974375178e-09  grad at x: [-2.66643158e-06 -1.05479248e-05]  gradient norm: 1.0879732332018012e-05\n",
            "iter: 932780  x: [ 3.99995648 15.99965181]  f(x): 1.894373787009851e-09  grad at x: [ 8.36042105e-05 -2.13312214e-05]  gradient norm: 8.628258821410126e-05\n",
            "iter: 932781  x: [ 3.99995648 15.99965181]  f(x): 1.8943169732226337e-09  grad at x: [-2.66712198e-06 -1.05475065e-05]  gradient norm: 1.087949595597896e-05\n",
            "iter: 932782  x: [ 3.99995648 15.99965182]  f(x): 1.894258230361583e-09  grad at x: [ 8.36510330e-05 -2.13367421e-05]  gradient norm: 8.632932228060851e-05\n",
            "iter: 932783  x: [ 3.99995648 15.99965182]  f(x): 1.894201356072705e-09  grad at x: [-2.66779791e-06 -1.05470899e-05]  gradient norm: 1.0879257849782613e-05\n",
            "iter: 932784  x: [ 3.99995648 15.99965183]  f(x): 1.894142679678142e-09  grad at x: [ 8.36969677e-05 -2.13421517e-05]  gradient norm: 8.637516914134686e-05\n",
            "iter: 932785  x: [ 3.99995648 15.99965183]  f(x): 1.8940857459686715e-09  grad at x: [-2.66847392e-06 -1.05466734e-05]  gradient norm: 1.0879019816145768e-05\n",
            "iter: 932786  x: [ 3.99995648 15.99965184]  f(x): 1.8940271360351145e-09  grad at x: [ 8.37428732e-05 -2.13475578e-05]  gradient norm: 8.642098725424426e-05\n",
            "iter: 932787  x: [ 3.99995648 15.99965184]  f(x): 1.893970142928946e-09  grad at x: [-2.66913546e-06 -1.05462586e-05]  gradient norm: 1.0878780047902453e-05\n",
            "iter: 932788  x: [ 3.99995648 15.99965185]  f(x): 1.893911598315808e-09  grad at x: [ 8.37878764e-05 -2.13528510e-05]  gradient norm: 8.646590357743872e-05\n",
            "iter: 932789  x: [ 3.99995648 15.99965185]  f(x): 1.8938545469356555e-09  grad at x: [-2.66982619e-06 -1.05458403e-05]  gradient norm: 1.0878543966629905e-05\n",
            "iter: 932790  x: [ 3.99995648 15.99965186]  f(x): 1.89379607009357e-09  grad at x: [ 8.38347422e-05 -2.13583771e-05]  gradient norm: 8.651268273954945e-05\n",
            "iter: 932791  x: [ 3.99995648 15.99965186]  f(x): 1.8937389580060266e-09  grad at x: [-2.67050244e-06 -1.05454237e-05]  gradient norm: 1.0878306150790554e-05\n",
            "iter: 932792  x: [ 3.99995649 15.99965187]  f(x): 1.893680547757237e-09  grad at x: [ 8.38806766e-05 -2.13637868e-05]  gradient norm: 8.655853101026394e-05\n",
            "iter: 932793  x: [ 3.99995648 15.99965187]  f(x): 1.893623376121003e-09  grad at x: [-2.67117877e-06 -1.05450072e-05]  gradient norm: 1.0878068407808135e-05\n",
            "iter: 932794  x: [ 3.99995649 15.99965188]  f(x): 1.893565032497216e-09  grad at x: [ 8.39266109e-05 -2.13691965e-05]  gradient norm: 8.660437962923428e-05\n",
            "iter: 932795  x: [ 3.99995649 15.99965188]  f(x): 1.893507801298994e-09  grad at x: [-2.67184064e-06 -1.05445924e-05]  gradient norm: 1.0877828926461139e-05\n",
            "iter: 932796  x: [ 3.99995649 15.99965189]  f(x): 1.893449523157136e-09  grad at x: [ 8.39716429e-05 -2.13744934e-05]  gradient norm: 8.664932642604652e-05\n",
            "iter: 932797  x: [ 3.99995649 15.99965189]  f(x): 1.8933922335221305e-09  grad at x: [-2.67253168e-06 -1.05441741e-05]  gradient norm: 1.0877593139839522e-05\n",
            "iter: 932798  x: [ 3.99995649 15.9996519 ]  f(x): 1.8933340232807805e-09  grad at x: [ 8.40185083e-05 -2.13800195e-05]  gradient norm: 8.669610702337176e-05\n",
            "iter: 932799  x: [ 3.99995649 15.9996519 ]  f(x): 1.8932766727889058e-09  grad at x: [-2.67322281e-06 -1.05437557e-05]  gradient norm: 1.0877357428182716e-05\n",
            "iter: 932800  x: [ 3.99995649 15.99965191]  f(x): 1.8932185305564097e-09  grad at x: [ 8.40654174e-05 -2.13855510e-05]  gradient norm: 8.674293163875473e-05\n",
            "iter: 932801  x: [ 3.99995649 15.99965191]  f(x): 1.893161119137642e-09  grad at x: [-2.67391403e-06 -1.05433373e-05]  gradient norm: 1.0877121791292833e-05\n",
            "iter: 932802  x: [ 3.99995649 15.99965192]  f(x): 1.8931030448710858e-09  grad at x: [ 8.41122972e-05 -2.13910789e-05]  gradient norm: 8.678972751776451e-05\n",
            "iter: 932803  x: [ 3.99995649 15.99965192]  f(x): 1.893045572529371e-09  grad at x: [-2.67460532e-06 -1.05429190e-05]  gradient norm: 1.0876886229408543e-05\n",
            "iter: 932804  x: [ 3.99995649 15.99965193]  f(x): 1.8929875662998084e-09  grad at x: [ 8.41591916e-05 -2.13966086e-05]  gradient norm: 8.68365383115294e-05\n",
            "iter: 932805  x: [ 3.99995649 15.99965193]  f(x): 1.892930032982497e-09  grad at x: [-2.67528214e-06 -1.05425024e-05]  gradient norm: 1.0876648926158054e-05\n",
            "iter: 932806  x: [ 3.9999565  15.99965194]  f(x): 1.8928720936450006e-09  grad at x: [ 8.42051836e-05 -2.14020256e-05]  gradient norm: 8.688244725470441e-05\n",
            "iter: 932807  x: [ 3.99995649 15.99965194]  f(x): 1.8928145004779693e-09  grad at x: [-2.67595904e-06 -1.05420859e-05]  gradient norm: 1.0876411695467574e-05\n",
            "iter: 932808  x: [ 3.9999565  15.99965195]  f(x): 1.892756628026912e-09  grad at x: [ 8.42511464e-05 -2.14074389e-05]  gradient norm: 8.692832744065415e-05\n",
            "iter: 932809  x: [ 3.9999565  15.99965196]  f(x): 1.892698975015467e-09  grad at x: [-2.67663602e-06 -1.05416693e-05]  gradient norm: 1.0876174537793939e-05\n",
            "iter: 932810  x: [ 3.9999565  15.99965197]  f(x): 1.892641169520031e-09  grad at x: [ 8.42971383e-05 -2.14128559e-05]  gradient norm: 8.697423707526979e-05\n",
            "iter: 932811  x: [ 3.9999565  15.99965197]  f(x): 1.892583456614581e-09  grad at x: [-2.67732764e-06 -1.05412510e-05]  gradient norm: 1.0875939272157524e-05\n",
            "iter: 932812  x: [ 3.9999565  15.99965197]  f(x): 1.8925401438607174e-09  grad at x: [ 4.08333669e-05 -1.59798201e-05]  gradient norm: 4.38488141083366e-05\n",
            "iter: 932813  x: [ 3.9999565  15.99965197]  f(x): 1.8925248015856795e-09  grad at x: [-1.99781820e-06 -1.06260195e-05]  gradient norm: 1.0812195338832399e-05\n",
            "iter: 932814  x: [ 3.99995651 15.99965201]  f(x): 1.892292352566051e-09  grad at x: [ 1.6941921e-04 -3.2051430e-05]  gradient norm: 0.00017242436890051963\n",
            "iter: 932815  x: [ 3.9999565  15.99965201]  f(x): 1.8921228961333843e-09  grad at x: [ 8.27056592e-05 -2.12124414e-05]  gradient norm: 8.538263134156815e-05\n",
            "iter: 932816  x: [ 3.9999565  15.99965201]  f(x): 1.892067243694246e-09  grad at x: [-2.65224723e-06 -1.05429026e-05]  gradient norm: 1.087139414318293e-05\n",
            "iter: 932817  x: [ 3.99995651 15.99965202]  f(x): 1.8920074739607344e-09  grad at x: [ 8.27507484e-05 -2.12177456e-05]  gradient norm: 8.542762483236182e-05\n",
            "iter: 932818  x: [ 3.9999565  15.99965202]  f(x): 1.891951763849699e-09  grad at x: [-2.65291018e-06 -1.05424879e-05]  gradient norm: 1.0871153708874479e-05\n",
            "iter: 932819  x: [ 3.99995651 15.99965203]  f(x): 1.891892058858558e-09  grad at x: [ 8.27958375e-05 -2.12230498e-05]  gradient norm: 8.5472618675727e-05\n",
            "iter: 932820  x: [ 3.99995651 15.99965203]  f(x): 1.8918362910447673e-09  grad at x: [-2.65357322e-06 -1.05420731e-05]  gradient norm: 1.0870913345229308e-05\n",
            "iter: 932821  x: [ 3.99995651 15.99965204]  f(x): 1.891776650826534e-09  grad at x: [ 8.28409265e-05 -2.12283539e-05]  gradient norm: 8.551761286926005e-05\n",
            "iter: 932822  x: [ 3.99995651 15.99965205]  f(x): 1.891720825299034e-09  grad at x: [-2.65425089e-06 -1.05416566e-05]  gradient norm: 1.0870674841624413e-05\n",
            "iter: 932823  x: [ 3.99995651 15.99965206]  f(x): 1.8916612510808823e-09  grad at x: [ 8.28869467e-05 -2.12337745e-05]  gradient norm: 8.55635385084927e-05\n",
            "iter: 932824  x: [ 3.99995651 15.99965206]  f(x): 1.8916053665922724e-09  grad at x: [-2.65492864e-06 -1.05412400e-05]  gradient norm: 1.0870436410517913e-05\n",
            "iter: 932825  x: [ 3.99995651 15.99965207]  f(x): 1.891545858442861e-09  grad at x: [ 8.29329960e-05 -2.12391988e-05]  gradient norm: 8.560949361163047e-05\n",
            "iter: 932826  x: [ 3.99995651 15.99965207]  f(x): 1.891489914942884e-09  grad at x: [-2.65559192e-06 -1.05408253e-05]  gradient norm: 1.0870196261190236e-05\n",
            "iter: 932827  x: [ 3.99995651 15.99965208]  f(x): 1.891430471659286e-09  grad at x: [ 8.29780848e-05 -2.12445029e-05]  gradient norm: 8.565448887026452e-05\n",
            "iter: 932828  x: [ 3.99995651 15.99965208]  f(x): 1.8913744703318224e-09  grad at x: [-2.65625528e-06 -1.05404106e-05]  gradient norm: 1.0869956182604158e-05\n",
            "iter: 932829  x: [ 3.99995651 15.99965209]  f(x): 1.8913150919814432e-09  grad at x: [ 8.30232026e-05 -2.12498107e-05]  gradient norm: 8.569951357505182e-05\n",
            "iter: 932830  x: [ 3.99995651 15.99965209]  f(x): 1.8912590327786676e-09  grad at x: [-2.65693327e-06 -1.05399940e-05]  gradient norm: 1.08697179681637e-05\n",
            "iter: 932831  x: [ 3.99995651 15.9996521 ]  f(x): 1.891199720591308e-09  grad at x: [ 8.30692517e-05 -2.12552350e-05]  gradient norm: 8.57454697587541e-05\n",
            "iter: 932832  x: [ 3.99995651 15.9996521 ]  f(x): 1.8911436022631943e-09  grad at x: [-2.65761135e-06 -1.05395775e-05]  gradient norm: 1.0869479826518025e-05\n",
            "iter: 932833  x: [ 3.99995652 15.99965211]  f(x): 1.8910843562707237e-09  grad at x: [ 8.31153006e-05 -2.12606592e-05]  gradient norm: 8.579142630411792e-05\n",
            "iter: 932834  x: [ 3.99995651 15.99965211]  f(x): 1.8910281787850814e-09  grad at x: [-2.65828950e-06 -1.05391609e-05]  gradient norm: 1.086924175746982e-05\n",
            "iter: 932835  x: [ 3.99995652 15.99965212]  f(x): 1.8909689990193685e-09  grad at x: [ 8.31613495e-05 -2.12660834e-05]  gradient norm: 8.583738321386999e-05\n",
            "iter: 932836  x: [ 3.99995652 15.99965212]  f(x): 1.8909127623627268e-09  grad at x: [-2.65895319e-06 -1.05387462e-05]  gradient norm: 1.086900196525514e-05\n",
            "iter: 932837  x: [ 3.99995652 15.99965213]  f(x): 1.8908536476914045e-09  grad at x: [ 8.32064961e-05 -2.12713949e-05]  gradient norm: 8.588243843004521e-05\n",
            "iter: 932838  x: [ 3.99995652 15.99965213]  f(x): 1.8907973529770872e-09  grad at x: [-2.65961695e-06 -1.05383315e-05]  gradient norm: 1.0868762243880041e-05\n",
            "iter: 932839  x: [ 3.99995652 15.99965214]  f(x): 1.8907383034307708e-09  grad at x: [ 8.32516426e-05 -2.12767063e-05]  gradient norm: 8.592749399299194e-05\n",
            "iter: 932840  x: [ 3.99995652 15.99965214]  f(x): 1.890681950629022e-09  grad at x: [-2.66030990e-06 -1.05379131e-05]  gradient norm: 1.0868526190028576e-05\n",
            "iter: 932841  x: [ 3.99995652 15.99965215]  f(x): 1.890622968606285e-09  grad at x: [ 8.32986226e-05 -2.12822470e-05]  gradient norm: 8.597438314389496e-05\n",
            "iter: 932842  x: [ 3.99995652 15.99965215]  f(x): 1.8905665553357473e-09  grad at x: [-2.66098838e-06 -1.05374966e-05]  gradient norm: 1.086828841163802e-05\n",
            "iter: 932843  x: [ 3.99995652 15.99965216]  f(x): 1.8905076397036416e-09  grad at x: [ 8.33447002e-05 -2.12876748e-05]  gradient norm: 8.602037059160868e-05\n",
            "iter: 932844  x: [ 3.99995652 15.99965216]  f(x): 1.890451167078221e-09  grad at x: [-2.66166694e-06 -1.05370800e-05]  gradient norm: 1.0868050706379127e-05\n",
            "iter: 932845  x: [ 3.99995652 15.99965217]  f(x): 1.89039231790569e-09  grad at x: [ 8.33908069e-05 -2.12931063e-05]  gradient norm: 8.606638749981134e-05\n",
            "iter: 932846  x: [ 3.99995652 15.99965217]  f(x): 1.890335785874839e-09  grad at x: [-2.66233103e-06 -1.05366653e-05]  gradient norm: 1.086781127276818e-05\n",
            "iter: 932847  x: [ 3.99995653 15.99965218]  f(x): 1.890277001952333e-09  grad at x: [ 8.34359531e-05 -2.12984178e-05]  gradient norm: 8.611144447088344e-05\n",
            "iter: 932848  x: [ 3.99995652 15.99965218]  f(x): 1.890220411707743e-09  grad at x: [-2.66302430e-06 -1.05362469e-05]  gradient norm: 1.0867575514901458e-05\n",
            "iter: 932849  x: [ 3.99995653 15.99965219]  f(x): 1.89016169547606e-09  grad at x: [ 8.34829619e-05 -2.13039621e-05]  gradient norm: 8.61583641946373e-05\n",
            "iter: 932850  x: [ 3.99995653 15.99965219]  f(x): 1.8901050445754296e-09  grad at x: [-2.66371766e-06 -1.05358286e-05]  gradient norm: 1.0867339831846663e-05\n",
            "iter: 932851  x: [ 3.99995653 15.9996522 ]  f(x): 1.890046396104896e-09  grad at x: [ 8.35299997e-05 -2.13095100e-05]  gradient norm: 8.620531339616257e-05\n",
            "iter: 932852  x: [ 3.99995653 15.9996522 ]  f(x): 1.889989684496292e-09  grad at x: [-2.66439654e-06 -1.05354120e-05]  gradient norm: 1.0867102419680092e-05\n",
            "iter: 932853  x: [ 3.99995653 15.99965221]  f(x): 1.8899311026137438e-09  grad at x: [ 8.35761060e-05 -2.13149415e-05]  gradient norm: 8.625133174755259e-05\n",
            "iter: 932854  x: [ 3.99995653 15.99965222]  f(x): 1.8898743314512924e-09  grad at x: [-2.66507551e-06 -1.05349955e-05]  gradient norm: 1.0866865080527685e-05\n",
            "iter: 932855  x: [ 3.99995653 15.99965223]  f(x): 1.8898158161886793e-09  grad at x: [ 8.36222123e-05 -2.13203730e-05]  gradient norm: 8.629735045730053e-05\n",
            "iter: 932856  x: [ 3.99995653 15.99965223]  f(x): 1.8897589854401087e-09  grad at x: [-2.66575455e-06 -1.05345789e-05]  gradient norm: 1.0866627814191488e-05\n",
            "iter: 932857  x: [ 3.99995653 15.99965224]  f(x): 1.88970053682938e-09  grad at x: [ 8.36683185e-05 -2.13258045e-05]  gradient norm: 8.634336952470536e-05\n",
            "iter: 932858  x: [ 3.99995653 15.99965224]  f(x): 1.889643646482316e-09  grad at x: [-2.66644823e-06 -1.05341605e-05]  gradient norm: 1.086639242877994e-05\n",
            "iter: 932859  x: [ 3.99995653 15.99965225]  f(x): 1.889585265800995e-09  grad at x: [ 8.37153851e-05 -2.13313560e-05]  gradient norm: 8.639034929588642e-05\n",
            "iter: 932860  x: [ 3.99995653 15.99965225]  f(x): 1.889528314557695e-09  grad at x: [-2.66714199e-06 -1.05337422e-05]  gradient norm: 1.0866157118499505e-05\n",
            "iter: 932861  x: [ 3.99995653 15.99965226]  f(x): 1.889470001801896e-09  grad at x: [ 8.37624225e-05 -2.13369040e-05]  gradient norm: 8.643730033766476e-05\n",
            "iter: 932862  x: [ 3.99995653 15.99965226]  f(x): 1.8894129896659248e-09  grad at x: [-2.66783583e-06 -1.05333238e-05]  gradient norm: 1.0865921883152476e-05\n",
            "iter: 932863  x: [ 3.99995654 15.99965227]  f(x): 1.8893547449061384e-09  grad at x: [ 8.38094889e-05 -2.13424555e-05]  gradient norm: 8.648428085491214e-05\n",
            "iter: 932864  x: [ 3.99995653 15.99965227]  f(x): 1.8892976718441035e-09  grad at x: [-2.66850065e-06 -1.05329091e-05]  gradient norm: 1.0865683102114706e-05\n",
            "iter: 932865  x: [ 3.99995654 15.99965228]  f(x): 1.889239492654928e-09  grad at x: [ 8.38546780e-05 -2.13477724e-05]  gradient norm: 8.652938464422685e-05\n",
            "iter: 932866  x: [ 3.99995654 15.99965228]  f(x): 1.8891823610357766e-09  grad at x: [-2.66918010e-06 -1.05324925e-05]  gradient norm: 1.0865446203722635e-05\n",
            "iter: 932867  x: [ 3.99995654 15.99965229]  f(x): 1.889124248696848e-09  grad at x: [ 8.39008129e-05 -2.13532076e-05]  gradient norm: 8.65754346034312e-05\n",
            "iter: 932868  x: [ 3.99995654 15.99965229]  f(x): 1.889067057259334e-09  grad at x: [-2.66985964e-06 -1.05320760e-05]  gradient norm: 1.0865209378484713e-05\n",
            "iter: 932869  x: [ 3.99995654 15.9996523 ]  f(x): 1.8890090118026414e-09  grad at x: [ 8.39469477e-05 -2.13586427e-05]  gradient norm: 8.662148491488286e-05\n",
            "iter: 932870  x: [ 3.99995654 15.9996523 ]  f(x): 1.8889517605331615e-09  grad at x: [-2.67052470e-06 -1.05316612e-05]  gradient norm: 1.0864970812851842e-05\n",
            "iter: 932871  x: [ 3.99995654 15.99965231]  f(x): 1.888893780815654e-09  grad at x: [ 8.39921802e-05 -2.13639651e-05]  gradient norm: 8.666663338477674e-05\n",
            "iter: 932872  x: [ 3.99995654 15.99965231]  f(x): 1.8888364708382285e-09  grad at x: [-2.67118984e-06 -1.05312465e-05]  gradient norm: 1.0864732318393294e-05\n",
            "iter: 932873  x: [ 3.99995654 15.99965232]  f(x): 1.8887785568906384e-09  grad at x: [ 8.40374127e-05 -2.13692874e-05]  gradient norm: 8.671178219148173e-05\n",
            "iter: 932874  x: [ 3.99995654 15.99965232]  f(x): 1.888721188175399e-09  grad at x: [-2.67188417e-06 -1.05308281e-05]  gradient norm: 1.0864497526286916e-05\n",
            "iter: 932875  x: [ 3.99995654 15.99965233]  f(x): 1.88866334241838e-09  grad at x: [ 8.40844786e-05 -2.13748390e-05]  gradient norm: 8.675876485496594e-05\n",
            "iter: 932876  x: [ 3.99995654 15.99965233]  f(x): 1.888605912561872e-09  grad at x: [-2.67256402e-06 -1.05304116e-05]  gradient norm: 1.0864260993063683e-05\n",
            "iter: 932877  x: [ 3.99995655 15.99965234]  f(x): 1.8885481338517907e-09  grad at x: [ 8.41306422e-05 -2.13802778e-05]  gradient norm: 8.680484566925803e-05\n",
            "iter: 932878  x: [ 3.99995654 15.99965234]  f(x): 1.888490643978619e-09  grad at x: [-2.67324396e-06 -1.05299951e-05]  gradient norm: 1.0864024533094341e-05\n",
            "iter: 932879  x: [ 3.99995655 15.99965235]  f(x): 1.8884329324228764e-09  grad at x: [ 8.41768494e-05 -2.13857220e-05]  gradient norm: 8.685097048816624e-05\n",
            "iter: 932880  x: [ 3.99995655 15.99965235]  f(x): 1.8883753824265047e-09  grad at x: [-2.67395308e-06 -1.05295749e-05]  gradient norm: 1.0863791783755322e-05\n",
            "iter: 932881  x: [ 3.99995655 15.99965236]  f(x): 1.8883177404130363e-09  grad at x: [ 8.42248755e-05 -2.13913936e-05]  gradient norm: 8.689891467761369e-05\n",
            "iter: 932882  x: [ 3.99995655 15.99965236]  f(x): 1.8882745309081954e-09  grad at x: [ 4.07751284e-05 -1.59602769e-05]  gradient norm: 4.378745865962495e-05\n",
            "iter: 932883  x: [ 3.99995655 15.99965236]  f(x): 1.8882592310341647e-09  grad at x: [-1.99538910e-06 -1.06140596e-05]  gradient norm: 1.0799992586384409e-05\n",
            "iter: 932884  x: [ 3.99995655 15.99965241]  f(x): 1.888027187066912e-09  grad at x: [ 1.69182494e-04 -3.20095787e-05]  gradient norm: 0.00017218399821596812\n",
            "iter: 932885  x: [ 3.99995655 15.99965241]  f(x): 1.887858202676685e-09  grad at x: [ 8.25899283e-05 -2.11857132e-05]  gradient norm: 8.526388856511495e-05\n",
            "iter: 932886  x: [ 3.99995655 15.99965241]  f(x): 1.887802704441505e-09  grad at x: [-2.64889866e-06 -1.05310592e-05]  gradient norm: 1.0859091635374805e-05\n",
            "iter: 932887  x: [ 3.99995655 15.99965242]  f(x): 1.887743040091897e-09  grad at x: [ 8.26345488e-05 -2.11909592e-05]  gradient norm: 8.530841341992413e-05\n",
            "iter: 932888  x: [ 3.99995655 15.99965242]  f(x): 1.887687484874926e-09  grad at x: [-2.64955005e-06 -1.05306463e-05]  gradient norm: 1.0858850120242544e-05\n",
            "iter: 932889  x: [ 3.99995656 15.99965243]  f(x): 1.8876278842355106e-09  grad at x: [ 8.26788927e-05 -2.11961706e-05]  gradient norm: 8.535266220490306e-05\n",
            "iter: 932890  x: [ 3.99995655 15.99965243]  f(x): 1.8875722723372326e-09  grad at x: [-2.65023064e-06 -1.05302297e-05]  gradient norm: 1.085861224974951e-05\n",
            "iter: 932891  x: [ 3.99995656 15.99965244]  f(x): 1.8875127378252297e-09  grad at x: [ 8.27251138e-05 -2.12016166e-05]  gradient norm: 8.539878804438155e-05\n",
            "iter: 932892  x: [ 3.99995656 15.99965244]  f(x): 1.887457066845632e-09  grad at x: [-2.65089675e-06 -1.05298150e-05]  gradient norm: 1.0858372663738905e-05\n",
            "iter: 932893  x: [ 3.99995656 15.99965245]  f(x): 1.887397597298178e-09  grad at x: [ 8.27704035e-05 -2.12069463e-05]  gradient norm: 8.5443983164173e-05\n",
            "iter: 932894  x: [ 3.99995656 15.99965245]  f(x): 1.8873418683997997e-09  grad at x: [-2.65154839e-06 -1.05294021e-05]  gradient norm: 1.0858131359225474e-05\n",
            "iter: 932895  x: [ 3.99995656 15.99965246]  f(x): 1.887282462614423e-09  grad at x: [ 8.28147472e-05 -2.12121577e-05]  gradient norm: 8.548823298840566e-05\n",
            "iter: 932896  x: [ 3.99995656 15.99965246]  f(x): 1.887226676962007e-09  grad at x: [-2.65221466e-06 -1.05289873e-05]  gradient norm: 1.0857891914543066e-05\n",
            "iter: 932897  x: [ 3.99995656 15.99965247]  f(x): 1.8871673362021524e-09  grad at x: [ 8.28600367e-05 -2.12174873e-05]  gradient norm: 8.553342880533953e-05\n",
            "iter: 932898  x: [ 3.99995656 15.99965247]  f(x): 1.8871114925506353e-09  grad at x: [-2.65288101e-06 -1.05285726e-05]  gradient norm: 1.0857652541054946e-05\n",
            "iter: 932899  x: [ 3.99995656 15.99965248]  f(x): 1.887052216847117e-09  grad at x: [ 8.29053261e-05 -2.12228169e-05]  gradient norm: 8.557862497581219e-05\n",
            "iter: 932900  x: [ 3.99995656 15.99965248]  f(x): 1.886996315165365e-09  grad at x: [-2.65354745e-06 -1.05281579e-05]  gradient norm: 1.0857413238780701e-05\n",
            "iter: 932901  x: [ 3.99995656 15.99965249]  f(x): 1.886937104585833e-09  grad at x: [ 8.29506445e-05 -2.12281502e-05]  gradient norm: 8.562385059627557e-05\n",
            "iter: 932902  x: [ 3.99995656 15.99965249]  f(x): 1.8868811448245745e-09  grad at x: [-2.65419941e-06 -1.05277450e-05]  gradient norm: 1.0857172214310071e-05\n",
            "iter: 932903  x: [ 3.99995656 15.9996525 ]  f(x): 1.88682199816486e-09  grad at x: [ 8.29950025e-05 -2.12333634e-05]  gradient norm: 8.56681163363819e-05\n",
            "iter: 932904  x: [ 3.99995656 15.9996525 ]  f(x): 1.886765981510418e-09  grad at x: [-2.65488056e-06 -1.05273284e-05]  gradient norm: 1.0856934848169402e-05\n",
            "iter: 932905  x: [ 3.99995657 15.99965251]  f(x): 1.8867069012722652e-09  grad at x: [ 8.30412666e-05 -2.12388150e-05]  gradient norm: 8.571428834059246e-05\n",
            "iter: 932906  x: [ 3.99995657 15.99965251]  f(x): 1.886650825240097e-09  grad at x: [-2.65554723e-06 -1.05269137e-05]  gradient norm: 1.0856695759871658e-05\n",
            "iter: 932907  x: [ 3.99995657 15.99965252]  f(x): 1.8865918101807388e-09  grad at x: [ 8.30865703e-05 -2.12441464e-05]  gradient norm: 8.575950046453757e-05\n",
            "iter: 932908  x: [ 3.99995657 15.99965252]  f(x): 1.8865356759758897e-09  grad at x: [-2.65622854e-06 -1.05264971e-05]  gradient norm: 1.085645853954058e-05\n",
            "iter: 932909  x: [ 3.99995657 15.99965253]  f(x): 1.886476727364013e-09  grad at x: [ 8.31328198e-05 -2.12495961e-05]  gradient norm: 8.580565864705456e-05\n",
            "iter: 932910  x: [ 3.99995657 15.99965253]  f(x): 1.886420533736175e-09  grad at x: [-2.65690994e-06 -1.05260806e-05]  gradient norm: 1.0856221392546754e-05\n",
            "iter: 932911  x: [ 3.99995657 15.99965254]  f(x): 1.8863616516408714e-09  grad at x: [ 8.31790983e-05 -2.12550494e-05]  gradient norm: 8.585184629476516e-05\n",
            "iter: 932912  x: [ 3.99995657 15.99965254]  f(x): 1.886305398539329e-09  grad at x: [-2.65757686e-06 -1.05256659e-05]  gradient norm: 1.0855982520190986e-05\n",
            "iter: 932913  x: [ 3.99995657 15.99965255]  f(x): 1.8862465817544106e-09  grad at x: [ 8.32244162e-05 -2.12603827e-05]  gradient norm: 8.589707403082906e-05\n",
            "iter: 932914  x: [ 3.99995657 15.99965255]  f(x): 1.886190270366331e-09  grad at x: [-2.65824386e-06 -1.05252511e-05]  gradient norm: 1.0855743719186686e-05\n",
            "iter: 932915  x: [ 3.99995657 15.99965256]  f(x): 1.88613151895963e-09  grad at x: [ 8.32697632e-05 -2.12657196e-05]  gradient norm: 8.594233121443644e-05\n",
            "iter: 932916  x: [ 3.99995657 15.99965256]  f(x): 1.8860751492168596e-09  grad at x: [-2.65891094e-06 -1.05248364e-05]  gradient norm: 1.085550498955346e-05\n",
            "iter: 932917  x: [ 3.99995657 15.99965258]  f(x): 1.886016463257053e-09  grad at x: [ 8.33151247e-05 -2.12710584e-05]  gradient norm: 8.598760329607239e-05\n",
            "iter: 932918  x: [ 3.99995657 15.99965258]  f(x): 1.8859600351104698e-09  grad at x: [-2.65959265e-06 -1.05244198e-05]  gradient norm: 1.0855268133257648e-05\n",
            "iter: 932919  x: [ 3.99995658 15.99965259]  f(x): 1.8859014157562284e-09  grad at x: [ 8.33613883e-05 -2.12765099e-05]  gradient norm: 8.603377782536229e-05\n",
            "iter: 932920  x: [ 3.99995657 15.99965259]  f(x): 1.885844928007088e-09  grad at x: [-2.66025990e-06 -1.05240051e-05]  gradient norm: 1.0855029547429043e-05\n",
            "iter: 932921  x: [ 3.99995658 15.9996526 ]  f(x): 1.885786374124383e-09  grad at x: [ 8.34067350e-05 -2.12818468e-05]  gradient norm: 8.607903605871286e-05\n",
            "iter: 932922  x: [ 3.99995658 15.9996526 ]  f(x): 1.8857298279274503e-09  grad at x: [-2.66095632e-06 -1.05235868e-05]  gradient norm: 1.0854794640779617e-05\n",
            "iter: 932923  x: [ 3.99995658 15.99965261]  f(x): 1.88567134199355e-09  grad at x: [ 8.34539735e-05 -2.12874202e-05]  gradient norm: 8.612618617363689e-05\n",
            "iter: 932924  x: [ 3.99995658 15.99965261]  f(x): 1.8856147348700546e-09  grad at x: [-2.66165283e-06 -1.05231684e-05]  gradient norm: 1.08545598094557e-05\n",
            "iter: 932925  x: [ 3.99995658 15.99965262]  f(x): 1.8855563168814373e-09  grad at x: [ 8.35011827e-05 -2.12929899e-05]  gradient norm: 8.617330756632084e-05\n",
            "iter: 932926  x: [ 3.99995658 15.99965262]  f(x): 1.8854996488719643e-09  grad at x: [-2.66232032e-06 -1.05227537e-05]  gradient norm: 1.0854321442210023e-05\n",
            "iter: 932927  x: [ 3.99995658 15.99965263]  f(x): 1.8854412964494195e-09  grad at x: [ 8.35465438e-05 -2.12983286e-05]  gradient norm: 8.62185814167041e-05\n",
            "iter: 932928  x: [ 3.99995658 15.99965263]  f(x): 1.8853845698755973e-09  grad at x: [-2.66297334e-06 -1.05223407e-05]  gradient norm: 1.0854081339627426e-05\n",
            "iter: 932929  x: [ 3.99995658 15.99965264]  f(x): 1.885326281919101e-09  grad at x: [ 8.35910025e-05 -2.13035546e-05]  gradient norm: 8.626295346982238e-05\n",
            "iter: 932930  x: [ 3.99995658 15.99965264]  f(x): 1.8852694979016883e-09  grad at x: [-2.66365554e-06 -1.05219242e-05]  gradient norm: 1.0853844922207041e-05\n",
            "iter: 932931  x: [ 3.99995658 15.99965265]  f(x): 1.8852112768175846e-09  grad at x: [ 8.36373093e-05 -2.13090116e-05]  gradient norm: 8.630917380208365e-05\n",
            "iter: 932932  x: [ 3.99995658 15.99965265]  f(x): 1.8851544329487346e-09  grad at x: [-2.66433782e-06 -1.05215076e-05]  gradient norm: 1.0853608578125685e-05\n",
            "iter: 932933  x: [ 3.99995658 15.99965266]  f(x): 1.8850962788064193e-09  grad at x: [ 8.36836451e-05 -2.13144722e-05]  gradient norm: 8.63554235939427e-05\n",
            "iter: 932934  x: [ 3.99995658 15.99965266]  f(x): 1.8850393750164155e-09  grad at x: [-2.66502018e-06 -1.05210911e-05]  gradient norm: 1.0853372307839403e-05\n",
            "iter: 932935  x: [ 3.99995659 15.99965267]  f(x): 1.8849812878109778e-09  grad at x: [ 8.37299517e-05 -2.13199291e-05]  gradient norm: 8.640164464404853e-05\n",
            "iter: 932936  x: [ 3.99995658 15.99965267]  f(x): 1.884924324123098e-09  grad at x: [-2.66568807e-06 -1.05206764e-05]  gradient norm: 1.0853134300247246e-05\n",
            "iter: 932937  x: [ 3.99995659 15.99965268]  f(x): 1.8848663026768524e-09  grad at x: [ 8.37753415e-05 -2.13252715e-05]  gradient norm: 8.644694932616495e-05\n",
            "iter: 932938  x: [ 3.99995659 15.99965268]  f(x): 1.8848092802310823e-09  grad at x: [-2.66637059e-06 -1.05202598e-05]  gradient norm: 1.0852898176150968e-05\n",
            "iter: 932939  x: [ 3.99995659 15.99965269]  f(x): 1.8847513258606477e-09  grad at x: [ 8.38216916e-05 -2.13307339e-05]  gradient norm: 8.64932147360038e-05\n",
            "iter: 932940  x: [ 3.99995659 15.99965269]  f(x): 1.884694243358737e-09  grad at x: [-2.66705320e-06 -1.05198433e-05]  gradient norm: 1.0852662125691813e-05\n",
            "iter: 932941  x: [ 3.99995659 15.9996527 ]  f(x): 1.884636356058505e-09  grad at x: [ 8.38680271e-05 -2.13361945e-05]  gradient norm: 8.653946595092744e-05\n",
            "iter: 932942  x: [ 3.99995659 15.9996527 ]  f(x): 1.8845792135057413e-09  grad at x: [-2.66773588e-06 -1.05194267e-05]  gradient norm: 1.0852426148889838e-05\n",
            "iter: 932943  x: [ 3.99995659 15.99965271]  f(x): 1.884521393307985e-09  grad at x: [ 8.39143625e-05 -2.13416552e-05]  gradient norm: 8.65857175228696e-05\n",
            "iter: 932944  x: [ 3.99995659 15.99965271]  f(x): 1.8844641907103287e-09  grad at x: [-2.66841865e-06 -1.05190102e-05]  gradient norm: 1.0852190245983491e-05\n",
            "iter: 932945  x: [ 3.99995659 15.99965272]  f(x): 1.8844064376466848e-09  grad at x: [ 8.39607124e-05 -2.13471176e-05]  gradient norm: 8.663198400256131e-05\n",
            "iter: 932946  x: [ 3.99995659 15.99965272]  f(x): 1.8843491749137513e-09  grad at x: [-2.66908694e-06 -1.05185954e-05]  gradient norm: 1.0851952600549364e-05\n",
            "iter: 932947  x: [ 3.99995659 15.99965273]  f(x): 1.884291487804622e-09  grad at x: [ 8.40061163e-05 -2.13524618e-05]  gradient norm: 8.667730496615472e-05\n",
            "iter: 932948  x: [ 3.99995659 15.99965273]  f(x): 1.8842341661355573e-09  grad at x: [-2.66975532e-06 -1.05181807e-05]  gradient norm: 1.0851715026801978e-05\n",
            "iter: 932949  x: [ 3.9999566  15.99965274]  f(x): 1.8841765450871793e-09  grad at x: [ 8.40515638e-05 -2.13578114e-05]  gradient norm: 8.672266992514193e-05\n",
            "iter: 932950  x: [ 3.99995659 15.99965275]  f(x): 1.884119164376612e-09  grad at x: [-2.67045288e-06 -1.05177623e-05]  gradient norm: 1.0851481161035048e-05\n",
            "iter: 932951  x: [ 3.9999566  15.99965276]  f(x): 1.884061611809689e-09  grad at x: [ 8.40988593e-05 -2.13633921e-05]  gradient norm: 8.676988333570811e-05\n",
            "iter: 932952  x: [ 3.9999566  15.99965276]  f(x): 1.884004169654091e-09  grad at x: [-2.67113597e-06 -1.05173458e-05]  gradient norm: 1.0851245552013291e-05\n",
            "iter: 932953  x: [ 3.9999566  15.99965276]  f(x): 1.883961050881757e-09  grad at x: [ 4.07370364e-05 -1.59431002e-05]  gradient norm: 4.37457264052164e-05\n",
            "iter: 932954  x: [ 3.9999566  15.99965276]  f(x): 1.8839457805086455e-09  grad at x: [-1.99323032e-06 -1.06019143e-05]  gradient norm: 1.0787657436398653e-05\n",
            "iter: 932955  x: [ 3.9999566 15.9996528]  f(x): 1.8837143485108582e-09  grad at x: [ 1.69020654e-04 -3.19769351e-05]  gradient norm: 0.00017201891115208287\n",
            "iter: 932956  x: [ 3.9999566 15.9996528]  f(x): 1.8835456880713504e-09  grad at x: [ 8.25110350e-05 -2.11634379e-05]  gradient norm: 8.518193465731324e-05\n",
            "iter: 932957  x: [ 3.9999566 15.9996528]  f(x): 1.883490296778696e-09  grad at x: [-2.64615525e-06 -1.05189883e-05]  gradient norm: 1.0846716251496053e-05\n",
            "iter: 932958  x: [ 3.9999566  15.99965281]  f(x): 1.8834307919962023e-09  grad at x: [ 8.25582864e-05 -2.11690131e-05]  gradient norm: 8.522908989748192e-05\n",
            "iter: 932959  x: [ 3.9999566  15.99965281]  f(x): 1.883375340442829e-09  grad at x: [-2.64680968e-06 -1.05185754e-05]  gradient norm: 1.0846475495291184e-05\n",
            "iter: 932960  x: [ 3.99995661 15.99965282]  f(x): 1.8833158994837417e-09  grad at x: [ 8.26028019e-05 -2.11742463e-05]  gradient norm: 8.527351048817973e-05\n",
            "iter: 932961  x: [ 3.9999566  15.99965282]  f(x): 1.8832603911039406e-09  grad at x: [-2.64747874e-06 -1.05181607e-05]  gradient norm: 1.0846236596702427e-05\n",
            "iter: 932962  x: [ 3.99995661 15.99965283]  f(x): 1.883201015266465e-09  grad at x: [ 8.26482778e-05 -2.11795996e-05]  gradient norm: 8.53188916024612e-05\n",
            "iter: 932963  x: [ 3.99995661 15.99965283]  f(x): 1.883145448780393e-09  grad at x: [-2.64814788e-06 -1.05177460e-05]  gradient norm: 1.0845997769933378e-05\n",
            "iter: 932964  x: [ 3.99995661 15.99965285]  f(x): 1.8830861380946934e-09  grad at x: [ 8.26937682e-05 -2.11849547e-05]  gradient norm: 8.536428762399564e-05\n",
            "iter: 932965  x: [ 3.99995661 15.99965285]  f(x): 1.88303051349055e-09  grad at x: [-2.64880255e-06 -1.05173331e-05]  gradient norm: 1.0845757224530133e-05\n",
            "iter: 932966  x: [ 3.99995661 15.99965286]  f(x): 1.882971266718834e-09  grad at x: [ 8.27382835e-05 -2.11901879e-05]  gradient norm: 8.540870925408173e-05\n",
            "iter: 932967  x: [ 3.99995661 15.99965286]  f(x): 1.882915585196723e-09  grad at x: [-2.64947185e-06 -1.05169183e-05]  gradient norm: 1.084551853980208e-05\n",
            "iter: 932968  x: [ 3.99995661 15.99965287]  f(x): 1.8828564036382898e-09  grad at x: [ 8.27837737e-05 -2.11955430e-05]  gradient norm: 8.545410598180105e-05\n",
            "iter: 932969  x: [ 3.99995661 15.99965287]  f(x): 1.882800663917275e-09  grad at x: [-2.65014123e-06 -1.05165036e-05]  gradient norm: 1.0845279926735815e-05\n",
            "iter: 932970  x: [ 3.99995661 15.99965288]  f(x): 1.8827415476408765e-09  grad at x: [ 8.28292784e-05 -2.12008999e-05]  gradient norm: 8.549951761362648e-05\n",
            "iter: 932971  x: [ 3.99995661 15.99965288]  f(x): 1.8826857496518845e-09  grad at x: [-2.65081070e-06 -1.05160889e-05]  gradient norm: 1.0845041385351037e-05\n",
            "iter: 932972  x: [ 3.99995661 15.99965289]  f(x): 1.882626698650961e-09  grad at x: [ 8.28747684e-05 -2.12062550e-05]  gradient norm: 8.55449150537345e-05\n",
            "iter: 932973  x: [ 3.99995661 15.99965289]  f(x): 1.8825708424189103e-09  grad at x: [-2.65146569e-06 -1.05156760e-05]  gradient norm: 1.0844801121835394e-05\n",
            "iter: 932974  x: [ 3.99995661 15.9996529 ]  f(x): 1.882511855526631e-09  grad at x: [ 8.29193416e-05 -2.12114956e-05]  gradient norm: 8.558939626126001e-05\n",
            "iter: 932975  x: [ 3.99995661 15.9996529 ]  f(x): 1.8824559421806713e-09  grad at x: [-2.65213532e-06 -1.05152612e-05]  gradient norm: 1.084456272286519e-05\n",
            "iter: 932976  x: [ 3.99995662 15.99965291]  f(x): 1.8823970206631023e-09  grad at x: [ 8.29648460e-05 -2.12168525e-05]  gradient norm: 8.563480895147154e-05\n",
            "iter: 932977  x: [ 3.99995661 15.99965291]  f(x): 1.8823410489555268e-09  grad at x: [-2.65280503e-06 -1.05148465e-05]  gradient norm: 1.0844324395635433e-05\n",
            "iter: 932978  x: [ 3.99995662 15.99965292]  f(x): 1.8822821928429448e-09  grad at x: [ 8.30103649e-05 -2.12222112e-05]  gradient norm: 8.568023654553001e-05\n",
            "iter: 932979  x: [ 3.99995662 15.99965292]  f(x): 1.882226162761833e-09  grad at x: [-2.65346026e-06 -1.05144336e-05]  gradient norm: 1.084408434311309e-05\n",
            "iter: 932980  x: [ 3.99995662 15.99965293]  f(x): 1.8821673708486695e-09  grad at x: [ 8.30549379e-05 -2.12274517e-05]  gradient norm: 8.572471878088652e-05\n",
            "iter: 932981  x: [ 3.99995662 15.99965293]  f(x): 1.882111283561914e-09  grad at x: [-2.65413013e-06 -1.05140189e-05]  gradient norm: 1.0843846158415367e-05\n",
            "iter: 932982  x: [ 3.99995662 15.99965294]  f(x): 1.882052557115343e-09  grad at x: [ 8.31004566e-05 -2.12328105e-05]  gradient norm: 8.577014707286371e-05\n",
            "iter: 932983  x: [ 3.99995662 15.99965294]  f(x): 1.881996411374126e-09  grad at x: [-2.65480008e-06 -1.05136041e-05]  gradient norm: 1.0843608045517066e-05\n",
            "iter: 932984  x: [ 3.99995662 15.99965295]  f(x): 1.881937750463005e-09  grad at x: [ 8.31459898e-05 -2.12381710e-05]  gradient norm: 8.581559026556001e-05\n",
            "iter: 932985  x: [ 3.99995662 15.99965295]  f(x): 1.8818815461981482e-09  grad at x: [-2.65547011e-06 -1.05131894e-05]  gradient norm: 1.0843370004655411e-05\n",
            "iter: 932986  x: [ 3.99995662 15.99965296]  f(x): 1.8818229508151006e-09  grad at x: [ 8.31915230e-05 -2.12435316e-05]  gradient norm: 8.58610338108685e-05\n",
            "iter: 932987  x: [ 3.99995662 15.99965296]  f(x): 1.881766688014986e-09  grad at x: [-2.65615477e-06 -1.05127729e-05]  gradient norm: 1.084313383650062e-05\n",
            "iter: 932988  x: [ 3.99995662 15.99965297]  f(x): 1.8817081593935196e-09  grad at x: [ 8.32379728e-05 -2.12490067e-05]  gradient norm: 8.590739435400886e-05\n",
            "iter: 932989  x: [ 3.99995662 15.99965297]  f(x): 1.8816518368429927e-09  grad at x: [-2.65683952e-06 -1.05123563e-05]  gradient norm: 1.0842897742023367e-05\n",
            "iter: 932990  x: [ 3.99995663 15.99965298]  f(x): 1.881593375090286e-09  grad at x: [ 8.32844662e-05 -2.12544874e-05]  gradient norm: 8.59537989142682e-05\n",
            "iter: 932991  x: [ 3.99995662 15.99965298]  f(x): 1.8815369927005223e-09  grad at x: [-2.65750979e-06 -1.05119416e-05]  gradient norm: 1.0842659918754937e-05\n",
            "iter: 932992  x: [ 3.99995663 15.99965299]  f(x): 1.8814785965706436e-09  grad at x: [ 8.33299991e-05 -2.12598479e-05]  gradient norm: 8.599924352827662e-05\n",
            "iter: 932993  x: [ 3.99995663 15.99965299]  f(x): 1.8814221555499056e-09  grad at x: [-2.6581947e-06 -1.0511525e-05]  gradient norm: 1.0842423971317722e-05\n",
            "iter: 932994  x: [ 3.99995663 15.999653  ]  f(x): 1.881363826315324e-09  grad at x: [ 8.33764778e-05 -2.12653267e-05]  gradient norm: 8.604563426121422e-05\n",
            "iter: 932995  x: [ 3.99995663 15.999653  ]  f(x): 1.8813073254281673e-09  grad at x: [-2.65886513e-06 -1.05111103e-05]  gradient norm: 1.0842186292656903e-05\n",
            "iter: 932996  x: [ 3.99995663 15.99965301]  f(x): 1.8812490619171568e-09  grad at x: [ 8.34220251e-05 -2.12706891e-05]  gradient norm: 8.609109413108665e-05\n",
            "iter: 932997  x: [ 3.99995663 15.99965301]  f(x): 1.8811925022976424e-09  grad at x: [-2.65955020e-06 -1.05106938e-05]  gradient norm: 1.0841950492122106e-05\n",
            "iter: 932998  x: [ 3.99995663 15.99965303]  f(x): 1.881134305783291e-09  grad at x: [ 8.34685328e-05 -2.12761715e-05]  gradient norm: 8.613751468773958e-05\n",
            "iter: 932999  x: [ 3.99995663 15.99965303]  f(x): 1.8810776861766837e-09  grad at x: [-2.66023535e-06 -1.05102772e-05]  gradient norm: 1.0841714765582916e-05\n",
            "iter: 933000  x: [ 3.99995663 15.99965304]  f(x): 1.8810195566544187e-09  grad at x: [ 8.35150112e-05 -2.12816503e-05]  gradient norm: 8.618390650697727e-05\n",
            "iter: 933001  x: [ 3.99995663 15.99965304]  f(x): 1.8809628770836375e-09  grad at x: [-2.66090602e-06 -1.05098625e-05]  gradient norm: 1.0841477304813639e-05\n",
            "iter: 933002  x: [ 3.99995663 15.99965305]  f(x): 1.8809048134168756e-09  grad at x: [ 8.35605874e-05 -2.12870164e-05]  gradient norm: 8.622939653713566e-05\n",
            "iter: 933003  x: [ 3.99995663 15.99965305]  f(x): 1.8808480749808445e-09  grad at x: [-2.66159133e-06 -1.05094459e-05]  gradient norm: 1.0841241725297058e-05\n",
            "iter: 933004  x: [ 3.99995663 15.99965306]  f(x): 1.880790078407612e-09  grad at x: [ 8.36070948e-05 -2.12924988e-05]  gradient norm: 8.627581817688719e-05\n",
            "iter: 933005  x: [ 3.99995663 15.99965306]  f(x): 1.880733279886654e-09  grad at x: [-2.66227672e-06 -1.05090294e-05]  gradient norm: 1.0841006219836402e-05\n",
            "iter: 933006  x: [ 3.99995664 15.99965307]  f(x): 1.8806753504394678e-09  grad at x: [ 8.36536021e-05 -2.12979812e-05]  gradient norm: 8.632224017798105e-05\n",
            "iter: 933007  x: [ 3.99995663 15.99965307]  f(x): 1.880618491819412e-09  grad at x: [-2.66294764e-06 -1.05086147e-05]  gradient norm: 1.0840768977137923e-05\n",
            "iter: 933008  x: [ 3.99995664 15.99965308]  f(x): 1.8805606283598225e-09  grad at x: [ 8.36992071e-05 -2.13033509e-05]  gradient norm: 8.636776036252767e-05\n",
            "iter: 933009  x: [ 3.99995664 15.99965308]  f(x): 1.880503710741463e-09  grad at x: [-2.66363319e-06 -1.05081981e-05]  gradient norm: 1.0840533618820104e-05\n",
            "iter: 933010  x: [ 3.99995664 15.99965309]  f(x): 1.8804459144723135e-09  grad at x: [ 8.37457143e-05 -2.13088333e-05]  gradient norm: 8.641418307781676e-05\n",
            "iter: 933011  x: [ 3.99995664 15.99965309]  f(x): 1.880388936689818e-09  grad at x: [-2.66430427e-06 -1.05077834e-05]  gradient norm: 1.0840296521265078e-05\n",
            "iter: 933012  x: [ 3.99995664 15.9996531 ]  f(x): 1.880331206433532e-09  grad at x: [ 8.37913046e-05 -2.13142011e-05]  gradient norm: 8.645968940966944e-05\n",
            "iter: 933013  x: [ 3.99995664 15.9996531 ]  f(x): 1.8802741696069783e-09  grad at x: [-2.66497544e-06 -1.05073686e-05]  gradient norm: 1.0840059495806488e-05\n",
            "iter: 933014  x: [ 3.99995664 15.99965311]  f(x): 1.8802165054705293e-09  grad at x: [ 8.38369239e-05 -2.13195726e-05]  gradient norm: 8.650522518826029e-05\n",
            "iter: 933015  x: [ 3.99995664 15.99965311]  f(x): 1.880159409532321e-09  grad at x: [-2.66567578e-06 -1.05069503e-05]  gradient norm: 1.0839826173013297e-05\n",
            "iter: 933016  x: [ 3.99995664 15.99965312]  f(x): 1.8801018139305866e-09  grad at x: [ 8.38843913e-05 -2.13251751e-05]  gradient norm: 8.655260938146034e-05\n",
            "iter: 933017  x: [ 3.99995664 15.99965312]  f(x): 1.880044656483005e-09  grad at x: [-2.66636166e-06 -1.05065337e-05]  gradient norm: 1.0839591110251385e-05\n",
            "iter: 933018  x: [ 3.99995664 15.99965313]  f(x): 1.879987128238452e-09  grad at x: [ 8.39309272e-05 -2.13306612e-05]  gradient norm: 8.659906262852929e-05\n",
            "iter: 933019  x: [ 3.99995664 15.99965313]  f(x): 1.8799299104213827e-09  grad at x: [-2.66706217e-06 -1.05061154e-05]  gradient norm: 1.0839357939159599e-05\n",
            "iter: 933020  x: [ 3.99995665 15.99965314]  f(x): 1.8798724508159487e-09  grad at x: [ 8.39784235e-05 -2.13362673e-05]  gradient norm: 8.664647666819059e-05\n",
            "iter: 933021  x: [ 3.99995664 15.99965314]  f(x): 1.8798151713844597e-09  grad at x: [-2.66774820e-06 -1.05056988e-05]  gradient norm: 1.0839123025841737e-05\n",
            "iter: 933022  x: [ 3.99995665 15.99965315]  f(x): 1.8797577791640903e-09  grad at x: [ 8.40249447e-05 -2.13417516e-05]  gradient norm: 8.669291608846256e-05\n",
            "iter: 933023  x: [ 3.99995665 15.99965315]  f(x): 1.8797147742448194e-09  grad at x: [ 4.06782552e-05 -1.59235169e-05]  gradient norm: 4.368385099246099e-05\n",
            "iter: 933024  x: [ 3.99995665 15.99965315]  f(x): 1.8796995465217397e-09  grad at x: [-1.99077646e-06 -1.05899853e-05]  gradient norm: 1.0775480502246528e-05\n",
            "iter: 933025  x: [ 3.99995665 15.99965319]  f(x): 1.879468497442199e-09  grad at x: [ 1.68776642e-04 -3.19341998e-05]  gradient norm: 0.00017177120831831378\n",
            "iter: 933026  x: [ 3.99995665 15.99965319]  f(x): 1.8793003222674407e-09  grad at x: [ 8.23917053e-05 -2.11362876e-05]  gradient norm: 8.505960119355245e-05\n",
            "iter: 933027  x: [ 3.99995665 15.99965319]  f(x): 1.879245089443184e-09  grad at x: [-2.64270914e-06 -1.05071849e-05]  gradient norm: 1.0834428763025916e-05\n",
            "iter: 933028  x: [ 3.99995665 15.9996532 ]  f(x): 1.8791856809573315e-09  grad at x: [ 8.24356067e-05 -2.11414444e-05]  gradient norm: 8.510340727655841e-05\n",
            "iter: 933029  x: [ 3.99995665 15.99965321]  f(x): 1.8791303921743383e-09  grad at x: [-2.64339565e-06 -1.05067684e-05]  gradient norm: 1.0834192277092218e-05\n",
            "iter: 933030  x: [ 3.99995665 15.99965322]  f(x): 1.8790710500877644e-09  grad at x: [ 8.24822002e-05 -2.11469378e-05]  gradient norm: 8.514990507673857e-05\n",
            "iter: 933031  x: [ 3.99995665 15.99965322]  f(x): 1.8790157019092944e-09  grad at x: [-2.64408225e-06 -1.05063518e-05]  gradient norm: 1.0833955865240466e-05\n",
            "iter: 933032  x: [ 3.99995666 15.99965323]  f(x): 1.878956426217989e-09  grad at x: [ 8.25287646e-05 -2.11524275e-05]  gradient norm: 8.519637416076523e-05\n",
            "iter: 933033  x: [ 3.99995665 15.99965323]  f(x): 1.8789010186663952e-09  grad at x: [-2.64475438e-06 -1.05059371e-05]  gradient norm: 1.08337177389858e-05\n",
            "iter: 933034  x: [ 3.99995666 15.99965324]  f(x): 1.8788418082474807e-09  grad at x: [ 8.25744266e-05 -2.11578044e-05]  gradient norm: 8.524194163002515e-05\n",
            "iter: 933035  x: [ 3.99995666 15.99965324]  f(x): 1.878786342407993e-09  grad at x: [-2.64544114e-06 -1.05055205e-05]  gradient norm: 1.0833481474327172e-05\n",
            "iter: 933036  x: [ 3.99995666 15.99965325]  f(x): 1.878727198522289e-09  grad at x: [ 8.26210489e-05 -2.11633014e-05]  gradient norm: 8.528846965593762e-05\n",
            "iter: 933037  x: [ 3.99995666 15.99965325]  f(x): 1.8786716731710923e-09  grad at x: [-2.64611343e-06 -1.05051058e-05]  gradient norm: 1.0833243493262485e-05\n",
            "iter: 933038  x: [ 3.99995666 15.99965326]  f(x): 1.8786125946211096e-09  grad at x: [ 8.26667108e-05 -2.11686784e-05]  gradient norm: 8.53340378568751e-05\n",
            "iter: 933039  x: [ 3.99995666 15.99965326]  f(x): 1.8785570108993892e-09  grad at x: [-2.64681491e-06 -1.05046875e-05]  gradient norm: 1.0833009167457528e-05\n",
            "iter: 933040  x: [ 3.99995666 15.99965327]  f(x): 1.8784980001414175e-09  grad at x: [ 8.27142643e-05 -2.11742918e-05]  gradient norm: 8.538149774908769e-05\n",
            "iter: 933041  x: [ 3.99995666 15.99965327]  f(x): 1.8784423556473704e-09  grad at x: [-2.64747281e-06 -1.05042745e-05]  gradient norm: 1.0832769540082357e-05\n",
            "iter: 933042  x: [ 3.99995666 15.99965328]  f(x): 1.8783834090943315e-09  grad at x: [ 8.27589947e-05 -2.11795523e-05]  gradient norm: 8.542613556214299e-05\n",
            "iter: 933043  x: [ 3.99995666 15.99965328]  f(x): 1.8783277073785703e-09  grad at x: [-2.64814534e-06 -1.05038598e-05]  gradient norm: 1.083253177622886e-05\n",
            "iter: 933044  x: [ 3.99995666 15.99965329]  f(x): 1.878268826292688e-09  grad at x: [ 8.28046854e-05 -2.11849328e-05]  gradient norm: 8.54717339490743e-05\n",
            "iter: 933045  x: [ 3.99995666 15.99965329]  f(x): 1.878213066129986e-09  grad at x: [-2.64880340e-06 -1.05034469e-05]  gradient norm: 1.0832292289955644e-05\n",
            "iter: 933046  x: [ 3.99995666 15.9996533 ]  f(x): 1.8781542493089376e-09  grad at x: [ 8.28494301e-05 -2.11901952e-05]  gradient norm: 8.551638700325785e-05\n",
            "iter: 933047  x: [ 3.99995666 15.9996533 ]  f(x): 1.8780984318639806e-09  grad at x: [-2.64947609e-06 -1.05030322e-05]  gradient norm: 1.0832054669682996e-05\n",
            "iter: 933048  x: [ 3.99995667 15.99965331]  f(x): 1.878039680646637e-09  grad at x: [ 8.28951643e-05 -2.11955812e-05]  gradient norm: 8.556202974708124e-05\n",
            "iter: 933049  x: [ 3.99995666 15.99965331]  f(x): 1.8779838045988923e-09  grad at x: [-2.65014887e-06 -1.05026174e-05]  gradient norm: 1.0831817121410896e-05\n",
            "iter: 933050  x: [ 3.99995667 15.99965332]  f(x): 1.877925118904528e-09  grad at x: [ 8.29408403e-05 -2.12009600e-05]  gradient norm: 8.56076146501683e-05\n",
            "iter: 933051  x: [ 3.99995667 15.99965332]  f(x): 1.8778691843157444e-09  grad at x: [-2.65083627e-06 -1.05022009e-05]  gradient norm: 1.0831581443012888e-05\n",
            "iter: 933052  x: [ 3.99995667 15.99965333]  f(x): 1.877810565485903e-09  grad at x: [ 8.29875056e-05 -2.12064624e-05]  gradient norm: 8.565418927621484e-05\n",
            "iter: 933053  x: [ 3.99995667 15.99965333]  f(x): 1.877754571051528e-09  grad at x: [-2.65150921e-06 -1.05017862e-05]  gradient norm: 1.0831344040248832e-05\n",
            "iter: 933054  x: [ 3.99995667 15.99965334]  f(x): 1.8776960178080565e-09  grad at x: [ 8.30331814e-05 -2.12118412e-05]  gradient norm: 8.569977490208839e-05\n",
            "iter: 933055  x: [ 3.99995667 15.99965334]  f(x): 1.877639964767435e-09  grad at x: [-2.65216767e-06 -1.05013733e-05]  gradient norm: 1.0831104910099125e-05\n",
            "iter: 933056  x: [ 3.99995667 15.99965335]  f(x): 1.8775814760546637e-09  grad at x: [ 8.30779839e-05 -2.12171108e-05]  gradient norm: 8.57444878962037e-05\n",
            "iter: 933057  x: [ 3.99995667 15.99965335]  f(x): 1.877525365484155e-09  grad at x: [-2.65285532e-06 -1.05009567e-05]  gradient norm: 1.0830869451572485e-05\n",
            "iter: 933058  x: [ 3.99995667 15.99965336]  f(x): 1.8774669436936205e-09  grad at x: [ 8.31246491e-05 -2.12226132e-05]  gradient norm: 8.57910636159486e-05\n",
            "iter: 933059  x: [ 3.99995667 15.99965336]  f(x): 1.877410773180359e-09  grad at x: [-2.6535285e-06 -1.0500542e-05]  gradient norm: 1.0830632265482228e-05\n",
            "iter: 933060  x: [ 3.99995667 15.99965337]  f(x): 1.8773524171826803e-09  grad at x: [ 8.31703828e-05 -2.12279992e-05]  gradient norm: 8.583670850566968e-05\n",
            "iter: 933061  x: [ 3.99995667 15.99965337]  f(x): 1.8772961878767365e-09  grad at x: [-2.65423086e-06 -1.05001236e-05]  gradient norm: 1.0830398757412267e-05\n",
            "iter: 933062  x: [ 3.99995668 15.99965338]  f(x): 1.8772379000681495e-09  grad at x: [ 8.32179646e-05 -2.12336163e-05]  gradient norm: 8.588420161687797e-05\n",
            "iter: 933063  x: [ 3.99995667 15.99965338]  f(x): 1.8771816095892617e-09  grad at x: [-2.65488965e-06 -1.04997107e-05]  gradient norm: 1.0830159914286287e-05\n",
            "iter: 933064  x: [ 3.99995668 15.9996534 ]  f(x): 1.877123386435008e-09  grad at x: [ 8.32627813e-05 -2.12388877e-05]  gradient norm: 8.592893056286091e-05\n",
            "iter: 933065  x: [ 3.99995668 15.9996534 ]  f(x): 1.8770670382814893e-09  grad at x: [-2.65556307e-06 -1.04992960e-05]  gradient norm: 1.0829922946497309e-05\n",
            "iter: 933066  x: [ 3.99995668 15.99965341]  f(x): 1.8770088809765515e-09  grad at x: [ 8.33085148e-05 -2.12442737e-05]  gradient norm: 8.597457652161253e-05\n",
            "iter: 933067  x: [ 3.99995668 15.99965341]  f(x): 1.876952473953101e-09  grad at x: [-2.65625112e-06 -1.04988794e-05]  gradient norm: 1.0829687856671598e-05\n",
            "iter: 933068  x: [ 3.99995668 15.99965342]  f(x): 1.876894383769874e-09  grad at x: [ 8.33551941e-05 -2.12497780e-05]  gradient norm: 8.602116861750297e-05\n",
            "iter: 933069  x: [ 3.99995668 15.99965342]  f(x): 1.8768379166410753e-09  grad at x: [-2.65692470e-06 -1.04984647e-05]  gradient norm: 1.0829451034491544e-05\n",
            "iter: 933070  x: [ 3.99995668 15.99965343]  f(x): 1.876779892408442e-09  grad at x: [ 8.34009420e-05 -2.12551658e-05]  gradient norm: 8.60668298381532e-05\n",
            "iter: 933071  x: [ 3.99995668 15.99965343]  f(x): 1.876723366307794e-09  grad at x: [-2.65761292e-06 -1.04980481e-05]  gradient norm: 1.0829216092580518e-05\n",
            "iter: 933072  x: [ 3.99995668 15.99965344]  f(x): 1.8766654092987923e-09  grad at x: [ 8.34476502e-05 -2.12606737e-05]  gradient norm: 8.611345176231055e-05\n",
            "iter: 933073  x: [ 3.99995668 15.99965344]  f(x): 1.876608822970406e-09  grad at x: [-2.65827211e-06 -1.04976352e-05]  gradient norm: 1.0828977607459519e-05\n",
            "iter: 933074  x: [ 3.99995668 15.99965345]  f(x): 1.876550930770389e-09  grad at x: [ 8.34924666e-05 -2.12659452e-05]  gradient norm: 8.615818243321583e-05\n",
            "iter: 933075  x: [ 3.99995668 15.99965345]  f(x): 1.876494286611123e-09  grad at x: [-2.65894593e-06 -1.04972205e-05]  gradient norm: 1.0828741002429132e-05\n",
            "iter: 933076  x: [ 3.99995668 15.99965346]  f(x): 1.8764364604931698e-09  grad at x: [ 8.35382433e-05 -2.12713367e-05]  gradient norm: 8.620387380677207e-05\n",
            "iter: 933077  x: [ 3.99995668 15.99965346]  f(x): 1.876379757266919e-09  grad at x: [-2.65960528e-06 -1.04968076e-05]  gradient norm: 1.082850265903677e-05\n",
            "iter: 933078  x: [ 3.99995669 15.99965347]  f(x): 1.8763219960560535e-09  grad at x: [ 8.35830886e-05 -2.12766117e-05]  gradient norm: 8.624863425499593e-05\n",
            "iter: 933079  x: [ 3.99995668 15.99965347]  f(x): 1.8762652348815355e-09  grad at x: [-2.66029382e-06 -1.04963910e-05]  gradient norm: 1.0828268009874622e-05\n",
            "iter: 933080  x: [ 3.99995669 15.99965348]  f(x): 1.8762075410221796e-09  grad at x: [ 8.36297965e-05 -2.12821196e-05]  gradient norm: 8.629525760172089e-05\n",
            "iter: 933081  x: [ 3.99995669 15.99965348]  f(x): 1.8761507195105894e-09  grad at x: [-2.66096788e-06 -1.04959763e-05]  gradient norm: 1.0828031622608451e-05\n",
            "iter: 933082  x: [ 3.99995669 15.99965349]  f(x): 1.8760930918277674e-09  grad at x: [ 8.36755730e-05 -2.12875111e-05]  gradient norm: 8.634095002174827e-05\n",
            "iter: 933083  x: [ 3.99995669 15.99965349]  f(x): 1.8760362111164713e-09  grad at x: [-2.66165658e-06 -1.04955598e-05]  gradient norm: 1.082779712160141e-05\n",
            "iter: 933084  x: [ 3.99995669 15.9996535 ]  f(x): 1.875978650887282e-09  grad at x: [ 8.37223099e-05 -2.12930227e-05]  gradient norm: 8.638760319259561e-05\n",
            "iter: 933085  x: [ 3.99995669 15.9996535 ]  f(x): 1.875921709717506e-09  grad at x: [-2.66234536e-06 -1.04951432e-05]  gradient norm: 1.0827562695219563e-05\n",
            "iter: 933086  x: [ 3.99995669 15.99965351]  f(x): 1.875864216937591e-09  grad at x: [ 8.37690175e-05 -2.12985306e-05]  gradient norm: 8.643422762325882e-05\n",
            "iter: 933087  x: [ 3.99995669 15.99965351]  f(x): 1.8758072152947295e-09  grad at x: [-2.66304877e-06 -1.04947248e-05]  gradient norm: 1.0827330159495114e-05\n",
            "iter: 933088  x: [ 3.99995669 15.99965352]  f(x): 1.875749791243882e-09  grad at x: [ 8.38166856e-05 -2.13041585e-05]  gradient norm: 8.648181283720927e-05\n",
            "iter: 933089  x: [ 3.99995669 15.99965352]  f(x): 1.8756927278839257e-09  grad at x: [-2.66370861e-06 -1.04943119e-05]  gradient norm: 1.0827092249384922e-05\n",
            "iter: 933090  x: [ 3.99995669 15.99965353]  f(x): 1.8756353689650343e-09  grad at x: [ 8.38615595e-05 -2.13094372e-05]  gradient norm: 8.652660445490799e-05\n",
            "iter: 933091  x: [ 3.99995669 15.99965353]  f(x): 1.8755782474300298e-09  grad at x: [-2.66439763e-06 -1.04938954e-05]  gradient norm: 1.0826858045746345e-05\n",
            "iter: 933092  x: [ 3.9999567  15.99965354]  f(x): 1.875520956133326e-09  grad at x: [ 8.39083106e-05 -2.13149506e-05]  gradient norm: 8.65732736188317e-05\n",
            "iter: 933093  x: [ 3.99995669 15.99965354]  f(x): 1.87546377398983e-09  grad at x: [-2.66510128e-06 -1.04934770e-05]  gradient norm: 1.0826625736130922e-05\n",
            "iter: 933094  x: [ 3.9999567  15.99965355]  f(x): 1.875420851241577e-09  grad at x: [ 4.06454531e-05 -1.59070296e-05]  gradient norm: 4.3647295991468366e-05\n",
            "iter: 933095  x: [ 3.99995669 15.99965355]  f(x): 1.8754056495498116e-09  grad at x: [-1.98871210e-06 -1.05778563e-05]  gradient norm: 1.076317888568414e-05\n",
            "iter: 933096  x: [ 3.9999567  15.99965359]  f(x): 1.875175269885593e-09  grad at x: [ 1.68638370e-04 -3.19045303e-05]  gradient norm: 0.0001716298307706919\n",
            "iter: 933097  x: [ 3.9999567  15.99965359]  f(x): 1.8750073715838658e-09  grad at x: [ 8.23244321e-05 -2.11154929e-05]  gradient norm: 8.498927087850559e-05\n",
            "iter: 933098  x: [ 3.9999567  15.99965359]  f(x): 1.874952230598445e-09  grad at x: [-2.64014743e-06 -1.04951196e-05]  gradient norm: 1.0822102993322459e-05\n",
            "iter: 933099  x: [ 3.9999567 15.9996536]  f(x): 1.874892995287803e-09  grad at x: [ 8.23707462e-05 -2.11209517e-05]  gradient norm: 8.503548923562565e-05\n",
            "iter: 933100  x: [ 3.9999567 15.9996536]  f(x): 1.8748377953560627e-09  grad at x: [-2.64080787e-06 -1.04947067e-05]  gradient norm: 1.0821863703831664e-05\n",
            "iter: 933101  x: [ 3.9999567  15.99965361]  f(x): 1.8747786242217314e-09  grad at x: [ 8.24156486e-05 -2.11262341e-05]  gradient norm: 8.508029680043004e-05\n",
            "iter: 933102  x: [ 3.9999567  15.99965361]  f(x): 1.8747233670868393e-09  grad at x: [-2.64148294e-06 -1.04942919e-05]  gradient norm: 1.0821626272664875e-05\n",
            "iter: 933103  x: [ 3.99995671 15.99965362]  f(x): 1.874664261349611e-09  grad at x: [ 8.24614823e-05 -2.11316328e-05]  gradient norm: 8.51260358025481e-05\n",
            "iter: 933104  x: [ 3.9999567  15.99965362]  f(x): 1.874608945827739e-09  grad at x: [-2.64214354e-06 -1.04938790e-05]  gradient norm: 1.082138712518803e-05\n",
            "iter: 933105  x: [ 3.99995671 15.99965363]  f(x): 1.8745499043646663e-09  grad at x: [ 8.25064137e-05 -2.11369188e-05]  gradient norm: 8.517087317191552e-05\n",
            "iter: 933106  x: [ 3.99995671 15.99965363]  f(x): 1.8744945315225185e-09  grad at x: [-2.64283332e-06 -1.04934625e-05]  gradient norm: 1.0821151628164365e-05\n",
            "iter: 933107  x: [ 3.99995671 15.99965364]  f(x): 1.8744355567850894e-09  grad at x: [ 8.25532222e-05 -2.11424394e-05]  gradient norm: 8.521758764697488e-05\n",
            "iter: 933108  x: [ 3.99995671 15.99965364]  f(x): 1.8743801242267804e-09  grad at x: [-2.64350864e-06 -1.04930477e-05]  gradient norm: 1.0820914414653593e-05\n",
            "iter: 933109  x: [ 3.99995671 15.99965365]  f(x): 1.8743212149803337e-09  grad at x: [ 8.25990702e-05 -2.11478400e-05]  gradient norm: 8.526334229399076e-05\n",
            "iter: 933110  x: [ 3.99995671 15.99965365]  f(x): 1.8742657239017505e-09  grad at x: [-2.64416948e-06 -1.04926348e-05]  gradient norm: 1.0820675481624268e-05\n",
            "iter: 933111  x: [ 3.99995671 15.99965366]  f(x): 1.8742068790223425e-09  grad at x: [ 8.26440014e-05 -2.11531260e-05]  gradient norm: 8.530818073309813e-05\n",
            "iter: 933112  x: [ 3.99995671 15.99965366]  f(x): 1.8741513305482836e-09  grad at x: [-2.64484495e-06 -1.04922201e-05]  gradient norm: 1.0820438412082492e-05\n",
            "iter: 933113  x: [ 3.99995671 15.99965368]  f(x): 1.874092551296711e-09  grad at x: [ 8.26898929e-05 -2.11585320e-05]  gradient norm: 8.535397974631318e-05\n",
            "iter: 933114  x: [ 3.99995671 15.99965368]  f(x): 1.8740369442033364e-09  grad at x: [-2.64550596e-06 -1.04918072e-05]  gradient norm: 1.0820199621263523e-05\n",
            "iter: 933115  x: [ 3.99995671 15.99965369]  f(x): 1.873978229380106e-09  grad at x: [ 8.27348238e-05 -2.11638180e-05]  gradient norm: 8.53988188864363e-05\n",
            "iter: 933116  x: [ 3.99995671 15.99965369]  f(x): 1.8739225648106776e-09  grad at x: [-2.64619614e-06 -1.04913906e-05]  gradient norm: 1.0819964491130118e-05\n",
            "iter: 933117  x: [ 3.99995671 15.9996537 ]  f(x): 1.8738639168729666e-09  grad at x: [ 8.27816465e-05 -2.11693405e-05]  gradient norm: 8.544554976301432e-05\n",
            "iter: 933118  x: [ 3.99995671 15.9996537 ]  f(x): 1.873808192425897e-09  grad at x: [-2.64687186e-06 -1.04909759e-05]  gradient norm: 1.0819727639542186e-05\n",
            "iter: 933119  x: [ 3.99995672 15.99965371]  f(x): 1.873749610210956e-09  grad at x: [ 8.28275378e-05 -2.11747465e-05]  gradient norm: 8.549134986431959e-05\n",
            "iter: 933120  x: [ 3.99995671 15.99965371]  f(x): 1.8736938270114038e-09  grad at x: [-2.64756221e-06 -1.04905594e-05]  gradient norm: 1.0819492657844086e-05\n",
            "iter: 933121  x: [ 3.99995672 15.99965372]  f(x): 1.873635311747253e-09  grad at x: [ 8.28743603e-05 -2.11802690e-05]  gradient norm: 8.553808148929474e-05\n",
            "iter: 933122  x: [ 3.99995672 15.99965372]  f(x): 1.873579468565703e-09  grad at x: [-2.64823809e-06 -1.04901446e-05]  gradient norm: 1.0819255952676355e-05\n",
            "iter: 933123  x: [ 3.99995672 15.99965373]  f(x): 1.8735210190882778e-09  grad at x: [ 8.29202514e-05 -2.11856750e-05]  gradient norm: 8.558388232046884e-05\n",
            "iter: 933124  x: [ 3.99995672 15.99965373]  f(x): 1.8734651171082857e-09  grad at x: [-2.64891405e-06 -1.04897299e-05]  gradient norm: 1.0819019320022234e-05\n",
            "iter: 933125  x: [ 3.99995672 15.99965374]  f(x): 1.8734067334860817e-09  grad at x: [ 8.29661715e-05 -2.11910847e-05]  gradient norm: 8.562971261099501e-05\n",
            "iter: 933126  x: [ 3.99995672 15.99965374]  f(x): 1.8733507726201983e-09  grad at x: [-2.64960464e-06 -1.04893134e-05]  gradient norm: 1.0818784560392034e-05\n",
            "iter: 933127  x: [ 3.99995672 15.99965375]  f(x): 1.8732924560463803e-09  grad at x: [ 8.30129938e-05 -2.11966071e-05]  gradient norm: 8.567644535160398e-05\n",
            "iter: 933128  x: [ 3.99995672 15.99965375]  f(x): 1.8732364351383877e-09  grad at x: [-2.65028076e-06 -1.04888986e-05]  gradient norm: 1.0818548074495687e-05\n",
            "iter: 933129  x: [ 3.99995672 15.99965376]  f(x): 1.873178184483805e-09  grad at x: [ 8.30589137e-05 -2.12020168e-05]  gradient norm: 8.572227636847733e-05\n",
            "iter: 933130  x: [ 3.99995672 15.99965376]  f(x): 1.8731221046252678e-09  grad at x: [-2.65097151e-06 -1.04884821e-05]  gradient norm: 1.0818313463502504e-05\n",
            "iter: 933131  x: [ 3.99995672 15.99965377]  f(x): 1.8730639211212675e-09  grad at x: [ 8.31057649e-05 -2.12075429e-05]  gradient norm: 8.576903894833482e-05\n",
            "iter: 933132  x: [ 3.99995672 15.99965377]  f(x): 1.873007781079344e-09  grad at x: [-2.65164779e-06 -1.04880673e-05]  gradient norm: 1.081807712379139e-05\n",
            "iter: 933133  x: [ 3.99995672 15.99965378]  f(x): 1.8729496635586157e-09  grad at x: [ 8.31516847e-05 -2.12129526e-05]  gradient norm: 8.581487069066478e-05\n",
            "iter: 933134  x: [ 3.99995672 15.99965378]  f(x): 1.8728934645201043e-09  grad at x: [-2.65232415e-06 -1.04876526e-05]  gradient norm: 1.0817840857128781e-05\n",
            "iter: 933135  x: [ 3.99995673 15.99965379]  f(x): 1.87283541301434e-09  grad at x: [ 8.31976045e-05 -2.12183622e-05]  gradient norm: 8.586070278875145e-05\n",
            "iter: 933136  x: [ 3.99995673 15.99965379]  f(x): 1.872779154947229e-09  grad at x: [-2.65300059e-06 -1.04872379e-05]  gradient norm: 1.0817604663099145e-05\n",
            "iter: 933137  x: [ 3.99995673 15.9996538 ]  f(x): 1.872721169487386e-09  grad at x: [ 8.32435386e-05 -2.12237737e-05]  gradient norm: 8.590654979383028e-05\n",
            "iter: 933138  x: [ 3.99995673 15.9996538 ]  f(x): 1.8726648523219625e-09  grad at x: [-2.65367712e-06 -1.04868232e-05]  gradient norm: 1.0817368541722232e-05\n",
            "iter: 933139  x: [ 3.99995673 15.99965381]  f(x): 1.8726069330151767e-09  grad at x: [ 8.32895019e-05 -2.12291889e-05]  gradient norm: 8.595242625593759e-05\n",
            "iter: 933140  x: [ 3.99995673 15.99965381]  f(x): 1.87255055670105e-09  grad at x: [-2.65433917e-06 -1.04864102e-05]  gradient norm: 1.0817130686028422e-05\n",
            "iter: 933141  x: [ 3.99995673 15.99965382]  f(x): 1.872492702338436e-09  grad at x: [ 8.33345191e-05 -2.12344858e-05]  gradient norm: 8.599735727449101e-05\n",
            "iter: 933142  x: [ 3.99995673 15.99965382]  f(x): 1.8724362680469144e-09  grad at x: [-2.65501585e-06 -1.04859955e-05]  gradient norm: 1.0816894709432846e-05\n",
            "iter: 933143  x: [ 3.99995673 15.99965383]  f(x): 1.8723784798247373e-09  grad at x: [ 8.33804530e-05 -2.12398973e-05]  gradient norm: 8.604320533686102e-05\n",
            "iter: 933144  x: [ 3.99995673 15.99965383]  f(x): 1.8723219863592385e-09  grad at x: [-2.65570717e-06 -1.04855790e-05]  gradient norm: 1.0816660615449931e-05\n",
            "iter: 933145  x: [ 3.99995673 15.99965384]  f(x): 1.872264265588908e-09  grad at x: [ 8.34273474e-05 -2.12454288e-05]  gradient norm: 8.609001411734596e-05\n",
            "iter: 933146  x: [ 3.99995673 15.99965384]  f(x): 1.8722077116563295e-09  grad at x: [-2.65639857e-06 -1.04851624e-05]  gradient norm: 1.0816426596258284e-05\n",
            "iter: 933147  x: [ 3.99995673 15.99965385]  f(x): 1.8721500583331643e-09  grad at x: [ 8.34742270e-05 -2.12509585e-05]  gradient norm: 8.61368087177668e-05\n",
            "iter: 933148  x: [ 3.99995673 15.99965386]  f(x): 1.8720934439378673e-09  grad at x: [-2.65709004e-06 -1.04847459e-05]  gradient norm: 1.0816192652096276e-05\n",
            "iter: 933149  x: [ 3.99995674 15.99965387]  f(x): 1.872035858094248e-09  grad at x: [ 8.35211212e-05 -2.12564901e-05]  gradient norm: 8.61836182407104e-05\n",
            "iter: 933150  x: [ 3.99995673 15.99965387]  f(x): 1.8719791831651037e-09  grad at x: [-2.65778160e-06 -1.04843293e-05]  gradient norm: 1.0815958782766026e-05\n",
            "iter: 933151  x: [ 3.99995674 15.99965388]  f(x): 1.871921664909641e-09  grad at x: [ 8.35680444e-05 -2.12620253e-05]  gradient norm: 8.623045723352442e-05\n",
            "iter: 933152  x: [ 3.99995674 15.99965388]  f(x): 1.871864929394772e-09  grad at x: [-2.65845869e-06 -1.04839146e-05]  gradient norm: 1.081572317510158e-05\n",
            "iter: 933153  x: [ 3.99995674 15.99965389]  f(x): 1.8718074774787803e-09  grad at x: [ 8.36139924e-05 -2.12674386e-05]  gradient norm: 8.627632164046605e-05\n",
            "iter: 933154  x: [ 3.99995674 15.99965389]  f(x): 1.871750682589305e-09  grad at x: [-2.65915041e-06 -1.04834980e-05]  gradient norm: 1.081548945489235e-05\n",
            "iter: 933155  x: [ 3.99995674 15.9996539 ]  f(x): 1.8716932982885687e-09  grad at x: [ 8.36609155e-05 -2.12729738e-05]  gradient norm: 8.632316136202443e-05\n",
            "iter: 933156  x: [ 3.99995674 15.9996539 ]  f(x): 1.871636442747204e-09  grad at x: [-2.65982766e-06 -1.04830833e-05]  gradient norm: 1.0815253993892354e-05\n",
            "iter: 933157  x: [ 3.99995674 15.99965391]  f(x): 1.8715791249250566e-09  grad at x: [ 8.37069070e-05 -2.12783925e-05]  gradient norm: 8.636907013516443e-05\n",
            "iter: 933158  x: [ 3.99995674 15.99965391]  f(x): 1.871522209887952e-09  grad at x: [-2.66050499e-06 -1.04826686e-05]  gradient norm: 1.0815018606181119e-05\n",
            "iter: 933159  x: [ 3.99995674 15.99965392]  f(x): 1.8714649585383767e-09  grad at x: [ 8.37528840e-05 -2.12838095e-05]  gradient norm: 8.64149647053304e-05\n",
            "iter: 933160  x: [ 3.99995674 15.99965392]  f(x): 1.871407983992609e-09  grad at x: [-2.66119695e-06 -1.04822520e-05]  gradient norm: 1.0814785109066296e-05\n",
            "iter: 933161  x: [ 3.99995674 15.99965393]  f(x): 1.8713508003562795e-09  grad at x: [ 8.37998068e-05 -2.12893447e-05]  gradient norm: 8.646180550920754e-05\n",
            "iter: 933162  x: [ 3.99995674 15.99965393]  f(x): 1.871293765078295e-09  grad at x: [-2.66185988e-06 -1.04818391e-05]  gradient norm: 1.0814548049612428e-05\n",
            "iter: 933163  x: [ 3.99995674 15.99965394]  f(x): 1.8712366468058193e-09  grad at x: [ 8.38448813e-05 -2.12946488e-05]  gradient norm: 8.650679854903396e-05\n",
            "iter: 933164  x: [ 3.99995674 15.99965394]  f(x): 1.8711938263715126e-09  grad at x: [ 4.05911647e-05 -1.58880357e-05]  gradient norm: 4.358981907416011e-05\n",
            "iter: 933165  x: [ 3.99995674 15.99965394]  f(x): 1.871178664351097e-09  grad at x: [-1.98634940e-06 -1.05659437e-05]  gradient norm: 1.0751034882116776e-05\n",
            "iter: 933166  x: [ 3.99995675 15.99965398]  f(x): 1.8709487232728825e-09  grad at x: [ 1.68417070e-04 -3.18646617e-05]  gradient norm: 0.00017140497709070238\n",
            "iter: 933167  x: [ 3.99995675 15.99965398]  f(x): 1.870781264533452e-09  grad at x: [ 8.22162747e-05 -2.10897670e-05]  gradient norm: 8.487811318293793e-05\n",
            "iter: 933168  x: [ 3.99995675 15.99965398]  f(x): 1.8707262673744716e-09  grad at x: [-2.63693797e-06 -1.04833143e-05]  gradient norm: 1.0809871466835414e-05\n",
            "iter: 933169  x: [ 3.99995675 15.99965399]  f(x): 1.8706671466218953e-09  grad at x: [ 8.22629933e-05 -2.10952767e-05]  gradient norm: 8.492473585142396e-05\n",
            "iter: 933170  x: [ 3.99995675 15.99965399]  f(x): 1.8706120900675265e-09  grad at x: [-2.63761594e-06 -1.04828996e-05]  gradient norm: 1.0809634675262447e-05\n",
            "iter: 933171  x: [ 3.99995675 15.999654  ]  f(x): 1.8705530348077664e-09  grad at x: [ 8.23090132e-05 -2.11006991e-05]  gradient norm: 8.497066059711338e-05\n",
            "iter: 933172  x: [ 3.99995675 15.999654  ]  f(x): 1.8704979197207735e-09  grad at x: [-2.63827944e-06 -1.04824867e-05]  gradient norm: 1.0809396168905437e-05\n",
            "iter: 933173  x: [ 3.99995675 15.99965401]  f(x): 1.8704389288341816e-09  grad at x: [ 8.23541163e-05 -2.11060069e-05]  gradient norm: 8.5015669177531e-05\n",
            "iter: 933174  x: [ 3.99995675 15.99965401]  f(x): 1.8703837563350647e-09  grad at x: [-2.63895757e-06 -1.04820720e-05]  gradient norm: 1.0809159522063159e-05\n",
            "iter: 933175  x: [ 3.99995676 15.99965402]  f(x): 1.8703248310793173e-09  grad at x: [ 8.24001653e-05 -2.11114329e-05]  gradient norm: 8.506162375294742e-05\n",
            "iter: 933176  x: [ 3.99995675 15.99965402]  f(x): 1.8702695999287014e-09  grad at x: [-2.63963578e-06 -1.04816572e-05]  gradient norm: 1.0808922948452232e-05\n",
            "iter: 933177  x: [ 3.99995676 15.99965403]  f(x): 1.8702107402606495e-09  grad at x: [ 8.24461850e-05 -2.11168554e-05]  gradient norm: 8.510754960073912e-05\n",
            "iter: 933178  x: [ 3.99995676 15.99965403]  f(x): 1.8701554505001923e-09  grad at x: [-2.64028497e-06 -1.04812461e-05]  gradient norm: 1.0808682865851207e-05\n",
            "iter: 933179  x: [ 3.99995676 15.99965404]  f(x): 1.8700966541439926e-09  grad at x: [ 8.24903856e-05 -2.11220504e-05]  gradient norm: 8.515165724254308e-05\n",
            "iter: 933180  x: [ 3.99995676 15.99965404]  f(x): 1.8700413080131524e-09  grad at x: [-2.64096335e-06 -1.04808314e-05]  gradient norm: 1.0808446436067712e-05\n",
            "iter: 933181  x: [ 3.99995676 15.99965406]  f(x): 1.8699825774187545e-09  grad at x: [ 8.25364634e-05 -2.11274801e-05]  gradient norm: 8.519764200518185e-05\n",
            "iter: 933182  x: [ 3.99995676 15.99965406]  f(x): 1.8699271725045002e-09  grad at x: [-2.64164180e-06 -1.04804167e-05]  gradient norm: 1.0808210079141334e-05\n",
            "iter: 933183  x: [ 3.99995676 15.99965407]  f(x): 1.869868507666277e-09  grad at x: [ 8.25825265e-05 -2.11329079e-05]  gradient norm: 8.524361258809432e-05\n",
            "iter: 933184  x: [ 3.99995676 15.99965407]  f(x): 1.8698130439739168e-09  grad at x: [-2.64232033e-06 -1.04800019e-05]  gradient norm: 1.080797379552619e-05\n",
            "iter: 933185  x: [ 3.99995676 15.99965408]  f(x): 1.8697544448862117e-09  grad at x: [ 8.26285751e-05 -2.11383340e-05]  gradient norm: 8.528956898843355e-05\n",
            "iter: 933186  x: [ 3.99995676 15.99965408]  f(x): 1.8696989224012925e-09  grad at x: [-2.6429844e-06 -1.0479589e-05]  gradient norm: 1.0807735789952074e-05\n",
            "iter: 933187  x: [ 3.99995676 15.99965409]  f(x): 1.8696403879400287e-09  grad at x: [ 8.26737067e-05 -2.11436454e-05]  gradient norm: 8.533460916051338e-05\n",
            "iter: 933188  x: [ 3.99995676 15.99965409]  f(x): 1.8695848077688674e-09  grad at x: [-2.64367765e-06 -1.04791725e-05]  gradient norm: 1.0807501447006822e-05\n",
            "iter: 933189  x: [ 3.99995676 15.9996541 ]  f(x): 1.8695263404272666e-09  grad at x: [ 8.27207446e-05 -2.11491952e-05]  gradient norm: 8.538155563398704e-05\n",
            "iter: 933190  x: [ 3.99995676 15.9996541 ]  f(x): 1.869470700132168e-09  grad at x: [-2.64435642e-06 -1.04787578e-05]  gradient norm: 1.08072653823596e-05\n",
            "iter: 933191  x: [ 3.99995677 15.99965411]  f(x): 1.869412298674336e-09  grad at x: [ 8.27668074e-05 -2.11546230e-05]  gradient norm: 8.542752768087303e-05\n",
            "iter: 933192  x: [ 3.99995676 15.99965411]  f(x): 1.8693565994536468e-09  grad at x: [-2.64504983e-06 -1.04783412e-05]  gradient norm: 1.0807031189048414e-05\n",
            "iter: 933193  x: [ 3.99995677 15.99965412]  f(x): 1.8692982651061527e-09  grad at x: [ 8.28138161e-05 -2.11601691e-05]  gradient norm: 8.547444581335418e-05\n",
            "iter: 933194  x: [ 3.99995677 15.99965412]  f(x): 1.8692425057504227e-09  grad at x: [-2.64571422e-06 -1.04779283e-05]  gradient norm: 1.0806793472607334e-05\n",
            "iter: 933195  x: [ 3.99995677 15.99965413]  f(x): 1.8691842361918046e-09  grad at x: [ 8.28589765e-05 -2.11654842e-05]  gradient norm: 8.55195165187656e-05\n",
            "iter: 933196  x: [ 3.99995677 15.99965413]  f(x): 1.8691284190047385e-09  grad at x: [-2.64639324e-06 -1.04775136e-05]  gradient norm: 1.0806557627542345e-05\n",
            "iter: 933197  x: [ 3.99995677 15.99965414]  f(x): 1.869070215462418e-09  grad at x: [ 8.29050682e-05 -2.11709157e-05]  gradient norm: 8.55655187561684e-05\n",
            "iter: 933198  x: [ 3.99995677 15.99965414]  f(x): 1.8690143391964902e-09  grad at x: [-2.64707233e-06 -1.04770988e-05]  gradient norm: 1.080632185527636e-05\n",
            "iter: 933199  x: [ 3.99995677 15.99965415]  f(x): 1.8689562017768565e-09  grad at x: [ 8.29512034e-05 -2.11763527e-05]  gradient norm: 8.561156500760948e-05\n",
            "iter: 933200  x: [ 3.99995677 15.99965415]  f(x): 1.868900266383543e-09  grad at x: [-2.64776607e-06 -1.04766823e-05]  gradient norm: 1.080608795873812e-05\n",
            "iter: 933201  x: [ 3.99995677 15.99965416]  f(x): 1.8688421962045812e-09  grad at x: [ 8.29982117e-05 -2.11818988e-05]  gradient norm: 8.565848462504783e-05\n",
            "iter: 933202  x: [ 3.99995677 15.99965416]  f(x): 1.8687862005260055e-09  grad at x: [-2.64844532e-06 -1.04762676e-05]  gradient norm: 1.080585233402398e-05\n",
            "iter: 933203  x: [ 3.99995677 15.99965417]  f(x): 1.8687281964966964e-09  grad at x: [ 8.30443323e-05 -2.11873339e-05]  gradient norm: 8.570451705890228e-05\n",
            "iter: 933204  x: [ 3.99995677 15.99965417]  f(x): 1.8686721416247353e-09  grad at x: [-2.64913922e-06 -1.04758510e-05]  gradient norm: 1.080561858670998e-05\n",
            "iter: 933205  x: [ 3.99995678 15.99965418]  f(x): 1.868614204976479e-09  grad at x: [ 8.30913841e-05 -2.11928855e-05]  gradient norm: 8.575148107487885e-05\n",
            "iter: 933206  x: [ 3.99995677 15.99965418]  f(x): 1.8685580896968457e-09  grad at x: [-2.64980409e-06 -1.04754381e-05]  gradient norm: 1.0805381304498136e-05\n",
            "iter: 933207  x: [ 3.99995678 15.99965419]  f(x): 1.868500218062763e-09  grad at x: [ 8.31365731e-05 -2.11982042e-05]  gradient norm: 8.579658300938162e-05\n",
            "iter: 933208  x: [ 3.99995678 15.99965419]  f(x): 1.8684440447059786e-09  grad at x: [-2.65049814e-06 -1.04750216e-05]  gradient norm: 1.0805147705663045e-05\n",
            "iter: 933209  x: [ 3.99995678 15.9996542 ]  f(x): 1.8683862405182065e-09  grad at x: [ 8.31836248e-05 -2.12037558e-05]  gradient norm: 8.584354776173175e-05\n",
            "iter: 933210  x: [ 3.99995678 15.9996542 ]  f(x): 1.868330006689031e-09  grad at x: [-2.65119227e-06 -1.04746050e-05]  gradient norm: 1.0804914182468438e-05\n",
            "iter: 933211  x: [ 3.99995678 15.99965421]  f(x): 1.8682722699808663e-09  grad at x: [ 8.32306764e-05 -2.12093073e-05]  gradient norm: 8.589051289056404e-05\n",
            "iter: 933212  x: [ 3.99995678 15.99965421]  f(x): 1.868215975625901e-09  grad at x: [-2.65187193e-06 -1.04741903e-05]  gradient norm: 1.0804678926038419e-05\n",
            "iter: 933213  x: [ 3.99995678 15.99965422]  f(x): 1.8681583052655503e-09  grad at x: [ 8.32768256e-05 -2.12147461e-05]  gradient norm: 8.593657624211385e-05\n",
            "iter: 933214  x: [ 3.99995678 15.99965422]  f(x): 1.8681019515360525e-09  grad at x: [-2.65255168e-06 -1.04737755e-05]  gradient norm: 1.0804443743220835e-05\n",
            "iter: 933215  x: [ 3.99995678 15.99965423]  f(x): 1.8680443475555297e-09  grad at x: [ 8.33229748e-05 -2.12201849e-05]  gradient norm: 8.598263995235072e-05\n",
            "iter: 933216  x: [ 3.99995678 15.99965423]  f(x): 1.8679879344005607e-09  grad at x: [-2.65324605e-06 -1.04733590e-05]  gradient norm: 1.0804210443891781e-05\n",
            "iter: 933217  x: [ 3.99995678 15.99965425]  f(x): 1.8679303979975578e-09  grad at x: [ 8.33700407e-05 -2.12257382e-05]  gradient norm: 8.602962073884035e-05\n",
            "iter: 933218  x: [ 3.99995678 15.99965425]  f(x): 1.867873924199326e-09  grad at x: [-2.65394051e-06 -1.04729424e-05]  gradient norm: 1.0803977220066755e-05\n",
            "iter: 933219  x: [ 3.99995678 15.99965426]  f(x): 1.867816455482592e-09  grad at x: [ 8.34171356e-05 -2.12312952e-05]  gradient norm: 8.607663100106205e-05\n",
            "iter: 933220  x: [ 3.99995678 15.99965426]  f(x): 1.8677599209890204e-09  grad at x: [-2.65462049e-06 -1.04725277e-05]  gradient norm: 1.0803742259166613e-05\n",
            "iter: 933221  x: [ 3.99995679 15.99965427]  f(x): 1.867702518749466e-09  grad at x: [ 8.34632845e-05 -2.12367340e-05]  gradient norm: 8.612269579628317e-05\n",
            "iter: 933222  x: [ 3.99995678 15.99965427]  f(x): 1.8676459247321165e-09  grad at x: [-2.65531511e-06 -1.04721112e-05]  gradient norm: 1.0803509185147854e-05\n",
            "iter: 933223  x: [ 3.99995679 15.99965428]  f(x): 1.8675885902442175e-09  grad at x: [ 8.35103938e-05 -2.12422929e-05]  gradient norm: 8.61697213475722e-05\n",
            "iter: 933224  x: [ 3.99995679 15.99965428]  f(x): 1.8675319354271185e-09  grad at x: [-2.65599526e-06 -1.04716964e-05]  gradient norm: 1.0803274372242658e-05\n",
            "iter: 933225  x: [ 3.99995679 15.99965429]  f(x): 1.8674746674811026e-09  grad at x: [ 8.35565426e-05 -2.12477316e-05]  gradient norm: 8.621578686231895e-05\n",
            "iter: 933226  x: [ 3.99995679 15.99965429]  f(x): 1.8674179530748863e-09  grad at x: [-2.65669003e-06 -1.04712799e-05]  gradient norm: 1.0803041448111214e-05\n",
            "iter: 933227  x: [ 3.99995679 15.9996543 ]  f(x): 1.867360752908841e-09  grad at x: [ 8.36036371e-05 -2.12532887e-05]  gradient norm: 8.626279859571306e-05\n",
            "iter: 933228  x: [ 3.99995679 15.9996543 ]  f(x): 1.8673039776925233e-09  grad at x: [-2.65735579e-06 -1.04708670e-05]  gradient norm: 1.0802804966560376e-05\n",
            "iter: 933229  x: [ 3.99995679 15.99965431]  f(x): 1.8672468429628486e-09  grad at x: [ 8.36488835e-05 -2.12586147e-05]  gradient norm: 8.630796260929453e-05\n",
            "iter: 933230  x: [ 3.99995679 15.99965431]  f(x): 1.867190009243691e-09  grad at x: [-2.65805073e-06 -1.04704504e-05]  gradient norm: 1.0802572191351828e-05\n",
            "iter: 933231  x: [ 3.99995679 15.99965432]  f(x): 1.867132942434922e-09  grad at x: [ 8.36960070e-05 -2.12641753e-05]  gradient norm: 8.635500416837826e-05\n",
            "iter: 933232  x: [ 3.99995679 15.99965432]  f(x): 1.8670760477652695e-09  grad at x: [-2.65874575e-06 -1.04700339e-05]  gradient norm: 1.0802339492008349e-05\n",
            "iter: 933233  x: [ 3.99995679 15.99965433]  f(x): 1.867019048910212e-09  grad at x: [ 8.37431450e-05 -2.12697378e-05]  gradient norm: 8.640206065078897e-05\n",
            "iter: 933234  x: [ 3.99995679 15.99965433]  f(x): 1.866976332071472e-09  grad at x: [ 4.05418594e-05 -1.58696785e-05]  gradient norm: 4.353721459863007e-05\n",
            "iter: 933235  x: [ 3.99995679 15.99965433]  f(x): 1.8669612064906624e-09  grad at x: [-1.98405318e-06 -1.05540366e-05]  gradient norm: 1.0738908524216424e-05\n",
            "iter: 933236  x: [ 3.9999568  15.99965437]  f(x): 1.8667317458898685e-09  grad at x: [ 1.68212555e-04 -3.18269049e-05]  gradient norm: 0.0001711970084027925\n",
            "iter: 933237  x: [ 3.9999568  15.99965437]  f(x): 1.866564693208216e-09  grad at x: [ 8.21163601e-05 -2.10650851e-05]  gradient norm: 8.4775199279816e-05\n",
            "iter: 933238  x: [ 3.9999568  15.99965437]  f(x): 1.866509829169292e-09  grad at x: [-2.63386773e-06 -1.04715054e-05]  gradient norm: 1.0797670376513019e-05\n",
            "iter: 933239  x: [ 3.9999568  15.99965438]  f(x): 1.866450833751899e-09  grad at x: [ 8.21640216e-05 -2.10707130e-05]  gradient norm: 8.482276461247286e-05\n",
            "iter: 933240  x: [ 3.9999568  15.99965438]  f(x): 1.86639590920694e-09  grad at x: [-2.63453413e-06 -1.04710925e-05]  gradient norm: 1.0797432517759699e-05\n",
            "iter: 933241  x: [ 3.9999568  15.99965439]  f(x): 1.8663369783026223e-09  grad at x: [ 8.22093256e-05 -2.10760463e-05]  gradient norm: 8.486797356384674e-05\n",
            "iter: 933242  x: [ 3.9999568  15.99965439]  f(x): 1.866281996194176e-09  grad at x: [-2.63521515e-06 -1.04706778e-05]  gradient norm: 1.0797196518248162e-05\n",
            "iter: 933243  x: [ 3.9999568 15.9996544]  f(x): 1.866223130984782e-09  grad at x: [ 8.22555316e-05 -2.10814924e-05]  gradient norm: 8.491408485989459e-05\n",
            "iter: 933244  x: [ 3.9999568 15.9996544]  f(x): 1.866168090130683e-09  grad at x: [-2.63591081e-06 -1.04702613e-05]  gradient norm: 1.079696238064536e-05\n",
            "iter: 933245  x: [ 3.9999568  15.99965441]  f(x): 1.866109291873067e-09  grad at x: [ 8.23026981e-05 -2.10870585e-05]  gradient norm: 8.49611567206492e-05\n",
            "iter: 933246  x: [ 3.9999568  15.99965441]  f(x): 1.866054191033571e-09  grad at x: [-2.63657745e-06 -1.04698483e-05]  gradient norm: 1.0796724739192619e-05\n",
            "iter: 933247  x: [ 3.99995681 15.99965442]  f(x): 1.8659954573834528e-09  grad at x: [ 8.23480018e-05 -2.10923918e-05]  gradient norm: 8.50063667697038e-05\n",
            "iter: 933248  x: [ 3.9999568  15.99965442]  f(x): 1.865940298885093e-09  grad at x: [-2.63725872e-06 -1.04694336e-05]  gradient norm: 1.0796488959905552e-05\n",
            "iter: 933249  x: [ 3.99995681 15.99965443]  f(x): 1.8658816310628177e-09  grad at x: [ 8.23942368e-05 -2.10978415e-05]  gradient norm: 8.505250828299108e-05\n",
            "iter: 933250  x: [ 3.99995681 15.99965443]  f(x): 1.8658264136837607e-09  grad at x: [-2.63792552e-06 -1.04690207e-05]  gradient norm: 1.0796251461977937e-05\n",
            "iter: 933251  x: [ 3.99995681 15.99965445]  f(x): 1.8657678105304244e-09  grad at x: [ 8.24395548e-05 -2.11031766e-05]  gradient norm: 8.509773360154029e-05\n",
            "iter: 933252  x: [ 3.99995681 15.99965445]  f(x): 1.8657125354304263e-09  grad at x: [-2.63860695e-06 -1.04686060e-05]  gradient norm: 1.0796015828507553e-05\n",
            "iter: 933253  x: [ 3.99995681 15.99965446]  f(x): 1.8656539981685614e-09  grad at x: [ 8.24857896e-05 -2.11086262e-05]  gradient norm: 8.514387585334408e-05\n",
            "iter: 933254  x: [ 3.99995681 15.99965446]  f(x): 1.8655986641236017e-09  grad at x: [-2.63927391e-06 -1.04681931e-05]  gradient norm: 1.0795778474618014e-05\n",
            "iter: 933255  x: [ 3.99995681 15.99965447]  f(x): 1.8655401916305318e-09  grad at x: [ 8.25311221e-05 -2.11139632e-05]  gradient norm: 8.518911643749571e-05\n",
            "iter: 933256  x: [ 3.99995681 15.99965447]  f(x): 1.8654847997455455e-09  grad at x: [-2.63997005e-06 -1.04677765e-05]  gradient norm: 1.0795544781617112e-05\n",
            "iter: 933257  x: [ 3.99995681 15.99965448]  f(x): 1.865426394473894e-09  grad at x: [ 8.25783318e-05 -2.11195347e-05]  gradient norm: 8.523623421162071e-05\n",
            "iter: 933258  x: [ 3.99995681 15.99965448]  f(x): 1.8653709423517243e-09  grad at x: [-2.64065172e-06 -1.04673618e-05]  gradient norm: 1.079530936867145e-05\n",
            "iter: 933259  x: [ 3.99995681 15.99965449]  f(x): 1.8653126031046955e-09  grad at x: [ 8.26245954e-05 -2.11249881e-05]  gradient norm: 8.528240667273711e-05\n",
            "iter: 933260  x: [ 3.99995681 15.99965449]  f(x): 1.8652570919034575e-09  grad at x: [-2.64131892e-06 -1.04669489e-05]  gradient norm: 1.0795072232065677e-05\n",
            "iter: 933261  x: [ 3.99995681 15.9996545 ]  f(x): 1.865198817519793e-09  grad at x: [ 8.26699277e-05 -2.11303250e-05]  gradient norm: 8.532764834318563e-05\n",
            "iter: 933262  x: [ 3.99995681 15.9996545 ]  f(x): 1.8651432484015986e-09  grad at x: [-2.64200076e-06 -1.04665341e-05]  gradient norm: 1.0794836965136158e-05\n",
            "iter: 933263  x: [ 3.99995682 15.99965451]  f(x): 1.865085040106255e-09  grad at x: [ 8.27161912e-05 -2.11357783e-05]  gradient norm: 8.537382153307194e-05\n",
            "iter: 933264  x: [ 3.99995681 15.99965451]  f(x): 1.8650294118458322e-09  grad at x: [-2.64269722e-06 -1.04661176e-05]  gradient norm: 1.0794603570770324e-05\n",
            "iter: 933265  x: [ 3.99995682 15.99965452]  f(x): 1.864971270902488e-09  grad at x: [ 8.27634150e-05 -2.11413517e-05]  gradient norm: 8.542095536770746e-05\n",
            "iter: 933266  x: [ 3.99995682 15.99965452]  f(x): 1.8649155822346656e-09  grad at x: [-2.64337922e-06 -1.04657029e-05]  gradient norm: 1.0794368451776095e-05\n",
            "iter: 933267  x: [ 3.99995682 15.99965453]  f(x): 1.8648575074446724e-09  grad at x: [ 8.28096784e-05 -2.11468050e-05]  gradient norm: 8.54671293024729e-05\n",
            "iter: 933268  x: [ 3.99995682 15.99965453]  f(x): 1.8648017595689558e-09  grad at x: [-2.64407584e-06 -1.04652863e-05]  gradient norm: 1.0794135207679981e-05\n",
            "iter: 933269  x: [ 3.99995682 15.99965454]  f(x): 1.864743752159787e-09  grad at x: [ 8.28568875e-05 -2.11523766e-05]  gradient norm: 8.551424934853991e-05\n",
            "iter: 933270  x: [ 3.99995682 15.99965454]  f(x): 1.864687943847211e-09  grad at x: [-2.64475800e-06 -1.04648716e-05]  gradient norm: 1.0793900236919098e-05\n",
            "iter: 933271  x: [ 3.99995682 15.99965455]  f(x): 1.8646300026932294e-09  grad at x: [ 8.29031798e-05 -2.11578335e-05]  gradient norm: 8.556045312465607e-05\n",
            "iter: 933272  x: [ 3.99995682 15.99965455]  f(x): 1.864574135088875e-09  grad at x: [-2.64544023e-06 -1.04644569e-05]  gradient norm: 1.0793665340117207e-05\n",
            "iter: 933273  x: [ 3.99995682 15.99965456]  f(x): 1.8645162602591354e-09  grad at x: [ 8.29495011e-05 -2.11632942e-05]  gradient norm: 8.56066863649051e-05\n",
            "iter: 933274  x: [ 3.99995682 15.99965456]  f(x): 1.864460333273867e-09  grad at x: [-2.6461080e-06 -1.0464044e-05]  gradient norm: 1.0793428712792925e-05\n",
            "iter: 933275  x: [ 3.99995682 15.99965457]  f(x): 1.8644025235657216e-09  grad at x: [ 8.29948619e-05 -2.11686347e-05]  gradient norm: 8.565195965083418e-05\n",
            "iter: 933276  x: [ 3.99995682 15.99965457]  f(x): 1.864346538403043e-09  grad at x: [-2.64679039e-06 -1.04636292e-05]  gradient norm: 1.0793193962069465e-05\n",
            "iter: 933277  x: [ 3.99995683 15.99965458]  f(x): 1.864288795082977e-09  grad at x: [ 8.30411830e-05 -2.11740953e-05]  gradient norm: 8.56981936133318e-05\n",
            "iter: 933278  x: [ 3.99995682 15.99965458]  f(x): 1.8642327504749108e-09  grad at x: [-2.64745832e-06 -1.04632163e-05]  gradient norm: 1.0792957479042404e-05\n",
            "iter: 933279  x: [ 3.99995683 15.99965459]  f(x): 1.8641750723389345e-09  grad at x: [ 8.30865436e-05 -2.11794359e-05]  gradient norm: 8.574346760115838e-05\n",
            "iter: 933280  x: [ 3.99995683 15.99965459]  f(x): 1.8641189694903274e-09  grad at x: [-2.64814087e-06 -1.04628016e-05]  gradient norm: 1.0792722874912582e-05\n",
            "iter: 933281  x: [ 3.99995683 15.9996546 ]  f(x): 1.864061357806268e-09  grad at x: [ 8.31328646e-05 -2.11848965e-05]  gradient norm: 8.578970228308101e-05\n",
            "iter: 933282  x: [ 3.99995683 15.9996546 ]  f(x): 1.8640051954478e-09  grad at x: [-2.64880896e-06 -1.04623887e-05]  gradient norm: 1.0792486536261897e-05\n",
            "iter: 933283  x: [ 3.99995683 15.99965461]  f(x): 1.863947649047265e-09  grad at x: [ 8.31782542e-05 -2.11902407e-05]  gradient norm: 8.583500607289236e-05\n",
            "iter: 933284  x: [ 3.99995683 15.99965461]  f(x): 1.8638914283481863e-09  grad at x: [-2.64949167e-06 -1.04619739e-05]  gradient norm: 1.0792252078369586e-05\n",
            "iter: 933285  x: [ 3.99995683 15.99965462]  f(x): 1.8638339485003854e-09  grad at x: [ 8.32246041e-05 -2.11957049e-05]  gradient norm: 8.588127057135806e-05\n",
            "iter: 933286  x: [ 3.99995683 15.99965462]  f(x): 1.863777668172586e-09  grad at x: [-2.65020358e-06 -1.04615556e-05]  gradient norm: 1.079202131478667e-05\n",
            "iter: 933287  x: [ 3.99995683 15.99965463]  f(x): 1.863720257314445e-09  grad at x: [ 8.32728021e-05 -2.12014002e-05]  gradient norm: 8.592938342148138e-05\n",
            "iter: 933288  x: [ 3.99995683 15.99965464]  f(x): 1.8636639149578493e-09  grad at x: [-2.65091556e-06 -1.04611372e-05]  gradient norm: 1.0791790629522196e-05\n",
            "iter: 933289  x: [ 3.99995683 15.99965465]  f(x): 1.8636065731236583e-09  grad at x: [ 8.33210145e-05 -2.12070972e-05]  gradient norm: 8.597751121772122e-05\n",
            "iter: 933290  x: [ 3.99995683 15.99965465]  f(x): 1.8635501686838977e-09  grad at x: [-2.65161307e-06 -1.04607207e-05]  gradient norm: 1.0791558209580241e-05\n",
            "iter: 933291  x: [ 3.99995683 15.99965466]  f(x): 1.8634928947052916e-09  grad at x: [ 8.33682956e-05 -2.12126779e-05]  gradient norm: 8.602470812098301e-05\n",
            "iter: 933292  x: [ 3.99995683 15.99965466]  f(x): 1.8634364293515904e-09  grad at x: [-2.65232521e-06 -1.04603023e-05]  gradient norm: 1.0791327679291603e-05\n",
            "iter: 933293  x: [ 3.99995684 15.99965467]  f(x): 1.8633792244285237e-09  grad at x: [ 8.34164933e-05 -2.12183731e-05]  gradient norm: 8.607282214580003e-05\n",
            "iter: 933294  x: [ 3.99995683 15.99965467]  f(x): 1.863322696978013e-09  grad at x: [-2.65300833e-06 -1.04598876e-05]  gradient norm: 1.0791093597784964e-05\n",
            "iter: 933295  x: [ 3.99995684 15.99965468]  f(x): 1.8632655587737544e-09  grad at x: [ 8.34628428e-05 -2.12238374e-05]  gradient norm: 8.611908850378482e-05\n",
            "iter: 933296  x: [ 3.99995684 15.99965468]  f(x): 1.863208971544265e-09  grad at x: [-2.65367698e-06 -1.04594747e-05]  gradient norm: 1.079085777478805e-05\n",
            "iter: 933297  x: [ 3.99995684 15.99965469]  f(x): 1.8631518988857777e-09  grad at x: [ 8.35082609e-05 -2.12291852e-05]  gradient norm: 8.616442390580111e-05\n",
            "iter: 933298  x: [ 3.99995684 15.99965469]  f(x): 1.8630952530512075e-09  grad at x: [-2.65436026e-06 -1.04590599e-05]  gradient norm: 1.0790623840237027e-05\n",
            "iter: 933299  x: [ 3.99995684 15.9996547 ]  f(x): 1.8630382472125714e-09  grad at x: [ 8.35546394e-05 -2.12346531e-05]  gradient norm: 8.621072007491853e-05\n",
            "iter: 933300  x: [ 3.99995684 15.9996547 ]  f(x): 1.862981541498523e-09  grad at x: [-2.65505818e-06 -1.04586434e-05]  gradient norm: 1.0790391797025682e-05\n",
            "iter: 933301  x: [ 3.99995684 15.99965471]  f(x): 1.862924603718729e-09  grad at x: [ 8.36019491e-05 -2.12402374e-05]  gradient norm: 8.625794793084544e-05\n",
            "iter: 933302  x: [ 3.99995684 15.99965471]  f(x): 1.8628678368847147e-09  grad at x: [-2.65574162e-06 -1.04582286e-05]  gradient norm: 1.0790158011353722e-05\n",
            "iter: 933303  x: [ 3.99995684 15.99965472]  f(x): 1.8628109659901072e-09  grad at x: [ 8.36483274e-05 -2.12457053e-05]  gradient norm: 8.630424482091847e-05\n",
            "iter: 933304  x: [ 3.99995684 15.99965472]  f(x): 1.862768345811122e-09  grad at x: [ 4.04959511e-05 -1.58517596e-05]  gradient norm: 4.3487933278478125e-05\n",
            "iter: 933305  x: [ 3.99995684 15.99965472]  f(x): 1.862753254429402e-09  grad at x: [-1.98180875e-06 -1.05421368e-05]  gradient norm: 1.072679888681843e-05\n",
            "iter: 933306  x: [ 3.99995685 15.99965476]  f(x): 1.8625243062300736e-09  grad at x: [ 1.68021028e-04 -3.17907852e-05]  gradient norm: 0.0001710021046424459\n",
            "iter: 933307  x: [ 3.99995685 15.99965476]  f(x): 1.8623576337209127e-09  grad at x: [ 8.20228695e-05 -2.10412200e-05]  gradient norm: 8.467871078709389e-05\n",
            "iter: 933308  x: [ 3.99995685 15.99965476]  f(x): 1.8623028945028351e-09  grad at x: [-2.63084927e-06 -1.04597038e-05]  gradient norm: 1.0785488974410196e-05\n",
            "iter: 933309  x: [ 3.99995685 15.99965477]  f(x): 1.8622440281231135e-09  grad at x: [ 8.20682870e-05 -2.10465678e-05]  gradient norm: 8.472403285356206e-05\n",
            "iter: 933310  x: [ 3.99995685 15.99965477]  f(x): 1.8621892312977445e-09  grad at x: [-2.63153320e-06 -1.04592891e-05]  gradient norm: 1.0785253624633633e-05\n",
            "iter: 933311  x: [ 3.99995685 15.99965478]  f(x): 1.862130430752915e-09  grad at x: [ 8.21146939e-05 -2.10520393e-05]  gradient norm: 8.4770344547586e-05\n",
            "iter: 933312  x: [ 3.99995685 15.99965478]  f(x): 1.8620755750293226e-09  grad at x: [-2.63220265e-06 -1.04588762e-05]  gradient norm: 1.0785016560966124e-05\n",
            "iter: 933313  x: [ 3.99995685 15.99965479]  f(x): 1.8620168391655896e-09  grad at x: [ 8.21601694e-05 -2.10573944e-05]  gradient norm: 8.481572553813494e-05\n",
            "iter: 933314  x: [ 3.99995685 15.99965479]  f(x): 1.86196192569842e-09  grad at x: [-2.63288673e-06 -1.04584615e-05]  gradient norm: 1.0784781357561449e-05\n",
            "iter: 933315  x: [ 3.99995685 15.9996548 ]  f(x): 1.8619032557336814e-09  grad at x: [ 8.22065762e-05 -2.10628659e-05]  gradient norm: 8.486203798201424e-05\n",
            "iter: 933316  x: [ 3.99995685 15.9996548 ]  f(x): 1.861848283303551e-09  grad at x: [-2.63355634e-06 -1.04580486e-05]  gradient norm: 1.0784544438478218e-05\n",
            "iter: 933317  x: [ 3.99995685 15.99965481]  f(x): 1.8617896781192343e-09  grad at x: [ 8.22520806e-05 -2.10682247e-05]  gradient norm: 8.490744880009003e-05\n",
            "iter: 933318  x: [ 3.99995685 15.99965481]  f(x): 1.8617346478455667e-09  grad at x: [-2.63424058e-06 -1.04576338e-05]  gradient norm: 1.078430938195897e-05\n",
            "iter: 933319  x: [ 3.99995686 15.99965482]  f(x): 1.8616761086243666e-09  grad at x: [ 8.22984873e-05 -2.10736962e-05]  gradient norm: 8.49537619894277e-05\n",
            "iter: 933320  x: [ 3.99995685 15.99965482]  f(x): 1.8616210193229802e-09  grad at x: [-2.63491035e-06 -1.04572209e-05]  gradient norm: 1.0784072607539458e-05\n",
            "iter: 933321  x: [ 3.99995686 15.99965483]  f(x): 1.8615625449450603e-09  grad at x: [ 8.23439916e-05 -2.10790549e-05]  gradient norm: 8.499917353660284e-05\n",
            "iter: 933322  x: [ 3.99995686 15.99965484]  f(x): 1.861507397736644e-09  grad at x: [-2.63559475e-06 -1.04568062e-05]  gradient norm: 1.0783837697551749e-05\n",
            "iter: 933323  x: [ 3.99995686 15.99965485]  f(x): 1.861448989422551e-09  grad at x: [ 8.23904271e-05 -2.10845301e-05]  gradient norm: 8.504551656733318e-05\n",
            "iter: 933324  x: [ 3.99995686 15.99965485]  f(x): 1.8613937830862402e-09  grad at x: [-2.63629379e-06 -1.04563896e-05]  gradient norm: 1.0783604655547745e-05\n",
            "iter: 933325  x: [ 3.99995686 15.99965486]  f(x): 1.8613354420584998e-09  grad at x: [ 8.24377939e-05 -2.10901217e-05]  gradient norm: 8.509279110848154e-05\n",
            "iter: 933326  x: [ 3.99995686 15.99965486]  f(x): 1.8612801753888556e-09  grad at x: [-2.63696380e-06 -1.04559767e-05]  gradient norm: 1.0783368099901024e-05\n",
            "iter: 933327  x: [ 3.99995686 15.99965487]  f(x): 1.8612218992988365e-09  grad at x: [ 8.24833125e-05 -2.10954822e-05]  gradient norm: 8.513821830409367e-05\n",
            "iter: 933328  x: [ 3.99995686 15.99965487]  f(x): 1.861166574607024e-09  grad at x: [-2.63763389e-06 -1.04555638e-05]  gradient norm: 1.0783131616060474e-05\n",
            "iter: 933329  x: [ 3.99995686 15.99965488]  f(x): 1.861108363486696e-09  grad at x: [ 8.25288165e-05 -2.11008410e-05]  gradient norm: 8.51836313082165e-05\n",
            "iter: 933330  x: [ 3.99995686 15.99965488]  f(x): 1.861052980760173e-09  grad at x: [-2.63831862e-06 -1.04551491e-05]  gradient norm: 1.0782897000842772e-05\n",
            "iter: 933331  x: [ 3.99995686 15.99965489]  f(x): 1.8609948359068705e-09  grad at x: [ 8.25752954e-05 -2.11063216e-05]  gradient norm: 8.523001947458969e-05\n",
            "iter: 933332  x: [ 3.99995686 15.99965489]  f(x): 1.8609393938479856e-09  grad at x: [-2.63901798e-06 -1.04547325e-05]  gradient norm: 1.0782664257802012e-05\n",
            "iter: 933333  x: [ 3.99995686 15.9996549 ]  f(x): 1.8608813164494157e-09  grad at x: [ 8.26226910e-05 -2.11119168e-05]  gradient norm: 8.527732463587671e-05\n",
            "iter: 933334  x: [ 3.99995686 15.9996549 ]  f(x): 1.860825813868973e-09  grad at x: [-2.63970286e-06 -1.04543178e-05]  gradient norm: 1.078242979185724e-05\n",
            "iter: 933335  x: [ 3.99995687 15.99965491]  f(x): 1.8607678027655281e-09  grad at x: [ 8.26691552e-05 -2.11173956e-05]  gradient norm: 8.532369900771309e-05\n",
            "iter: 933336  x: [ 3.99995686 15.99965491]  f(x): 1.8607122408239895e-09  grad at x: [-2.64040238e-06 -1.04539013e-05]  gradient norm: 1.0782197199781689e-05\n",
            "iter: 933337  x: [ 3.99995687 15.99965492]  f(x): 1.8606542972421913e-09  grad at x: [ 8.27165506e-05 -2.11229908e-05]  gradient norm: 8.537100493747187e-05\n",
            "iter: 933338  x: [ 3.99995687 15.99965492]  f(x): 1.8605986747115455e-09  grad at x: [-2.64108743e-06 -1.04534865e-05]  gradient norm: 1.0781962882973682e-05\n",
            "iter: 933339  x: [ 3.99995687 15.99965493]  f(x): 1.860540797527209e-09  grad at x: [ 8.27630437e-05 -2.11284732e-05]  gradient norm: 8.541740916003547e-05\n",
            "iter: 933340  x: [ 3.99995687 15.99965493]  f(x): 1.8604851155324962e-09  grad at x: [-2.64178711e-06 -1.04530700e-05]  gradient norm: 1.0781730442380005e-05\n",
            "iter: 933341  x: [ 3.99995687 15.99965494]  f(x): 1.8604273059367411e-09  grad at x: [ 8.28104390e-05 -2.11340684e-05]  gradient norm: 8.546471585719868e-05\n",
            "iter: 933342  x: [ 3.99995687 15.99965494]  f(x): 1.860371563285351e-09  grad at x: [-2.64247231e-06 -1.04526553e-05]  gradient norm: 1.07814962745723e-05\n",
            "iter: 933343  x: [ 3.99995687 15.99965495]  f(x): 1.8603138201527009e-09  grad at x: [ 8.28569320e-05 -2.11395509e-05]  gradient norm: 8.551112082899988e-05\n",
            "iter: 933344  x: [ 3.99995687 15.99965495]  f(x): 1.8602580179709659e-09  grad at x: [-2.64317215e-06 -1.04522387e-05]  gradient norm: 1.0781263985324732e-05\n",
            "iter: 933345  x: [ 3.99995687 15.99965496]  f(x): 1.8602003425306492e-09  grad at x: [ 8.29043562e-05 -2.11451497e-05]  gradient norm: 8.555845738890169e-05\n",
            "iter: 933346  x: [ 3.99995687 15.99965496]  f(x): 1.8601444795878503e-09  grad at x: [-2.64385752e-06 -1.04518240e-05]  gradient norm: 1.0781029967033823e-05\n",
            "iter: 933347  x: [ 3.99995687 15.99965497]  f(x): 1.8600868706763013e-09  grad at x: [ 8.29508490e-05 -2.11506322e-05]  gradient norm: 8.560486310549859e-05\n",
            "iter: 933348  x: [ 3.99995687 15.99965497]  f(x): 1.8600309481171203e-09  grad at x: [-2.64454297e-06 -1.04514093e-05]  gradient norm: 1.0780796022578941e-05\n",
            "iter: 933349  x: [ 3.99995688 15.99965498]  f(x): 1.859973405766842e-09  grad at x: [ 8.29973417e-05 -2.11561146e-05]  gradient norm: 8.565126919001092e-05\n",
            "iter: 933350  x: [ 3.99995687 15.99965498]  f(x): 1.8599174235782001e-09  grad at x: [-2.64524305e-06 -1.04509927e-05]  gradient norm: 1.0780563959867772e-05\n",
            "iter: 933351  x: [ 3.99995688 15.99965499]  f(x): 1.8598599490572935e-09  grad at x: [ 8.30447948e-05 -2.11617171e-05]  gradient norm: 8.569863599028746e-05\n",
            "iter: 933352  x: [ 3.99995688 15.99965499]  f(x): 1.8598039059881616e-09  grad at x: [-2.64591411e-06 -1.04505798e-05]  gradient norm: 1.0780328356782762e-05\n",
            "iter: 933353  x: [ 3.99995688 15.999655  ]  f(x): 1.859746496894127e-09  grad at x: [ 8.30903706e-05 -2.11670849e-05]  gradient norm: 8.574412611161091e-05\n",
            "iter: 933354  x: [ 3.99995688 15.999655  ]  f(x): 1.8596903953095585e-09  grad at x: [-2.64658524e-06 -1.04501669e-05]  gradient norm: 1.0780092825762198e-05\n",
            "iter: 933355  x: [ 3.99995688 15.99965501]  f(x): 1.859633051674302e-09  grad at x: [ 8.31359317e-05 -2.11724509e-05]  gradient norm: 8.578960203326337e-05\n",
            "iter: 933356  x: [ 3.99995688 15.99965501]  f(x): 1.8595768915618129e-09  grad at x: [-2.64727101e-06 -1.04497522e-05]  gradient norm: 1.0779859177342917e-05\n",
            "iter: 933357  x: [ 3.99995688 15.99965502]  f(x): 1.8595196146910847e-09  grad at x: [ 8.31824823e-05 -2.11779407e-05]  gradient norm: 8.583606777752998e-05\n",
            "iter: 933358  x: [ 3.99995688 15.99965502]  f(x): 1.8594633947434324e-09  grad at x: [-2.64794231e-06 -1.04493392e-05]  gradient norm: 1.077962379152569e-05\n",
            "iter: 933359  x: [ 3.99995688 15.99965503]  f(x): 1.8594061834315189e-09  grad at x: [ 8.32280724e-05 -2.11833103e-05]  gradient norm: 8.588157350420875e-05\n",
            "iter: 933360  x: [ 3.99995688 15.99965504]  f(x): 1.859349904855275e-09  grad at x: [-2.64862824e-06 -1.04489245e-05]  gradient norm: 1.0779390290618186e-05\n",
            "iter: 933361  x: [ 3.99995688 15.99965505]  f(x): 1.8592927603353928e-09  grad at x: [ 8.32745937e-05 -2.11887964e-05]  gradient norm: 8.592801086589797e-05\n",
            "iter: 933362  x: [ 3.99995688 15.99965505]  f(x): 1.8592364218958476e-09  grad at x: [-2.64929970e-06 -1.04485116e-05]  gradient norm: 1.0779155050520139e-05\n",
            "iter: 933363  x: [ 3.99995688 15.99965506]  f(x): 1.8591793430348979e-09  grad at x: [ 8.33202127e-05 -2.11941697e-05]  gradient norm: 8.597354639758696e-05\n",
            "iter: 933364  x: [ 3.99995688 15.99965506]  f(x): 1.8591229458474495e-09  grad at x: [-2.65000034e-06 -1.04480951e-05]  gradient norm: 1.0778923511625143e-05\n",
            "iter: 933365  x: [ 3.99995689 15.99965507]  f(x): 1.8590659350839372e-09  grad at x: [ 8.33676798e-05 -2.11997740e-05]  gradient norm: 8.602093033284526e-05\n",
            "iter: 933366  x: [ 3.99995688 15.99965507]  f(x): 1.8590094767283248e-09  grad at x: [-2.65071562e-06 -1.04476767e-05]  gradient norm: 1.0778693864551184e-05\n",
            "iter: 933367  x: [ 3.99995689 15.99965508]  f(x): 1.8589525352995127e-09  grad at x: [ 8.34160927e-05 -2.12054965e-05]  gradient norm: 8.6069260511538e-05\n",
            "iter: 933368  x: [ 3.99995689 15.99965508]  f(x): 1.8588960145369796e-09  grad at x: [-2.65141642e-06 -1.04472601e-05]  gradient norm: 1.0778462479601738e-05\n",
            "iter: 933369  x: [ 3.99995689 15.99965509]  f(x): 1.8588391412734676e-09  grad at x: [ 8.34635742e-05 -2.12111026e-05]  gradient norm: 8.611665976442502e-05\n",
            "iter: 933370  x: [ 3.99995689 15.99965509]  f(x): 1.858782559292831e-09  grad at x: [-2.65211730e-06 -1.04468436e-05]  gradient norm: 1.0778231171019143e-05\n",
            "iter: 933371  x: [ 3.99995689 15.9996551 ]  f(x): 1.8587257542279339e-09  grad at x: [ 8.35110701e-05 -2.12167106e-05]  gradient norm: 8.616407394688133e-05\n",
            "iter: 933372  x: [ 3.99995689 15.9996551 ]  f(x): 1.858669110957269e-09  grad at x: [-2.65281827e-06 -1.04464270e-05]  gradient norm: 1.077799993904252e-05\n",
            "iter: 933373  x: [ 3.99995689 15.99965511]  f(x): 1.858612374125517e-09  grad at x: [ 8.35585514e-05 -2.12223167e-05]  gradient norm: 8.621147395304073e-05\n",
            "iter: 933374  x: [ 3.99995689 15.99965511]  f(x): 1.8585698455594416e-09  grad at x: [ 4.04525233e-05 -1.58341645e-05]  gradient norm: 4.344107973706905e-05\n",
            "iter: 933375  x: [ 3.99995689 15.99965511]  f(x): 1.8585547867857374e-09  grad at x: [-1.97960144e-06 -1.05302461e-05]  gradient norm: 1.0714705045966304e-05\n",
            "iter: 933376  x: [ 3.9999569  15.99965515]  f(x): 1.8583263729241727e-09  grad at x: [ 1.67838660e-04 -3.17558242e-05]  gradient norm: 0.000170816416481683\n",
            "iter: 933377  x: [ 3.9999569  15.99965515]  f(x): 1.858160062209099e-09  grad at x: [ 8.19338675e-05 -2.10179296e-05]  gradient norm: 8.4586712964882e-05\n",
            "iter: 933378  x: [ 3.99995689 15.99965515]  f(x): 1.858105441924707e-09  grad at x: [-2.62795524e-06 -1.04479004e-05]  gradient norm: 1.077333615786669e-05\n",
            "iter: 933379  x: [ 3.9999569  15.99965516]  f(x): 1.8580467141543666e-09  grad at x: [ 8.19804025e-05 -2.10234175e-05]  gradient norm: 8.463315237603494e-05\n",
            "iter: 933380  x: [ 3.9999569  15.99965516]  f(x): 1.8579920349266683e-09  grad at x: [-2.62862758e-06 -1.04474875e-05]  gradient norm: 1.0773099751310973e-05\n",
            "iter: 933381  x: [ 3.9999569  15.99965517]  f(x): 1.8579333719096322e-09  grad at x: [ 8.20260352e-05 -2.10287926e-05]  gradient norm: 8.467869019065654e-05\n",
            "iter: 933382  x: [ 3.9999569  15.99965517]  f(x): 1.8578786348350102e-09  grad at x: [-2.62930000e-06 -1.04470746e-05]  gradient norm: 1.0772863416864533e-05\n",
            "iter: 933383  x: [ 3.9999569  15.99965518]  f(x): 1.8578200366763886e-09  grad at x: [ 8.20717115e-05 -2.10341732e-05]  gradient norm: 8.472427201642173e-05\n",
            "iter: 933384  x: [ 3.9999569  15.99965518]  f(x): 1.8577652416691419e-09  grad at x: [-2.62998705e-06 -1.04466599e-05]  gradient norm: 1.0772628943452565e-05\n",
            "iter: 933385  x: [ 3.9999569  15.99965519]  f(x): 1.857706709585837e-09  grad at x: [ 8.21183190e-05 -2.10396702e-05]  gradient norm: 8.477078529865132e-05\n",
            "iter: 933386  x: [ 3.9999569  15.99965519]  f(x): 1.8576518554275794e-09  grad at x: [-2.63065963e-06 -1.04462470e-05]  gradient norm: 1.0772392754518281e-05\n",
            "iter: 933387  x: [ 3.9999569 15.9996552]  f(x): 1.8575933882660483e-09  grad at x: [ 8.21639951e-05 -2.10450507e-05]  gradient norm: 8.48163678620447e-05\n",
            "iter: 933388  x: [ 3.9999569 15.9996552]  f(x): 1.8575384760914486e-09  grad at x: [-2.63133229e-06 -1.04458341e-05]  gradient norm: 1.0772156637752685e-05\n",
            "iter: 933389  x: [ 3.9999569  15.99965521]  f(x): 1.8574800739204413e-09  grad at x: [ 8.22096857e-05 -2.10504331e-05]  gradient norm: 8.486196533806725e-05\n",
            "iter: 933390  x: [ 3.9999569  15.99965521]  f(x): 1.857425103680158e-09  grad at x: [-2.63201958e-06 -1.04454193e-05]  gradient norm: 1.0771922385153743e-05\n",
            "iter: 933391  x: [ 3.99995691 15.99965522]  f(x): 1.8573667676811512e-09  grad at x: [ 8.22562930e-05 -2.10559301e-05]  gradient norm: 8.490847974768568e-05\n",
            "iter: 933392  x: [ 3.9999569  15.99965522]  f(x): 1.8573117382119444e-09  grad at x: [-2.63270696e-06 -1.04450046e-05]  gradient norm: 1.0771688207035641e-05\n",
            "iter: 933393  x: [ 3.99995691 15.99965523]  f(x): 1.8572534684167407e-09  grad at x: [ 8.23029148e-05 -2.10614289e-05]  gradient norm: 8.49550090859451e-05\n",
            "iter: 933394  x: [ 3.99995691 15.99965523]  f(x): 1.857198379648214e-09  grad at x: [-2.63339441e-06 -1.04445899e-05]  gradient norm: 1.0771454102984428e-05\n",
            "iter: 933395  x: [ 3.99995691 15.99965525]  f(x): 1.857140176126923e-09  grad at x: [ 8.23495510e-05 -2.10669295e-05]  gradient norm: 8.500155335249586e-05\n",
            "iter: 933396  x: [ 3.99995691 15.99965525]  f(x): 1.8570850279886508e-09  grad at x: [-2.63408194e-06 -1.04441751e-05]  gradient norm: 1.0771220073454474e-05\n",
            "iter: 933397  x: [ 3.99995691 15.99965526]  f(x): 1.857026890737388e-09  grad at x: [ 8.23961581e-05 -2.10724265e-05]  gradient norm: 8.504806890040914e-05\n",
            "iter: 933398  x: [ 3.99995691 15.99965526]  f(x): 1.8569716832514914e-09  grad at x: [-2.63475501e-06 -1.04437622e-05]  gradient norm: 1.0770984322336425e-05\n",
            "iter: 933399  x: [ 3.99995691 15.99965527]  f(x): 1.856913611185994e-09  grad at x: [ 8.24418919e-05 -2.10778144e-05]  gradient norm: 8.509371186758213e-05\n",
            "iter: 933400  x: [ 3.99995691 15.99965527]  f(x): 1.856858345437588e-09  grad at x: [-2.63544270e-06 -1.04433475e-05]  gradient norm: 1.0770750440654458e-05\n",
            "iter: 933401  x: [ 3.99995691 15.99965528]  f(x): 1.8568003397434612e-09  grad at x: [ 8.24885279e-05 -2.10833150e-05]  gradient norm: 8.51402572605058e-05\n",
            "iter: 933402  x: [ 3.99995691 15.99965528]  f(x): 1.8567450145640045e-09  grad at x: [-2.63610137e-06 -1.04429364e-05]  gradient norm: 1.0770513037418367e-05\n",
            "iter: 933403  x: [ 3.99995691 15.99965529]  f(x): 1.8566870728910385e-09  grad at x: [ 8.25333011e-05 -2.10885828e-05]  gradient norm: 8.51849406873123e-05\n",
            "iter: 933404  x: [ 3.99995691 15.99965529]  f(x): 1.8566316905759424e-09  grad at x: [-2.63680378e-06 -1.04425199e-05]  gradient norm: 1.0770281101614345e-05\n",
            "iter: 933405  x: [ 3.99995691 15.9996553 ]  f(x): 1.8565738165672217e-09  grad at x: [ 8.25808974e-05 -2.10942035e-05]  gradient norm: 8.523244709304537e-05\n",
            "iter: 933406  x: [ 3.99995691 15.9996553 ]  f(x): 1.8565183735090169e-09  grad at x: [-2.63749171e-06 -1.04421051e-05]  gradient norm: 1.0770047442265704e-05\n",
            "iter: 933407  x: [ 3.99995692 15.99965531]  f(x): 1.8564605660058375e-09  grad at x: [ 8.26275623e-05 -2.10997077e-05]  gradient norm: 8.527902270327641e-05\n",
            "iter: 933408  x: [ 3.99995691 15.99965531]  f(x): 1.85640506336291e-09  grad at x: [-2.63816518e-06 -1.04416922e-05]  gradient norm: 1.0769812056276875e-05\n",
            "iter: 933409  x: [ 3.99995692 15.99965532]  f(x): 1.8563473212045813e-09  grad at x: [ 8.26732957e-05 -2.11050956e-05]  gradient norm: 8.532466749324809e-05\n",
            "iter: 933410  x: [ 3.99995692 15.99965532]  f(x): 1.8562917601384754e-09  grad at x: [-2.63885327e-06 -1.04412775e-05]  gradient norm: 1.0769578544977326e-05\n",
            "iter: 933411  x: [ 3.99995692 15.99965533]  f(x): 1.8562340845505194e-09  grad at x: [ 8.27199604e-05 -2.11105998e-05]  gradient norm: 8.537124384448342e-05\n",
            "iter: 933412  x: [ 3.99995692 15.99965533]  f(x): 1.8561784638342256e-09  grad at x: [-2.63952689e-06 -1.04408646e-05]  gradient norm: 1.0769343305019712e-05\n",
            "iter: 933413  x: [ 3.99995692 15.99965534]  f(x): 1.856120853654639e-09  grad at x: [ 8.27656937e-05 -2.11159877e-05]  gradient norm: 8.54168893553424e-05\n",
            "iter: 933414  x: [ 3.99995692 15.99965534]  f(x): 1.8560651744324686e-09  grad at x: [-2.6402297e-06 -1.0440448e-05]  gradient norm: 1.0769111745794563e-05\n",
            "iter: 933415  x: [ 3.99995692 15.99965535]  f(x): 1.8560076321202745e-09  grad at x: [ 8.28133187e-05 -2.11216120e-05]  gradient norm: 8.546442676563135e-05\n",
            "iter: 933416  x: [ 3.99995692 15.99965535]  f(x): 1.8559518919502627e-09  grad at x: [-2.64091804e-06 -1.04400333e-05]  gradient norm: 1.0768878458169497e-05\n",
            "iter: 933417  x: [ 3.99995692 15.99965536]  f(x): 1.8558944163067018e-09  grad at x: [ 8.28599831e-05 -2.11271163e-05]  gradient norm: 8.551100423593254e-05\n",
            "iter: 933418  x: [ 3.99995692 15.99965536]  f(x): 1.8558386163687465e-09  grad at x: [-2.64160646e-06 -1.04396186e-05]  gradient norm: 1.0768645245070449e-05\n",
            "iter: 933419  x: [ 3.99995692 15.99965537]  f(x): 1.855781207463384e-09  grad at x: [ 8.29066766e-05 -2.11326242e-05]  gradient norm: 8.555761117661346e-05\n",
            "iter: 933420  x: [ 3.99995692 15.99965537]  f(x): 1.8557253477258647e-09  grad at x: [-2.64229495e-06 -1.04392038e-05]  gradient norm: 1.0768412106735528e-05\n",
            "iter: 933421  x: [ 3.99995693 15.99965538]  f(x): 1.8556680055539382e-09  grad at x: [ 8.29533555e-05 -2.11381303e-05]  gradient norm: 8.560420393980572e-05\n",
            "iter: 933422  x: [ 3.99995692 15.99965538]  f(x): 1.8556120859830399e-09  grad at x: [-2.64298353e-06 -1.04387891e-05]  gradient norm: 1.0768179042967097e-05\n",
            "iter: 933423  x: [ 3.99995693 15.99965539]  f(x): 1.8555548106524348e-09  grad at x: [ 8.30000633e-05 -2.11436400e-05]  gradient norm: 8.565082617269892e-05\n",
            "iter: 933424  x: [ 3.99995693 15.99965539]  f(x): 1.855498831158498e-09  grad at x: [-2.64365764e-06 -1.04383762e-05]  gradient norm: 1.0767944244424922e-05\n",
            "iter: 933425  x: [ 3.99995693 15.9996554 ]  f(x): 1.8554416215026076e-09  grad at x: [ 8.30458543e-05 -2.11490351e-05]  gradient norm: 8.569653206308226e-05\n",
            "iter: 933426  x: [ 3.99995693 15.9996554 ]  f(x): 1.855385583234555e-09  grad at x: [-2.64436092e-06 -1.04379596e-05]  gradient norm: 1.076771313942853e-05\n",
            "iter: 933427  x: [ 3.99995693 15.99965541]  f(x): 1.855328441646759e-09  grad at x: [ 8.30934788e-05 -2.11546594e-05]  gradient norm: 8.574407174786753e-05\n",
            "iter: 933428  x: [ 3.99995693 15.99965541]  f(x): 1.8552723422468037e-09  grad at x: [-2.64503519e-06 -1.04375467e-05]  gradient norm: 1.0767478488258357e-05\n",
            "iter: 933429  x: [ 3.99995693 15.99965542]  f(x): 1.8552152663604433e-09  grad at x: [ 8.31392551e-05 -2.11600527e-05]  gradient norm: 8.5789763808537e-05\n",
            "iter: 933430  x: [ 3.99995693 15.99965542]  f(x): 1.855159108157844e-09  grad at x: [-2.64570954e-06 -1.04371338e-05]  gradient norm: 1.0767243909674649e-05\n",
            "iter: 933431  x: [ 3.99995693 15.99965543]  f(x): 1.855102098079611e-09  grad at x: [ 8.31850604e-05 -2.11654497e-05]  gradient norm: 8.583548532087684e-05\n",
            "iter: 933432  x: [ 3.99995693 15.99965543]  f(x): 1.8550458809685356e-09  grad at x: [-2.64641307e-06 -1.04367173e-05]  gradient norm: 1.0767013030680558e-05\n",
            "iter: 933433  x: [ 3.99995693 15.99965544]  f(x): 1.8549889390950756e-09  grad at x: [ 8.32327138e-05 -2.11710776e-05]  gradient norm: 8.588305522814381e-05\n",
            "iter: 933434  x: [ 3.99995693 15.99965545]  f(x): 1.8549326606959277e-09  grad at x: [-2.64710213e-06 -1.04363025e-05]  gradient norm: 1.0766780414131274e-05\n",
            "iter: 933435  x: [ 3.99995693 15.99965546]  f(x): 1.854875785859366e-09  grad at x: [ 8.32794358e-05 -2.11765891e-05]  gradient norm: 8.592969421366992e-05\n",
            "iter: 933436  x: [ 3.99995693 15.99965546]  f(x): 1.8548194473408787e-09  grad at x: [-2.64780582e-06 -1.04358860e-05]  gradient norm: 1.0766549688110728e-05\n",
            "iter: 933437  x: [ 3.99995694 15.99965547]  f(x): 1.8547626407761259e-09  grad at x: [ 8.33271035e-05 -2.11822189e-05]  gradient norm: 8.597727943036484e-05\n",
            "iter: 933438  x: [ 3.99995693 15.99965547]  f(x): 1.8547062408821828e-09  grad at x: [-2.64848048e-06 -1.04354731e-05]  gradient norm: 1.0766315405395008e-05\n",
            "iter: 933439  x: [ 3.99995694 15.99965548]  f(x): 1.8546495002172896e-09  grad at x: [ 8.3372894e-05 -2.1187614e-05]  gradient norm: 8.602298783170872e-05\n",
            "iter: 933440  x: [ 3.99995694 15.99965548]  f(x): 1.8545930413404133e-09  grad at x: [-2.64916978e-06 -1.04350584e-05]  gradient norm: 1.076608301324853e-05\n",
            "iter: 933441  x: [ 3.99995694 15.99965549]  f(x): 1.8545363678856048e-09  grad at x: [ 8.34196593e-05 -2.11931310e-05]  gradient norm: 8.606967156656884e-05\n",
            "iter: 933442  x: [ 3.99995694 15.99965549]  f(x): 1.8544798486967173e-09  grad at x: [-2.64988827e-06 -1.04346400e-05]  gradient norm: 1.0765854333559615e-05\n",
            "iter: 933443  x: [ 3.99995694 15.9996555 ]  f(x): 1.854423244856632e-09  grad at x: [ 8.34682727e-05 -2.11988790e-05]  gradient norm: 8.611820379352285e-05\n",
            "iter: 933444  x: [ 3.99995694 15.9996555 ]  f(x): 1.854380808294453e-09  grad at x: [ 4.04088548e-05 -1.58165531e-05]  gradient norm: 4.3393996065813566e-05\n",
            "iter: 933445  x: [ 3.99995694 15.9996555 ]  f(x): 1.8543657822201626e-09  grad at x: [-1.97741659e-06 -1.05183663e-05]  gradient norm: 1.0702626078499078e-05\n",
            "iter: 933446  x: [ 3.99995695 15.99965554]  f(x): 1.8541379147855508e-09  grad at x: [ 1.67661669e-04 -3.17215490e-05]  gradient norm: 0.00017063613851371352\n",
            "iter: 933447  x: [ 3.99995694 15.99965554]  f(x): 1.8539719549360762e-09  grad at x: [ 8.18474916e-05 -2.09949812e-05]  gradient norm: 8.44973438224944e-05\n",
            "iter: 933448  x: [ 3.99995694 15.99965554]  f(x): 1.8539174501531814e-09  grad at x: [-2.62506909e-06 -1.04361097e-05]  gradient norm: 1.0761197612733075e-05\n",
            "iter: 933449  x: [ 3.99995695 15.99965555]  f(x): 1.8538588609993416e-09  grad at x: [ 8.18928885e-05 -2.10003273e-05]  gradient norm: 8.45426456786359e-05\n",
            "iter: 933450  x: [ 3.99995694 15.99965555]  f(x): 1.8538042987574129e-09  grad at x: [-2.62574439e-06 -1.04356968e-05]  gradient norm: 1.0760961935452515e-05\n",
            "iter: 933451  x: [ 3.99995695 15.99965556]  f(x): 1.8537457745717345e-09  grad at x: [ 8.19387366e-05 -2.10057296e-05]  gradient norm: 8.45883988874586e-05\n",
            "iter: 933452  x: [ 3.99995695 15.99965556]  f(x): 1.853691154257506e-09  grad at x: [-2.62644888e-06 -1.04352803e-05]  gradient norm: 1.0760729906335844e-05\n",
            "iter: 933453  x: [ 3.99995695 15.99965557]  f(x): 1.8536326974388772e-09  grad at x: [ 8.19864472e-05 -2.10113649e-05]  gradient norm: 8.463601463612778e-05\n",
            "iter: 933454  x: [ 3.99995695 15.99965557]  f(x): 1.8535780166890524e-09  grad at x: [-2.62712435e-06 -1.04348674e-05]  gradient norm: 1.076049437669904e-05\n",
            "iter: 933455  x: [ 3.99995695 15.99965558]  f(x): 1.8535196249021755e-09  grad at x: [ 8.20323096e-05 -2.10167691e-05]  gradient norm: 8.468178314781164e-05\n",
            "iter: 933456  x: [ 3.99995695 15.99965558]  f(x): 1.8534648859961265e-09  grad at x: [-2.62781445e-06 -1.04344526e-05]  gradient norm: 1.0760260709111367e-05\n",
            "iter: 933457  x: [ 3.99995695 15.99965559]  f(x): 1.8534065604958237e-09  grad at x: [ 8.20791032e-05 -2.10222897e-05]  gradient norm: 8.472848313236733e-05\n",
            "iter: 933458  x: [ 3.99995695 15.99965559]  f(x): 1.8533517622166515e-09  grad at x: [-2.62851918e-06 -1.04340361e-05]  gradient norm: 1.0760028907587252e-05\n",
            "iter: 933459  x: [ 3.99995695 15.9996556 ]  f(x): 1.8532935042206173e-09  grad at x: [ 8.21268427e-05 -2.10279286e-05]  gradient norm: 8.477612916190165e-05\n",
            "iter: 933460  x: [ 3.99995695 15.9996556 ]  f(x): 1.853238645349144e-09  grad at x: [-2.62920944e-06 -1.04336214e-05]  gradient norm: 1.0759795390891549e-05\n",
            "iter: 933461  x: [ 3.99995695 15.99965561]  f(x): 1.8531804536679868e-09  grad at x: [ 8.21736362e-05 -2.10334492e-05]  gradient norm: 8.482282992359727e-05\n",
            "iter: 933462  x: [ 3.99995695 15.99965561]  f(x): 1.8531255353747536e-09  grad at x: [-2.62989978e-06 -1.04332066e-05]  gradient norm: 1.0759561948934248e-05\n",
            "iter: 933463  x: [ 3.99995696 15.99965562]  f(x): 1.8530674101161518e-09  grad at x: [ 8.22204588e-05 -2.10389735e-05]  gradient norm: 8.486956016808488e-05\n",
            "iter: 933464  x: [ 3.99995695 15.99965562]  f(x): 1.8530124323116977e-09  grad at x: [-2.63057564e-06 -1.04327937e-05]  gradient norm: 1.0759326787675535e-05\n",
            "iter: 933465  x: [ 3.99995696 15.99965563]  f(x): 1.8529543722836016e-09  grad at x: [ 8.22663353e-05 -2.10443795e-05]  gradient norm: 8.491534510833348e-05\n",
            "iter: 933466  x: [ 3.99995696 15.99965563]  f(x): 1.852899336160827e-09  grad at x: [-2.63126614e-06 -1.04323790e-05]  gradient norm: 1.0759093494430071e-05\n",
            "iter: 933467  x: [ 3.99995696 15.99965564]  f(x): 1.8528413425457697e-09  grad at x: [ 8.23131286e-05 -2.10499002e-05]  gradient norm: 8.496204701096903e-05\n",
            "iter: 933468  x: [ 3.99995696 15.99965564]  f(x): 1.8527862469021257e-09  grad at x: [-2.63195672e-06 -1.04319643e-05]  gradient norm: 1.075886027598375e-05\n",
            "iter: 933469  x: [ 3.99995696 15.99965565]  f(x): 1.8527283198070182e-09  grad at x: [ 8.23599654e-05 -2.10554263e-05]  gradient norm: 8.500879294222924e-05\n",
            "iter: 933470  x: [ 3.99995696 15.99965566]  f(x): 1.852673164535279e-09  grad at x: [-2.63264738e-06 -1.04315495e-05]  gradient norm: 1.0758627132356827e-05\n",
            "iter: 933471  x: [ 3.99995696 15.99965567]  f(x): 1.8526153040305272e-09  grad at x: [ 8.24068167e-05 -2.10609542e-05]  gradient norm: 8.505555380597648e-05\n",
            "iter: 933472  x: [ 3.99995696 15.99965567]  f(x): 1.8525600890982e-09  grad at x: [-2.63333813e-06 -1.04311348e-05]  gradient norm: 1.0758394063786965e-05\n",
            "iter: 933473  x: [ 3.99995696 15.99965568]  f(x): 1.8525022951419712e-09  grad at x: [ 8.24536389e-05 -2.10664784e-05]  gradient norm: 8.510228595053491e-05\n",
            "iter: 933474  x: [ 3.99995696 15.99965568]  f(x): 1.8524470205326455e-09  grad at x: [-2.63401439e-06 -1.04307219e-05]  gradient norm: 1.0758159270603231e-05\n",
            "iter: 933475  x: [ 3.99995696 15.99965569]  f(x): 1.8523892920043974e-09  grad at x: [ 8.24995441e-05 -2.10718881e-05]  gradient norm: 8.514810184385311e-05\n",
            "iter: 933476  x: [ 3.99995696 15.99965569]  f(x): 1.8523339588776965e-09  grad at x: [-2.63470529e-06 -1.04303072e-05]  gradient norm: 1.0757926350730018e-05\n",
            "iter: 933477  x: [ 3.99995696 15.9996557 ]  f(x): 1.852276297038146e-09  grad at x: [ 8.25463952e-05 -2.10774160e-05]  gradient norm: 8.519486383793533e-05\n",
            "iter: 933478  x: [ 3.99995696 15.9996557 ]  f(x): 1.8522209041330368e-09  grad at x: [-2.63541083e-06 -1.04298906e-05]  gradient norm: 1.0757695307318695e-05\n",
            "iter: 933479  x: [ 3.99995697 15.99965571]  f(x): 1.8521633101692534e-09  grad at x: [ 8.25941775e-05 -2.10830603e-05]  gradient norm: 8.524255740857768e-05\n",
            "iter: 933480  x: [ 3.99995696 15.99965571]  f(x): 1.8521078562774837e-09  grad at x: [-2.63608734e-06 -1.04294777e-05]  gradient norm: 1.07574607359228e-05\n",
            "iter: 933481  x: [ 3.99995697 15.99965572]  f(x): 1.852050327838684e-09  grad at x: [ 8.26400825e-05 -2.10884700e-05]  gradient norm: 8.528837441037015e-05\n",
            "iter: 933482  x: [ 3.99995697 15.99965572]  f(x): 1.851994815313062e-09  grad at x: [-2.63679303e-06 -1.04290611e-05]  gradient norm: 1.0757229844461313e-05\n",
            "iter: 933483  x: [ 3.99995697 15.99965573]  f(x): 1.8519373548923189e-09  grad at x: [ 8.26878938e-05 -2.10941180e-05]  gradient norm: 8.533609785341635e-05\n",
            "iter: 933484  x: [ 3.99995697 15.99965573]  f(x): 1.8518817812753368e-09  grad at x: [-2.63746970e-06 -1.04286482e-05]  gradient norm: 1.075699542109747e-05\n",
            "iter: 933485  x: [ 3.99995697 15.99965574]  f(x): 1.851824386443523e-09  grad at x: [ 8.27338132e-05 -2.10995295e-05]  gradient norm: 8.538193014367966e-05\n",
            "iter: 933486  x: [ 3.99995697 15.99965574]  f(x): 1.8517687541084164e-09  grad at x: [-2.63816100e-06 -1.04282335e-05]  gradient norm: 1.0756762876147123e-05\n",
            "iter: 933487  x: [ 3.99995697 15.99965575]  f(x): 1.8517114261296463e-09  grad at x: [ 8.27806785e-05 -2.11050592e-05]  gradient norm: 8.542870857488294e-05\n",
            "iter: 933488  x: [ 3.99995697 15.99965575]  f(x): 1.851655733867558e-09  grad at x: [-2.63882328e-06 -1.04278224e-05]  gradient norm: 1.0756526793127974e-05\n",
            "iter: 933489  x: [ 3.99995697 15.99965576]  f(x): 1.8515984704204765e-09  grad at x: [ 8.28257100e-05 -2.11103597e-05]  gradient norm: 8.547365399993502e-05\n",
            "iter: 933490  x: [ 3.99995697 15.99965576]  f(x): 1.851542720498046e-09  grad at x: [-2.63952929e-06 -1.04274059e-05]  gradient norm: 1.0756296203900563e-05\n",
            "iter: 933491  x: [ 3.99995697 15.99965577]  f(x): 1.85148552516501e-09  grad at x: [ 8.28735064e-05 -2.11160059e-05]  gradient norm: 8.55213644130531e-05\n",
            "iter: 933492  x: [ 3.99995697 15.99965577]  f(x): 1.851429714035441e-09  grad at x: [-2.64022083e-06 -1.04269911e-05]  gradient norm: 1.0756063883190091e-05\n",
            "iter: 933493  x: [ 3.99995697 15.99965578]  f(x): 1.8513725856907285e-09  grad at x: [ 8.29204005e-05 -2.11215392e-05]  gradient norm: 8.556817306113017e-05\n",
            "iter: 933494  x: [ 3.99995697 15.99965578]  f(x): 1.8513167144794252e-09  grad at x: [-2.64089790e-06 -1.04265782e-05]  gradient norm: 1.0755829827882536e-05\n",
            "iter: 933495  x: [ 3.99995698 15.99965579]  f(x): 1.8512596519585351e-09  grad at x: [ 8.29663632e-05 -2.11269562e-05]  gradient norm: 8.561405081545922e-05\n",
            "iter: 933496  x: [ 3.99995697 15.99965579]  f(x): 1.8512037218123343e-09  grad at x: [-2.64160416e-06 -1.04261617e-05]  gradient norm: 1.075559946719576e-05\n",
            "iter: 933497  x: [ 3.99995698 15.9996558 ]  f(x): 1.8511467275434924e-09  grad at x: [ 8.30141884e-05 -2.11326060e-05]  gradient norm: 8.566179147411875e-05\n",
            "iter: 933498  x: [ 3.99995698 15.9996558 ]  f(x): 1.851090736051201e-09  grad at x: [-2.64229594e-06 -1.04257470e-05]  gradient norm: 1.0755367371952593e-05\n",
            "iter: 933499  x: [ 3.99995698 15.99965581]  f(x): 1.8510338088699054e-09  grad at x: [ 8.30610823e-05 -2.11381393e-05]  gradient norm: 8.570860124098704e-05\n",
            "iter: 933500  x: [ 3.99995698 15.99965581]  f(x): 1.8509777571771884e-09  grad at x: [-2.64298780e-06 -1.04253322e-05]  gradient norm: 1.0755135351833136e-05\n",
            "iter: 933501  x: [ 3.99995698 15.99965582]  f(x): 1.8509208971534223e-09  grad at x: [ 8.31080052e-05 -2.11436763e-05]  gradient norm: 8.575544047989223e-05\n",
            "iter: 933502  x: [ 3.99995698 15.99965582]  f(x): 1.8508647851899826e-09  grad at x: [-2.64367975e-06 -1.04249175e-05]  gradient norm: 1.0754903406857676e-05\n",
            "iter: 933503  x: [ 3.99995698 15.99965583]  f(x): 1.8508079923199325e-09  grad at x: [ 8.31548989e-05 -2.11492097e-05]  gradient norm: 8.580225098917923e-05\n",
            "iter: 933504  x: [ 3.99995698 15.99965583]  f(x): 1.8507518201274773e-09  grad at x: [-2.64437177e-06 -1.04245028e-05]  gradient norm: 1.0754671537264894e-05\n",
            "iter: 933505  x: [ 3.99995698 15.99965584]  f(x): 1.8506950944811658e-09  grad at x: [ 8.32018216e-05 -2.11547467e-05]  gradient norm: 8.584909096955327e-05\n",
            "iter: 933506  x: [ 3.99995698 15.99965584]  f(x): 1.85063886193263e-09  grad at x: [-2.64507842e-06 -1.04240862e-05]  gradient norm: 1.0754441558808729e-05\n",
            "iter: 933507  x: [ 3.99995698 15.99965585]  f(x): 1.8505822047447577e-09  grad at x: [ 8.32496755e-05 -2.11604001e-05]  gradient norm: 8.589686263622799e-05\n",
            "iter: 933508  x: [ 3.99995698 15.99965585]  f(x): 1.8505259106606756e-09  grad at x: [-2.64575606e-06 -1.04236733e-05]  gradient norm: 1.0754208023653735e-05\n",
            "iter: 933509  x: [ 3.99995699 15.99965586]  f(x): 1.8504693195235899e-09  grad at x: [ 8.32956522e-05 -2.11658189e-05]  gradient norm: 8.594275748716408e-05\n",
            "iter: 933510  x: [ 3.99995698 15.99965587]  f(x): 1.8504129662557492e-09  grad at x: [-2.64644832e-06 -1.04232586e-05]  gradient norm: 1.0753976379675954e-05\n",
            "iter: 933511  x: [ 3.99995699 15.99965588]  f(x): 1.8503564424793468e-09  grad at x: [ 8.33425892e-05 -2.11713577e-05]  gradient norm: 8.598961312629532e-05\n",
            "iter: 933512  x: [ 3.99995699 15.99965588]  f(x): 1.8503000287372282e-09  grad at x: [-2.64716977e-06 -1.04228402e-05]  gradient norm: 1.0753748449362137e-05\n",
            "iter: 933513  x: [ 3.99995699 15.99965588]  f(x): 1.8502576820640044e-09  grad at x: [ 4.03721168e-05 -1.57999857e-05]  gradient norm: 4.335374681778997e-05\n",
            "iter: 933514  x: [ 3.99995699 15.99965588]  f(x): 1.850242684172606e-09  grad at x: [-1.97532985e-06 -1.05066520e-05]  gradient norm: 1.069072791891763e-05\n",
            "iter: 933515  x: [ 3.99995699 15.99965592]  f(x): 1.8500153987243983e-09  grad at x: [ 1.67504414e-04 -3.16899186e-05]  gradient norm: 0.0001704757448447366\n",
            "iter: 933516  x: [ 3.99995699 15.99965592]  f(x): 1.849849750826074e-09  grad at x: [ 8.17708549e-05 -2.09734280e-05]  gradient norm: 8.441775524907274e-05\n",
            "iter: 933517  x: [ 3.99995699 15.99965592]  f(x): 1.8497953489738863e-09  grad at x: [-2.62238275e-06 -1.04244718e-05]  gradient norm: 1.074925599209691e-05\n",
            "iter: 933518  x: [ 3.99995699 15.99965593]  f(x): 1.8497369090623128e-09  grad at x: [ 8.18167583e-05 -2.09788377e-05]  gradient norm: 8.446356358735713e-05\n",
            "iter: 933519  x: [ 3.99995699 15.99965593]  f(x): 1.8496824491722332e-09  grad at x: [-2.62304642e-06 -1.04240607e-05]  gradient norm: 1.0749019257504103e-05\n",
            "iter: 933520  x: [ 3.999957   15.99965594]  f(x): 1.8496240731957933e-09  grad at x: [ 8.18618467e-05 -2.09841455e-05]  gradient norm: 8.450855760158207e-05\n",
            "iter: 933521  x: [ 3.99995699 15.99965594]  f(x): 1.8495695562549335e-09  grad at x: [-2.62373929e-06 -1.04236460e-05]  gradient norm: 1.0748786170292092e-05\n",
            "iter: 933522  x: [ 3.999957   15.99965595]  f(x): 1.8495112466455909e-09  grad at x: [ 8.19088268e-05 -2.09896898e-05]  gradient norm: 8.455544324269653e-05\n",
            "iter: 933523  x: [ 3.999957   15.99965595]  f(x): 1.849456670239024e-09  grad at x: [-2.62441768e-06 -1.04232331e-05]  gradient norm: 1.0748551369285147e-05\n",
            "iter: 933524  x: [ 3.999957   15.99965596]  f(x): 1.849398425846782e-09  grad at x: [ 8.19548754e-05 -2.09951177e-05]  gradient norm: 8.460139817827379e-05\n",
            "iter: 933525  x: [ 3.999957   15.99965596]  f(x): 1.8493437910871582e-09  grad at x: [-2.62511070e-06 -1.04228184e-05]  gradient norm: 1.074831843130192e-05\n",
            "iter: 933526  x: [ 3.999957   15.99965597]  f(x): 1.8492856130913293e-09  grad at x: [ 8.20018263e-05 -2.10006583e-05]  gradient norm: 8.46482554964063e-05\n",
            "iter: 933527  x: [ 3.999957   15.99965598]  f(x): 1.8492309188545656e-09  grad at x: [-2.62577470e-06 -1.04224073e-05]  gradient norm: 1.0748081986077789e-05\n",
            "iter: 933528  x: [ 3.999957   15.99965599]  f(x): 1.8491728049548476e-09  grad at x: [ 8.20469580e-05 -2.10059716e-05]  gradient norm: 8.46932946194898e-05\n",
            "iter: 933529  x: [ 3.999957   15.99965599]  f(x): 1.8491180534853875e-09  grad at x: [-2.62645333e-06 -1.04219944e-05]  gradient norm: 1.0747847404134033e-05\n",
            "iter: 933530  x: [ 3.999957 15.999656]  f(x): 1.8490600049357206e-09  grad at x: [ 8.20930209e-05 -2.10114013e-05]  gradient norm: 8.473926521869079e-05\n",
            "iter: 933531  x: [ 3.999957 15.999656]  f(x): 1.8490051950175023e-09  grad at x: [-2.62714659e-06 -1.04215796e-05]  gradient norm: 1.0747614688791082e-05\n",
            "iter: 933532  x: [ 3.999957   15.99965601]  f(x): 1.8489472129609264e-09  grad at x: [ 8.21399861e-05 -2.10169437e-05]  gradient norm: 8.478613822177098e-05\n",
            "iter: 933533  x: [ 3.999957   15.99965601]  f(x): 1.8488923434297494e-09  grad at x: [-2.62781083e-06 -1.04211686e-05]  gradient norm: 1.0747378460100343e-05\n",
            "iter: 933534  x: [ 3.999957   15.99965602]  f(x): 1.8488344256376883e-09  grad at x: [ 8.21851466e-05 -2.10222606e-05]  gradient norm: 8.483120752972495e-05\n",
            "iter: 933535  x: [ 3.999957   15.99965602]  f(x): 1.8487794987241468e-09  grad at x: [-2.62850425e-06 -1.04207538e-05]  gradient norm: 1.0747145893140109e-05\n",
            "iter: 933536  x: [ 3.99995701 15.99965603]  f(x): 1.848721647564114e-09  grad at x: [ 8.22321553e-05 -2.10278085e-05]  gradient norm: 8.48781249350415e-05\n",
            "iter: 933537  x: [ 3.999957   15.99965603]  f(x): 1.848666660917724e-09  grad at x: [-2.62918320e-06 -1.04203409e-05]  gradient norm: 1.0746911605094529e-05\n",
            "iter: 933538  x: [ 3.99995701 15.99965604]  f(x): 1.8486088752351734e-09  grad at x: [ 8.22782325e-05 -2.10332400e-05]  gradient norm: 8.49241115697685e-05\n",
            "iter: 933539  x: [ 3.99995701 15.99965604]  f(x): 1.8485538299928222e-09  grad at x: [-2.62989133e-06 -1.04199244e-05]  gradient norm: 1.0746680985265992e-05\n",
            "iter: 933540  x: [ 3.99995701 15.99965605]  f(x): 1.8484961121965647e-09  grad at x: [ 8.23261723e-05 -2.10389044e-05]  gradient norm: 8.49719609042392e-05\n",
            "iter: 933541  x: [ 3.99995701 15.99965605]  f(x): 1.8484410059664682e-09  grad at x: [-2.63058500e-06 -1.04195096e-05]  gradient norm: 1.0746448644392956e-05\n",
            "iter: 933542  x: [ 3.99995701 15.99965606]  f(x): 1.8483833549385392e-09  grad at x: [ 8.23732098e-05 -2.10444559e-05]  gradient norm: 8.501890856350434e-05\n",
            "iter: 933543  x: [ 3.99995701 15.99965606]  f(x): 1.8483281888198376e-09  grad at x: [-2.63127874e-06 -1.04190949e-05]  gradient norm: 1.0746216378850677e-05\n",
            "iter: 933544  x: [ 3.99995701 15.99965607]  f(x): 1.8482706045569157e-09  grad at x: [ 8.24202181e-05 -2.10500039e-05]  gradient norm: 8.50658275079545e-05\n",
            "iter: 933545  x: [ 3.99995701 15.99965607]  f(x): 1.8482153785711226e-09  grad at x: [-2.63195801e-06 -1.04186820e-05]  gradient norm: 1.0745982388110917e-05\n",
            "iter: 933546  x: [ 3.99995701 15.99965608]  f(x): 1.8481578599526147e-09  grad at x: [ 8.24663241e-05 -2.10554390e-05]  gradient norm: 8.511184474323479e-05\n",
            "iter: 933547  x: [ 3.99995701 15.99965608]  f(x): 1.8481025751829937e-09  grad at x: [-2.63265191e-06 -1.04182673e-05]  gradient norm: 1.0745750272242474e-05\n",
            "iter: 933548  x: [ 3.99995701 15.99965609]  f(x): 1.84804512343197e-09  grad at x: [ 8.25133613e-05 -2.10609905e-05]  gradient norm: 8.515879354531843e-05\n",
            "iter: 933549  x: [ 3.99995701 15.99965609]  f(x): 1.847989778693319e-09  grad at x: [-2.63336045e-06 -1.04178507e-05]  gradient norm: 1.0745520034629723e-05\n",
            "iter: 933550  x: [ 3.99995701 15.9996561 ]  f(x): 1.847932394997428e-09  grad at x: [ 8.25613153e-05 -2.10666567e-05]  gradient norm: 8.520665938605055e-05\n",
            "iter: 933551  x: [ 3.99995701 15.9996561 ]  f(x): 1.8478769890809383e-09  grad at x: [-2.63403996e-06 -1.04174378e-05]  gradient norm: 1.074528626713657e-05\n",
            "iter: 933552  x: [ 3.99995702 15.99965611]  f(x): 1.8478196711647238e-09  grad at x: [ 8.26074356e-05 -2.10720937e-05]  gradient norm: 8.525269229073597e-05\n",
            "iter: 933553  x: [ 3.99995701 15.99965611]  f(x): 1.8477642063663808e-09  grad at x: [-2.63473410e-06 -1.04170231e-05]  gradient norm: 1.0745054377722319e-05\n",
            "iter: 933554  x: [ 3.99995702 15.99965612]  f(x): 1.8477069554167561e-09  grad at x: [ 8.26544871e-05 -2.10776470e-05]  gradient norm: 8.529965678439655e-05\n",
            "iter: 933555  x: [ 3.99995702 15.99965612]  f(x): 1.8476514305111526e-09  grad at x: [-2.63544288e-06 -1.04166065e-05]  gradient norm: 1.0744824369554959e-05\n",
            "iter: 933556  x: [ 3.99995702 15.99965613]  f(x): 1.847594247793391e-09  grad at x: [ 8.27024700e-05 -2.10833168e-05]  gradient norm: 8.53475528937859e-05\n",
            "iter: 933557  x: [ 3.99995702 15.99965613]  f(x): 1.8475386615704504e-09  grad at x: [-2.63612263e-06 -1.04161936e-05]  gradient norm: 1.0744590825273097e-05\n",
            "iter: 933558  x: [ 3.99995702 15.99965614]  f(x): 1.8474815446920873e-09  grad at x: [ 8.27485900e-05 -2.10887538e-05]  gradient norm: 8.539358691208741e-05\n",
            "iter: 933559  x: [ 3.99995702 15.99965614]  f(x): 1.8474258995069508e-09  grad at x: [-2.63680246e-06 -1.04157807e-05]  gradient norm: 1.0744357354405562e-05\n",
            "iter: 933560  x: [ 3.99995702 15.99965615]  f(x): 1.8473688485374368e-09  grad at x: [ 8.27947245e-05 -2.10941926e-05]  gradient norm: 8.543963584224238e-05\n",
            "iter: 933561  x: [ 3.99995702 15.99965615]  f(x): 1.8473131443018378e-09  grad at x: [-2.63749692e-06 -1.04153660e-05]  gradient norm: 1.074412576587569e-05\n",
            "iter: 933562  x: [ 3.99995702 15.99965616]  f(x): 1.847256160468945e-09  grad at x: [ 8.28417903e-05 -2.10997478e-05]  gradient norm: 8.548661639282254e-05\n",
            "iter: 933563  x: [ 3.99995702 15.99965616]  f(x): 1.847200396010301e-09  grad at x: [-2.63816236e-06 -1.04149549e-05]  gradient norm: 1.0743890633211397e-05\n",
            "iter: 933564  x: [ 3.99995702 15.99965617]  f(x): 1.8471434769544818e-09  grad at x: [ 8.28869934e-05 -2.11050701e-05]  gradient norm: 8.553173478445892e-05\n",
            "iter: 933565  x: [ 3.99995702 15.99965617]  f(x): 1.8470876545765219e-09  grad at x: [-2.63884244e-06 -1.04145420e-05]  gradient norm: 1.0743657382706663e-05\n",
            "iter: 933566  x: [ 3.99995703 15.99965618]  f(x): 1.8470308015623784e-09  grad at x: [ 8.29331568e-05 -2.11105125e-05]  gradient norm: 8.557781389694083e-05\n",
            "iter: 933567  x: [ 3.99995702 15.99965619]  f(x): 1.8469749200383579e-09  grad at x: [-2.63953714e-06 -1.04141272e-05]  gradient norm: 1.074342601790871e-05\n",
            "iter: 933568  x: [ 3.99995703 15.9996562 ]  f(x): 1.8469181342956662e-09  grad at x: [ 8.29802514e-05 -2.11160714e-05]  gradient norm: 8.562482465331153e-05\n",
            "iter: 933569  x: [ 3.99995703 15.9996562 ]  f(x): 1.8468621923573248e-09  grad at x: [-2.64024647e-06 -1.04137107e-05]  gradient norm: 1.074319654177041e-05\n",
            "iter: 933570  x: [ 3.99995703 15.99965621]  f(x): 1.8468054750809956e-09  grad at x: [ 8.30282482e-05 -2.11217430e-05]  gradient norm: 8.567273797767856e-05\n",
            "iter: 933571  x: [ 3.99995703 15.99965621]  f(x): 1.8467494715886032e-09  grad at x: [-2.64092679e-06 -1.04132978e-05]  gradient norm: 1.0742963515118844e-05\n",
            "iter: 933572  x: [ 3.99995703 15.99965622]  f(x): 1.8466928204520107e-09  grad at x: [ 8.30744114e-05 -2.11271854e-05]  gradient norm: 8.571881819051697e-05\n",
            "iter: 933573  x: [ 3.99995703 15.99965622]  f(x): 1.846636757676383e-09  grad at x: [-2.64162173e-06 -1.04128831e-05]  gradient norm: 1.0742732377167717e-05\n",
            "iter: 933574  x: [ 3.99995703 15.99965623]  f(x): 1.8465801739482242e-09  grad at x: [ 8.31215349e-05 -2.11327479e-05]  gradient norm: 8.576585917341163e-05\n",
            "iter: 933575  x: [ 3.99995703 15.99965623]  f(x): 1.8465240506573447e-09  grad at x: [-2.64230220e-06 -1.04124701e-05]  gradient norm: 1.0742499498894886e-05\n",
            "iter: 933576  x: [ 3.99995703 15.99965624]  f(x): 1.846467533133676e-09  grad at x: [ 8.31676979e-05 -2.11381903e-05]  gradient norm: 8.58119401082941e-05\n",
            "iter: 933577  x: [ 3.99995703 15.99965624]  f(x): 1.8464113504941805e-09  grad at x: [-2.64299731e-06 -1.04120554e-05]  gradient norm: 1.0742268511226118e-05\n",
            "iter: 933578  x: [ 3.99995703 15.99965625]  f(x): 1.8463549004826233e-09  grad at x: [ 8.32148358e-05 -2.11437546e-05]  gradient norm: 8.585899638249964e-05\n",
            "iter: 933579  x: [ 3.99995703 15.99965625]  f(x): 1.8462986572432359e-09  grad at x: [-2.64369249e-06 -1.04116407e-05]  gradient norm: 1.0742037599472992e-05\n",
            "iter: 933580  x: [ 3.99995703 15.99965626]  f(x): 1.8462422746650979e-09  grad at x: [ 8.32619155e-05 -2.11493116e-05]  gradient norm: 8.590599482005424e-05\n",
            "iter: 933581  x: [ 3.99995703 15.99965626]  f(x): 1.8461859708660315e-09  grad at x: [-2.64438775e-06 -1.04112260e-05]  gradient norm: 1.0741806763437445e-05\n",
            "iter: 933582  x: [ 3.99995703 15.99965626]  f(x): 1.8461437215816508e-09  grad at x: [ 4.03323182e-05 -1.57830491e-05]  gradient norm: 4.331051289299061e-05\n",
            "iter: 933583  x: [ 3.99995703 15.99965626]  f(x): 1.8461287538026518e-09  grad at x: [-1.97321871e-06 -1.04949540e-05]  gradient norm: 1.0678841341240898e-05\n",
            "iter: 933584  x: [ 3.99995704 15.9996563 ]  f(x): 1.8459020311365939e-09  grad at x: [ 1.67340402e-04 -3.16574569e-05]  gradient norm: 0.00017030855751821617\n",
            "iter: 933585  x: [ 3.99995704 15.99965631]  f(x): 1.8457367080435292e-09  grad at x: [ 8.16908812e-05 -2.09514710e-05]  gradient norm: 8.433483386809786e-05\n",
            "iter: 933586  x: [ 3.99995704 15.99965631]  f(x): 1.84568241323536e-09  grad at x: [-2.61964289e-06 -1.04128540e-05]  gradient norm: 1.0737320724199217e-05\n",
            "iter: 933587  x: [ 3.99995704 15.99965632]  f(x): 1.8456241176227626e-09  grad at x: [ 8.17370872e-05 -2.09569189e-05]  gradient norm: 8.43809449875667e-05\n",
            "iter: 933588  x: [ 3.99995704 15.99965632]  f(x): 1.84556976445664e-09  grad at x: [-2.62032404e-06 -1.04124410e-05]  gradient norm: 1.073708650190995e-05\n",
            "iter: 933589  x: [ 3.99995704 15.99965633]  f(x): 1.845511534143354e-09  grad at x: [ 8.17833078e-05 -2.09623686e-05]  gradient norm: 8.442707103281972e-05\n",
            "iter: 933590  x: [ 3.99995704 15.99965633]  f(x): 1.8454571225496247e-09  grad at x: [-2.62100527e-06 -1.04120281e-05]  gradient norm: 1.0736852353333188e-05\n",
            "iter: 933591  x: [ 3.99995704 15.99965634]  f(x): 1.8453989575677722e-09  grad at x: [ 8.18295282e-05 -2.09678183e-05]  gradient norm: 8.44731974537872e-05\n",
            "iter: 933592  x: [ 3.99995704 15.99965634]  f(x): 1.8453444875324945e-09  grad at x: [-2.62167203e-06 -1.04116170e-05]  gradient norm: 1.0736616488680304e-05\n",
            "iter: 933593  x: [ 3.99995705 15.99965635]  f(x): 1.8452863867321585e-09  grad at x: [ 8.18748172e-05 -2.09731515e-05]  gradient norm: 8.45183931549684e-05\n",
            "iter: 933594  x: [ 3.99995704 15.99965635]  f(x): 1.8452318593679447e-09  grad at x: [-2.62235342e-06 -1.04112041e-05]  gradient norm: 1.0736382486122675e-05\n",
            "iter: 933595  x: [ 3.99995705 15.99965636]  f(x): 1.845173823999894e-09  grad at x: [ 8.19210521e-05 -2.09786031e-05]  gradient norm: 8.456453486989594e-05\n",
            "iter: 933596  x: [ 3.99995705 15.99965636]  f(x): 1.8451192380938145e-09  grad at x: [-2.62304944e-06 -1.04107894e-05]  gradient norm: 1.0736150348561018e-05\n",
            "iter: 933597  x: [ 3.99995705 15.99965637]  f(x): 1.8450612693353888e-09  grad at x: [ 8.19682182e-05 -2.09841710e-05]  gradient norm: 8.46116080758045e-05\n",
            "iter: 933598  x: [ 3.99995705 15.99965637]  f(x): 1.8450066236901305e-09  grad at x: [-2.62374554e-06 -1.04103747e-05]  gradient norm: 1.0735918286660436e-05\n",
            "iter: 933599  x: [ 3.99995705 15.99965638]  f(x): 1.8449487215756608e-09  grad at x: [ 8.20153696e-05 -2.09897371e-05]  gradient norm: 8.465866712532795e-05\n",
            "iter: 933600  x: [ 3.99995705 15.99965638]  f(x): 1.8448940161565788e-09  grad at x: [-2.62444172e-06 -1.04099599e-05]  gradient norm: 1.073568630044139e-05\n",
            "iter: 933601  x: [ 3.99995705 15.99965639]  f(x): 1.844836180755955e-09  grad at x: [ 8.20625501e-05 -2.09953068e-05]  gradient norm: 8.470575566332772e-05\n",
            "iter: 933602  x: [ 3.99995705 15.99965639]  f(x): 1.8447814155113357e-09  grad at x: [-2.62512343e-06 -1.04095470e-05]  gradient norm: 1.0735452595326139e-05\n",
            "iter: 933603  x: [ 3.99995705 15.9996564 ]  f(x): 1.8447236456726862e-09  grad at x: [ 8.21087992e-05 -2.10007602e-05]  gradient norm: 8.475191345033687e-05\n",
            "iter: 933604  x: [ 3.99995705 15.9996564 ]  f(x): 1.8446688217171044e-09  grad at x: [-2.62581978e-06 -1.04091323e-05]  gradient norm: 1.073522075969584e-05\n",
            "iter: 933605  x: [ 3.99995705 15.99965641]  f(x): 1.8446111186950917e-09  grad at x: [ 8.21560086e-05 -2.10063336e-05]  gradient norm: 8.47990318584439e-05\n",
            "iter: 933606  x: [ 3.99995705 15.99965641]  f(x): 1.8445562348105516e-09  grad at x: [-2.62650165e-06 -1.04087194e-05]  gradient norm: 1.0734987202906645e-05\n",
            "iter: 933607  x: [ 3.99995705 15.99965642]  f(x): 1.844498597415513e-09  grad at x: [ 8.22022575e-05 -2.10117869e-05]  gradient norm: 8.48451903990257e-05\n",
            "iter: 933608  x: [ 3.99995705 15.99965642]  f(x): 1.8444436547728719e-09  grad at x: [-2.62718360e-06 -1.04083065e-05]  gradient norm: 1.0734753719793973e-05\n",
            "iter: 933609  x: [ 3.99995706 15.99965643]  f(x): 1.8443860830734952e-09  grad at x: [ 8.22485355e-05 -2.10172439e-05]  gradient norm: 8.489137840930133e-05\n",
            "iter: 933610  x: [ 3.99995705 15.99965643]  f(x): 1.8443310815852631e-09  grad at x: [-2.62788018e-06 -1.04078918e-05]  gradient norm: 1.0734522109129467e-05\n",
            "iter: 933611  x: [ 3.99995706 15.99965644]  f(x): 1.8442735768017501e-09  grad at x: [ 8.22957447e-05 -2.10228172e-05]  gradient norm: 8.493849796865625e-05\n",
            "iter: 933612  x: [ 3.99995706 15.99965644]  f(x): 1.8442185152843882e-09  grad at x: [-2.62856229e-06 -1.04074788e-05]  gradient norm: 1.0734288774681233e-05\n",
            "iter: 933613  x: [ 3.99995706 15.99965645]  f(x): 1.8441610762615976e-09  grad at x: [ 8.23420225e-05 -2.10282742e-05]  gradient norm: 8.498468672881686e-05\n",
            "iter: 933614  x: [ 3.99995706 15.99965645]  f(x): 1.8441059558699302e-09  grad at x: [-2.62922993e-06 -1.04070677e-05]  gradient norm: 1.0734053712933079e-05\n",
            "iter: 933615  x: [ 3.99995706 15.99965646]  f(x): 1.8440485814133867e-09  grad at x: [ 8.23873543e-05 -2.10336129e-05]  gradient norm: 8.502993011552407e-05\n",
            "iter: 933616  x: [ 3.99995706 15.99965646]  f(x): 1.843993403304601e-09  grad at x: [-2.62991220e-06 -1.04066548e-05]  gradient norm: 1.0733820524944617e-05\n",
            "iter: 933617  x: [ 3.99995706 15.99965647]  f(x): 1.8439360947098896e-09  grad at x: [ 8.24336464e-05 -2.10390717e-05]  gradient norm: 8.50761341551803e-05\n",
            "iter: 933618  x: [ 3.99995706 15.99965647]  f(x): 1.8438808576262265e-09  grad at x: [-2.63060910e-06 -1.04062401e-05]  gradient norm: 1.0733589213620567e-05\n",
            "iter: 933619  x: [ 3.99995706 15.99965648]  f(x): 1.8438236161154407e-09  grad at x: [ 8.24808844e-05 -2.10446487e-05]  gradient norm: 8.512328432522096e-05\n",
            "iter: 933620  x: [ 3.99995706 15.99965648]  f(x): 1.8437683188148389e-09  grad at x: [-2.63130608e-06 -1.04058254e-05]  gradient norm: 1.0733357978181852e-05\n",
            "iter: 933621  x: [ 3.99995706 15.99965649]  f(x): 1.8437111443475053e-09  grad at x: [ 8.25280787e-05 -2.10502203e-05]  gradient norm: 8.517039122849802e-05\n",
            "iter: 933622  x: [ 3.99995706 15.99965649]  f(x): 1.8436557868504716e-09  grad at x: [-2.63198859e-06 -1.04054125e-05]  gradient norm: 1.0733125013435334e-05\n",
            "iter: 933623  x: [ 3.99995707 15.9996565 ]  f(x): 1.843598678379609e-09  grad at x: [ 8.25743997e-05 -2.10556827e-05]  gradient norm: 8.521662548822167e-05\n",
            "iter: 933624  x: [ 3.99995706 15.9996565 ]  f(x): 1.8435432617721152e-09  grad at x: [-2.63268573e-06 -1.04049977e-05]  gradient norm: 1.0732893928992168e-05\n",
            "iter: 933625  x: [ 3.99995707 15.99965651]  f(x): 1.8434862204851968e-09  grad at x: [ 8.26216374e-05 -2.10612598e-05]  gradient norm: 8.526377680219933e-05\n",
            "iter: 933626  x: [ 3.99995707 15.99965652]  f(x): 1.8434307435413206e-09  grad at x: [-2.63339751e-06 -1.04045812e-05]  gradient norm: 1.0732664727382492e-05\n",
            "iter: 933627  x: [ 3.99995707 15.99965653]  f(x): 1.8433737706652262e-09  grad at x: [ 8.26698064e-05 -2.10669532e-05]  gradient norm: 8.531185974383359e-05\n",
            "iter: 933628  x: [ 3.99995707 15.99965653]  f(x): 1.8433182321947389e-09  grad at x: [-2.63409481e-06 -1.04041665e-05]  gradient norm: 1.0732433795689907e-05\n",
            "iter: 933629  x: [ 3.99995707 15.99965654]  f(x): 1.843261326607133e-09  grad at x: [ 8.27170731e-05 -2.10725339e-05]  gradient norm: 8.535904093227488e-05\n",
            "iter: 933630  x: [ 3.99995707 15.99965654]  f(x): 1.8432057277135728e-09  grad at x: [-2.63479219e-06 -1.04037517e-05]  gradient norm: 1.073220293998506e-05\n",
            "iter: 933631  x: [ 3.99995707 15.99965655]  f(x): 1.8431488893738692e-09  grad at x: [ 8.27642961e-05 -2.10781091e-05]  gradient norm: 8.540617884862847e-05\n",
            "iter: 933632  x: [ 3.99995707 15.99965655]  f(x): 1.843093230079028e-09  grad at x: [-2.63550420e-06 -1.04033352e-05]  gradient norm: 1.0731973970577154e-05\n",
            "iter: 933633  x: [ 3.99995707 15.99965656]  f(x): 1.8430364603277927e-09  grad at x: [ 8.28125085e-05 -2.10838080e-05]  gradient norm: 8.545430662102772e-05\n",
            "iter: 933634  x: [ 3.99995707 15.99965656]  f(x): 1.8429807393277513e-09  grad at x: [-2.63620174e-06 -1.04029205e-05]  gradient norm: 1.0731743267964306e-05\n",
            "iter: 933635  x: [ 3.99995707 15.99965657]  f(x): 1.8429240369664885e-09  grad at x: [ 8.28597749e-05 -2.10893886e-05]  gradient norm: 8.550148896068328e-05\n",
            "iter: 933636  x: [ 3.99995707 15.99965657]  f(x): 1.8428682554594265e-09  grad at x: [-2.63688481e-06 -1.04025075e-05]  gradient norm: 1.0731510829220071e-05\n",
            "iter: 933637  x: [ 3.99995707 15.99965658]  f(x): 1.8428116192875973e-09  grad at x: [ 8.29060954e-05 -2.10948510e-05]  gradient norm: 8.554772584077362e-05\n",
            "iter: 933638  x: [ 3.99995707 15.99965658]  f(x): 1.8427557784552588e-09  grad at x: [-2.63756796e-06 -1.04020946e-05]  gradient norm: 1.0731278464236558e-05\n",
            "iter: 933639  x: [ 3.99995708 15.99965659]  f(x): 1.8426992085426077e-09  grad at x: [ 8.29524304e-05 -2.11003153e-05]  gradient norm: 8.559397763190271e-05\n",
            "iter: 933640  x: [ 3.99995707 15.99965659]  f(x): 1.8426433082964575e-09  grad at x: [-2.63826575e-06 -1.04016799e-05]  gradient norm: 1.0731047987722334e-05\n",
            "iter: 933641  x: [ 3.99995708 15.9996566 ]  f(x): 1.8425868059476107e-09  grad at x: [ 8.29997402e-05 -2.11059014e-05]  gradient norm: 8.56412047462599e-05\n",
            "iter: 933642  x: [ 3.99995708 15.9996566 ]  f(x): 1.842530845019663e-09  grad at x: [-2.63894906e-06 -1.04012670e-05]  gradient norm: 1.0730815772011143e-05\n",
            "iter: 933643  x: [ 3.99995708 15.99965661]  f(x): 1.842474408957745e-09  grad at x: [ 8.30460605e-05 -2.11113638e-05]  gradient norm: 8.568744271604969e-05\n",
            "iter: 933644  x: [ 3.99995708 15.99965661]  f(x): 1.8424183886060838e-09  grad at x: [-2.63963245e-06 -1.04008541e-05]  gradient norm: 1.0730583630120849e-05\n",
            "iter: 933645  x: [ 3.99995708 15.99965662]  f(x): 1.8423620189377683e-09  grad at x: [ 8.30924243e-05 -2.11168317e-05]  gradient norm: 8.573372470181313e-05\n",
            "iter: 933646  x: [ 3.99995708 15.99965662]  f(x): 1.8423059390369303e-09  grad at x: [-2.64033047e-06 -1.04004394e-05]  gradient norm: 1.0730353379888029e-05\n",
            "iter: 933647  x: [ 3.99995708 15.99965663]  f(x): 1.8422496370320418e-09  grad at x: [ 8.31397339e-05 -2.11224178e-05]  gradient norm: 8.578095292853099e-05\n",
            "iter: 933648  x: [ 3.99995708 15.99965663]  f(x): 1.8421934963500119e-09  grad at x: [-2.64104312e-06 -1.04000228e-05]  gradient norm: 1.0730125024719497e-05\n",
            "iter: 933649  x: [ 3.99995708 15.99965664]  f(x): 1.842137263167823e-09  grad at x: [ 8.31879457e-05 -2.11281167e-05]  gradient norm: 8.582908376731075e-05\n",
            "iter: 933650  x: [ 3.99995708 15.99965664]  f(x): 1.8420951110314134e-09  grad at x: [ 4.02731022e-05 -1.57638624e-05]  gradient norm: 4.324837703792896e-05\n",
            "iter: 933651  x: [ 3.99995708 15.99965664]  f(x): 1.8420801855617363e-09  grad at x: [-1.97082124e-06 -1.04834689e-05]  gradient norm: 1.066711101491514e-05\n",
            "iter: 933652  x: [ 3.99995709 15.99965668]  f(x): 1.8418538052998324e-09  grad at x: [ 1.67096582e-04 -3.16151963e-05]  gradient norm: 0.00017006113088961273\n",
            "iter: 933653  x: [ 3.99995709 15.99965668]  f(x): 1.8416889620642462e-09  grad at x: [ 8.15716119e-05 -2.09247792e-05]  gradient norm: 8.42126727536902e-05\n",
            "iter: 933654  x: [ 3.99995709 15.99965668]  f(x): 1.8416348238366045e-09  grad at x: [-2.61629638e-06 -1.04014889e-05]  gradient norm: 1.0725482658483745e-05\n",
            "iter: 933655  x: [ 3.99995709 15.99965669]  f(x): 1.8415766178347383e-09  grad at x: [ 8.16171893e-05 -2.09301488e-05]  gradient norm: 8.425815524703339e-05\n",
            "iter: 933656  x: [ 3.99995709 15.99965669]  f(x): 1.8415224220978499e-09  grad at x: [-2.61698041e-06 -1.04010760e-05]  gradient norm: 1.0725249104625372e-05\n",
            "iter: 933657  x: [ 3.99995709 15.9996567 ]  f(x): 1.8414642815126274e-09  grad at x: [ 8.16635816e-05 -2.09356203e-05]  gradient norm: 8.430445280070234e-05\n",
            "iter: 933658  x: [ 3.99995709 15.9996567 ]  f(x): 1.8414100272194937e-09  grad at x: [-2.61766452e-06 -1.04006631e-05]  gradient norm: 1.0725015624931021e-05\n",
            "iter: 933659  x: [ 3.99995709 15.99965671]  f(x): 1.8413519520460803e-09  grad at x: [ 8.17099593e-05 -2.09410900e-05]  gradient norm: 8.435073618630063e-05\n",
            "iter: 933660  x: [ 3.99995709 15.99965671]  f(x): 1.8412976392012217e-09  grad at x: [-2.61834870e-06 -1.04002502e-05]  gradient norm: 1.0724782218987321e-05\n",
            "iter: 933661  x: [ 3.99995709 15.99965672]  f(x): 1.8412396295454795e-09  grad at x: [ 8.17563805e-05 -2.09465652e-05]  gradient norm: 8.439706359833867e-05\n",
            "iter: 933662  x: [ 3.99995709 15.99965672]  f(x): 1.8411852580242463e-09  grad at x: [-2.61904752e-06 -1.03998354e-05]  gradient norm: 1.072455067683674e-05\n",
            "iter: 933663  x: [ 3.99995709 15.99965673]  f(x): 1.8411273151004637e-09  grad at x: [ 8.18037184e-05 -2.09521550e-05]  gradient norm: 8.444430794458711e-05\n",
            "iter: 933664  x: [ 3.99995709 15.99965673]  f(x): 1.8410728837252016e-09  grad at x: [-2.61973187e-06 -1.03994225e-05]  gradient norm: 1.0724317420142689e-05\n",
            "iter: 933665  x: [ 3.9999571  15.99965674]  f(x): 1.8410150063845489e-09  grad at x: [ 8.18501395e-05 -2.09576301e-05]  gradient norm: 8.44906361256299e-05\n",
            "iter: 933666  x: [ 3.99995709 15.99965675]  f(x): 1.8409605162852992e-09  grad at x: [-2.62041629e-06 -1.03990096e-05]  gradient norm: 1.0724084237259637e-05\n",
            "iter: 933667  x: [ 3.9999571  15.99965676]  f(x): 1.840902704522944e-09  grad at x: [ 8.18965459e-05 -2.09631035e-05]  gradient norm: 8.453695013727451e-05\n",
            "iter: 933668  x: [ 3.9999571  15.99965676]  f(x): 1.840848155704225e-09  grad at x: [-2.62110080e-06 -1.03985967e-05]  gradient norm: 1.0723851128641706e-05\n",
            "iter: 933669  x: [ 3.9999571  15.99965677]  f(x): 1.840790409626191e-09  grad at x: [ 8.19429959e-05 -2.09685822e-05]  gradient norm: 8.458330817278079e-05\n",
            "iter: 933670  x: [ 3.9999571  15.99965677]  f(x): 1.8407358019631942e-09  grad at x: [-2.62179994e-06 -1.03981820e-05]  gradient norm: 1.0723619887851384e-05\n",
            "iter: 933671  x: [ 3.9999571  15.99965678]  f(x): 1.8406781227864168e-09  grad at x: [ 8.19903626e-05 -2.09741756e-05]  gradient norm: 8.463058317433512e-05\n",
            "iter: 933672  x: [ 3.9999571  15.99965678]  f(x): 1.8406234550988352e-09  grad at x: [-2.62248460e-06 -1.03977691e-05]  gradient norm: 1.0723386928211033e-05\n",
            "iter: 933673  x: [ 3.9999571  15.99965679]  f(x): 1.8405658416346527e-09  grad at x: [ 8.20367979e-05 -2.09796526e-05]  gradient norm: 8.467692742665296e-05\n",
            "iter: 933674  x: [ 3.9999571  15.99965679]  f(x): 1.8405111150923626e-09  grad at x: [-2.62316935e-06 -1.03973562e-05]  gradient norm: 1.0723154042896547e-05\n",
            "iter: 933675  x: [ 3.9999571 15.9996568]  f(x): 1.8404535673740252e-09  grad at x: [ 8.20832186e-05 -2.09851278e-05]  gradient norm: 8.472325750455505e-05\n",
            "iter: 933676  x: [ 3.9999571 15.9996568]  f(x): 1.840398781943462e-09  grad at x: [-2.62385417e-06 -1.03969433e-05]  gradient norm: 1.0722921231493584e-05\n",
            "iter: 933677  x: [ 3.9999571  15.99965681]  f(x): 1.840341300039848e-09  grad at x: [ 8.21296683e-05 -2.09906066e-05]  gradient norm: 8.476961705605244e-05\n",
            "iter: 933678  x: [ 3.9999571  15.99965681]  f(x): 1.840286455633352e-09  grad at x: [-2.62455363e-06 -1.03965285e-05]  gradient norm: 1.0722690292606455e-05\n",
            "iter: 933679  x: [ 3.9999571  15.99965682]  f(x): 1.8402290408004966e-09  grad at x: [ 8.21770638e-05 -2.09962036e-05]  gradient norm: 8.481692270498044e-05\n",
            "iter: 933680  x: [ 3.9999571  15.99965682]  f(x): 1.840174136198655e-09  grad at x: [-2.62523862e-06 -1.03961156e-05]  gradient norm: 1.0722457630560146e-05\n",
            "iter: 933681  x: [ 3.99995711 15.99965683]  f(x): 1.840116787245292e-09  grad at x: [ 8.22235279e-05 -2.10016842e-05]  gradient norm: 8.486329756577629e-05\n",
            "iter: 933682  x: [ 3.9999571  15.99965683]  f(x): 1.8400618236205886e-09  grad at x: [-2.62592368e-06 -1.03957027e-05]  gradient norm: 1.072222504270315e-05\n",
            "iter: 933683  x: [ 3.99995711 15.99965684]  f(x): 1.840004540579965e-09  grad at x: [ 8.22699773e-05 -2.10071630e-05]  gradient norm: 8.490965824915296e-05\n",
            "iter: 933684  x: [ 3.99995711 15.99965684]  f(x): 1.8399495178988386e-09  grad at x: [-2.62660883e-06 -1.03952898e-05]  gradient norm: 1.0721992529273197e-05\n",
            "iter: 933685  x: [ 3.99995711 15.99965685]  f(x): 1.8398923008399563e-09  grad at x: [ 8.23164558e-05 -2.10126454e-05]  gradient norm: 8.495604840646729e-05\n",
            "iter: 933686  x: [ 3.99995711 15.99965685]  f(x): 1.8398372190330912e-09  grad at x: [-2.62729406e-06 -1.03948769e-05]  gradient norm: 1.0721760089855342e-05\n",
            "iter: 933687  x: [ 3.99995711 15.99965686]  f(x): 1.8397800679884363e-09  grad at x: [ 8.23629342e-05 -2.10181279e-05]  gradient norm: 8.500243893469722e-05\n",
            "iter: 933688  x: [ 3.99995711 15.99965686]  f(x): 1.8397249270045682e-09  grad at x: [-2.62799391e-06 -1.03944622e-05]  gradient norm: 1.0721529528269135e-05\n",
            "iter: 933689  x: [ 3.99995711 15.99965687]  f(x): 1.8396678431962315e-09  grad at x: [ 8.24103438e-05 -2.10237267e-05]  gradient norm: 8.504976105257498e-05\n",
            "iter: 933690  x: [ 3.99995711 15.99965687]  f(x): 1.839612641849885e-09  grad at x: [-2.62867930e-06 -1.03940492e-05]  gradient norm: 1.0721297238410432e-05\n",
            "iter: 933691  x: [ 3.99995711 15.99965688]  f(x): 1.8395556241214075e-09  grad at x: [ 8.24568221e-05 -2.10292092e-05]  gradient norm: 8.509615233237825e-05\n",
            "iter: 933692  x: [ 3.99995711 15.99965688]  f(x): 1.8395003635318e-09  grad at x: [-2.62937932e-06 -1.03936345e-05]  gradient norm: 1.0721066828522643e-05\n",
            "iter: 933693  x: [ 3.99995711 15.99965689]  f(x): 1.8394434131066047e-09  grad at x: [ 8.25042315e-05 -2.10348080e-05]  gradient norm: 8.514347521580581e-05\n",
            "iter: 933694  x: [ 3.99995711 15.99965689]  f(x): 1.8393880920684635e-09  grad at x: [-2.63007941e-06 -1.03932198e-05]  gradient norm: 1.0720836494826583e-05\n",
            "iter: 933695  x: [ 3.99995712 15.9996569 ]  f(x): 1.83933120901703e-09  grad at x: [ 8.25516701e-05 -2.10404105e-05]  gradient norm: 8.519082758848834e-05\n",
            "iter: 933696  x: [ 3.99995711 15.9996569 ]  f(x): 1.8392758274595618e-09  grad at x: [-2.63077959e-06 -1.03928051e-05]  gradient norm: 1.07206062375606e-05\n",
            "iter: 933697  x: [ 3.99995712 15.99965691]  f(x): 1.8392190117790677e-09  grad at x: [ 8.25990794e-05 -2.10460094e-05]  gradient norm: 8.523815124503668e-05\n",
            "iter: 933698  x: [ 3.99995712 15.99965691]  f(x): 1.8391635696863202e-09  grad at x: [-2.63149440e-06 -1.03923885e-05]  gradient norm: 1.0720377865406624e-05\n",
            "iter: 933699  x: [ 3.99995712 15.99965692]  f(x): 1.8391068226402575e-09  grad at x: [ 8.26474491e-05 -2.10517283e-05]  gradient norm: 8.528643564741025e-05\n",
            "iter: 933700  x: [ 3.99995712 15.99965692]  f(x): 1.8390513187853468e-09  grad at x: [-2.63219474e-06 -1.03919738e-05]  gradient norm: 1.0720147762340502e-05\n",
            "iter: 933701  x: [ 3.99995712 15.99965693]  f(x): 1.8389946392152782e-09  grad at x: [ 8.26948874e-05 -2.10573307e-05]  gradient norm: 8.533378918583744e-05\n",
            "iter: 933702  x: [ 3.99995712 15.99965693]  f(x): 1.8389390747378662e-09  grad at x: [-2.63289515e-06 -1.03915590e-05]  gradient norm: 1.0719917735548351e-05\n",
            "iter: 933703  x: [ 3.99995712 15.99965694]  f(x): 1.8388824627143979e-09  grad at x: [ 8.27423547e-05 -2.10629369e-05]  gradient norm: 8.538117221030246e-05\n",
            "iter: 933704  x: [ 3.99995712 15.99965694]  f(x): 1.8388268375435653e-09  grad at x: [-2.63359565e-06 -1.03911443e-05]  gradient norm: 1.0719687785268785e-05\n",
            "iter: 933705  x: [ 3.99995712 15.99965695]  f(x): 1.8387702930638316e-09  grad at x: [ 8.27897928e-05 -2.10685394e-05]  gradient norm: 8.542852651497586e-05\n",
            "iter: 933706  x: [ 3.99995712 15.99965695]  f(x): 1.8387146072021296e-09  grad at x: [-2.63429623e-06 -1.03907296e-05]  gradient norm: 1.0719457911740662e-05\n",
            "iter: 933707  x: [ 3.99995712 15.99965696]  f(x): 1.8386581302993427e-09  grad at x: [ 8.28372454e-05 -2.10741437e-05]  gradient norm: 8.547589575523263e-05\n",
            "iter: 933708  x: [ 3.99995712 15.99965697]  f(x): 1.838602383675162e-09  grad at x: [-2.63499688e-06 -1.03903149e-05]  gradient norm: 1.0719228114329775e-05\n",
            "iter: 933709  x: [ 3.99995712 15.99965698]  f(x): 1.838545974421287e-09  grad at x: [ 8.28846979e-05 -2.10797480e-05]  gradient norm: 8.552326537768085e-05\n",
            "iter: 933710  x: [ 3.99995712 15.99965698]  f(x): 1.8384901670200608e-09  grad at x: [-2.63571217e-06 -1.03898983e-05]  gradient norm: 1.0719000208753874e-05\n",
            "iter: 933711  x: [ 3.99995713 15.99965699]  f(x): 1.8384338266453747e-09  grad at x: [ 8.29330962e-05 -2.10854705e-05]  gradient norm: 8.557158124221313e-05\n",
            "iter: 933712  x: [ 3.99995712 15.99965699]  f(x): 1.8383779572157146e-09  grad at x: [-2.63639843e-06 -1.03894854e-05]  gradient norm: 1.0718768749688257e-05\n",
            "iter: 933713  x: [ 3.99995713 15.999657  ]  f(x): 1.8383216833600703e-09  grad at x: [ 8.29796318e-05 -2.10909602e-05]  gradient norm: 8.561803487094351e-05\n",
            "iter: 933714  x: [ 3.99995713 15.999657  ]  f(x): 1.8382657542629797e-09  grad at x: [-2.63708478e-06 -1.03890725e-05]  gradient norm: 1.0718537364917911e-05\n",
            "iter: 933715  x: [ 3.99995713 15.99965701]  f(x): 1.8382095469958151e-09  grad at x: [ 8.30261964e-05 -2.10964536e-05]  gradient norm: 8.566451796462236e-05\n",
            "iter: 933716  x: [ 3.99995713 15.99965701]  f(x): 1.8381535581615417e-09  grad at x: [-2.63777120e-06 -1.03886596e-05]  gradient norm: 1.0718306054899992e-05\n",
            "iter: 933717  x: [ 3.99995713 15.99965702]  f(x): 1.838097417441088e-09  grad at x: [ 8.30727172e-05 -2.11019415e-05]  gradient norm: 8.571095776587918e-05\n",
            "iter: 933718  x: [ 3.99995713 15.99965702]  f(x): 1.8380413689110875e-09  grad at x: [-2.63845771e-06 -1.03882467e-05]  gradient norm: 1.0718074819217585e-05\n",
            "iter: 933719  x: [ 3.99995713 15.99965702]  f(x): 1.8379993042176618e-09  grad at x: [ 4.02404120e-05 -1.57478407e-05]  gradient norm: 4.321209602322523e-05\n",
            "iter: 933720  x: [ 3.99995713 15.99965702]  f(x): 1.8379844042678837e-09  grad at x: [-1.96881957e-06 -1.04717838e-05]  gradient norm: 1.0655257174940578e-05\n",
            "iter: 933721  x: [ 3.99995714 15.99965706]  f(x): 1.837758654103934e-09  grad at x: [ 1.66960081e-04 -3.15861998e-05]  gradient norm: 0.00016992161880637765\n",
            "iter: 933722  x: [ 3.99995714 15.99965706]  f(x): 1.8375940813316822e-09  grad at x: [ 8.15051641e-05 -2.09045393e-05]  gradient norm: 8.414327980619633e-05\n",
            "iter: 933723  x: [ 3.99995713 15.99965706]  f(x): 1.8375400327828914e-09  grad at x: [-2.61378238e-06 -1.03898692e-05]  gradient norm: 1.0713600720503955e-05\n",
            "iter: 933724  x: [ 3.99995714 15.99965707]  f(x): 1.837481988225777e-09  grad at x: [ 8.15517427e-05 -2.09100344e-05]  gradient norm: 8.418976351612454e-05\n",
            "iter: 933725  x: [ 3.99995714 15.99965707]  f(x): 1.8374278809695475e-09  grad at x: [-2.61448387e-06 -1.03894545e-05]  gradient norm: 1.0713369693336637e-05\n",
            "iter: 933726  x: [ 3.99995714 15.99965708]  f(x): 1.837369903198538e-09  grad at x: [ 8.15992672e-05 -2.09156478e-05]  gradient norm: 8.423719324002908e-05\n",
            "iter: 933727  x: [ 3.99995714 15.99965709]  f(x): 1.8373157360039985e-09  grad at x: [-2.61515634e-06 -1.03890434e-05]  gradient norm: 1.0713135166110317e-05\n",
            "iter: 933728  x: [ 3.99995714 15.9996571 ]  f(x): 1.8372578226956074e-09  grad at x: [ 8.16449288e-05 -2.09210284e-05]  gradient norm: 8.428276118891233e-05\n",
            "iter: 933729  x: [ 3.99995714 15.9996571 ]  f(x): 1.8372035978870911e-09  grad at x: [-2.61582889e-06 -1.03886323e-05]  gradient norm: 1.071290071125524e-05\n",
            "iter: 933730  x: [ 3.99995714 15.99965711]  f(x): 1.8371457490726589e-09  grad at x: [ 8.16905904e-05 -2.09264090e-05]  gradient norm: 8.432832950334336e-05\n",
            "iter: 933731  x: [ 3.99995714 15.99965711]  f(x): 1.837091466618512e-09  grad at x: [-2.61650152e-06 -1.03882212e-05]  gradient norm: 1.0712666328791216e-05\n",
            "iter: 933732  x: [ 3.99995714 15.99965712]  f(x): 1.8370336823293781e-09  grad at x: [ 8.17362519e-05 -2.09317895e-05]  gradient norm: 8.437389818603889e-05\n",
            "iter: 933733  x: [ 3.99995714 15.99965712]  f(x): 1.8369793421794943e-09  grad at x: [-2.61718878e-06 -1.03878083e-05]  gradient norm: 1.0712433809868426e-05\n",
            "iter: 933734  x: [ 3.99995714 15.99965713]  f(x): 1.8369216235904826e-09  grad at x: [ 8.17828302e-05 -2.09372847e-05]  gradient norm: 8.442038380088255e-05\n",
            "iter: 933735  x: [ 3.99995714 15.99965713]  f(x): 1.8368672245881787e-09  grad at x: [-2.61787612e-06 -1.03873954e-05]  gradient norm: 1.0712201365658858e-05\n",
            "iter: 933736  x: [ 3.99995714 15.99965714]  f(x): 1.8368095717691209e-09  grad at x: [ 8.18294229e-05 -2.09427817e-05]  gradient norm: 8.446688434635655e-05\n",
            "iter: 933737  x: [ 3.99995714 15.99965714]  f(x): 1.8367551138442517e-09  grad at x: [-2.61856354e-06 -1.03869825e-05]  gradient norm: 1.0711968995748698e-05\n",
            "iter: 933738  x: [ 3.99995715 15.99965715]  f(x): 1.836697526864158e-09  grad at x: [ 8.18760446e-05 -2.09482823e-05]  gradient norm: 8.451341437249919e-05\n",
            "iter: 933739  x: [ 3.99995714 15.99965715]  f(x): 1.8366430099277862e-09  grad at x: [-2.61923648e-06 -1.03865714e-05]  gradient norm: 1.07117349058993e-05\n",
            "iter: 933740  x: [ 3.99995715 15.99965716]  f(x): 1.8365854876739106e-09  grad at x: [ 8.19217494e-05 -2.09536684e-05]  gradient norm: 8.455902818627025e-05\n",
            "iter: 933741  x: [ 3.99995715 15.99965716]  f(x): 1.8365309128592457e-09  grad at x: [-2.61993861e-06 -1.03861566e-05]  gradient norm: 1.0711504479558547e-05\n",
            "iter: 933742  x: [ 3.99995715 15.99965717]  f(x): 1.8364734576923854e-09  grad at x: [ 8.19693023e-05 -2.09592854e-05]  gradient norm: 8.46064901154002e-05\n",
            "iter: 933743  x: [ 3.99995715 15.99965717]  f(x): 1.8364188226371546e-09  grad at x: [-2.62064083e-06 -1.03857419e-05]  gradient norm: 1.0711274130118382e-05\n",
            "iter: 933744  x: [ 3.99995715 15.99965718]  f(x): 1.8363614345913363e-09  grad at x: [ 8.20168552e-05 -2.09649024e-05]  gradient norm: 8.465395244189855e-05\n",
            "iter: 933745  x: [ 3.99995715 15.99965718]  f(x): 1.8363067392611987e-09  grad at x: [-2.62134312e-06 -1.03853272e-05]  gradient norm: 1.0711043857164929e-05\n",
            "iter: 933746  x: [ 3.99995715 15.99965719]  f(x): 1.8362494183704495e-09  grad at x: [ 8.20644079e-05 -2.09705195e-05]  gradient norm: 8.470141516496263e-05\n",
            "iter: 933747  x: [ 3.99995715 15.99965719]  f(x): 1.8361946627310643e-09  grad at x: [-2.62204549e-06 -1.03849125e-05]  gradient norm: 1.071081366115353e-05\n",
            "iter: 933748  x: [ 3.99995715 15.9996572 ]  f(x): 1.8361374090658766e-09  grad at x: [ 8.21119897e-05 -2.09761401e-05]  gradient norm: 8.47489073825051e-05\n",
            "iter: 933749  x: [ 3.99995715 15.9996572 ]  f(x): 1.8360825930268272e-09  grad at x: [-2.62273339e-06 -1.03844995e-05]  gradient norm: 1.0710581741680565e-05\n",
            "iter: 933750  x: [ 3.99995715 15.99965721]  f(x): 1.8360254053979781e-09  grad at x: [ 8.21586255e-05 -2.09816426e-05]  gradient norm: 8.479545426304258e-05\n",
            "iter: 933751  x: [ 3.99995715 15.99965721]  f(x): 1.8359705301677856e-09  grad at x: [-2.62342136e-06 -1.03840866e-05]  gradient norm: 1.071034989708357e-05\n",
            "iter: 933752  x: [ 3.99995715 15.99965722]  f(x): 1.8359134086452672e-09  grad at x: [ 8.22052757e-05 -2.09871469e-05]  gradient norm: 8.484201606855123e-05\n",
            "iter: 933753  x: [ 3.99995715 15.99965722]  f(x): 1.8358584741536257e-09  grad at x: [-2.62410942e-06 -1.03836737e-05]  gradient norm: 1.0710118126947755e-05\n",
            "iter: 933754  x: [ 3.99995716 15.99965723]  f(x): 1.8358014187701687e-09  grad at x: [ 8.22519259e-05 -2.09926511e-05]  gradient norm: 8.488857825064267e-05\n",
            "iter: 933755  x: [ 3.99995716 15.99965723]  f(x): 1.8357464249840343e-09  grad at x: [-2.62479756e-06 -1.03832608e-05]  gradient norm: 1.0709886431728543e-05\n",
            "iter: 933756  x: [ 3.99995716 15.99965724]  f(x): 1.8356894357723691e-09  grad at x: [ 8.22985760e-05 -2.09981554e-05]  gradient norm: 8.49351408102871e-05\n",
            "iter: 933757  x: [ 3.99995716 15.99965724]  f(x): 1.8356343826402537e-09  grad at x: [-2.62550033e-06 -1.03828461e-05]  gradient norm: 1.0709656614959055e-05\n",
            "iter: 933758  x: [ 3.99995716 15.99965725]  f(x): 1.8355774608217829e-09  grad at x: [ 8.23461574e-05 -2.10037761e-05]  gradient norm: 8.49826349641102e-05\n",
            "iter: 933759  x: [ 3.99995716 15.99965725]  f(x): 1.83552234713925e-09  grad at x: [-2.62617408e-06 -1.03824350e-05]  gradient norm: 1.0709423265032695e-05\n",
            "iter: 933760  x: [ 3.99995716 15.99965726]  f(x): 1.8354654904059526e-09  grad at x: [ 8.23919051e-05 -2.10091675e-05]  gradient norm: 8.5028296154399e-05\n",
            "iter: 933761  x: [ 3.99995716 15.99965726]  f(x): 1.8354103184818748e-09  grad at x: [-2.62684790e-06 -1.03820239e-05]  gradient norm: 1.070918998779689e-05\n",
            "iter: 933762  x: [ 3.99995716 15.99965727]  f(x): 1.83535352686521e-09  grad at x: [ 8.24376527e-05 -2.10145590e-05]  gradient norm: 8.507395770015176e-05\n",
            "iter: 933763  x: [ 3.99995716 15.99965727]  f(x): 1.8352982966309316e-09  grad at x: [-2.62755091e-06 -1.03816092e-05]  gradient norm: 1.070896039715773e-05\n",
            "iter: 933764  x: [ 3.99995716 15.99965728]  f(x): 1.8352415725809782e-09  grad at x: [ 8.24852775e-05 -2.10201852e-05]  gradient norm: 8.512149664521852e-05\n",
            "iter: 933765  x: [ 3.99995716 15.99965728]  f(x): 1.8351862816426003e-09  grad at x: [-2.62826855e-06 -1.03811926e-05]  gradient norm: 1.0708732692010258e-05\n",
            "iter: 933766  x: [ 3.99995716 15.99965729]  f(x): 1.835129626347472e-09  grad at x: [ 8.25338190e-05 -2.10259259e-05]  gradient norm: 8.516995268322687e-05\n",
            "iter: 933767  x: [ 3.99995716 15.99965729]  f(x): 1.835074273495792e-09  grad at x: [-2.62895717e-06 -1.03807797e-05]  gradient norm: 1.0708501447064307e-05\n",
            "iter: 933768  x: [ 3.99995717 15.9996573 ]  f(x): 1.835017684606929e-09  grad at x: [ 8.25804977e-05 -2.10314338e-05]  gradient norm: 8.521654660176319e-05\n",
            "iter: 933769  x: [ 3.99995716 15.9996573 ]  f(x): 1.83496227217292e-09  grad at x: [-2.62966042e-06 -1.03803650e-05]  gradient norm: 1.0708272087433562e-05\n",
            "iter: 933770  x: [ 3.99995717 15.99965732]  f(x): 1.8349057508783985e-09  grad at x: [ 8.26280932e-05 -2.10370563e-05]  gradient norm: 8.526405761285013e-05\n",
            "iter: 933771  x: [ 3.99995717 15.99965732]  f(x): 1.834850277692112e-09  grad at x: [-2.63036374e-06 -1.03799503e-05]  gradient norm: 1.0708042804556213e-05\n",
            "iter: 933772  x: [ 3.99995717 15.99965733]  f(x): 1.8347938241001168e-09  grad at x: [ 8.26757322e-05 -2.10426842e-05]  gradient norm: 8.531161266405691e-05\n",
            "iter: 933773  x: [ 3.99995717 15.99965733]  f(x): 1.8347382900530544e-09  grad at x: [-2.63106715e-06 -1.03795355e-05]  gradient norm: 1.0707813598889245e-05\n",
            "iter: 933774  x: [ 3.99995717 15.99965734]  f(x): 1.8346819041977368e-09  grad at x: [ 8.27233711e-05 -2.10483122e-05]  gradient norm: 8.535916810250298e-05\n",
            "iter: 933775  x: [ 3.99995717 15.99965734]  f(x): 1.8346263092358284e-09  grad at x: [-2.63175609e-06 -1.03791226e-05]  gradient norm: 1.0707582656346996e-05\n",
            "iter: 933776  x: [ 3.99995717 15.99965735]  f(x): 1.8345699899566387e-09  grad at x: [ 8.27700787e-05 -2.10538237e-05]  gradient norm: 8.540579263100402e-05\n",
            "iter: 933777  x: [ 3.99995717 15.99965735]  f(x): 1.8345143352597265e-09  grad at x: [-2.63244510e-06 -1.03787097e-05]  gradient norm: 1.0707351788945424e-05\n",
            "iter: 933778  x: [ 3.99995717 15.99965736]  f(x): 1.8344580825894767e-09  grad at x: [ 8.28167861e-05 -2.10593353e-05]  gradient norm: 8.545241752816132e-05\n",
            "iter: 933779  x: [ 3.99995717 15.99965736]  f(x): 1.8344023681244356e-09  grad at x: [-2.63313420e-06 -1.03782968e-05]  gradient norm: 1.0707120996268148e-05\n",
            "iter: 933780  x: [ 3.99995717 15.99965737]  f(x): 1.8343461820959375e-09  grad at x: [ 8.28634935e-05 -2.10648468e-05]  gradient norm: 8.549904279496236e-05\n",
            "iter: 933781  x: [ 3.99995717 15.99965737]  f(x): 1.8342904078112071e-09  grad at x: [-2.63383793e-06 -1.03778821e-05]  gradient norm: 1.0706892095361275e-05\n",
            "iter: 933782  x: [ 3.99995717 15.99965738]  f(x): 1.8342342896907844e-09  grad at x: [ 8.29111612e-05 -2.10704784e-05]  gradient norm: 8.55466288538772e-05\n",
            "iter: 933783  x: [ 3.99995717 15.99965738]  f(x): 1.8341784543381643e-09  grad at x: [-2.63454173e-06 -1.03774673e-05]  gradient norm: 1.0706663271331078e-05\n",
            "iter: 933784  x: [ 3.99995718 15.99965739]  f(x): 1.8341224041600098e-09  grad at x: [ 8.29588288e-05 -2.10761100e-05]  gradient norm: 8.559421529672363e-05\n",
            "iter: 933785  x: [ 3.99995717 15.99965739]  f(x): 1.8340665077049932e-09  grad at x: [-2.63524562e-06 -1.03770526e-05]  gradient norm: 1.07064345246353e-05\n",
            "iter: 933786  x: [ 3.99995718 15.9996574 ]  f(x): 1.834010525466437e-09  grad at x: [ 8.30064673e-05 -2.10817379e-05]  gradient norm: 8.564177301720606e-05\n",
            "iter: 933787  x: [ 3.99995718 15.9996574 ]  f(x): 1.8339685571545655e-09  grad at x: [ 4.01852807e-05 -1.57291906e-05]  gradient norm: 4.315395950013679e-05\n",
            "iter: 933788  x: [ 3.99995718 15.9996574 ]  f(x): 1.8339536968148455e-09  grad at x: [-1.96651388e-06 -1.04603132e-05]  gradient norm: 1.0643558108567578e-05\n",
            "iter: 933789  x: [ 3.99995718 15.99965744]  f(x): 1.833728344999284e-09  grad at x: [ 1.66739190e-04 -3.15468315e-05]  gradient norm: 0.00016969725995000462\n",
            "iter: 933790  x: [ 3.99995718 15.99965744]  f(x): 1.833564206443447e-09  grad at x: [ 8.13971829e-05 -2.08792844e-05]  gradient norm: 8.403240982186943e-05\n",
            "iter: 933791  x: [ 3.99995718 15.99965744]  f(x): 1.8335102998524844e-09  grad at x: [-2.6106295e-06 -1.0378506e-05]  gradient norm: 1.0701811653456166e-05\n",
            "iter: 933792  x: [ 3.99995718 15.99965745]  f(x): 1.8334523595378435e-09  grad at x: [ 8.14440206e-05 -2.08848123e-05]  gradient norm: 8.40791524389829e-05\n",
            "iter: 933793  x: [ 3.99995718 15.99965745]  f(x): 1.8333983939938972e-09  grad at x: [-2.61130475e-06 -1.03780949e-05]  gradient norm: 1.070157773225864e-05\n",
            "iter: 933794  x: [ 3.99995718 15.99965746]  f(x): 1.833340518235682e-09  grad at x: [ 8.14898541e-05 -2.08902147e-05]  gradient norm: 8.412489162836555e-05\n",
            "iter: 933795  x: [ 3.99995718 15.99965746]  f(x): 1.8332864949545654e-09  grad at x: [-2.61199465e-06 -1.03776820e-05]  gradient norm: 1.0701345671721368e-05\n",
            "iter: 933796  x: [ 3.99995719 15.99965747]  f(x): 1.833228684961515e-09  grad at x: [ 8.15366189e-05 -2.08957335e-05]  gradient norm: 8.417156227858879e-05\n",
            "iter: 933797  x: [ 3.99995719 15.99965747]  f(x): 1.8331746027526118e-09  grad at x: [-2.61268462e-06 -1.03772691e-05]  gradient norm: 1.0701113685860394e-05\n",
            "iter: 933798  x: [ 3.99995719 15.99965748]  f(x): 1.8331168585576212e-09  grad at x: [ 8.15833836e-05 -2.09012524e-05]  gradient norm: 8.421823331572788e-05\n",
            "iter: 933799  x: [ 3.99995719 15.99965748]  f(x): 1.8330627173877233e-09  grad at x: [-2.61337467e-06 -1.03768562e-05]  gradient norm: 1.0700881775129692e-05\n",
            "iter: 933800  x: [ 3.99995719 15.99965749]  f(x): 1.8330050390599393e-09  grad at x: [ 8.16301773e-05 -2.09067748e-05]  gradient norm: 8.426493383716045e-05\n",
            "iter: 933801  x: [ 3.99995719 15.99965749]  f(x): 1.8329508388411539e-09  grad at x: [-2.61407935e-06 -1.03764414e-05]  gradient norm: 1.070065173013928e-05\n",
            "iter: 933802  x: [ 3.99995719 15.9996575 ]  f(x): 1.8328932275564036e-09  grad at x: [ 8.16778731e-05 -2.09124100e-05]  gradient norm: 8.431253676324747e-05\n",
            "iter: 933803  x: [ 3.99995719 15.9996575 ]  f(x): 1.8328389671298634e-09  grad at x: [-2.61475501e-06 -1.03760303e-05]  gradient norm: 1.0700418178056005e-05\n",
            "iter: 933804  x: [ 3.99995719 15.99965751]  f(x): 1.8327814205990102e-09  grad at x: [ 8.17237354e-05 -2.09178161e-05]  gradient norm: 8.435830694859417e-05\n",
            "iter: 933805  x: [ 3.99995719 15.99965751]  f(x): 1.832727102236268e-09  grad at x: [-2.61544530e-06 -1.03756174e-05]  gradient norm: 1.0700186491970547e-05\n",
            "iter: 933806  x: [ 3.99995719 15.99965752]  f(x): 1.832669621671411e-09  grad at x: [ 8.17705288e-05 -2.09233385e-05]  gradient norm: 8.440500863203327e-05\n",
            "iter: 933807  x: [ 3.99995719 15.99965752]  f(x): 1.8326152441784862e-09  grad at x: [-2.61613566e-06 -1.03752045e-05]  gradient norm: 1.06999548808798e-05\n",
            "iter: 933808  x: [ 3.99995719 15.99965753]  f(x): 1.8325578296125618e-09  grad at x: [ 8.18173222e-05 -2.09288610e-05]  gradient norm: 8.445171070077688e-05\n",
            "iter: 933809  x: [ 3.99995719 15.99965753]  f(x): 1.8325033929377762e-09  grad at x: [-2.61684067e-06 -1.03747898e-05]  gradient norm: 1.0699725139801685e-05\n",
            "iter: 933810  x: [ 3.9999572  15.99965754]  f(x): 1.83244604558554e-09  grad at x: [ 8.18650469e-05 -2.09344998e-05]  gradient norm: 8.449934430276358e-05\n",
            "iter: 933811  x: [ 3.99995719 15.99965755]  f(x): 1.8323915485322549e-09  grad at x: [-2.61754575e-06 -1.03743751e-05]  gradient norm: 1.0699495476092315e-05\n",
            "iter: 933812  x: [ 3.9999572  15.99965756]  f(x): 1.8323342684643615e-09  grad at x: [ 8.19128006e-05 -2.09401423e-05]  gradient norm: 8.454700740245555e-05\n",
            "iter: 933813  x: [ 3.9999572  15.99965756]  f(x): 1.8322797109604468e-09  grad at x: [-2.6182218e-06 -1.0373964e-05]  gradient norm: 1.06992622946559e-05\n",
            "iter: 933814  x: [ 3.9999572  15.99965757]  f(x): 1.8322224958448785e-09  grad at x: [ 8.19586915e-05 -2.09455520e-05]  gradient norm: 8.45928085756607e-05\n",
            "iter: 933815  x: [ 3.9999572  15.99965757]  f(x): 1.8321678802047735e-09  grad at x: [-2.61891249e-06 -1.03735510e-05]  gradient norm: 1.0699030984360982e-05\n",
            "iter: 933816  x: [ 3.9999572  15.99965758]  f(x): 1.8321107312205866e-09  grad at x: [ 8.20054846e-05 -2.09510745e-05]  gradient norm: 8.463951218886337e-05\n",
            "iter: 933817  x: [ 3.9999572  15.99965758]  f(x): 1.8320560562833497e-09  grad at x: [-2.61960326e-06 -1.03731381e-05]  gradient norm: 1.0698799749379873e-05\n",
            "iter: 933818  x: [ 3.9999572  15.99965759]  f(x): 1.831998973499919e-09  grad at x: [ 8.20523067e-05 -2.09566006e-05]  gradient norm: 8.468624528240777e-05\n",
            "iter: 933819  x: [ 3.9999572  15.99965759]  f(x): 1.8319442391774372e-09  grad at x: [-2.62030866e-06 -1.03727234e-05]  gradient norm: 1.0698570389775019e-05\n",
            "iter: 933820  x: [ 3.9999572 15.9996576]  f(x): 1.8318872238493561e-09  grad at x: [ 8.21000892e-05 -2.09622467e-05]  gradient norm: 8.473393904862807e-05\n",
            "iter: 933821  x: [ 3.9999572 15.9996576]  f(x): 1.8318324289051495e-09  grad at x: [-2.62101414e-06 -1.03723087e-05]  gradient norm: 1.06983411076424e-05\n",
            "iter: 933822  x: [ 3.9999572  15.99965761]  f(x): 1.8317754810302973e-09  grad at x: [ 8.21478424e-05 -2.09678892e-05]  gradient norm: 8.478160411213429e-05\n",
            "iter: 933823  x: [ 3.9999572  15.99965761]  f(x): 1.8317206254465852e-09  grad at x: [-2.62170515e-06 -1.03718958e-05]  gradient norm: 1.0698110099953165e-05\n",
            "iter: 933824  x: [ 3.9999572  15.99965762]  f(x): 1.831663743909273e-09  grad at x: [ 8.21946934e-05 -2.09734189e-05]  gradient norm: 8.482836746601925e-05\n",
            "iter: 933825  x: [ 3.9999572  15.99965762]  f(x): 1.831608828839444e-09  grad at x: [-2.62238168e-06 -1.03714847e-05]  gradient norm: 1.0697877363798091e-05\n",
            "iter: 933826  x: [ 3.99995721 15.99965763]  f(x): 1.8315520124117348e-09  grad at x: [ 8.22405693e-05 -2.09788268e-05]  gradient norm: 8.48741563310566e-05\n",
            "iter: 933827  x: [ 3.9999572  15.99965763]  f(x): 1.8314970390269775e-09  grad at x: [-2.62305829e-06 -1.03710736e-05]  gradient norm: 1.0697644700327016e-05\n",
            "iter: 933828  x: [ 3.99995721 15.99965764]  f(x): 1.8314402878143331e-09  grad at x: [ 8.22864888e-05 -2.09842401e-05]  gradient norm: 8.491998920904158e-05\n",
            "iter: 933829  x: [ 3.99995721 15.99965764]  f(x): 1.8313852560468844e-09  grad at x: [-2.62373499e-06 -1.03706625e-05]  gradient norm: 1.0697412110213044e-05\n",
            "iter: 933830  x: [ 3.99995721 15.99965765]  f(x): 1.8313285700810053e-09  grad at x: [ 8.23324082e-05 -2.09896534e-05]  gradient norm: 8.496582244796655e-05\n",
            "iter: 933831  x: [ 3.99995721 15.99965765]  f(x): 1.831273479880431e-09  grad at x: [-2.62442631e-06 -1.03702496e-05]  gradient norm: 1.069718139999126e-05\n",
            "iter: 933832  x: [ 3.99995721 15.99965766]  f(x): 1.8312168603821368e-09  grad at x: [ 8.23792588e-05 -2.09951831e-05]  gradient norm: 8.50125872907111e-05\n",
            "iter: 933833  x: [ 3.99995721 15.99965766]  f(x): 1.8311617105457263e-09  grad at x: [-2.62511772e-06 -1.03698367e-05]  gradient norm: 1.0696950765028428e-05\n",
            "iter: 933834  x: [ 3.99995721 15.99965767]  f(x): 1.8311051575846397e-09  grad at x: [ 8.24261385e-05 -2.10007165e-05]  gradient norm: 8.505938161096379e-05\n",
            "iter: 933835  x: [ 3.99995721 15.99965767]  f(x): 1.8310499480240376e-09  grad at x: [-2.62582376e-06 -1.03694219e-05]  gradient norm: 1.0696722013979185e-05\n",
            "iter: 933836  x: [ 3.99995721 15.99965768]  f(x): 1.8309934628236805e-09  grad at x: [ 8.24739494e-05 -2.10063663e-05]  gradient norm: 8.510710756660765e-05\n",
            "iter: 933837  x: [ 3.99995721 15.99965768]  f(x): 1.8309381923323068e-09  grad at x: [-2.62650077e-06 -1.03690109e-05]  gradient norm: 1.0696489720524914e-05\n",
            "iter: 933838  x: [ 3.99995721 15.99965769]  f(x): 1.8308817725081647e-09  grad at x: [ 8.25198685e-05 -2.10117796e-05]  gradient norm: 8.515294227616805e-05\n",
            "iter: 933839  x: [ 3.99995721 15.99965769]  f(x): 1.830826443452968e-09  grad at x: [-2.62719242e-06 -1.03685979e-05]  gradient norm: 1.0696259311242879e-05\n",
            "iter: 933840  x: [ 3.99995722 15.9996577 ]  f(x): 1.8307700903025232e-09  grad at x: [ 8.25667625e-05 -2.10173148e-05]  gradient norm: 8.519975227528788e-05\n",
            "iter: 933841  x: [ 3.99995721 15.9996577 ]  f(x): 1.8307147014041275e-09  grad at x: [-2.62788414e-06 -1.03681850e-05]  gradient norm: 1.0696028977301158e-05\n",
            "iter: 933842  x: [ 3.99995722 15.99965771]  f(x): 1.8306584149231138e-09  grad at x: [ 8.26136418e-05 -2.10228482e-05]  gradient norm: 8.524654809589636e-05\n",
            "iter: 933843  x: [ 3.99995722 15.99965771]  f(x): 1.8306029661670558e-09  grad at x: [-2.62859050e-06 -1.03677703e-05]  gradient norm: 1.0695800531555096e-05\n",
            "iter: 933844  x: [ 3.99995722 15.99965772]  f(x): 1.8305467476183663e-09  grad at x: [ 8.26614816e-05 -2.10285016e-05]  gradient norm: 8.52943046870384e-05\n",
            "iter: 933845  x: [ 3.99995722 15.99965772]  f(x): 1.8304912377598579e-09  grad at x: [-2.62929693e-06 -1.03673556e-05]  gradient norm: 1.0695572163529297e-05\n",
            "iter: 933846  x: [ 3.99995722 15.99965773]  f(x): 1.8304350871412055e-09  grad at x: [ 8.27092921e-05 -2.10341514e-05]  gradient norm: 8.5342032565689e-05\n",
            "iter: 933847  x: [ 3.99995722 15.99965773]  f(x): 1.8303795161822206e-09  grad at x: [-2.63000345e-06 -1.03669408e-05]  gradient norm: 1.0695343872807946e-05\n",
            "iter: 933848  x: [ 3.99995722 15.99965774]  f(x): 1.830323433527385e-09  grad at x: [ 8.27571171e-05 -2.10398030e-05]  gradient norm: 8.538977538462485e-05\n",
            "iter: 933849  x: [ 3.99995722 15.99965774]  f(x): 1.8302678013958338e-09  grad at x: [-2.63071004e-06 -1.03665261e-05]  gradient norm: 1.069511565963013e-05\n",
            "iter: 933850  x: [ 3.99995722 15.99965775]  f(x): 1.8302117867766252e-09  grad at x: [ 8.28049566e-05 -2.10454564e-05]  gradient norm: 8.54375331451853e-05\n",
            "iter: 933851  x: [ 3.99995722 15.99965775]  f(x): 1.8301560934383838e-09  grad at x: [-2.63141672e-06 -1.03661114e-05]  gradient norm: 1.0694887523798121e-05\n",
            "iter: 933852  x: [ 3.99995722 15.99965776]  f(x): 1.830100146889246e-09  grad at x: [ 8.28527960e-05 -2.10511098e-05]  gradient norm: 8.548529129354001e-05\n",
            "iter: 933853  x: [ 3.99995722 15.99965776]  f(x): 1.8300443922899758e-09  grad at x: [-2.63210892e-06 -1.03656985e-05]  gradient norm: 1.069465764714453e-05\n",
            "iter: 933854  x: [ 3.99995722 15.99965777]  f(x): 1.8299885126488335e-09  grad at x: [ 8.28997040e-05 -2.10566468e-05]  gradient norm: 8.553211849094604e-05\n",
            "iter: 933855  x: [ 3.99995722 15.99965777]  f(x): 1.829946651637218e-09  grad at x: [ 4.01334514e-05 -1.57109662e-05]  gradient norm: 4.3099053097243184e-05\n",
            "iter: 933856  x: [ 3.99995722 15.99965777]  f(x): 1.8299318287919488e-09  grad at x: [-1.96422409e-06 -1.04488536e-05]  gradient norm: 1.0631872707147673e-05\n",
            "iter: 933857  x: [ 3.99995723 15.99965782]  f(x): 1.8297068834580048e-09  grad at x: [ 1.66522009e-04 -3.15079396e-05]  gradient norm: 0.00016947663453008706\n",
            "iter: 933858  x: [ 3.99995723 15.99965782]  f(x): 1.8295431713331043e-09  grad at x: [ 8.12910194e-05 -2.08542697e-05]  gradient norm: 8.392336024219065e-05\n",
            "iter: 933859  x: [ 3.99995723 15.99965782]  f(x): 1.8294894041986018e-09  grad at x: [-2.60750705e-06 -1.03671518e-05]  gradient norm: 1.069003883840656e-05\n",
            "iter: 933860  x: [ 3.99995723 15.99965783]  f(x): 1.8294315701447927e-09  grad at x: [ 8.13381598e-05 -2.08598358e-05]  gradient norm: 8.397040542695756e-05\n",
            "iter: 933861  x: [ 3.99995723 15.99965783]  f(x): 1.829377743758861e-09  grad at x: [-2.60819973e-06 -1.03667389e-05]  gradient norm: 1.0689807385214933e-05\n",
            "iter: 933862  x: [ 3.99995723 15.99965784]  f(x): 1.8293199755266076e-09  grad at x: [ 8.13850819e-05 -2.08653746e-05]  gradient norm: 8.401723278993049e-05\n",
            "iter: 933863  x: [ 3.99995723 15.99965784]  f(x): 1.829266090125993e-09  grad at x: [-2.60887793e-06 -1.03663278e-05]  gradient norm: 1.0689574219382847e-05\n",
            "iter: 933864  x: [ 3.99995723 15.99965785]  f(x): 1.8292083866098422e-09  grad at x: [ 8.14310870e-05 -2.08707988e-05]  gradient norm: 8.406314401116233e-05\n",
            "iter: 933865  x: [ 3.99995723 15.99965785]  f(x): 1.8291544433008454e-09  grad at x: [-2.60957077e-06 -1.03659149e-05]  gradient norm: 1.0689342915607674e-05\n",
            "iter: 933866  x: [ 3.99995723 15.99965786]  f(x): 1.8290968057451077e-09  grad at x: [ 8.14780526e-05 -2.08763431e-05]  gradient norm: 8.411001579669653e-05\n",
            "iter: 933867  x: [ 3.99995723 15.99965786]  f(x): 1.8290428033015198e-09  grad at x: [-2.61026369e-06 -1.03655020e-05]  gradient norm: 1.0689111687205657e-05\n",
            "iter: 933868  x: [ 3.99995724 15.99965787]  f(x): 1.8289852317393778e-09  grad at x: [ 8.15250181e-05 -2.08818874e-05]  gradient norm: 8.41568879728901e-05\n",
            "iter: 933869  x: [ 3.99995723 15.99965787]  f(x): 1.828931170108132e-09  grad at x: [-2.61094213e-06 -1.03650909e-05]  gradient norm: 1.0688878743303788e-05\n",
            "iter: 933870  x: [ 3.99995724 15.99965788]  f(x): 1.8288736633589061e-09  grad at x: [ 8.15710230e-05 -2.08873116e-05]  gradient norm: 8.420280033666356e-05\n",
            "iter: 933871  x: [ 3.99995724 15.99965788]  f(x): 1.8288195437215295e-09  grad at x: [-2.61163521e-06 -1.03646780e-05]  gradient norm: 1.0688647664439764e-05\n",
            "iter: 933872  x: [ 3.99995724 15.99965789]  f(x): 1.8287621031049387e-09  grad at x: [ 8.16180320e-05 -2.08928614e-05]  gradient norm: 8.424971693322904e-05\n",
            "iter: 933873  x: [ 3.99995724 15.99965789]  f(x): 1.8287079241782235e-09  grad at x: [-2.61231381e-06 -1.03642669e-05]  gradient norm: 1.0688414868248013e-05\n",
            "iter: 933874  x: [ 3.99995724 15.9996579 ]  f(x): 1.8286505484380388e-09  grad at x: [ 8.16640513e-05 -2.08982874e-05]  gradient norm: 8.429564459976029e-05\n",
            "iter: 933875  x: [ 3.99995724 15.9996579 ]  f(x): 1.8285963114215084e-09  grad at x: [-2.61299250e-06 -1.03638558e-05]  gradient norm: 1.0688182145207908e-05\n",
            "iter: 933876  x: [ 3.99995724 15.99965791]  f(x): 1.8285390006267075e-09  grad at x: [ 8.17100852e-05 -2.09037153e-05]  gradient norm: 8.43415871883127e-05\n",
            "iter: 933877  x: [ 3.99995724 15.99965791]  f(x): 1.8284847054706445e-09  grad at x: [-2.61368581e-06 -1.03634429e-05]  gradient norm: 1.068795129016741e-05\n",
            "iter: 933878  x: [ 3.99995724 15.99965792]  f(x): 1.8284274608696625e-09  grad at x: [ 8.17570793e-05 -2.09092632e-05]  gradient norm: 8.438849038945813e-05\n",
            "iter: 933879  x: [ 3.99995724 15.99965792]  f(x): 1.8283731063437295e-09  grad at x: [-2.61437921e-06 -1.03630300e-05]  gradient norm: 1.068772051083919e-05\n",
            "iter: 933880  x: [ 3.99995724 15.99965793]  f(x): 1.82831592796979e-09  grad at x: [ 8.18040734e-05 -2.09148111e-05]  gradient norm: 8.443539397886766e-05\n",
            "iter: 933881  x: [ 3.99995724 15.99965793]  f(x): 1.8282615140220428e-09  grad at x: [-2.61508723e-06 -1.03626153e-05]  gradient norm: 1.0687491603980896e-05\n",
            "iter: 933882  x: [ 3.99995724 15.99965794]  f(x): 1.8282044030899825e-09  grad at x: [ 8.18519988e-05 -2.09204754e-05]  gradient norm: 8.44832291189212e-05\n",
            "iter: 933883  x: [ 3.99995724 15.99965794]  f(x): 1.8281499285041124e-09  grad at x: [-2.61578079e-06 -1.03622024e-05]  gradient norm: 1.0687260976540323e-05\n",
            "iter: 933884  x: [ 3.99995725 15.99965795]  f(x): 1.82809288386621e-09  grad at x: [ 8.18989928e-05 -2.09260234e-05]  gradient norm: 8.45301334912473e-05\n",
            "iter: 933885  x: [ 3.99995725 15.99965795]  f(x): 1.8280383498276006e-09  grad at x: [-2.61645987e-06 -1.03617913e-05]  gradient norm: 1.068702862559496e-05\n",
            "iter: 933886  x: [ 3.99995725 15.99965796]  f(x): 1.8279813703341316e-09  grad at x: [ 8.19450553e-05 -2.09314549e-05]  gradient norm: 8.457610707233089e-05\n",
            "iter: 933887  x: [ 3.99995725 15.99965796]  f(x): 1.827926777936976e-09  grad at x: [-2.61716814e-06 -1.03613766e-05]  gradient norm: 1.0686799948131645e-05\n",
            "iter: 933888  x: [ 3.99995725 15.99965797]  f(x): 1.8278698660234711e-09  grad at x: [ 8.19930095e-05 -2.09371228e-05]  gradient norm: 8.462397249538612e-05\n",
            "iter: 933889  x: [ 3.99995725 15.99965797]  f(x): 1.8278152128491725e-09  grad at x: [-2.61786193e-06 -1.03609636e-05]  gradient norm: 1.0686569547204326e-05\n",
            "iter: 933890  x: [ 3.99995725 15.99965798]  f(x): 1.827758367329517e-09  grad at x: [ 8.20400032e-05 -2.09426707e-05]  gradient norm: 8.467087802512456e-05\n",
            "iter: 933891  x: [ 3.99995725 15.99965798]  f(x): 1.8277036545834451e-09  grad at x: [-2.61855580e-06 -1.03605507e-05]  gradient norm: 1.0686339221894763e-05\n",
            "iter: 933892  x: [ 3.99995725 15.99965799]  f(x): 1.8276468755273163e-09  grad at x: [ 8.20870259e-05 -2.09482223e-05]  gradient norm: 8.471781303979737e-05\n",
            "iter: 933893  x: [ 3.99995725 15.99965799]  f(x): 1.8275921031210775e-09  grad at x: [-2.61926431e-06 -1.03601360e-05]  gradient norm: 1.0686110775302448e-05\n",
            "iter: 933894  x: [ 3.99995725 15.999658  ]  f(x): 1.8275353917473696e-09  grad at x: [ 8.21349799e-05 -2.09538903e-05]  gradient norm: 8.476567965159236e-05\n",
            "iter: 933895  x: [ 3.99995725 15.999658  ]  f(x): 1.8274805584789987e-09  grad at x: [-2.61994379e-06 -1.03597249e-05]  gradient norm: 1.068587879777522e-05\n",
            "iter: 933896  x: [ 3.99995725 15.99965801]  f(x): 1.8274239124124858e-09  grad at x: [ 8.21810566e-05 -2.09593236e-05]  gradient norm: 8.48116696683906e-05\n",
            "iter: 933897  x: [ 3.99995725 15.99965801]  f(x): 1.8273690206396565e-09  grad at x: [-2.6206379e-06 -1.0359312e-05]  gradient norm: 1.0685648699223742e-05\n",
            "iter: 933898  x: [ 3.99995726 15.99965802]  f(x): 1.8273124412102125e-09  grad at x: [ 8.22281228e-05 -2.09648806e-05]  gradient norm: 8.485864948136267e-05\n",
            "iter: 933899  x: [ 3.99995725 15.99965803]  f(x): 1.8272574896027402e-09  grad at x: [-2.62134664e-06 -1.03588973e-05]  gradient norm: 1.0685420482831674e-05\n",
            "iter: 933900  x: [ 3.99995726 15.99965804]  f(x): 1.8272009779575342e-09  grad at x: [ 8.22760765e-05 -2.09705486e-05]  gradient norm: 8.490651726652619e-05\n",
            "iter: 933901  x: [ 3.99995726 15.99965804]  f(x): 1.8271459653667751e-09  grad at x: [-2.62204092e-06 -1.03584844e-05]  gradient norm: 1.0685190536536366e-05\n",
            "iter: 933902  x: [ 3.99995726 15.99965805]  f(x): 1.8270895203886664e-09  grad at x: [ 8.23231280e-05 -2.09761038e-05]  gradient norm: 8.495348330191165e-05\n",
            "iter: 933903  x: [ 3.99995726 15.99965805]  f(x): 1.8270344479510137e-09  grad at x: [-2.62273527e-06 -1.03580714e-05]  gradient norm: 1.0684960665981495e-05\n",
            "iter: 933904  x: [ 3.99995726 15.99965806]  f(x): 1.8269780696733074e-09  grad at x: [ 8.23701793e-05 -2.09816590e-05]  gradient norm: 8.500044971735425e-05\n",
            "iter: 933905  x: [ 3.99995726 15.99965806]  f(x): 1.826922937355143e-09  grad at x: [-2.62342970e-06 -1.03576585e-05]  gradient norm: 1.0684730870969465e-05\n",
            "iter: 933906  x: [ 3.99995726 15.99965807]  f(x): 1.8268666257738631e-09  grad at x: [ 8.24172160e-05 -2.09872123e-05]  gradient norm: 8.504740196133728e-05\n",
            "iter: 933907  x: [ 3.99995726 15.99965807]  f(x): 1.826811433540889e-09  grad at x: [-2.62412421e-06 -1.03572456e-05]  gradient norm: 1.0684501151738695e-05\n",
            "iter: 933908  x: [ 3.99995726 15.99965808]  f(x): 1.8267551887639042e-09  grad at x: [ 8.24642818e-05 -2.09927694e-05]  gradient norm: 8.509438368536332e-05\n",
            "iter: 933909  x: [ 3.99995726 15.99965808]  f(x): 1.8266999365275051e-09  grad at x: [-2.62483335e-06 -1.03568309e-05]  gradient norm: 1.068427332006422e-05\n",
            "iter: 933910  x: [ 3.99995726 15.99965809]  f(x): 1.8266437597784684e-09  grad at x: [ 8.25122933e-05 -2.09984446e-05]  gradient norm: 8.514231162286567e-05\n",
            "iter: 933911  x: [ 3.99995726 15.99965809]  f(x): 1.8265884463330777e-09  grad at x: [-2.62554257e-06 -1.03564162e-05]  gradient norm: 1.0684045566342552e-05\n",
            "iter: 933912  x: [ 3.99995726 15.9996581 ]  f(x): 1.8265323376100202e-09  grad at x: [ 8.25602757e-05 -2.10041162e-05]  gradient norm: 8.519021085283292e-05\n",
            "iter: 933913  x: [ 3.99995726 15.9996581 ]  f(x): 1.8264769629561276e-09  grad at x: [-2.62622277e-06 -1.03560051e-05]  gradient norm: 1.0683814262585874e-05\n",
            "iter: 933914  x: [ 3.99995727 15.99965811]  f(x): 1.8264209199083858e-09  grad at x: [ 8.26064099e-05 -2.10095568e-05]  gradient norm: 8.523626242757343e-05\n",
            "iter: 933915  x: [ 3.99995726 15.99965811]  f(x): 1.8263654863607173e-09  grad at x: [-2.62693215e-06 -1.03555903e-05]  gradient norm: 1.0683586662244718e-05\n",
            "iter: 933916  x: [ 3.99995727 15.99965812]  f(x): 1.8263095114436187e-09  grad at x: [ 8.26544212e-05 -2.10152321e-05]  gradient norm: 8.528419153101089e-05\n",
            "iter: 933917  x: [ 3.99995727 15.99965812]  f(x): 1.8262540165821605e-09  grad at x: [-2.62761251e-06 -1.03551793e-05]  gradient norm: 1.0683355507905213e-05\n",
            "iter: 933918  x: [ 3.99995727 15.99965813]  f(x): 1.8261981074803855e-09  grad at x: [ 8.27005843e-05 -2.10206763e-05]  gradient norm: 8.533027294445672e-05\n",
            "iter: 933919  x: [ 3.99995727 15.99965813]  f(x): 1.8261425536029171e-09  grad at x: [-2.62830749e-06 -1.03547663e-05]  gradient norm: 1.0683126244410698e-05\n",
            "iter: 933920  x: [ 3.99995727 15.99965814]  f(x): 1.8260867115054847e-09  grad at x: [ 8.27476642e-05 -2.10262351e-05]  gradient norm: 8.537727148940841e-05\n",
            "iter: 933921  x: [ 3.99995727 15.99965814]  f(x): 1.826031097441069e-09  grad at x: [-2.62900256e-06 -1.03543534e-05]  gradient norm: 1.0682897056840714e-05\n",
            "iter: 933922  x: [ 3.99995727 15.99965815]  f(x): 1.8259753223807337e-09  grad at x: [ 8.27947585e-05 -2.10317958e-05]  gradient norm: 8.542428495995056e-05\n",
            "iter: 933923  x: [ 3.99995727 15.99965815]  f(x): 1.8259196480583518e-09  grad at x: [-2.62969771e-06 -1.03539405e-05]  gradient norm: 1.0682667944997109e-05\n",
            "iter: 933924  x: [ 3.99995727 15.99965816]  f(x): 1.8258778598927402e-09  grad at x: [ 4.01060775e-05 -1.56956485e-05]  gradient norm: 4.3067979182695524e-05\n",
            "iter: 933925  x: [ 3.99995727 15.99965816]  f(x): 1.8258630591050732e-09  grad at x: [-1.96229042e-06 -1.04371993e-05]  gradient norm: 1.0620061821071615e-05\n",
            "iter: 933926  x: [ 3.99995728 15.9996582 ]  f(x): 1.8256387803830196e-09  grad at x: [ 1.66401840e-04 -3.14810241e-05]  gradient norm: 0.0001693535569177635\n",
            "iter: 933927  x: [ 3.99995728 15.9996582 ]  f(x): 1.8254753061254312e-09  grad at x: [ 8.12326092e-05 -2.08350739e-05]  gradient norm: 8.386201222650777e-05\n",
            "iter: 933928  x: [ 3.99995728 15.9996582 ]  f(x): 1.8254216182581738e-09  grad at x: [-2.60509012e-06 -1.03555594e-05]  gradient norm: 1.0678207036943132e-05\n",
            "iter: 933929  x: [ 3.99995728 15.99965821]  f(x): 1.8253639517342282e-09  grad at x: [ 8.12786116e-05 -2.08404981e-05]  gradient norm: 8.390792016325254e-05\n",
            "iter: 933930  x: [ 3.99995728 15.99965821]  f(x): 1.825310206069774e-09  grad at x: [-2.60578570e-06 -1.03551465e-05]  gradient norm: 1.0677976327314384e-05\n",
            "iter: 933931  x: [ 3.99995728 15.99965822]  f(x): 1.8252526055626462e-09  grad at x: [ 8.13257199e-05 -2.08460606e-05]  gradient norm: 8.395493413530126e-05\n",
            "iter: 933932  x: [ 3.99995728 15.99965822]  f(x): 1.8251988006952847e-09  grad at x: [-2.60645226e-06 -1.03547372e-05]  gradient norm: 1.067774211687865e-05\n",
            "iter: 933933  x: [ 3.99995728 15.99965823]  f(x): 1.8251412639619747e-09  grad at x: [ 8.13710092e-05 -2.08513957e-05]  gradient norm: 8.400012996960723e-05\n",
            "iter: 933934  x: [ 3.99995728 15.99965823]  f(x): 1.8250874021183138e-09  grad at x: [-2.60716255e-06 -1.03543225e-05]  gradient norm: 1.0677513346017504e-05\n",
            "iter: 933935  x: [ 3.99995728 15.99965824]  f(x): 1.8250299326788949e-09  grad at x: [ 8.14190778e-05 -2.08570782e-05]  gradient norm: 8.404810491185953e-05\n",
            "iter: 933936  x: [ 3.99995728 15.99965824]  f(x): 1.824976010354629e-09  grad at x: [-2.60784382e-06 -1.03539114e-05]  gradient norm: 1.067728107229558e-05\n",
            "iter: 933937  x: [ 3.99995728 15.99965825]  f(x): 1.8249186058545808e-09  grad at x: [ 8.14652691e-05 -2.08625261e-05]  gradient norm: 8.409420350552305e-05\n",
            "iter: 933938  x: [ 3.99995728 15.99965825]  f(x): 1.8248646253671332e-09  grad at x: [-2.60852517e-06 -1.03535003e-05]  gradient norm: 1.0677048872130631e-05\n",
            "iter: 933939  x: [ 3.99995728 15.99965826]  f(x): 1.8248072859118116e-09  grad at x: [ 8.15115040e-05 -2.08679794e-05]  gradient norm: 8.414034612308778e-05\n",
            "iter: 933940  x: [ 3.99995728 15.99965826]  f(x): 1.8247532471750669e-09  grad at x: [-2.60922115e-06 -1.03530874e-05]  gradient norm: 1.0676818538138399e-05\n",
            "iter: 933941  x: [ 3.99995729 15.99965827]  f(x): 1.8246959739749035e-09  grad at x: [ 8.15586556e-05 -2.08735473e-05]  gradient norm: 8.418740569252818e-05\n",
            "iter: 933942  x: [ 3.99995728 15.99965827]  f(x): 1.8246418758148995e-09  grad at x: [-2.60990266e-06 -1.03526763e-05]  gradient norm: 1.0676586486619363e-05\n",
            "iter: 933943  x: [ 3.99995729 15.99965828]  f(x): 1.82458466768731e-09  grad at x: [ 8.16048757e-05 -2.08789988e-05]  gradient norm: 8.423353452330812e-05\n",
            "iter: 933944  x: [ 3.99995729 15.99965828]  f(x): 1.8245305112299893e-09  grad at x: [-2.61058424e-06 -1.03522652e-05]  gradient norm: 1.0676354508717494e-05\n",
            "iter: 933945  x: [ 3.99995729 15.99965829]  f(x): 1.8244733682079384e-09  grad at x: [ 8.16510813e-05 -2.08844485e-05]  gradient norm: 8.427964918055042e-05\n",
            "iter: 933946  x: [ 3.99995729 15.99965829]  f(x): 1.8244191534395747e-09  grad at x: [-2.61128046e-06 -1.03518523e-05]  gradient norm: 1.0676124400182608e-05\n",
            "iter: 933947  x: [ 3.99995729 15.9996583 ]  f(x): 1.8243620768079655e-09  grad at x: [ 8.16982617e-05 -2.08900201e-05]  gradient norm: 8.432673900833207e-05\n",
            "iter: 933948  x: [ 3.99995729 15.9996583 ]  f(x): 1.8243078024617338e-09  grad at x: [-2.61197676e-06 -1.03514394e-05]  gradient norm: 1.0675894367618627e-05\n",
            "iter: 933949  x: [ 3.99995729 15.99965831]  f(x): 1.8242507922161236e-09  grad at x: [ 8.17454421e-05 -2.08955917e-05]  gradient norm: 8.437382923128332e-05\n",
            "iter: 933950  x: [ 3.99995729 15.99965831]  f(x): 1.8241964582582196e-09  grad at x: [-2.61267314e-06 -1.03510265e-05]  gradient norm: 1.0675664410611374e-05\n",
            "iter: 933951  x: [ 3.99995729 15.99965832]  f(x): 1.8241395144329068e-09  grad at x: [ 8.17926079e-05 -2.09011614e-05]  gradient norm: 8.442090529423443e-05\n",
            "iter: 933952  x: [ 3.99995729 15.99965832]  f(x): 1.8240851208482696e-09  grad at x: [-2.61338415e-06 -1.03506118e-05]  gradient norm: 1.0675436328540636e-05\n",
            "iter: 933953  x: [ 3.99995729 15.99965833]  f(x): 1.8240282446945014e-09  grad at x: [ 8.18407340e-05 -2.09068512e-05]  gradient norm: 8.446894202344626e-05\n",
            "iter: 933954  x: [ 3.99995729 15.99965833]  f(x): 1.823973790267184e-09  grad at x: [-2.61405158e-06 -1.03502025e-05]  gradient norm: 1.0675202925124146e-05\n",
            "iter: 933955  x: [ 3.9999573  15.99965834]  f(x): 1.8239169782371566e-09  grad at x: [ 8.18860369e-05 -2.09121881e-05]  gradient norm: 8.451415650515097e-05\n",
            "iter: 933956  x: [ 3.99995729 15.99965834]  f(x): 1.8238624664606536e-09  grad at x: [-2.61474820e-06 -1.03497896e-05]  gradient norm: 1.06749731951552e-05\n",
            "iter: 933957  x: [ 3.9999573  15.99965835]  f(x): 1.8238057209870739e-09  grad at x: [ 8.19332315e-05 -2.09177615e-05]  gradient norm: 8.456126282789372e-05\n",
            "iter: 933958  x: [ 3.9999573  15.99965835]  f(x): 1.8237511494455931e-09  grad at x: [-2.61543034e-06 -1.03493785e-05]  gradient norm: 1.0674741739198177e-05\n",
            "iter: 933959  x: [ 3.9999573  15.99965836]  f(x): 1.82369446937856e-09  grad at x: [ 8.19794947e-05 -2.09232185e-05]  gradient norm: 8.460743833862414e-05\n",
            "iter: 933960  x: [ 3.9999573  15.99965836]  f(x): 1.823639839241236e-09  grad at x: [-2.61611257e-06 -1.03489674e-05]  gradient norm: 1.0674510357454427e-05\n",
            "iter: 933961  x: [ 3.9999573  15.99965837]  f(x): 1.8235832246129347e-09  grad at x: [ 8.20257578e-05 -2.09286754e-05]  gradient norm: 8.46536142176947e-05\n",
            "iter: 933962  x: [ 3.9999573  15.99965837]  f(x): 1.8235285358105046e-09  grad at x: [-2.61682398e-06 -1.03485527e-05]  gradient norm: 1.0674282657155272e-05\n",
            "iter: 933963  x: [ 3.9999573  15.99965838]  f(x): 1.8234719890590383e-09  grad at x: [ 8.20739126e-05 -2.09343689e-05]  gradient norm: 8.470168200752211e-05\n",
            "iter: 933964  x: [ 3.9999573  15.99965838]  f(x): 1.8234172391703106e-09  grad at x: [-2.61752091e-06 -1.03481398e-05]  gradient norm: 1.0674053230107808e-05\n",
            "iter: 933965  x: [ 3.9999573  15.99965839]  f(x): 1.823360759108693e-09  grad at x: [ 8.21211069e-05 -2.09399423e-05]  gradient norm: 8.474878987124173e-05\n",
            "iter: 933966  x: [ 3.9999573 15.9996584]  f(x): 1.8233059493398862e-09  grad at x: [-2.61821793e-06 -1.03477269e-05]  gradient norm: 1.0673823879215502e-05\n",
            "iter: 933967  x: [ 3.9999573  15.99965841]  f(x): 1.823249536038119e-09  grad at x: [ 8.21683302e-05 -2.09455193e-05]  gradient norm: 8.479592722226783e-05\n",
            "iter: 933968  x: [ 3.9999573  15.99965841]  f(x): 1.8231946662809955e-09  grad at x: [-2.61891502e-06 -1.03473139e-05]  gradient norm: 1.0673594604280995e-05\n",
            "iter: 933969  x: [ 3.9999573  15.99965842]  f(x): 1.8231383197726342e-09  grad at x: [ 8.22155535e-05 -2.09510963e-05]  gradient norm: 8.484306495804319e-05\n",
            "iter: 933970  x: [ 3.9999573  15.99965842]  f(x): 1.823083390012872e-09  grad at x: [-2.61962674e-06 -1.03468992e-05]  gradient norm: 1.0673367213742454e-05\n",
            "iter: 933971  x: [ 3.99995731 15.99965843]  f(x): 1.823027111518905e-09  grad at x: [ 8.22637080e-05 -2.09567897e-05]  gradient norm: 8.489113433162587e-05\n",
            "iter: 933972  x: [ 3.9999573  15.99965843]  f(x): 1.8229721205708004e-09  grad at x: [-2.62029489e-06 -1.03464899e-05]  gradient norm: 1.0673134473563238e-05\n",
            "iter: 933973  x: [ 3.99995731 15.99965844]  f(x): 1.8229159065618169e-09  grad at x: [ 8.23090684e-05 -2.09621339e-05]  gradient norm: 8.493641031845575e-05\n",
            "iter: 933974  x: [ 3.99995731 15.99965844]  f(x): 1.8228608579004938e-09  grad at x: [-2.62099223e-06 -1.03460770e-05]  gradient norm: 1.0672905426000819e-05\n",
            "iter: 933975  x: [ 3.99995731 15.99965845]  f(x): 1.8228047108214793e-09  grad at x: [ 8.23563205e-05 -2.09677146e-05]  gradient norm: 8.498357829863143e-05\n",
            "iter: 933976  x: [ 3.99995731 15.99965845]  f(x): 1.8227496020200216e-09  grad at x: [-2.62170419e-06 -1.03456623e-05]  gradient norm: 1.0672678266055903e-05\n",
            "iter: 933977  x: [ 3.99995731 15.99965846]  f(x): 1.8226935230574093e-09  grad at x: [ 8.24044748e-05 -2.09734080e-05]  gradient norm: 8.503164883856776e-05\n",
            "iter: 933978  x: [ 3.99995731 15.99965846]  f(x): 1.8226383529462864e-09  grad at x: [-2.62238713e-06 -1.03452512e-05]  gradient norm: 1.0672447559451213e-05\n",
            "iter: 933979  x: [ 3.99995731 15.99965847]  f(x): 1.8225823397913778e-09  grad at x: [ 8.24507954e-05 -2.09788723e-05]  gradient norm: 8.507788630264377e-05\n",
            "iter: 933980  x: [ 3.99995731 15.99965847]  f(x): 1.8225271106433867e-09  grad at x: [-2.62309926e-06 -1.03448365e-05]  gradient norm: 1.0672220553985588e-05\n",
            "iter: 933981  x: [ 3.99995731 15.99965848]  f(x): 1.822471165709986e-09  grad at x: [ 8.24989786e-05 -2.09845693e-05]  gradient norm: 8.512598672524721e-05\n",
            "iter: 933982  x: [ 3.99995731 15.99965848]  f(x): 1.8224158751466007e-09  grad at x: [-2.62378235e-06 -1.03444254e-05]  gradient norm: 1.0671989997659792e-05\n",
            "iter: 933983  x: [ 3.99995731 15.99965849]  f(x): 1.8223599960494661e-09  grad at x: [ 8.25452845e-05 -2.09900318e-05]  gradient norm: 8.517221038311568e-05\n",
            "iter: 933984  x: [ 3.99995731 15.99965849]  f(x): 1.8223046464188657e-09  grad at x: [-2.62446553e-06 -1.03440143e-05]  gradient norm: 1.0671759515353901e-05\n",
            "iter: 933985  x: [ 3.99995731 15.9996585 ]  f(x): 1.8222488333015152e-09  grad at x: [ 8.25916485e-05 -2.09955015e-05]  gradient norm: 8.521849261068072e-05\n",
            "iter: 933986  x: [ 3.99995731 15.9996585 ]  f(x): 1.8221934244794122e-09  grad at x: [-2.62516334e-06 -1.03436014e-05]  gradient norm: 1.067153092392926e-05\n",
            "iter: 933987  x: [ 3.99995732 15.99965851]  f(x): 1.8221376784929285e-09  grad at x: [ 8.26389001e-05 -2.10010821e-05]  gradient norm: 8.526566286583895e-05\n",
            "iter: 933988  x: [ 3.99995731 15.99965851]  f(x): 1.822082209346303e-09  grad at x: [-2.62586123e-06 -1.03431885e-05]  gradient norm: 1.0671302408885234e-05\n",
            "iter: 933989  x: [ 3.99995732 15.99965852]  f(x): 1.822026530523685e-09  grad at x: [ 8.26861662e-05 -2.10066646e-05]  gradient norm: 8.531284805212965e-05\n",
            "iter: 933990  x: [ 3.99995732 15.99965852]  f(x): 1.821971000981315e-09  grad at x: [-2.62655920e-06 -1.03427756e-05]  gradient norm: 1.06710739700238e-05\n",
            "iter: 933991  x: [ 3.99995732 15.99965853]  f(x): 1.8219153894308302e-09  grad at x: [ 8.27334614e-05 -2.10122507e-05]  gradient norm: 8.536006272109563e-05\n",
            "iter: 933992  x: [ 3.99995732 15.99965853]  f(x): 1.8218736967348673e-09  grad at x: [ 4.00530948e-05 -1.56773058e-05]  gradient norm: 4.3011955513405424e-05\n",
            "iter: 933993  x: [ 3.99995732 15.99965853]  f(x): 1.821858934084327e-09  grad at x: [-1.96000441e-06 -1.04257651e-05]  gradient norm: 1.0608402144640305e-05\n",
            "iter: 933994  x: [ 3.99995733 15.99965857]  f(x): 1.8216350590847218e-09  grad at x: [ 1.66184801e-04 -3.14421759e-05]  gradient norm: 0.00016913307886924202\n",
            "iter: 933995  x: [ 3.99995732 15.99965857]  f(x): 1.821472010131499e-09  grad at x: [ 8.11265292e-05 -2.08100955e-05]  gradient norm: 8.375305256565479e-05\n",
            "iter: 933996  x: [ 3.99995732 15.99965857]  f(x): 1.821418461325912e-09  grad at x: [-2.60197142e-06 -1.03442308e-05]  gradient norm: 1.0666459829457052e-05\n",
            "iter: 933997  x: [ 3.99995733 15.99965858]  f(x): 1.8213609003083722e-09  grad at x: [ 8.11727762e-05 -2.08155507e-05]  gradient norm: 8.379920488694346e-05\n",
            "iter: 933998  x: [ 3.99995732 15.99965858]  f(x): 1.8213072934774254e-09  grad at x: [-2.60265532e-06 -1.03438197e-05]  gradient norm: 1.0666228012179978e-05\n",
            "iter: 933999  x: [ 3.99995733 15.99965859]  f(x): 1.821249797464944e-09  grad at x: [ 8.12191540e-05 -2.08210222e-05]  gradient norm: 8.384548852367733e-05\n",
            "iter: 934000  x: [ 3.99995733 15.99965859]  f(x): 1.8211961324328023e-09  grad at x: [-2.60333929e-06 -1.03434086e-05]  gradient norm: 1.0665996269069894e-05\n",
            "iter: 934001  x: [ 3.99995733 15.9996586 ]  f(x): 1.8211387014577273e-09  grad at x: [ 8.12655318e-05 -2.08264937e-05]  gradient norm: 8.389177254563395e-05\n",
            "iter: 934002  x: [ 3.99995733 15.9996586 ]  f(x): 1.8210849781538286e-09  grad at x: [-2.60402334e-06 -1.03429975e-05]  gradient norm: 1.0665764600147016e-05\n",
            "iter: 934003  x: [ 3.99995733 15.99965861]  f(x): 1.82102761224851e-09  grad at x: [ 8.13119095e-05 -2.08319652e-05]  gradient norm: 8.393805694860499e-05\n",
            "iter: 934004  x: [ 3.99995733 15.99965861]  f(x): 1.820973830678096e-09  grad at x: [-2.60470747e-06 -1.03425864e-05]  gradient norm: 1.0665533005214648e-05\n",
            "iter: 934005  x: [ 3.99995733 15.99965862]  f(x): 1.8209165298748817e-09  grad at x: [ 8.13582871e-05 -2.08374368e-05]  gradient norm: 8.398434173526675e-05\n",
            "iter: 934006  x: [ 3.99995733 15.99965862]  f(x): 1.8208626899673928e-09  grad at x: [-2.60539168e-06 -1.03421753e-05]  gradient norm: 1.0665301484292824e-05\n",
            "iter: 934007  x: [ 3.99995733 15.99965863]  f(x): 1.8208054543347842e-09  grad at x: [ 8.14046938e-05 -2.08429119e-05]  gradient norm: 8.403065599983118e-05\n",
            "iter: 934008  x: [ 3.99995733 15.99965863]  f(x): 1.8207515560593085e-09  grad at x: [-2.60607597e-06 -1.03417642e-05]  gradient norm: 1.066507003761861e-05\n",
            "iter: 934009  x: [ 3.99995733 15.99965864]  f(x): 1.8206943855926599e-09  grad at x: [ 8.14510858e-05 -2.08483852e-05]  gradient norm: 8.407695609862177e-05\n",
            "iter: 934010  x: [ 3.99995733 15.99965864]  f(x): 1.8206404289156337e-09  grad at x: [-2.60676033e-06 -1.03413531e-05]  gradient norm: 1.066483866499513e-05\n",
            "iter: 934011  x: [ 3.99995733 15.99965866]  f(x): 1.8205833237214043e-09  grad at x: [ 8.14975069e-05 -2.08538622e-05]  gradient norm: 8.412328567460952e-05\n",
            "iter: 934012  x: [ 3.99995733 15.99965866]  f(x): 1.8205293085555863e-09  grad at x: [-2.60745933e-06 -1.03409402e-05]  gradient norm: 1.0664609160758204e-05\n",
            "iter: 934013  x: [ 3.99995734 15.99965867]  f(x): 1.82047226980634e-09  grad at x: [ 8.15448446e-05 -2.08594538e-05]  gradient norm: 8.417053222100726e-05\n",
            "iter: 934014  x: [ 3.99995733 15.99965867]  f(x): 1.8204181949972247e-09  grad at x: [-2.60815841e-06 -1.03405273e-05]  gradient norm: 1.0664379732935458e-05\n",
            "iter: 934015  x: [ 3.99995734 15.99965868]  f(x): 1.8203612227266807e-09  grad at x: [ 8.15921823e-05 -2.08650454e-05]  gradient norm: 8.421777916192191e-05\n",
            "iter: 934016  x: [ 3.99995734 15.99965868]  f(x): 1.8203070882023431e-09  grad at x: [-2.60885757e-06 -1.03401144e-05]  gradient norm: 1.0664150381330259e-05\n",
            "iter: 934017  x: [ 3.99995734 15.99965869]  f(x): 1.8202501824442217e-09  grad at x: [ 8.16395199e-05 -2.08706369e-05]  gradient norm: 8.426502649999417e-05\n",
            "iter: 934018  x: [ 3.99995734 15.99965869]  f(x): 1.8201959882085252e-09  grad at x: [-2.60955681e-06 -1.03397015e-05]  gradient norm: 1.066392110618042e-05\n",
            "iter: 934019  x: [ 3.99995734 15.9996587 ]  f(x): 1.8201391489957389e-09  grad at x: [ 8.16868719e-05 -2.08762303e-05]  gradient norm: 8.431228878359769e-05\n",
            "iter: 934020  x: [ 3.99995734 15.9996587 ]  f(x): 1.8200848949775675e-09  grad at x: [-2.61025613e-06 -1.03392886e-05]  gradient norm: 1.066369190728919e-05\n",
            "iter: 934021  x: [ 3.99995734 15.99965871]  f(x): 1.8200281224180457e-09  grad at x: [ 8.17342530e-05 -2.08818274e-05]  gradient norm: 8.435958055821608e-05\n",
            "iter: 934022  x: [ 3.99995734 15.99965871]  f(x): 1.8199738085286857e-09  grad at x: [-2.61097008e-06 -1.03388738e-05]  gradient norm: 1.0663464584329133e-05\n",
            "iter: 934023  x: [ 3.99995734 15.99965872]  f(x): 1.8199171037625859e-09  grad at x: [ 8.17825363e-05 -2.08875372e-05]  gradient norm: 8.440777481321101e-05\n",
            "iter: 934024  x: [ 3.99995734 15.99965872]  f(x): 1.8198627288420455e-09  grad at x: [-2.61168411e-06 -1.03384591e-05]  gradient norm: 1.066323733981592e-05\n",
            "iter: 934025  x: [ 3.99995734 15.99965873]  f(x): 1.8198060919786955e-09  grad at x: [ 8.18308485e-05 -2.08932506e-05]  gradient norm: 8.445599857761937e-05\n",
            "iter: 934026  x: [ 3.99995734 15.99965873]  f(x): 1.8197516559552266e-09  grad at x: [-2.61239822e-06 -1.03380444e-05]  gradient norm: 1.0663010173988042e-05\n",
            "iter: 934027  x: [ 3.99995734 15.99965874]  f(x): 1.8196950869555161e-09  grad at x: [ 8.18791316e-05 -2.08989604e-05]  gradient norm: 8.450419365079907e-05\n",
            "iter: 934028  x: [ 3.99995734 15.99965874]  f(x): 1.8196405898300294e-09  grad at x: [-2.61311241e-06 -1.03376296e-05]  gradient norm: 1.0662783086648927e-05\n",
            "iter: 934029  x: [ 3.99995735 15.99965875]  f(x): 1.819584088839711e-09  grad at x: [ 8.19274729e-05 -2.09046775e-05]  gradient norm: 8.455244733545316e-05\n",
            "iter: 934030  x: [ 3.99995734 15.99965875]  f(x): 1.8195295305040311e-09  grad at x: [-2.61382667e-06 -1.03372149e-05]  gradient norm: 1.0662556078037201e-05\n",
            "iter: 934031  x: [ 3.99995735 15.99965876]  f(x): 1.8194730974839965e-09  grad at x: [ 8.19757849e-05 -2.09103910e-05]  gradient norm: 8.46006723289248e-05\n",
            "iter: 934032  x: [ 3.99995735 15.99965876]  f(x): 1.8194184779390352e-09  grad at x: [-2.61454102e-06 -1.03368002e-05]  gradient norm: 1.0662329147738374e-05\n",
            "iter: 934033  x: [ 3.99995735 15.99965877]  f(x): 1.8193621129987358e-09  grad at x: [ 8.2024126e-05 -2.0916108e-05]  gradient norm: 8.464892683013206e-05\n",
            "iter: 934034  x: [ 3.99995735 15.99965877]  f(x): 1.8193074321726163e-09  grad at x: [-2.61525545e-06 -1.03363855e-05]  gradient norm: 1.0662102296426725e-05\n",
            "iter: 934035  x: [ 3.99995735 15.99965878]  f(x): 1.8192511352729031e-09  grad at x: [ 8.20724378e-05 -2.09218215e-05]  gradient norm: 8.469715263793237e-05\n",
            "iter: 934036  x: [ 3.99995735 15.99965878]  f(x): 1.8191963931654185e-09  grad at x: [-2.61594085e-06 -1.03359744e-05]  gradient norm: 1.066187190966315e-05\n",
            "iter: 934037  x: [ 3.99995735 15.99965879]  f(x): 1.8191401620078534e-09  grad at x: [ 8.21189015e-05 -2.09273039e-05]  gradient norm: 8.474353091534086e-05\n",
            "iter: 934038  x: [ 3.99995735 15.99965879]  f(x): 1.8190853609561749e-09  grad at x: [-2.61662633e-06 -1.03355633e-05]  gradient norm: 1.066164159723455e-05\n",
            "iter: 934039  x: [ 3.99995735 15.9996588 ]  f(x): 1.8190291955732263e-09  grad at x: [ 8.21653651e-05 -2.09327864e-05]  gradient norm: 8.478990956155532e-05\n",
            "iter: 934040  x: [ 3.99995735 15.9996588 ]  f(x): 1.8189743355066938e-09  grad at x: [-2.61731189e-06 -1.03351522e-05]  gradient norm: 1.0661411359160992e-05\n",
            "iter: 934041  x: [ 3.99995735 15.99965881]  f(x): 1.8189182359673427e-09  grad at x: [ 8.22118577e-05 -2.09382724e-05]  gradient norm: 8.483631768064806e-05\n",
            "iter: 934042  x: [ 3.99995735 15.99965881]  f(x): 1.8188633168545446e-09  grad at x: [-2.61799753e-06 -1.03347411e-05]  gradient norm: 1.066118119568064e-05\n",
            "iter: 934043  x: [ 3.99995736 15.99965882]  f(x): 1.8188072831547702e-09  grad at x: [ 8.22583211e-05 -2.09437549e-05]  gradient norm: 8.488269706768822e-05\n",
            "iter: 934044  x: [ 3.99995735 15.99965882]  f(x): 1.8187523049615386e-09  grad at x: [-2.61868325e-06 -1.03343300e-05]  gradient norm: 1.0660951106595587e-05\n",
            "iter: 934045  x: [ 3.99995736 15.99965883]  f(x): 1.8186963371703621e-09  grad at x: [ 8.23048136e-05 -2.09492409e-05]  gradient norm: 8.49291059266631e-05\n",
            "iter: 934046  x: [ 3.99995736 15.99965883]  f(x): 1.8186412998468858e-09  grad at x: [-2.61938360e-06 -1.03339171e-05]  gradient norm: 1.066072290458998e-05\n",
            "iter: 934047  x: [ 3.99995736 15.99965884]  f(x): 1.818585399185488e-09  grad at x: [ 8.23522373e-05 -2.09548434e-05]  gradient norm: 8.497644644026074e-05\n",
            "iter: 934048  x: [ 3.99995736 15.99965884]  f(x): 1.8185303014907577e-09  grad at x: [-2.62008403e-06 -1.03335042e-05]  gradient norm: 1.0660494778912593e-05\n",
            "iter: 934049  x: [ 3.99995736 15.99965885]  f(x): 1.818474468029577e-09  grad at x: [ 8.23996900e-05 -2.09604495e-05]  gradient norm: 8.502381644244656e-05\n",
            "iter: 934050  x: [ 3.99995736 15.99965885]  f(x): 1.81841930993072e-09  grad at x: [-2.62078454e-06 -1.03330913e-05]  gradient norm: 1.0660266730020447e-05\n",
            "iter: 934051  x: [ 3.99995736 15.99965886]  f(x): 1.8183635436670256e-09  grad at x: [ 8.24471136e-05 -2.09660520e-05]  gradient norm: 8.507115772611782e-05\n",
            "iter: 934052  x: [ 3.99995736 15.99965886]  f(x): 1.8183083251285869e-09  grad at x: [-2.62148513e-06 -1.03326784e-05]  gradient norm: 1.0660038757715803e-05\n",
            "iter: 934053  x: [ 3.99995736 15.99965887]  f(x): 1.8182526261328592e-09  grad at x: [ 8.24945662e-05 -2.09716582e-05]  gradient norm: 8.511852849736442e-05\n",
            "iter: 934054  x: [ 3.99995736 15.99965887]  f(x): 1.8181973471219222e-09  grad at x: [-2.62218580e-06 -1.03322654e-05]  gradient norm: 1.065981086223765e-05\n",
            "iter: 934055  x: [ 3.99995736 15.99965888]  f(x): 1.8181417154280446e-09  grad at x: [ 8.25420187e-05 -2.09772643e-05]  gradient norm: 8.516589964953265e-05\n",
            "iter: 934056  x: [ 3.99995736 15.99965888]  f(x): 1.818086375872543e-09  grad at x: [-2.62288655e-06 -1.03318525e-05]  gradient norm: 1.0659583043388127e-05\n",
            "iter: 934057  x: [ 3.99995736 15.99965889]  f(x): 1.8180308115144021e-09  grad at x: [ 8.25894711e-05 -2.09828704e-05]  gradient norm: 8.52132711870157e-05\n",
            "iter: 934058  x: [ 3.99995736 15.99965889]  f(x): 1.81797541141801e-09  grad at x: [-2.62358737e-06 -1.03314396e-05]  gradient norm: 1.0659355301406347e-05\n",
            "iter: 934059  x: [ 3.99995737 15.9996589 ]  f(x): 1.8179199144294894e-09  grad at x: [ 8.26369234e-05 -2.09884765e-05]  gradient norm: 8.52606431038787e-05\n",
            "iter: 934060  x: [ 3.99995736 15.99965891]  f(x): 1.8178783187574772e-09  grad at x: [ 4.00062957e-05 -1.56597489e-05]  gradient norm: 4.296197661390002e-05\n",
            "iter: 934061  x: [ 3.99995736 15.99965891]  f(x): 1.8178635902686817e-09  grad at x: [-1.95782128e-06 -1.04143310e-05]  gradient norm: 1.0596761475276356e-05\n",
            "iter: 934062  x: [ 3.99995737 15.99965895]  f(x): 1.8176401845855832e-09  grad at x: [ 1.65993998e-04 -3.14066201e-05]  gradient norm: 0.0001689389921542871\n",
            "iter: 934063  x: [ 3.99995737 15.99965895]  f(x): 1.8174775096238306e-09  grad at x: [ 8.10333560e-05 -2.07867433e-05]  gradient norm: 8.365699902938102e-05\n",
            "iter: 934064  x: [ 3.99995737 15.99965895]  f(x): 1.817424083481354e-09  grad at x: [-2.59907201e-06 -1.03328875e-05]  gradient norm: 1.0654752003288684e-05\n",
            "iter: 934065  x: [ 3.99995737 15.99965896]  f(x): 1.8173666451217833e-09  grad at x: [ 8.10808662e-05 -2.07923567e-05]  gradient norm: 8.370441421466312e-05\n",
            "iter: 934066  x: [ 3.99995737 15.99965896]  f(x): 1.8173131594388022e-09  grad at x: [-2.59975876e-06 -1.03324764e-05]  gradient norm: 1.0654520880238872e-05\n",
            "iter: 934067  x: [ 3.99995737 15.99965897]  f(x): 1.817255786182941e-09  grad at x: [ 8.11274013e-05 -2.07978483e-05]  gradient norm: 8.375085508521652e-05\n",
            "iter: 934068  x: [ 3.99995737 15.99965897]  f(x): 1.817202242169423e-09  grad at x: [-2.60043104e-06 -1.03320672e-05]  gradient norm: 1.0654288043824967e-05\n",
            "iter: 934069  x: [ 3.99995737 15.99965898]  f(x): 1.8171449329148768e-09  grad at x: [ 8.11730195e-05 -2.08032252e-05]  gradient norm: 8.379637980767863e-05\n",
            "iter: 934070  x: [ 3.99995737 15.99965898]  f(x): 1.817091331655707e-09  grad at x: [-2.60113250e-06 -1.03316543e-05]  gradient norm: 1.0654058857599767e-05\n",
            "iter: 934071  x: [ 3.99995738 15.99965899]  f(x): 1.8170340888149843e-09  grad at x: [ 8.12205294e-05 -2.08088386e-05]  gradient norm: 8.384379618218507e-05\n",
            "iter: 934072  x: [ 3.99995737 15.99965899]  f(x): 1.8169804279145442e-09  grad at x: [-2.60181948e-06 -1.03312432e-05]  gradient norm: 1.0653827958267764e-05\n",
            "iter: 934073  x: [ 3.99995738 15.999659  ]  f(x): 1.816923250348357e-09  grad at x: [ 8.12671079e-05 -2.08143356e-05]  gradient norm: 8.389028185994261e-05\n",
            "iter: 934074  x: [ 3.99995738 15.999659  ]  f(x): 1.8168695309284277e-09  grad at x: [-2.60253566e-06 -1.03308284e-05]  gradient norm: 1.0653600715291615e-05\n",
            "iter: 934075  x: [ 3.99995738 15.99965901]  f(x): 1.81681242098115e-09  grad at x: [ 8.13155199e-05 -2.08200618e-05]  gradient norm: 8.393860104918264e-05\n",
            "iter: 934076  x: [ 3.99995738 15.99965901]  f(x): 1.8167586407325954e-09  grad at x: [-2.60322280e-06 -1.03304174e-05]  gradient norm: 1.0653369967011897e-05\n",
            "iter: 934077  x: [ 3.99995738 15.99965902]  f(x): 1.816701596126423e-09  grad at x: [ 8.13620982e-05 -2.08255587e-05]  gradient norm: 8.398508751436898e-05\n",
            "iter: 934078  x: [ 3.99995738 15.99965902]  f(x): 1.8166477572900348e-09  grad at x: [-2.60391003e-06 -1.03300063e-05]  gradient norm: 1.065313929324122e-05\n",
            "iter: 934079  x: [ 3.99995738 15.99965903]  f(x): 1.816590778093756e-09  grad at x: [ 8.14087056e-05 -2.08310594e-05]  gradient norm: 8.403160346241953e-05\n",
            "iter: 934080  x: [ 3.99995738 15.99965903]  f(x): 1.8165368806382922e-09  grad at x: [-2.60459733e-06 -1.03295952e-05]  gradient norm: 1.065290869421688e-05\n",
            "iter: 934081  x: [ 3.99995738 15.99965904]  f(x): 1.8164799668484065e-09  grad at x: [ 8.14552838e-05 -2.08365564e-05]  gradient norm: 8.407809069662784e-05\n",
            "iter: 934082  x: [ 3.99995738 15.99965904]  f(x): 1.8164260107392018e-09  grad at x: [-2.60528472e-06 -1.03291841e-05]  gradient norm: 1.0652678169959201e-05\n",
            "iter: 934083  x: [ 3.99995738 15.99965905]  f(x): 1.8163691624245387e-09  grad at x: [ 8.1501891e-05 -2.0842057e-05]  gradient norm: 8.412460741270814e-05\n",
            "iter: 934084  x: [ 3.99995738 15.99965905]  f(x): 1.8163151475936128e-09  grad at x: [-2.60600129e-06 -1.03287693e-05]  gradient norm: 1.065245131271684e-05\n",
            "iter: 934085  x: [ 3.99995738 15.99965906]  f(x): 1.8162583671051492e-09  grad at x: [ 8.15503317e-05 -2.08477868e-05]  gradient norm: 8.417295772360048e-05\n",
            "iter: 934086  x: [ 3.99995738 15.99965906]  f(x): 1.8162042912367536e-09  grad at x: [-2.60668883e-06 -1.03283583e-05]  gradient norm: 1.0652220939715313e-05\n",
            "iter: 934087  x: [ 3.99995739 15.99965907]  f(x): 1.8161475762901638e-09  grad at x: [ 8.15969387e-05 -2.08532874e-05]  gradient norm: 8.421947522031319e-05\n",
            "iter: 934088  x: [ 3.99995738 15.99965907]  f(x): 1.8160934416316194e-09  grad at x: [-2.60737645e-06 -1.03279472e-05]  gradient norm: 1.065199064132407e-05\n",
            "iter: 934089  x: [ 3.99995739 15.99965908]  f(x): 1.8160367922595793e-09  grad at x: [ 8.16435457e-05 -2.08587880e-05]  gradient norm: 8.426599309932683e-05\n",
            "iter: 934090  x: [ 3.99995739 15.99965908]  f(x): 1.815982598797405e-09  grad at x: [-2.60807871e-06 -1.03275343e-05]  gradient norm: 1.0651762217178663e-05\n",
            "iter: 934091  x: [ 3.99995739 15.99965909]  f(x): 1.8159260162481304e-09  grad at x: [ 8.16911130e-05 -2.08644087e-05]  gradient norm: 8.431347163870784e-05\n",
            "iter: 934092  x: [ 3.99995739 15.99965909]  f(x): 1.8158717627326425e-09  grad at x: [-2.60876649e-06 -1.03271232e-05]  gradient norm: 1.0651532069552271e-05\n",
            "iter: 934093  x: [ 3.99995739 15.9996591 ]  f(x): 1.8158152457868757e-09  grad at x: [ 8.17377053e-05 -2.08699075e-05]  gradient norm: 8.435997573593657e-05\n",
            "iter: 934094  x: [ 3.99995739 15.9996591 ]  f(x): 1.8157609334186777e-09  grad at x: [-2.60945435e-06 -1.03267121e-05]  gradient norm: 1.0651301996379408e-05\n",
            "iter: 934095  x: [ 3.99995739 15.99965911]  f(x): 1.8157044822195584e-09  grad at x: [ 8.17843557e-05 -2.08754136e-05]  gradient norm: 8.440653841176295e-05\n",
            "iter: 934096  x: [ 3.99995739 15.99965911]  f(x): 1.8156501108930466e-09  grad at x: [-2.61014229e-06 -1.03263010e-05]  gradient norm: 1.0651071998115354e-05\n",
            "iter: 934097  x: [ 3.99995739 15.99965912]  f(x): 1.8155937254362169e-09  grad at x: [ 8.18309914e-05 -2.08809179e-05]  gradient norm: 8.445308691607239e-05\n",
            "iter: 934098  x: [ 3.99995739 15.99965912]  f(x): 1.815539295099252e-09  grad at x: [-2.61084486e-06 -1.03258881e-05]  gradient norm: 1.0650843878393985e-05\n",
            "iter: 934099  x: [ 3.99995739 15.99965913]  f(x): 1.8154829765993524e-09  grad at x: [ 8.18785584e-05 -2.08865386e-05]  gradient norm: 8.450056701577114e-05\n",
            "iter: 934100  x: [ 3.99995739 15.99965913]  f(x): 1.8154284860931713e-09  grad at x: [-2.61154751e-06 -1.03254752e-05]  gradient norm: 1.0650615835522783e-05\n",
            "iter: 934101  x: [ 3.9999574  15.99965914]  f(x): 1.8153722345842535e-09  grad at x: [ 8.19261254e-05 -2.08921592e-05]  gradient norm: 8.454804750938079e-05\n",
            "iter: 934102  x: [ 3.99995739 15.99965914]  f(x): 1.8153176838549924e-09  grad at x: [-2.61223569e-06 -1.03250641e-05]  gradient norm: 1.065038606377031e-05\n",
            "iter: 934103  x: [ 3.9999574  15.99965915]  f(x): 1.8152614981507117e-09  grad at x: [ 8.19727463e-05 -2.08976617e-05]  gradient norm: 8.4594582611976e-05\n",
            "iter: 934104  x: [ 3.9999574  15.99965915]  f(x): 1.8152068883477245e-09  grad at x: [-2.61293850e-06 -1.03246512e-05]  gradient norm: 1.065015817359173e-05\n",
            "iter: 934105  x: [ 3.9999574  15.99965916]  f(x): 1.8151507697754025e-09  grad at x: [ 8.20203568e-05 -2.09032878e-05]  gradient norm: 8.464210753677638e-05\n",
            "iter: 934106  x: [ 3.9999574  15.99965917]  f(x): 1.81509609962724e-09  grad at x: [-2.61364139e-06 -1.03242382e-05]  gradient norm: 1.0649930360542898e-05\n",
            "iter: 934107  x: [ 3.9999574  15.99965918]  f(x): 1.8150400481474016e-09  grad at x: [ 8.20679235e-05 -2.09089085e-05]  gradient norm: 8.468958920061502e-05\n",
            "iter: 934108  x: [ 3.9999574  15.99965918]  f(x): 1.8149853176737278e-09  grad at x: [-2.61432981e-06 -1.03238272e-05]  gradient norm: 1.0649700815703683e-05\n",
            "iter: 934109  x: [ 3.9999574  15.99965919]  f(x): 1.814929332134452e-09  grad at x: [ 8.21145733e-05 -2.09144146e-05]  gradient norm: 8.473615454600248e-05\n",
            "iter: 934110  x: [ 3.9999574  15.99965919]  f(x): 1.8148745424685395e-09  grad at x: [-2.61501830e-06 -1.03234161e-05]  gradient norm: 1.0649471345479715e-05\n",
            "iter: 934111  x: [ 3.9999574 15.9996592]  f(x): 1.814818622976886e-09  grad at x: [ 8.21612522e-05 -2.09199243e-05]  gradient norm: 8.478274936771571e-05\n",
            "iter: 934112  x: [ 3.9999574 15.9996592]  f(x): 1.8147637740308649e-09  grad at x: [-2.61572143e-06 -1.03230032e-05]  gradient norm: 1.0649243761368311e-05\n",
            "iter: 934113  x: [ 3.9999574  15.99965921]  f(x): 1.8147079217318789e-09  grad at x: [ 8.22088332e-05 -2.09255468e-05]  gradient norm: 8.48302467372681e-05\n",
            "iter: 934114  x: [ 3.9999574  15.99965921]  f(x): 1.8146530123592334e-09  grad at x: [-2.61641009e-06 -1.03225921e-05]  gradient norm: 1.0649014442358062e-05\n",
            "iter: 934115  x: [ 3.9999574  15.99965922]  f(x): 1.8145972261734106e-09  grad at x: [ 8.22555264e-05 -2.09310583e-05]  gradient norm: 8.487685686484944e-05\n",
            "iter: 934116  x: [ 3.9999574  15.99965922]  f(x): 1.8145422574349985e-09  grad at x: [-2.61709882e-06 -1.03221810e-05]  gradient norm: 1.064878519802365e-05\n",
            "iter: 934117  x: [ 3.99995741 15.99965923]  f(x): 1.8144865373957766e-09  grad at x: [ 8.23022051e-05 -2.09365680e-05]  gradient norm: 8.492345281278639e-05\n",
            "iter: 934118  x: [ 3.9999574  15.99965923]  f(x): 1.8144315092773488e-09  grad at x: [-2.61780218e-06 -1.03217681e-05]  gradient norm: 1.0648557843033889e-05\n",
            "iter: 934119  x: [ 3.99995741 15.99965924]  f(x): 1.8143758565682862e-09  grad at x: [ 8.23498149e-05 -2.09421942e-05]  gradient norm: 8.497098043553248e-05\n",
            "iter: 934120  x: [ 3.99995741 15.99965924]  f(x): 1.8143207678848129e-09  grad at x: [-2.61849108e-06 -1.03213570e-05]  gradient norm: 1.0648328749817157e-05\n",
            "iter: 934121  x: [ 3.99995741 15.99965925]  f(x): 1.8142651813879454e-09  grad at x: [ 8.23965079e-05 -2.09477057e-05]  gradient norm: 8.501759168547185e-05\n",
            "iter: 934122  x: [ 3.99995741 15.99965925]  f(x): 1.8142100332387463e-09  grad at x: [-2.61918005e-06 -1.03209459e-05]  gradient norm: 1.064809973177369e-05\n",
            "iter: 934123  x: [ 3.99995741 15.99965926]  f(x): 1.814154513024091e-09  grad at x: [ 8.24432154e-05 -2.09532191e-05]  gradient norm: 8.506421785632658e-05\n",
            "iter: 934124  x: [ 3.99995741 15.99965926]  f(x): 1.8140993053583368e-09  grad at x: [-2.61988365e-06 -1.03205330e-05]  gradient norm: 1.0647872606089841e-05\n",
            "iter: 934125  x: [ 3.99995741 15.99965927]  f(x): 1.8140438525748646e-09  grad at x: [ 8.24908251e-05 -2.09588452e-05]  gradient norm: 8.511174662233178e-05\n",
            "iter: 934126  x: [ 3.99995741 15.99965927]  f(x): 1.8139885842421118e-09  grad at x: [-2.62057278e-06 -1.03201219e-05]  gradient norm: 1.0647643739067867e-05\n",
            "iter: 934127  x: [ 3.99995741 15.99965928]  f(x): 1.8139331977698857e-09  grad at x: [ 8.25375178e-05 -2.09643567e-05]  gradient norm: 8.51583589881501e-05\n",
            "iter: 934128  x: [ 3.99995741 15.99965928]  f(x): 1.8138917018127718e-09  grad at x: [ 3.99581134e-05 -1.56420319e-05]  gradient norm: 4.2910651207998774e-05\n",
            "iter: 934129  x: [ 3.99995741 15.99965928]  f(x): 1.8138770083230874e-09  grad at x: [-1.95559538e-06 -1.04029150e-05]  gradient norm: 1.0585130782064165e-05\n",
            "iter: 934130  x: [ 3.99995742 15.99965932]  f(x): 1.8136540411398564e-09  grad at x: [ 1.65791712e-04 -3.13696419e-05]  gradient norm: 0.00016873335860404887\n",
            "iter: 934131  x: [ 3.99995742 15.99965932]  f(x): 1.813491761870701e-09  grad at x: [ 8.09345066e-05 -2.07626945e-05]  gradient norm: 8.35552741775097e-05\n",
            "iter: 934132  x: [ 3.99995742 15.99965932]  f(x): 1.8134384653840238e-09  grad at x: [-2.59604250e-06 -1.03215734e-05]  gradient norm: 1.06430406692035e-05\n",
            "iter: 934133  x: [ 3.99995742 15.99965933]  f(x): 1.8133811386381777e-09  grad at x: [ 8.09805005e-05 -2.07681187e-05]  gradient norm: 8.360117352089176e-05\n",
            "iter: 934134  x: [ 3.99995742 15.99965933]  f(x): 1.8133277845949627e-09  grad at x: [-2.59673211e-06 -1.03211623e-05]  gradient norm: 1.064281023007212e-05\n",
            "iter: 934135  x: [ 3.99995742 15.99965934]  f(x): 1.8132705231188904e-09  grad at x: [ 8.10272219e-05 -2.07736339e-05]  gradient norm: 8.364780064252262e-05\n",
            "iter: 934136  x: [ 3.99995742 15.99965934]  f(x): 1.8132171105496003e-09  grad at x: [-2.59742179e-06 -1.03207512e-05]  gradient norm: 1.0642579865590182e-05\n",
            "iter: 934137  x: [ 3.99995742 15.99965935]  f(x): 1.813159914449057e-09  grad at x: [ 8.10739869e-05 -2.07791545e-05]  gradient norm: 8.369447180073078e-05\n",
            "iter: 934138  x: [ 3.99995742 15.99965935]  f(x): 1.813106443267114e-09  grad at x: [-2.59812611e-06 -1.03203383e-05]  gradient norm: 1.0642351364821647e-05\n",
            "iter: 934139  x: [ 3.99995742 15.99965936]  f(x): 1.8130493136723154e-09  grad at x: [ 8.11216540e-05 -2.07847879e-05]  gradient norm: 8.374204534755285e-05\n",
            "iter: 934140  x: [ 3.99995742 15.99965936]  f(x): 1.8129957827460412e-09  grad at x: [-2.59881595e-06 -1.03199272e-05]  gradient norm: 1.0642121151618655e-05\n",
            "iter: 934141  x: [ 3.99995742 15.99965937]  f(x): 1.812938718556283e-09  grad at x: [ 8.11684043e-05 -2.07903067e-05]  gradient norm: 8.378870274947583e-05\n",
            "iter: 934142  x: [ 3.99995742 15.99965937]  f(x): 1.8128851289677402e-09  grad at x: [-2.59950587e-06 -1.03195162e-05]  gradient norm: 1.0641891013125878e-05\n",
            "iter: 934143  x: [ 3.99995743 15.99965938]  f(x): 1.8128281302528432e-09  grad at x: [ 8.12151690e-05 -2.07958274e-05]  gradient norm: 8.38353750890506e-05\n",
            "iter: 934144  x: [ 3.99995742 15.99965938]  f(x): 1.8127744819513878e-09  grad at x: [-2.60021042e-06 -1.03191032e-05]  gradient norm: 1.064166274158471e-05\n",
            "iter: 934145  x: [ 3.99995743 15.99965939]  f(x): 1.8127175498435117e-09  grad at x: [ 8.12628359e-05 -2.08014608e-05]  gradient norm: 8.388294984067239e-05\n",
            "iter: 934146  x: [ 3.99995743 15.99965939]  f(x): 1.8126638416955194e-09  grad at x: [-2.60090050e-06 -1.03186921e-05]  gradient norm: 1.0641432754493619e-05\n",
            "iter: 934147  x: [ 3.99995743 15.9996594 ]  f(x): 1.812606975128095e-09  grad at x: [ 8.13096151e-05 -2.08069832e-05]  gradient norm: 8.392963751767544e-05\n",
            "iter: 934148  x: [ 3.99995743 15.9996594 ]  f(x): 1.8125532081631674e-09  grad at x: [-2.60160521e-06 -1.03182792e-05]  gradient norm: 1.064120463608622e-05\n",
            "iter: 934149  x: [ 3.99995743 15.99965941]  f(x): 1.8124964083444603e-09  grad at x: [ 8.13573109e-05 -2.08126203e-05]  gradient norm: 8.39772421679039e-05\n",
            "iter: 934150  x: [ 3.99995743 15.99965941]  f(x): 1.8124425814101654e-09  grad at x: [-2.60231000e-06 -1.03178663e-05]  gradient norm: 1.0640976595030094e-05\n",
            "iter: 934151  x: [ 3.99995743 15.99965942]  f(x): 1.8123858483366044e-09  grad at x: [ 8.14050067e-05 -2.08182573e-05]  gradient norm: 8.402484722574133e-05\n",
            "iter: 934152  x: [ 3.99995743 15.99965942]  f(x): 1.8123319614167192e-09  grad at x: [-2.60300032e-06 -1.03174552e-05]  gradient norm: 1.0640746835287559e-05\n",
            "iter: 934153  x: [ 3.99995743 15.99965943]  f(x): 1.8122752939836778e-09  grad at x: [ 8.14517856e-05 -2.08237798e-05]  gradient norm: 8.407153608021122e-05\n",
            "iter: 934154  x: [ 3.99995743 15.99965944]  f(x): 1.8122213481641913e-09  grad at x: [-2.60369072e-06 -1.03170441e-05]  gradient norm: 1.0640517150376973e-05\n",
            "iter: 934155  x: [ 3.99995743 15.99965945]  f(x): 1.812164746404591e-09  grad at x: [ 8.14985644e-05 -2.08293022e-05]  gradient norm: 8.411822532156313e-05\n",
            "iter: 934156  x: [ 3.99995743 15.99965945]  f(x): 1.8121107416522739e-09  grad at x: [-2.60438120e-06 -1.03166331e-05]  gradient norm: 1.0640287540535796e-05\n",
            "iter: 934157  x: [ 3.99995743 15.99965946]  f(x): 1.8120542056722592e-09  grad at x: [ 8.15453868e-05 -2.08348301e-05]  gradient norm: 8.416495859515385e-05\n",
            "iter: 934158  x: [ 3.99995743 15.99965946]  f(x): 1.8120001419001407e-09  grad at x: [-2.60508631e-06 -1.03162201e-05]  gradient norm: 1.0640059805437842e-05\n",
            "iter: 934159  x: [ 3.99995744 15.99965947]  f(x): 1.8119436728002676e-09  grad at x: [ 8.15930823e-05 -2.08404672e-05]  gradient norm: 8.421256523739511e-05\n",
            "iter: 934160  x: [ 3.99995743 15.99965947]  f(x): 1.8118895489063253e-09  grad at x: [-2.60577694e-06 -1.03158090e-05]  gradient norm: 1.0639830347067527e-05\n",
            "iter: 934161  x: [ 3.99995744 15.99965948]  f(x): 1.8118331456155936e-09  grad at x: [ 8.16398899e-05 -2.08459933e-05]  gradient norm: 8.425928473939478e-05\n",
            "iter: 934162  x: [ 3.99995744 15.99965948]  f(x): 1.811778962652194e-09  grad at x: [-2.60646766e-06 -1.03153980e-05]  gradient norm: 1.063960096404522e-05\n",
            "iter: 934163  x: [ 3.99995744 15.99965949]  f(x): 1.8117226252035648e-09  grad at x: [ 8.16866975e-05 -2.08515194e-05]  gradient norm: 8.430600462571725e-05\n",
            "iter: 934164  x: [ 3.99995744 15.99965949]  f(x): 1.811668383138596e-09  grad at x: [-2.60718755e-06 -1.03149832e-05]  gradient norm: 1.0639375260993511e-05\n",
            "iter: 934165  x: [ 3.99995744 15.9996595 ]  f(x): 1.811612113924758e-09  grad at x: [ 8.17353678e-05 -2.08572783e-05]  gradient norm: 8.435458730682534e-05\n",
            "iter: 934166  x: [ 3.99995744 15.9996595 ]  f(x): 1.811557810382389e-09  grad at x: [-2.60789298e-06 -1.03145703e-05]  gradient norm: 1.0639147833895061e-05\n",
            "iter: 934167  x: [ 3.99995744 15.99965951]  f(x): 1.811501608258452e-09  grad at x: [ 8.17831065e-05 -2.08629208e-05]  gradient norm: 8.440223919045132e-05\n",
            "iter: 934168  x: [ 3.99995744 15.99965951]  f(x): 1.8114472443832622e-09  grad at x: [-2.60858393e-06 -1.03141592e-05]  gradient norm: 1.0638918679548596e-05\n",
            "iter: 934169  x: [ 3.99995744 15.99965952]  f(x): 1.8113911082386439e-09  grad at x: [ 8.18299430e-05 -2.08684505e-05]  gradient norm: 8.444898934782723e-05\n",
            "iter: 934170  x: [ 3.99995744 15.99965952]  f(x): 1.8113366851225852e-09  grad at x: [-2.60927496e-06 -1.03137481e-05]  gradient norm: 1.063868960063197e-05\n",
            "iter: 934171  x: [ 3.99995744 15.99965953]  f(x): 1.8112806149539266e-09  grad at x: [ 8.18767503e-05 -2.08739766e-05]  gradient norm: 8.449571078475035e-05\n",
            "iter: 934172  x: [ 3.99995744 15.99965953]  f(x): 1.8112261326012083e-09  grad at x: [-2.60999518e-06 -1.03133334e-05]  gradient norm: 1.0638464210321287e-05\n",
            "iter: 934173  x: [ 3.99995744 15.99965954]  f(x): 1.811170130842976e-09  grad at x: [ 8.19254493e-05 -2.08797392e-05]  gradient norm: 8.454432418760551e-05\n",
            "iter: 934174  x: [ 3.99995744 15.99965954]  f(x): 1.8111155868359848e-09  grad at x: [-2.61070092e-06 -1.03129205e-05]  gradient norm: 1.063823709177027e-05\n",
            "iter: 934175  x: [ 3.99995745 15.99965955]  f(x): 1.8110596523406331e-09  grad at x: [ 8.19732169e-05 -2.08853853e-05]  gradient norm: 8.459200675178744e-05\n",
            "iter: 934176  x: [ 3.99995744 15.99965955]  f(x): 1.8110050478266049e-09  grad at x: [-2.61139219e-06 -1.03125094e-05]  gradient norm: 1.0638008241993987e-05\n",
            "iter: 934177  x: [ 3.99995745 15.99965956]  f(x): 1.8109491794445529e-09  grad at x: [ 8.2020053e-05 -2.0890915e-05]  gradient norm: 8.463875845364861e-05\n",
            "iter: 934178  x: [ 3.99995745 15.99965956]  f(x): 1.8108945155555995e-09  grad at x: [-2.61211264e-06 -1.03120947e-05]  gradient norm: 1.063778308733314e-05\n",
            "iter: 934179  x: [ 3.99995745 15.99965957]  f(x): 1.8108387156890415e-09  grad at x: [ 8.20687518e-05 -2.08966776e-05]  gradient norm: 8.468737306966416e-05\n",
            "iter: 934180  x: [ 3.99995745 15.99965957]  f(x): 1.8107839900398193e-09  grad at x: [-2.61281862e-06 -1.03116818e-05]  gradient norm: 1.0637556201270508e-05\n",
            "iter: 934181  x: [ 3.99995745 15.99965958]  f(x): 1.8107282575385124e-09  grad at x: [ 8.21165337e-05 -2.09023256e-05]  gradient norm: 8.473507136924116e-05\n",
            "iter: 934182  x: [ 3.99995745 15.99965958]  f(x): 1.8106734712423213e-09  grad at x: [-2.61353923e-06 -1.03112670e-05]  gradient norm: 1.0637331204763558e-05\n",
            "iter: 934183  x: [ 3.99995745 15.99965959]  f(x): 1.8106178074008863e-09  grad at x: [ 8.21652760e-05 -2.09080936e-05]  gradient norm: 8.478373045272382e-05\n",
            "iter: 934184  x: [ 3.99995745 15.99965959]  f(x): 1.8105629592177466e-09  grad at x: [-2.61423082e-06 -1.03108559e-05]  gradient norm: 1.0637102661778865e-05\n",
            "iter: 934185  x: [ 3.99995745 15.9996596 ]  f(x): 1.810507361624982e-09  grad at x: [ 8.22121118e-05 -2.09136233e-05]  gradient norm: 8.483048370272231e-05\n",
            "iter: 934186  x: [ 3.99995745 15.9996596 ]  f(x): 1.810452453930314e-09  grad at x: [-2.61495159e-06 -1.03104412e-05]  gradient norm: 1.0636877822632828e-05\n",
            "iter: 934187  x: [ 3.99995745 15.99965961]  f(x): 1.810396925030398e-09  grad at x: [ 8.22608393e-05 -2.09193895e-05]  gradient norm: 8.487912903808077e-05\n",
            "iter: 934188  x: [ 3.99995745 15.99965961]  f(x): 1.8103419553968694e-09  grad at x: [-2.61565789e-06 -1.03100283e-05]  gradient norm: 1.0636651247847978e-05\n",
            "iter: 934189  x: [ 3.99995746 15.99965962]  f(x): 1.8102864940369196e-09  grad at x: [ 8.23086500e-05 -2.09250411e-05]  gradient norm: 8.492685802159989e-05\n",
            "iter: 934190  x: [ 3.99995745 15.99965962]  f(x): 1.810231463598789e-09  grad at x: [-2.61636427e-06 -1.03096154e-05]  gradient norm: 1.0636424750611071e-05\n",
            "iter: 934191  x: [ 3.99995746 15.99965963]  f(x): 1.8101760698138202e-09  grad at x: [ 8.23564461e-05 -2.09306909e-05]  gradient norm: 8.497457284377495e-05\n",
            "iter: 934192  x: [ 3.99995746 15.99965963]  f(x): 1.8101209785357656e-09  grad at x: [-2.61707072e-06 -1.03092025e-05]  gradient norm: 1.063619833116135e-05\n",
            "iter: 934193  x: [ 3.99995746 15.99965964]  f(x): 1.8100656523973539e-09  grad at x: [ 8.24042566e-05 -2.09363425e-05]  gradient norm: 8.502230260689626e-05\n",
            "iter: 934194  x: [ 3.99995746 15.99965964]  f(x): 1.8100105002269645e-09  grad at x: [-2.61779181e-06 -1.03087878e-05]  gradient norm: 1.063597380786547e-05\n",
            "iter: 934195  x: [ 3.99995746 15.99965965]  f(x): 1.8099552429589894e-09  grad at x: [ 8.24530129e-05 -2.09421123e-05]  gradient norm: 8.507097864980373e-05\n",
            "iter: 934196  x: [ 3.99995746 15.99965965]  f(x): 1.8099138321372e-09  grad at x: [ 3.99172500e-05 -1.56252427e-05]  gradient norm: 4.286647936798883e-05\n",
            "iter: 934197  x: [ 3.99995746 15.99965965]  f(x): 1.8098991689971247e-09  grad at x: [-1.95350122e-06 -1.03914954e-05]  gradient norm: 1.05735208539264e-05\n",
            "iter: 934198  x: [ 3.99995747 15.99965969]  f(x): 1.8096767245924387e-09  grad at x: [ 1.65623100e-04 -3.13368855e-05]  gradient norm: 0.00016856159592766874\n",
            "iter: 934199  x: [ 3.99995746 15.99965969]  f(x): 1.8095147756016084e-09  grad at x: [ 8.08522605e-05 -2.07407338e-05]  gradient norm: 8.347015075334748e-05\n",
            "iter: 934200  x: [ 3.99995746 15.99965969]  f(x): 1.8094615877813377e-09  grad at x: [-2.59333391e-06 -1.03102320e-05]  gradient norm: 1.06313811539021e-05\n",
            "iter: 934201  x: [ 3.99995747 15.9996597 ]  f(x): 1.8094043979948347e-09  grad at x: [ 8.09006090e-05 -2.07464527e-05]  gradient norm: 8.351840415849467e-05\n",
            "iter: 934202  x: [ 3.99995746 15.9996597 ]  f(x): 1.8093511497138794e-09  grad at x: [-2.59404092e-06 -1.03098191e-05]  gradient norm: 1.0631153207482376e-05\n",
            "iter: 934203  x: [ 3.99995747 15.99965971]  f(x): 1.8092940265090807e-09  grad at x: [ 8.09484335e-05 -2.07521061e-05]  gradient norm: 8.356613425840468e-05\n",
            "iter: 934204  x: [ 3.99995747 15.99965972]  f(x): 1.8092407183973336e-09  grad at x: [-2.59473345e-06 -1.03094080e-05]  gradient norm: 1.0630923550530007e-05\n",
            "iter: 934205  x: [ 3.99995747 15.99965973]  f(x): 1.8091836606384074e-09  grad at x: [ 8.09953412e-05 -2.07576450e-05]  gradient norm: 8.361294823418754e-05\n",
            "iter: 934206  x: [ 3.99995747 15.99965973]  f(x): 1.8091302938130772e-09  grad at x: [-2.59542607e-06 -1.03089969e-05]  gradient norm: 1.0630693969144363e-05\n",
            "iter: 934207  x: [ 3.99995747 15.99965974]  f(x): 1.8090733015700135e-09  grad at x: [ 8.10422633e-05 -2.07631856e-05]  gradient norm: 8.365977715225373e-05\n",
            "iter: 934208  x: [ 3.99995747 15.99965974]  f(x): 1.8090198759608027e-09  grad at x: [-2.59611876e-06 -1.03085858e-05]  gradient norm: 1.0630464462912153e-05\n",
            "iter: 934209  x: [ 3.99995747 15.99965975]  f(x): 1.808962949339632e-09  grad at x: [ 8.10892290e-05 -2.07687317e-05]  gradient norm: 8.370665011207939e-05\n",
            "iter: 934210  x: [ 3.99995747 15.99965975]  f(x): 1.808909464859666e-09  grad at x: [-2.59682609e-06 -1.03081729e-05]  gradient norm: 1.0630236823238134e-05\n",
            "iter: 934211  x: [ 3.99995747 15.99965976]  f(x): 1.8088526049919955e-09  grad at x: [ 8.11370823e-05 -2.07743888e-05]  gradient norm: 8.375441093029195e-05\n",
            "iter: 934212  x: [ 3.99995747 15.99965976]  f(x): 1.8087990604898948e-09  grad at x: [-2.59753349e-06 -1.03077600e-05]  gradient norm: 1.063000926132702e-05\n",
            "iter: 934213  x: [ 3.99995747 15.99965977]  f(x): 1.80874226744625e-09  grad at x: [ 8.11849646e-05 -2.07800495e-05]  gradient norm: 8.380220125716826e-05\n",
            "iter: 934214  x: [ 3.99995747 15.99965977]  f(x): 1.8086886628694907e-09  grad at x: [-2.59822642e-06 -1.03073489e-05]  gradient norm: 1.062977998365996e-05\n",
            "iter: 934215  x: [ 3.99995747 15.99965978]  f(x): 1.808631935475594e-09  grad at x: [ 8.12318864e-05 -2.07855901e-05]  gradient norm: 8.384903176705022e-05\n",
            "iter: 934216  x: [ 3.99995747 15.99965978]  f(x): 1.8085782719798348e-09  grad at x: [-2.59891943e-06 -1.03069378e-05]  gradient norm: 1.0629550781662032e-05\n",
            "iter: 934217  x: [ 3.99995748 15.99965979]  f(x): 1.8085216102679753e-09  grad at x: [ 8.12788227e-05 -2.07911326e-05]  gradient norm: 8.389587721791484e-05\n",
            "iter: 934218  x: [ 3.99995747 15.99965979]  f(x): 1.8084678878389275e-09  grad at x: [-2.59959797e-06 -1.03065286e-05]  gradient norm: 1.062931985971801e-05\n",
            "iter: 934219  x: [ 3.99995748 15.9996598 ]  f(x): 1.80841129070516e-09  grad at x: [ 8.13248421e-05 -2.07965604e-05]  gradient norm: 8.394180646250707e-05\n",
            "iter: 934220  x: [ 3.99995748 15.9996598 ]  f(x): 1.8083575104281516e-09  grad at x: [-2.60027659e-06 -1.03061193e-05]  gradient norm: 1.0629089011387798e-05\n",
            "iter: 934221  x: [ 3.99995748 15.99965981]  f(x): 1.80830097794046e-09  grad at x: [ 8.13708906e-05 -2.08019919e-05]  gradient norm: 8.398776517550622e-05\n",
            "iter: 934222  x: [ 3.99995748 15.99965981]  f(x): 1.8082471397300475e-09  grad at x: [-2.60099894e-06 -1.03057046e-05]  gradient norm: 1.0628863628366914e-05\n",
            "iter: 934223  x: [ 3.99995748 15.99965982]  f(x): 1.8081906754471889e-09  grad at x: [ 8.14197184e-05 -2.08077709e-05]  gradient norm: 8.403650320749452e-05\n",
            "iter: 934224  x: [ 3.99995748 15.99965982]  f(x): 1.8081367757980729e-09  grad at x: [-2.60169227e-06 -1.03052935e-05]  gradient norm: 1.0628634728598161e-05\n",
            "iter: 934225  x: [ 3.99995748 15.99965983]  f(x): 1.80808037740305e-09  grad at x: [ 8.14666980e-05 -2.08133188e-05]  gradient norm: 8.408339386578892e-05\n",
            "iter: 934226  x: [ 3.99995748 15.99965983]  f(x): 1.8080264185953057e-09  grad at x: [-2.60238567e-06 -1.03048824e-05]  gradient norm: 1.0628405904165889e-05\n",
            "iter: 934227  x: [ 3.99995748 15.99965984]  f(x): 1.8079700861213266e-09  grad at x: [ 8.15136776e-05 -2.08188667e-05]  gradient norm: 8.413028491175053e-05\n",
            "iter: 934228  x: [ 3.99995748 15.99965984]  f(x): 1.8079160681225936e-09  grad at x: [-2.60310826e-06 -1.03044677e-05]  gradient norm: 1.0628180756570875e-05\n",
            "iter: 934229  x: [ 3.99995748 15.99965985]  f(x): 1.8078598039206512e-09  grad at x: [ 8.15625052e-05 -2.08246456e-05]  gradient norm: 8.417902418034404e-05\n",
            "iter: 934230  x: [ 3.99995748 15.99965985]  f(x): 1.8078057243956216e-09  grad at x: [-2.60378728e-06 -1.03040584e-05]  gradient norm: 1.0627950284050973e-05\n",
            "iter: 934231  x: [ 3.99995748 15.99965986]  f(x): 1.8077495250044003e-09  grad at x: [ 8.16085532e-05 -2.08300771e-05]  gradient norm: 8.422498481857383e-05\n",
            "iter: 934232  x: [ 3.99995748 15.99965986]  f(x): 1.8076953873980885e-09  grad at x: [-2.60449547e-06 -1.03036455e-05]  gradient norm: 1.062772349054698e-05\n",
            "iter: 934233  x: [ 3.99995749 15.99965987]  f(x): 1.8076392552069197e-09  grad at x: [ 8.16564638e-05 -2.08357415e-05]  gradient norm: 8.4272808241596e-05\n",
            "iter: 934234  x: [ 3.99995748 15.99965987]  f(x): 1.8075850571285309e-09  grad at x: [-2.60520375e-06 -1.03032326e-05]  gradient norm: 1.0627496774598866e-05\n",
            "iter: 934235  x: [ 3.99995749 15.99965988]  f(x): 1.807528992208254e-09  grad at x: [ 8.17044035e-05 -2.08414094e-05]  gradient norm: 8.432066117014564e-05\n",
            "iter: 934236  x: [ 3.99995749 15.99965988]  f(x): 1.8074747336049428e-09  grad at x: [-2.60589755e-06 -1.03028215e-05]  gradient norm: 1.0627268331636623e-05\n",
            "iter: 934237  x: [ 3.99995749 15.99965989]  f(x): 1.8074187347737585e-09  grad at x: [ 8.17513827e-05 -2.08469573e-05]  gradient norm: 8.436755417235613e-05\n",
            "iter: 934238  x: [ 3.99995749 15.99965989]  f(x): 1.8073644168087135e-09  grad at x: [-2.60659143e-06 -1.03024104e-05]  gradient norm: 1.0627039964568745e-05\n",
            "iter: 934239  x: [ 3.99995749 15.9996599 ]  f(x): 1.8073084841361554e-09  grad at x: [ 8.17983908e-05 -2.08525089e-05]  gradient norm: 8.44144766615153e-05\n",
            "iter: 934240  x: [ 3.99995749 15.9996599 ]  f(x): 1.8072541067212352e-09  grad at x: [-2.60729995e-06 -1.03019975e-05]  gradient norm: 1.0626813479907094e-05\n",
            "iter: 934241  x: [ 3.99995749 15.99965991]  f(x): 1.8071982414590289e-09  grad at x: [ 8.18463448e-05 -2.08581787e-05]  gradient norm: 8.446234532727705e-05\n",
            "iter: 934242  x: [ 3.99995749 15.99965991]  f(x): 1.8071438033982581e-09  grad at x: [-2.60800854e-06 -1.03015846e-05]  gradient norm: 1.062658707353774e-05\n",
            "iter: 934243  x: [ 3.99995749 15.99965992]  f(x): 1.8070880055068947e-09  grad at x: [ 8.18942696e-05 -2.08638448e-05]  gradient norm: 8.451018529160614e-05\n",
            "iter: 934244  x: [ 3.99995749 15.99965992]  f(x): 1.807033506801716e-09  grad at x: [-2.60871721e-06 -1.03011716e-05]  gradient norm: 1.0626360744827729e-05\n",
            "iter: 934245  x: [ 3.99995749 15.99965993]  f(x): 1.8069777763892341e-09  grad at x: [ 8.19422380e-05 -2.08695164e-05]  gradient norm: 8.455806930801657e-05\n",
            "iter: 934246  x: [ 3.99995749 15.99965993]  f(x): 1.8069232169313012e-09  grad at x: [-2.60942596e-06 -1.03007587e-05]  gradient norm: 1.0626134494233871e-05\n",
            "iter: 934247  x: [ 3.9999575  15.99965994]  f(x): 1.8068675539959278e-09  grad at x: [ 8.19901772e-05 -2.08751844e-05]  gradient norm: 8.460592462109272e-05\n",
            "iter: 934248  x: [ 3.99995749 15.99965994]  f(x): 1.806812933805003e-09  grad at x: [-2.61012024e-06 -1.03003476e-05]  gradient norm: 1.0625906510094766e-05\n",
            "iter: 934249  x: [ 3.9999575  15.99965995]  f(x): 1.8067573372336194e-09  grad at x: [ 8.20372141e-05 -2.08807396e-05]  gradient norm: 8.465287815619056e-05\n",
            "iter: 934250  x: [ 3.9999575  15.99965995]  f(x): 1.8067026574042155e-09  grad at x: [-2.61081460e-06 -1.02999365e-05]  gradient norm: 1.0625678601973307e-05\n",
            "iter: 934251  x: [ 3.9999575  15.99965996]  f(x): 1.8066471272301115e-09  grad at x: [ 8.20842509e-05 -2.08862948e-05]  gradient norm: 8.469983207065642e-05\n",
            "iter: 934252  x: [ 3.9999575  15.99965996]  f(x): 1.8065923877286309e-09  grad at x: [-2.61150903e-06 -1.02995255e-05]  gradient norm: 1.0625450769453462e-05\n",
            "iter: 934253  x: [ 3.9999575  15.99965997]  f(x): 1.8065369239850962e-09  grad at x: [ 8.21312876e-05 -2.08918500e-05]  gradient norm: 8.474678636544816e-05\n",
            "iter: 934254  x: [ 3.9999575  15.99965997]  f(x): 1.8064821247791012e-09  grad at x: [-2.61223265e-06 -1.02991107e-05]  gradient norm: 1.0625226641865891e-05\n",
            "iter: 934255  x: [ 3.9999575  15.99965998]  f(x): 1.8064267298717387e-09  grad at x: [ 8.21801869e-05 -2.08976380e-05]  gradient norm: 8.479560364850815e-05\n",
            "iter: 934256  x: [ 3.9999575  15.99965999]  f(x): 1.8063718685724543e-09  grad at x: [-2.61294180e-06 -1.02986978e-05]  gradient norm: 1.0625000779132144e-05\n",
            "iter: 934257  x: [ 3.9999575 15.99966  ]  f(x): 1.8063165413869357e-09  grad at x: [ 8.22281839e-05 -2.09033133e-05]  gradient norm: 8.484351913315012e-05\n",
            "iter: 934258  x: [ 3.9999575 15.99966  ]  f(x): 1.8062616190900865e-09  grad at x: [-2.61365102e-06 -1.02982849e-05]  gradient norm: 1.0624774994202719e-05\n",
            "iter: 934259  x: [ 3.9999575  15.99966001]  f(x): 1.8062063596245537e-09  grad at x: [ 8.22761518e-05 -2.09089849e-05]  gradient norm: 8.489140590856289e-05\n",
            "iter: 934260  x: [ 3.9999575  15.99966001]  f(x): 1.8061513763316907e-09  grad at x: [-2.61436033e-06 -1.02978720e-05]  gradient norm: 1.0624549287535331e-05\n",
            "iter: 934261  x: [ 3.9999575  15.99966002]  f(x): 1.8060961846573415e-09  grad at x: [ 8.23241486e-05 -2.09146601e-05]  gradient norm: 8.493932218193743e-05\n",
            "iter: 934262  x: [ 3.9999575  15.99966002]  f(x): 1.8060411402969589e-09  grad at x: [-2.61506971e-06 -1.02974591e-05]  gradient norm: 1.0624323658713747e-05\n",
            "iter: 934263  x: [ 3.99995751 15.99966003]  f(x): 1.8059860164113114e-09  grad at x: [ 8.23721308e-05 -2.09203336e-05]  gradient norm: 8.498722429584533e-05\n",
            "iter: 934264  x: [ 3.9999575  15.99966003]  f(x): 1.8059446871883755e-09  grad at x: [ 3.98782049e-05 -1.56086935e-05]  gradient norm: 4.282408832510628e-05\n",
            "iter: 934265  x: [ 3.9999575  15.99966003]  f(x): 1.8059300532205913e-09  grad at x: [-1.95145139e-06 -1.03800830e-05]  gradient norm: 1.0561926266173887e-05\n",
            "iter: 934266  x: [ 3.99995751 15.99966007]  f(x): 1.8057081582498951e-09  grad at x: [ 1.65465605e-04 -3.13055316e-05]  gradient norm: 0.00016840101739818922\n",
            "iter: 934267  x: [ 3.99995751 15.99966007]  f(x): 1.8055465177230332e-09  grad at x: [ 8.07754708e-05 -2.07194680e-05]  gradient norm: 8.339048529023302e-05\n",
            "iter: 934268  x: [ 3.99995751 15.99966007]  f(x): 1.805493431636011e-09  grad at x: [-2.59065508e-06 -1.02988997e-05]  gradient norm: 1.0619737720278518e-05\n",
            "iter: 934269  x: [ 3.99995751 15.99966008]  f(x): 1.8054363805927687e-09  grad at x: [ 8.08224922e-05 -2.07250214e-05]  gradient norm: 8.343741219041423e-05\n",
            "iter: 934270  x: [ 3.99995751 15.99966008]  f(x): 1.8053832357581295e-09  grad at x: [-2.59136493e-06 -1.02984868e-05]  gradient norm: 1.0619510481273693e-05\n",
            "iter: 934271  x: [ 3.99995751 15.99966009]  f(x): 1.8053262514755104e-09  grad at x: [ 8.08705176e-05 -2.07307003e-05]  gradient norm: 8.348534330910391e-05\n",
            "iter: 934272  x: [ 3.99995751 15.99966009]  f(x): 1.8052730466200605e-09  grad at x: [-2.59206032e-06 -1.02980757e-05]  gradient norm: 1.061928153219039e-05\n",
            "iter: 934273  x: [ 3.99995751 15.9996601 ]  f(x): 1.8052161279645552e-09  grad at x: [ 8.09176116e-05 -2.07362627e-05]  gradient norm: 8.353234375795245e-05\n",
            "iter: 934274  x: [ 3.99995751 15.9996601 ]  f(x): 1.8051628642032016e-09  grad at x: [-2.59275578e-06 -1.02976646e-05]  gradient norm: 1.0619052658705812e-05\n",
            "iter: 934275  x: [ 3.99995752 15.99966011]  f(x): 1.8051060112081833e-09  grad at x: [ 8.09647055e-05 -2.07418252e-05]  gradient norm: 8.357934460486811e-05\n",
            "iter: 934276  x: [ 3.99995751 15.99966011]  f(x): 1.8050526885072453e-09  grad at x: [-2.59345132e-06 -1.02972535e-05]  gradient norm: 1.0618823861274043e-05\n",
            "iter: 934277  x: [ 3.99995752 15.99966012]  f(x): 1.8049959012420648e-09  grad at x: [ 8.10118284e-05 -2.07473913e-05]  gradient norm: 8.362637494724472e-05\n",
            "iter: 934278  x: [ 3.99995752 15.99966012]  f(x): 1.8049425195318847e-09  grad at x: [-2.59414694e-06 -1.02968424e-05]  gradient norm: 1.0618595139481742e-05\n",
            "iter: 934279  x: [ 3.99995752 15.99966013]  f(x): 1.8048857979939587e-09  grad at x: [ 8.10589221e-05 -2.07529538e-05]  gradient norm: 8.367337658987664e-05\n",
            "iter: 934280  x: [ 3.99995752 15.99966013]  f(x): 1.8048323572768116e-09  grad at x: [-2.59484264e-06 -1.02964314e-05]  gradient norm: 1.0618366493783247e-05\n",
            "iter: 934281  x: [ 3.99995752 15.99966014]  f(x): 1.8047757015355319e-09  grad at x: [ 8.11060449e-05 -2.07585199e-05]  gradient norm: 8.372040772691783e-05\n",
            "iter: 934282  x: [ 3.99995752 15.99966014]  f(x): 1.8047222017600086e-09  grad at x: [-2.59552387e-06 -1.02960221e-05]  gradient norm: 1.0618136130673544e-05\n",
            "iter: 934283  x: [ 3.99995752 15.99966015]  f(x): 1.804665610677226e-09  grad at x: [ 8.11522363e-05 -2.07639696e-05]  gradient norm: 8.376650812824824e-05\n",
            "iter: 934284  x: [ 3.99995752 15.99966015]  f(x): 1.8046120529640293e-09  grad at x: [-2.59623428e-06 -1.02956092e-05]  gradient norm: 1.0617909430098684e-05\n",
            "iter: 934285  x: [ 3.99995752 15.99966016]  f(x): 1.8045555289523445e-09  grad at x: [ 8.12003193e-05 -2.07696557e-05]  gradient norm: 8.381450028745158e-05\n",
            "iter: 934286  x: [ 3.99995752 15.99966016]  f(x): 1.8045019108874148e-09  grad at x: [-2.59694477e-06 -1.02951963e-05]  gradient norm: 1.0617682807824757e-05\n",
            "iter: 934287  x: [ 3.99995752 15.99966017]  f(x): 1.8044454539455536e-09  grad at x: [ 8.12483732e-05 -2.07753383e-05]  gradient norm: 8.386246375929754e-05\n",
            "iter: 934288  x: [ 3.99995752 15.99966017]  f(x): 1.8043917755298575e-09  grad at x: [-2.59765534e-06 -1.02947834e-05]  gradient norm: 1.0617456263438222e-05\n",
            "iter: 934289  x: [ 3.99995753 15.99966018]  f(x): 1.8043353857286886e-09  grad at x: [ 8.12964561e-05 -2.07810244e-05]  gradient norm: 8.39104567435646e-05\n",
            "iter: 934290  x: [ 3.99995752 15.99966018]  f(x): 1.80428164689105e-09  grad at x: [-2.59836599e-06 -1.02943704e-05]  gradient norm: 1.0617229797394489e-05\n",
            "iter: 934291  x: [ 3.99995753 15.99966019]  f(x): 1.8042253242292563e-09  grad at x: [ 8.13445098e-05 -2.07867070e-05]  gradient norm: 8.395842103822563e-05\n",
            "iter: 934292  x: [ 3.99995753 15.99966019]  f(x): 1.8041715249889706e-09  grad at x: [-2.59906216e-06 -1.02939593e-05]  gradient norm: 1.0617001610576522e-05\n",
            "iter: 934293  x: [ 3.99995753 15.9996602 ]  f(x): 1.8041152683625006e-09  grad at x: [ 8.13916612e-05 -2.07922767e-05]  gradient norm: 8.400548366654313e-05\n",
            "iter: 934294  x: [ 3.99995753 15.9996602 ]  f(x): 1.804061409805025e-09  grad at x: [-2.59975842e-06 -1.02935483e-05]  gradient norm: 1.0616773499996474e-05\n",
            "iter: 934295  x: [ 3.99995753 15.99966021]  f(x): 1.8040052192473342e-09  grad at x: [ 8.14388125e-05 -2.07978464e-05]  gradient norm: 8.405254668771565e-05\n",
            "iter: 934296  x: [ 3.99995753 15.99966021]  f(x): 1.8039513013389053e-09  grad at x: [-2.60045475e-06 -1.02931372e-05]  gradient norm: 1.0616545465239875e-05\n",
            "iter: 934297  x: [ 3.99995753 15.99966022]  f(x): 1.803895176883449e-09  grad at x: [ 8.14859638e-05 -2.08034162e-05]  gradient norm: 8.409961009923103e-05\n",
            "iter: 934298  x: [ 3.99995753 15.99966022]  f(x): 1.8038411995903047e-09  grad at x: [-2.60115116e-06 -1.02927261e-05]  gradient norm: 1.0616317506762228e-05\n",
            "iter: 934299  x: [ 3.99995753 15.99966023]  f(x): 1.8037851413067467e-09  grad at x: [ 8.15331441e-05 -2.08089896e-05]  gradient norm: 8.414670300155053e-05\n",
            "iter: 934300  x: [ 3.99995753 15.99966023]  f(x): 1.8037311045589152e-09  grad at x: [-2.60184765e-06 -1.02923150e-05]  gradient norm: 1.0616089624366496e-05\n",
            "iter: 934301  x: [ 3.99995753 15.99966024]  f(x): 1.8036751124445229e-09  grad at x: [ 8.15802951e-05 -2.08145593e-05]  gradient norm: 8.419376719337977e-05\n",
            "iter: 934302  x: [ 3.99995753 15.99966024]  f(x): 1.8036210162455854e-09  grad at x: [-2.60257333e-06 -1.02919003e-05]  gradient norm: 1.0615865426136421e-05\n",
            "iter: 934303  x: [ 3.99995753 15.99966025]  f(x): 1.803565092726695e-09  grad at x: [ 8.16293379e-05 -2.08203655e-05]  gradient norm: 8.424272331456183e-05\n",
            "iter: 934304  x: [ 3.99995753 15.99966025]  f(x): 1.8035109346488528e-09  grad at x: [-2.60329908e-06 -1.02914855e-05]  gradient norm: 1.0615641308365425e-05\n",
            "iter: 934305  x: [ 3.99995754 15.99966026]  f(x): 1.8034550797616929e-09  grad at x: [ 8.16783806e-05 -2.08261717e-05]  gradient norm: 8.429167986071739e-05\n",
            "iter: 934306  x: [ 3.99995753 15.99966026]  f(x): 1.803400859786691e-09  grad at x: [-2.60401036e-06 -1.02910726e-05]  gradient norm: 1.0615415465042907e-05\n",
            "iter: 934307  x: [ 3.99995754 15.99966027]  f(x): 1.8033450723877738e-09  grad at x: [ 8.17264919e-05 -2.08318615e-05]  gradient norm: 8.433970559131253e-05\n",
            "iter: 934308  x: [ 3.99995754 15.99966028]  f(x): 1.8032907916405102e-09  grad at x: [-2.60472172e-06 -1.02906597e-05]  gradient norm: 1.0615189699815636e-05\n",
            "iter: 934309  x: [ 3.99995754 15.99966029]  f(x): 1.8032350718010014e-09  grad at x: [ 8.17746323e-05 -2.08375550e-05]  gradient norm: 8.438776082819648e-05\n",
            "iter: 934310  x: [ 3.99995754 15.99966029]  f(x): 1.8031807302100035e-09  grad at x: [-2.60543316e-06 -1.02902468e-05]  gradient norm: 1.0614964013140314e-05\n",
            "iter: 934311  x: [ 3.99995754 15.9996603 ]  f(x): 1.8031250779284566e-09  grad at x: [ 8.18227434e-05 -2.08432448e-05]  gradient norm: 8.443578736553398e-05\n",
            "iter: 934312  x: [ 3.99995754 15.9996603 ]  f(x): 1.803070675494863e-09  grad at x: [-2.60614468e-06 -1.02898339e-05]  gradient norm: 1.0614738404601895e-05\n",
            "iter: 934313  x: [ 3.99995754 15.99966031]  f(x): 1.8030150908424858e-09  grad at x: [ 8.18708835e-05 -2.08489382e-05]  gradient norm: 8.448384340978395e-05\n",
            "iter: 934314  x: [ 3.99995754 15.99966031]  f(x): 1.802960627494782e-09  grad at x: [-2.60685628e-06 -1.02894210e-05]  gradient norm: 1.0614512874657337e-05\n",
            "iter: 934315  x: [ 3.99995754 15.99966032]  f(x): 1.8029051105064656e-09  grad at x: [ 8.19190236e-05 -2.08546317e-05]  gradient norm: 8.453189985575898e-05\n",
            "iter: 934316  x: [ 3.99995754 15.99966032]  f(x): 1.8028505862277299e-09  grad at x: [-2.60755340e-06 -1.02890099e-05]  gradient norm: 1.061428561123837e-05\n",
            "iter: 934317  x: [ 3.99995754 15.99966033]  f(x): 1.802795135718191e-09  grad at x: [ 8.19662177e-05 -2.08602069e-05]  gradient norm: 8.457901087147706e-05\n",
            "iter: 934318  x: [ 3.99995754 15.99966033]  f(x): 1.802740551656845e-09  grad at x: [-2.60826516e-06 -1.02885970e-05]  gradient norm: 1.0614060237023101e-05\n",
            "iter: 934319  x: [ 3.99995754 15.99966034]  f(x): 1.8026851688804552e-09  grad at x: [ 8.20143577e-05 -2.08659003e-05]  gradient norm: 8.462706811124974e-05\n",
            "iter: 934320  x: [ 3.99995754 15.99966034]  f(x): 1.8026305238000971e-09  grad at x: [-2.60897699e-06 -1.02881841e-05]  gradient norm: 1.0613834941027919e-05\n",
            "iter: 934321  x: [ 3.99995755 15.99966035]  f(x): 1.8025752087917474e-09  grad at x: [ 8.20624975e-05 -2.08715937e-05]  gradient norm: 8.467512575202643e-05\n",
            "iter: 934322  x: [ 3.99995754 15.99966035]  f(x): 1.8025205026571796e-09  grad at x: [-2.60968891e-06 -1.02877711e-05]  gradient norm: 1.0613609723710299e-05\n",
            "iter: 934323  x: [ 3.99995755 15.99966036]  f(x): 1.8024652554882253e-09  grad at x: [ 8.21106664e-05 -2.08772908e-05]  gradient norm: 8.472321289583076e-05\n",
            "iter: 934324  x: [ 3.99995755 15.99966036]  f(x): 1.8024104882277847e-09  grad at x: [-2.61040090e-06 -1.02873582e-05]  gradient norm: 1.061338458465444e-05\n",
            "iter: 934325  x: [ 3.99995755 15.99966037]  f(x): 1.8023553088966728e-09  grad at x: [ 8.21588061e-05 -2.08829842e-05]  gradient norm: 8.4771271333e-05\n",
            "iter: 934326  x: [ 3.99995755 15.99966037]  f(x): 1.802300480529879e-09  grad at x: [-2.61109842e-06 -1.02869471e-05]  gradient norm: 1.0613157707258402e-05\n",
            "iter: 934327  x: [ 3.99995755 15.99966038]  f(x): 1.8022453679214838e-09  grad at x: [ 8.22060434e-05 -2.08885649e-05]  gradient norm: 8.481842794839336e-05\n",
            "iter: 934328  x: [ 3.99995755 15.99966038]  f(x): 1.80219047954488e-09  grad at x: [-2.61179602e-06 -1.02865361e-05]  gradient norm: 1.0612930906232824e-05\n",
            "iter: 934329  x: [ 3.99995755 15.99966039]  f(x): 1.8021354336927808e-09  grad at x: [ 8.22532807e-05 -2.08941456e-05]  gradient norm: 8.486558494311166e-05\n",
            "iter: 934330  x: [ 3.99995755 15.99966039]  f(x): 1.8020804852724812e-09  grad at x: [-2.6124937e-06 -1.0286125e-05]  gradient norm: 1.061270418159819e-05\n",
            "iter: 934331  x: [ 3.99995755 15.99966039]  f(x): 1.8020392430588101e-09  grad at x: [ 3.98440048e-05 -1.55929247e-05]  gradient norm: 4.2786493438422765e-05\n",
            "iter: 934332  x: [ 3.99995755 15.99966039]  f(x): 1.8020246351362751e-09  grad at x: [-1.94947525e-06 -1.03688362e-05]  gradient norm: 1.0550507972629025e-05\n",
            "iter: 934333  x: [ 3.99995756 15.99966044]  f(x): 1.8018033090234093e-09  grad at x: [ 1.65321599e-04 -3.12760385e-05]  gradient norm: 0.0001682540387817852\n",
            "iter: 934334  x: [ 3.99995756 15.99966044]  f(x): 1.8016419506002645e-09  grad at x: [ 8.07053016e-05 -2.06992045e-05]  gradient norm: 8.331748176092022e-05\n",
            "iter: 934335  x: [ 3.99995756 15.99966044]  f(x): 1.801588957777379e-09  grad at x: [-2.58812252e-06 -1.02877239e-05]  gradient norm: 1.0608281683088608e-05\n",
            "iter: 934336  x: [ 3.99995756 15.99966045]  f(x): 1.8015320517917804e-09  grad at x: [ 8.07523638e-05 -2.07047633e-05]  gradient norm: 8.33644497533727e-05\n",
            "iter: 934337  x: [ 3.99995756 15.99966045]  f(x): 1.8014790002032934e-09  grad at x: [-2.58883518e-06 -1.02873109e-05]  gradient norm: 1.0608055148950128e-05\n",
            "iter: 934338  x: [ 3.99995756 15.99966046]  f(x): 1.801422161126988e-09  grad at x: [ 8.0800561e-05 -2.0710464e-05]  gradient norm: 8.341255290296355e-05\n",
            "iter: 934339  x: [ 3.99995756 15.99966046]  f(x): 1.8013690493580947e-09  grad at x: [-2.58953337e-06 -1.02868999e-05]  gradient norm: 1.0607826904824245e-05\n",
            "iter: 934340  x: [ 3.99995756 15.99966047]  f(x): 1.801312276022038e-09  grad at x: [ 8.08478123e-05 -2.07160465e-05]  gradient norm: 8.345971083333046e-05\n",
            "iter: 934341  x: [ 3.99995756 15.99966047]  f(x): 1.8012591052232005e-09  grad at x: [-2.59023164e-06 -1.02864888e-05]  gradient norm: 1.0607598736759108e-05\n",
            "iter: 934342  x: [ 3.99995756 15.99966048]  f(x): 1.8012023977337283e-09  grad at x: [ 8.08951071e-05 -2.07216344e-05]  gradient norm: 8.35069128111317e-05\n",
            "iter: 934343  x: [ 3.99995756 15.99966048]  f(x): 1.8011491677983039e-09  grad at x: [-2.59092999e-06 -1.02860777e-05]  gradient norm: 1.0607370645208946e-05\n",
            "iter: 934344  x: [ 3.99995756 15.99966049]  f(x): 1.8010925261531326e-09  grad at x: [ 8.09423728e-05 -2.07272187e-05]  gradient norm: 8.355408609535686e-05\n",
            "iter: 934345  x: [ 3.99995756 15.99966049]  f(x): 1.8010392370830974e-09  grad at x: [-2.59162842e-06 -1.02856666e-05]  gradient norm: 1.060714262997748e-05\n",
            "iter: 934346  x: [ 3.99995756 15.9996605 ]  f(x): 1.8009826613518158e-09  grad at x: [ 8.09896674e-05 -2.07328067e-05]  gradient norm: 8.36012888763537e-05\n",
            "iter: 934347  x: [ 3.99995756 15.9996605 ]  f(x): 1.8009293130772743e-09  grad at x: [-2.59232692e-06 -1.02852555e-05]  gradient norm: 1.0606914690868175e-05\n",
            "iter: 934348  x: [ 3.99995757 15.99966051]  f(x): 1.8008728032935446e-09  grad at x: [ 8.10369620e-05 -2.07383946e-05]  gradient norm: 8.364849205872772e-05\n",
            "iter: 934349  x: [ 3.99995756 15.99966051]  f(x): 1.8008193957805277e-09  grad at x: [-2.59302551e-06 -1.02848444e-05]  gradient norm: 1.0606686828335645e-05\n",
            "iter: 934350  x: [ 3.99995757 15.99966052]  f(x): 1.8007629519780122e-09  grad at x: [ 8.10842565e-05 -2.07439825e-05]  gradient norm: 8.369569563994638e-05\n",
            "iter: 934351  x: [ 3.99995757 15.99966052]  f(x): 1.8007094851925496e-09  grad at x: [-2.59372417e-06 -1.02844333e-05]  gradient norm: 1.0606459042183427e-05\n",
            "iter: 934352  x: [ 3.99995757 15.99966053]  f(x): 1.8006531074409416e-09  grad at x: [ 8.11315801e-05 -2.07495741e-05]  gradient norm: 8.374292871861645e-05\n",
            "iter: 934353  x: [ 3.99995757 15.99966053]  f(x): 1.8005995813130336e-09  grad at x: [-2.59442292e-06 -1.02840222e-05]  gradient norm: 1.0606231332432063e-05\n",
            "iter: 934354  x: [ 3.99995757 15.99966054]  f(x): 1.8005432696099855e-09  grad at x: [ 8.11788744e-05 -2.07551620e-05]  gradient norm: 8.379013309881593e-05\n",
            "iter: 934355  x: [ 3.99995757 15.99966054]  f(x): 1.8004896841599396e-09  grad at x: [-2.59510719e-06 -1.02836129e-05]  gradient norm: 1.0606001901967998e-05\n",
            "iter: 934356  x: [ 3.99995757 15.99966055]  f(x): 1.8004334373657283e-09  grad at x: [ 8.12252519e-05 -2.07606354e-05]  gradient norm: 8.383642126171156e-05\n",
            "iter: 934357  x: [ 3.99995757 15.99966055]  f(x): 1.8003797936770065e-09  grad at x: [-2.59579153e-06 -1.02832037e-05]  gradient norm: 1.0605772545829716e-05\n",
            "iter: 934358  x: [ 3.99995757 15.99966056]  f(x): 1.8003236118977645e-09  grad at x: [ 8.12716584e-05 -2.07661124e-05]  gradient norm: 8.388273890492909e-05\n",
            "iter: 934359  x: [ 3.99995757 15.99966056]  f(x): 1.8002699099027672e-09  grad at x: [-2.59650507e-06 -1.02827908e-05]  gradient norm: 1.0605546862300717e-05\n",
            "iter: 934360  x: [ 3.99995757 15.99966057]  f(x): 1.8002137954817938e-09  grad at x: [ 8.13199130e-05 -2.07718203e-05]  gradient norm: 8.393090473575424e-05\n",
            "iter: 934361  x: [ 3.99995757 15.99966057]  f(x): 1.8001600328357632e-09  grad at x: [-2.59721868e-06 -1.02823778e-05]  gradient norm: 1.0605321257411028e-05\n",
            "iter: 934362  x: [ 3.99995757 15.99966058]  f(x): 1.8001039858081185e-09  grad at x: [ 8.13681675e-05 -2.07775283e-05]  gradient norm: 8.397907097897559e-05\n",
            "iter: 934363  x: [ 3.99995757 15.99966058]  f(x): 1.8000501624756871e-09  grad at x: [-2.59793237e-06 -1.02819649e-05]  gradient norm: 1.0605095730964045e-05\n",
            "iter: 934364  x: [ 3.99995758 15.99966059]  f(x): 1.7999941829125885e-09  grad at x: [ 8.1416451e-05 -2.0783240e-05]  gradient norm: 8.402726673482597e-05\n",
            "iter: 934365  x: [ 3.99995757 15.99966059]  f(x): 1.799940298822232e-09  grad at x: [-2.59864614e-06 -1.02815520e-05]  gradient norm: 1.060487028341584e-05\n",
            "iter: 934366  x: [ 3.99995758 15.9996606 ]  f(x): 1.7998843867226038e-09  grad at x: [ 8.14647053e-05 -2.07889479e-05]  gradient norm: 8.407543380230193e-05\n",
            "iter: 934367  x: [ 3.99995758 15.9996606 ]  f(x): 1.799830441875091e-09  grad at x: [-2.59935998e-06 -1.02811391e-05]  gradient norm: 1.060464491435217e-05\n",
            "iter: 934368  x: [ 3.99995758 15.99966061]  f(x): 1.799774597310193e-09  grad at x: [ 8.15129887e-05 -2.07946596e-05]  gradient norm: 8.412363038127774e-05\n",
            "iter: 934369  x: [ 3.99995758 15.99966061]  f(x): 1.7997205916522188e-09  grad at x: [-2.60005936e-06 -1.02807280e-05]  gradient norm: 1.0604417819753695e-05\n",
            "iter: 934370  x: [ 3.99995758 15.99966062]  f(x): 1.7996648134428687e-09  grad at x: [ 8.1560326e-05 -2.0800253e-05]  gradient norm: 8.41708815963074e-05\n",
            "iter: 934371  x: [ 3.99995758 15.99966062]  f(x): 1.799610748115629e-09  grad at x: [-2.60074426e-06 -1.02803187e-05]  gradient norm: 1.060418899599894e-05\n",
            "iter: 934372  x: [ 3.99995758 15.99966063]  f(x): 1.799555035154518e-09  grad at x: [ 8.16067466e-05 -2.08057318e-05]  gradient norm: 8.421721652208658e-05\n",
            "iter: 934373  x: [ 3.99995758 15.99966063]  f(x): 1.7995009112844315e-09  grad at x: [-2.60142924e-06 -1.02799095e-05]  gradient norm: 1.0603960246732569e-05\n",
            "iter: 934374  x: [ 3.99995758 15.99966064]  f(x): 1.7994452636409411e-09  grad at x: [ 8.16531815e-05 -2.08112124e-05]  gradient norm: 8.426356637121309e-05\n",
            "iter: 934375  x: [ 3.99995758 15.99966064]  f(x): 1.7993910811594743e-09  grad at x: [-2.60214341e-06 -1.02794966e-05]  gradient norm: 1.0603735187241003e-05\n",
            "iter: 934376  x: [ 3.99995758 15.99966065]  f(x): 1.79933550122398e-09  grad at x: [ 8.17014937e-05 -2.08169276e-05]  gradient norm: 8.431179364350963e-05\n",
            "iter: 934377  x: [ 3.99995758 15.99966065]  f(x): 1.7992812577392964e-09  grad at x: [-2.60285765e-06 -1.02790837e-05]  gradient norm: 1.060351020677379e-05\n",
            "iter: 934378  x: [ 3.99995759 15.99966066]  f(x): 1.7992257455469425e-09  grad at x: [ 8.17498057e-05 -2.08226429e-05]  gradient norm: 8.436002132438593e-05\n",
            "iter: 934379  x: [ 3.99995758 15.99966066]  f(x): 1.7991714410235898e-09  grad at x: [-2.60357197e-06 -1.02786707e-05]  gradient norm: 1.060328530513403e-05\n",
            "iter: 934380  x: [ 3.99995759 15.99966067]  f(x): 1.799115996573195e-09  grad at x: [ 8.17980886e-05 -2.08283545e-05]  gradient norm: 8.440822030972676e-05\n",
            "iter: 934381  x: [ 3.99995759 15.99966067]  f(x): 1.7990616310303064e-09  grad at x: [-2.60427182e-06 -1.02782597e-05]  gradient norm: 1.0603058671212836e-05\n",
            "iter: 934382  x: [ 3.99995759 15.99966068]  f(x): 1.7990062531749279e-09  grad at x: [ 8.18454546e-05 -2.08339516e-05]  gradient norm: 8.445550297648243e-05\n",
            "iter: 934383  x: [ 3.99995759 15.99966068]  f(x): 1.7989518277214658e-09  grad at x: [-2.60495720e-06 -1.02778504e-05]  gradient norm: 1.0602830302039704e-05\n",
            "iter: 934384  x: [ 3.99995759 15.99966069]  f(x): 1.7988965153498473e-09  grad at x: [ 8.18919038e-05 -2.08394340e-05]  gradient norm: 8.450186929652757e-05\n",
            "iter: 934385  x: [ 3.99995759 15.99966069]  f(x): 1.7988420311161757e-09  grad at x: [-2.60564265e-06 -1.02774411e-05]  gradient norm: 1.0602602007476809e-05\n",
            "iter: 934386  x: [ 3.99995759 15.9996607 ]  f(x): 1.7987867842971597e-09  grad at x: [ 8.19383820e-05 -2.08449201e-05]  gradient norm: 8.454826508961076e-05\n",
            "iter: 934387  x: [ 3.99995759 15.9996607 ]  f(x): 1.7987322411958731e-09  grad at x: [-2.60634274e-06 -1.02770300e-05]  gradient norm: 1.060237560160605e-05\n",
            "iter: 934388  x: [ 3.99995759 15.99966071]  f(x): 1.7986770611459454e-09  grad at x: [ 8.19857768e-05 -2.08505207e-05]  gradient norm: 8.45955780014586e-05\n",
            "iter: 934389  x: [ 3.99995759 15.99966072]  f(x): 1.798622457979666e-09  grad at x: [-2.60707201e-06 -1.02766153e-05]  gradient norm: 1.0602152903048739e-05\n",
            "iter: 934390  x: [ 3.99995759 15.99966073]  f(x): 1.7985673471001224e-09  grad at x: [ 8.20350489e-05 -2.08563561e-05]  gradient norm: 8.464476847341931e-05\n",
            "iter: 934391  x: [ 3.99995759 15.99966073]  f(x): 1.7985126814843446e-09  grad at x: [-2.60778681e-06 -1.02762024e-05]  gradient norm: 1.060192846914396e-05\n",
            "iter: 934392  x: [ 3.99995759 15.99966074]  f(x): 1.7984576385899381e-09  grad at x: [ 8.20833749e-05 -2.08620731e-05]  gradient norm: 8.469301349397586e-05\n",
            "iter: 934393  x: [ 3.99995759 15.99966074]  f(x): 1.7984029116719354e-09  grad at x: [-2.60848713e-06 -1.02757913e-05]  gradient norm: 1.0601702296859924e-05\n",
            "iter: 934394  x: [ 3.9999576  15.99966075]  f(x): 1.7983479356494686e-09  grad at x: [ 8.21307841e-05 -2.08676756e-05]  gradient norm: 8.474034214076909e-05\n",
            "iter: 934395  x: [ 3.99995759 15.99966075]  f(x): 1.798293148561543e-09  grad at x: [-2.60918753e-06 -1.02753802e-05]  gradient norm: 1.0601476201409144e-05\n",
            "iter: 934396  x: [ 3.9999576  15.99966076]  f(x): 1.7982382394448433e-09  grad at x: [ 8.21781932e-05 -2.08732781e-05]  gradient norm: 8.47876711702808e-05\n",
            "iter: 934397  x: [ 3.9999576  15.99966076]  f(x): 1.798197103952342e-09  grad at x: [ 3.97841381e-05 -1.55741218e-05]  gradient norm: 4.2723891559833526e-05\n",
            "iter: 934398  x: [ 3.9999576  15.99966076]  f(x): 1.7981825380565592e-09  grad at x: [-1.94713189e-06 -1.03578095e-05]  gradient norm: 1.0539238138995828e-05\n",
            "iter: 934399  x: [ 3.9999576 15.9996608]  f(x): 1.7979615102002755e-09  grad at x: [ 1.65076880e-04 -3.12341308e-05]  gradient norm: 0.000168005795595373\n",
            "iter: 934400  x: [ 3.9999576 15.9996608]  f(x): 1.797800627388154e-09  grad at x: [ 8.05855566e-05 -2.06729183e-05]  gradient norm: 8.319496063954315e-05\n",
            "iter: 934401  x: [ 3.9999576 15.9996608]  f(x): 1.7977477896210925e-09  grad at x: [-2.58484423e-06 -1.02768154e-05]  gradient norm: 1.0596903034021385e-05\n",
            "iter: 934402  x: [ 3.9999576  15.99966081]  f(x): 1.7976909635345113e-09  grad at x: [ 8.06330963e-05 -2.06785371e-05]  gradient norm: 8.324240571228069e-05\n",
            "iter: 934403  x: [ 3.9999576  15.99966081]  f(x): 1.797638066500638e-09  grad at x: [-2.58554510e-06 -1.02764043e-05]  gradient norm: 1.0596675348805155e-05\n",
            "iter: 934404  x: [ 3.9999576  15.99966082]  f(x): 1.7975813062708386e-09  grad at x: [ 8.06805340e-05 -2.06841432e-05]  gradient norm: 8.328974936012148e-05\n",
            "iter: 934405  x: [ 3.9999576  15.99966082]  f(x): 1.7975283500800626e-09  grad at x: [-2.58624606e-06 -1.02759932e-05]  gradient norm: 1.0596447740295521e-05\n",
            "iter: 934406  x: [ 3.99995761 15.99966083]  f(x): 1.797471655740915e-09  grad at x: [ 8.07279717e-05 -2.06897494e-05]  gradient norm: 8.333709341467798e-05\n",
            "iter: 934407  x: [ 3.9999576  15.99966083]  f(x): 1.7974186403590596e-09  grad at x: [-2.58694709e-06 -1.02755821e-05]  gradient norm: 1.0596220208296271e-05\n",
            "iter: 934408  x: [ 3.99995761 15.99966084]  f(x): 1.797362011943544e-09  grad at x: [ 8.07754238e-05 -2.06953573e-05]  gradient norm: 8.338445242489861e-05\n",
            "iter: 934409  x: [ 3.99995761 15.99966084]  f(x): 1.7973089373179207e-09  grad at x: [-2.58763365e-06 -1.02751728e-05]  gradient norm: 1.0595990963245103e-05\n",
            "iter: 934410  x: [ 3.99995761 15.99966085]  f(x): 1.7972523737298705e-09  grad at x: [ 8.08219591e-05 -2.07008507e-05]  gradient norm: 8.343089528689169e-05\n",
            "iter: 934411  x: [ 3.99995761 15.99966085]  f(x): 1.7971992409757417e-09  grad at x: [-2.58832028e-06 -1.02747636e-05]  gradient norm: 1.0595761792838347e-05\n",
            "iter: 934412  x: [ 3.99995761 15.99966086]  f(x): 1.7971427422486025e-09  grad at x: [ 8.08684797e-05 -2.07063422e-05]  gradient norm: 8.347732398926187e-05\n",
            "iter: 934413  x: [ 3.99995761 15.99966086]  f(x): 1.7970895513333644e-09  grad at x: [-2.58903610e-06 -1.02743506e-05]  gradient norm: 1.0595536281140729e-05\n",
            "iter: 934414  x: [ 3.99995761 15.99966087]  f(x): 1.7970331198710889e-09  grad at x: [ 8.09169066e-05 -2.07120720e-05]  gradient norm: 8.352565896364903e-05\n",
            "iter: 934415  x: [ 3.99995761 15.99966087]  f(x): 1.796979868407584e-09  grad at x: [-2.58973745e-06 -1.02739396e-05]  gradient norm: 1.059530905540111e-05\n",
            "iter: 934416  x: [ 3.99995761 15.99966088]  f(x): 1.7969235030038738e-09  grad at x: [ 8.09643585e-05 -2.07176799e-05]  gradient norm: 8.357301958533016e-05\n",
            "iter: 934417  x: [ 3.99995761 15.99966088]  f(x): 1.796870192142193e-09  grad at x: [-2.59043888e-06 -1.02735285e-05]  gradient norm: 1.0595081906274595e-05\n",
            "iter: 934418  x: [ 3.99995761 15.99966089]  f(x): 1.7968138928677538e-09  grad at x: [ 8.10118248e-05 -2.07232897e-05]  gradient norm: 8.362039515954888e-05\n",
            "iter: 934419  x: [ 3.99995761 15.99966089]  f(x): 1.796760522574536e-09  grad at x: [-2.59114038e-06 -1.02731174e-05]  gradient norm: 1.059485483399886e-05\n",
            "iter: 934420  x: [ 3.99995761 15.9996609 ]  f(x): 1.796704289499277e-09  grad at x: [ 8.10593201e-05 -2.07289031e-05]  gradient norm: 8.366780023479944e-05\n",
            "iter: 934421  x: [ 3.99995761 15.9996609 ]  f(x): 1.7966508597225538e-09  grad at x: [-2.59182742e-06 -1.02727081e-05]  gradient norm: 1.0594626042380926e-05\n",
            "iter: 934422  x: [ 3.99995762 15.99966091]  f(x): 1.7965946917095653e-09  grad at x: [ 8.11058840e-05 -2.07344001e-05]  gradient norm: 8.371427455601358e-05\n",
            "iter: 934423  x: [ 3.99995761 15.99966091]  f(x): 1.7965412035494432e-09  grad at x: [-2.59252908e-06 -1.02722970e-05]  gradient norm: 1.059439912257851e-05\n",
            "iter: 934424  x: [ 3.99995762 15.99966092]  f(x): 1.796485101802867e-09  grad at x: [ 8.11533792e-05 -2.07400135e-05]  gradient norm: 8.376168042406978e-05\n",
            "iter: 934425  x: [ 3.99995762 15.99966092]  f(x): 1.7964315540731464e-09  grad at x: [-2.59323082e-06 -1.02718859e-05]  gradient norm: 1.0594172279905948e-05\n",
            "iter: 934426  x: [ 3.99995762 15.99966093]  f(x): 1.7963755186269355e-09  grad at x: [ 8.12008742e-05 -2.07456269e-05]  gradient norm: 8.380908669521192e-05\n",
            "iter: 934427  x: [ 3.99995762 15.99966093]  f(x): 1.7963219112751104e-09  grad at x: [-2.5939472e-06 -1.0271473e-05]  gradient norm: 1.0593947313599118e-05\n",
            "iter: 934428  x: [ 3.99995762 15.99966094]  f(x): 1.7962659433361037e-09  grad at x: [ 8.12493006e-05 -2.07513567e-05]  gradient norm: 8.385742454713344e-05\n",
            "iter: 934429  x: [ 3.99995762 15.99966094]  f(x): 1.7962122751915209e-09  grad at x: [-2.59464910e-06 -1.02710619e-05]  gradient norm: 1.0593720625886895e-05\n",
            "iter: 934430  x: [ 3.99995762 15.99966095]  f(x): 1.796156373657563e-09  grad at x: [ 8.12968246e-05 -2.07569738e-05]  gradient norm: 8.390486072487611e-05\n",
            "iter: 934431  x: [ 3.99995762 15.99966095]  f(x): 1.7961026457855806e-09  grad at x: [-2.59536563e-06 -1.02706490e-05]  gradient norm: 1.0593495816748484e-05\n",
            "iter: 934432  x: [ 3.99995762 15.99966096]  f(x): 1.7960468118287893e-09  grad at x: [ 8.13452508e-05 -2.07627036e-05]  gradient norm: 8.395319940072075e-05\n",
            "iter: 934433  x: [ 3.99995762 15.99966096]  f(x): 1.7959930230752285e-09  grad at x: [-2.59608224e-06 -1.02702361e-05]  gradient norm: 1.0593271086554783e-05\n",
            "iter: 934434  x: [ 3.99995762 15.99966097]  f(x): 1.7959372567670644e-09  grad at x: [ 8.1393706e-05 -2.0768437e-05]  gradient norm: 8.400156759221993e-05\n",
            "iter: 934435  x: [ 3.99995762 15.99966097]  f(x): 1.795883407040762e-09  grad at x: [-2.59678438e-06 -1.02698250e-05]  gradient norm: 1.0593044631758076e-05\n",
            "iter: 934436  x: [ 3.99995763 15.99966098]  f(x): 1.79582770724096e-09  grad at x: [ 8.14412298e-05 -2.07740541e-05]  gradient norm: 8.40490049815647e-05\n",
            "iter: 934437  x: [ 3.99995762 15.99966098]  f(x): 1.7957737977195134e-09  grad at x: [-2.59747204e-06 -1.02694157e-05]  gradient norm: 1.0592816449158008e-05\n",
            "iter: 934438  x: [ 3.99995763 15.99966099]  f(x): 1.7957181632857824e-09  grad at x: [ 8.14878222e-05 -2.07795547e-05]  gradient norm: 8.409551153979228e-05\n",
            "iter: 934439  x: [ 3.99995763 15.99966099]  f(x): 1.7956641950746906e-09  grad at x: [-2.59817433e-06 -1.02690046e-05]  gradient norm: 1.059259014738159e-05\n",
            "iter: 934440  x: [ 3.99995763 15.999661  ]  f(x): 1.795608627252845e-09  grad at x: [ 8.15353750e-05 -2.07851754e-05]  gradient norm: 8.414297881241808e-05\n",
            "iter: 934441  x: [ 3.99995763 15.999661  ]  f(x): 1.7955545991242303e-09  grad at x: [-2.59887671e-06 -1.02685935e-05]  gradient norm: 1.0592363922683143e-05\n",
            "iter: 934442  x: [ 3.99995763 15.99966101]  f(x): 1.7954990979120751e-09  grad at x: [ 8.15828985e-05 -2.07907924e-05]  gradient norm: 8.419041738018173e-05\n",
            "iter: 934443  x: [ 3.99995763 15.99966102]  f(x): 1.7954450098678252e-09  grad at x: [-2.59957916e-06 -1.02681825e-05]  gradient norm: 1.0592137775083332e-05\n",
            "iter: 934444  x: [ 3.99995763 15.99966103]  f(x): 1.795389575335606e-09  grad at x: [ 8.16304511e-05 -2.07964131e-05]  gradient norm: 8.423788544195344e-05\n",
            "iter: 934445  x: [ 3.99995763 15.99966103]  f(x): 1.79533542728693e-09  grad at x: [-2.60029624e-06 -1.02677695e-05]  gradient norm: 1.059191351352159e-05\n",
            "iter: 934446  x: [ 3.99995763 15.99966104]  f(x): 1.7952800606476676e-09  grad at x: [ 8.16789349e-05 -2.08021502e-05]  gradient norm: 8.428628515955614e-05\n",
            "iter: 934447  x: [ 3.99995763 15.99966104]  f(x): 1.7952258513994783e-09  grad at x: [-2.60101341e-06 -1.02673566e-05]  gradient norm: 1.059168933148683e-05\n",
            "iter: 934448  x: [ 3.99995763 15.99966105]  f(x): 1.7951705526885718e-09  grad at x: [ 8.17274187e-05 -2.08078873e-05]  gradient norm: 8.433468528662405e-05\n",
            "iter: 934449  x: [ 3.99995763 15.99966105]  f(x): 1.7951162822234018e-09  grad at x: [-2.60171610e-06 -1.02669455e-05]  gradient norm: 1.0591463417456184e-05\n",
            "iter: 934450  x: [ 3.99995763 15.99966106]  f(x): 1.7950610502589155e-09  grad at x: [ 8.17749565e-05 -2.08135061e-05]  gradient norm: 8.438213999384636e-05\n",
            "iter: 934451  x: [ 3.99995763 15.99966106]  f(x): 1.7950067197025248e-09  grad at x: [-2.60241887e-06 -1.02665344e-05]  gradient norm: 1.0591237580388892e-05\n",
            "iter: 934452  x: [ 3.99995764 15.99966107]  f(x): 1.794951554628778e-09  grad at x: [ 8.18225524e-05 -2.08191323e-05]  gradient norm: 8.442965329716178e-05\n",
            "iter: 934453  x: [ 3.99995763 15.99966107]  f(x): 1.7948971638741722e-09  grad at x: [-2.60312171e-06 -1.02661234e-05]  gradient norm: 1.0591011820523739e-05\n",
            "iter: 934454  x: [ 3.99995764 15.99966108]  f(x): 1.7948420656519116e-09  grad at x: [ 8.18701046e-05 -2.08247529e-05]  gradient norm: 8.447712333701052e-05\n",
            "iter: 934455  x: [ 3.99995764 15.99966108]  f(x): 1.7947876147562735e-09  grad at x: [-2.60381009e-06 -1.02657141e-05]  gradient norm: 1.059078432335059e-05\n",
            "iter: 934456  x: [ 3.99995764 15.99966109]  f(x): 1.7947325822365371e-09  grad at x: [ 8.1916740e-05 -2.0830259e-05]  gradient norm: 8.452367701348952e-05\n",
            "iter: 934457  x: [ 3.99995764 15.99966109]  f(x): 1.7946780722938152e-09  grad at x: [-2.60452765e-06 -1.02653012e-05]  gradient norm: 1.0590560532482548e-05\n",
            "iter: 934458  x: [ 3.99995764 15.9996611 ]  f(x): 1.7946231079494324e-09  grad at x: [ 8.19652670e-05 -2.08360016e-05]  gradient norm: 8.457212279305833e-05\n",
            "iter: 934459  x: [ 3.99995764 15.9996611 ]  f(x): 1.7945685365229633e-09  grad at x: [-2.60524528e-06 -1.02648883e-05]  gradient norm: 1.0590336820830763e-05\n",
            "iter: 934460  x: [ 3.99995764 15.99966111]  f(x): 1.794513640352373e-09  grad at x: [ 8.20137794e-05 -2.08417423e-05]  gradient norm: 8.462055442804277e-05\n",
            "iter: 934461  x: [ 3.99995764 15.99966111]  f(x): 1.7944590074616443e-09  grad at x: [-2.60594845e-06 -1.02644772e-05]  gradient norm: 1.0590111371056373e-05\n",
            "iter: 934462  x: [ 3.99995764 15.99966112]  f(x): 1.7944041782788282e-09  grad at x: [ 8.20613458e-05 -2.08473648e-05]  gradient norm: 8.466804058239868e-05\n",
            "iter: 934463  x: [ 3.99995764 15.99966112]  f(x): 1.7943494850536948e-09  grad at x: [-2.60665169e-06 -1.02640661e-05]  gradient norm: 1.0589885998369031e-05\n",
            "iter: 934464  x: [ 3.99995764 15.99966113]  f(x): 1.7942947230032605e-09  grad at x: [ 8.21089704e-05 -2.08529946e-05]  gradient norm: 8.471558533361658e-05\n",
            "iter: 934465  x: [ 3.99995764 15.99966113]  f(x): 1.7942536575174116e-09  grad at x: [ 3.97508004e-05 -1.55583239e-05]  gradient norm: 4.268708907888451e-05\n",
            "iter: 934466  x: [ 3.99995764 15.99966113]  f(x): 1.7942391171151832e-09  grad at x: [-1.94513733e-06 -1.03464281e-05]  gradient norm: 1.0527684153713785e-05\n",
            "iter: 934467  x: [ 3.99995765 15.99966117]  f(x): 1.7940186670902096e-09  grad at x: [ 1.64932485e-04 -3.12044522e-05]  gradient norm: 0.00016785840008136501\n",
            "iter: 934468  x: [ 3.99995765 15.99966117]  f(x): 1.793858066541418e-09  grad at x: [ 8.05152019e-05 -2.06524946e-05]  gradient norm: 8.312173765932283e-05\n",
            "iter: 934469  x: [ 3.99995765 15.99966117]  f(x): 1.793805322108646e-09  grad at x: [-2.58227884e-06 -1.02655067e-05]  gradient norm: 1.0585310205933836e-05\n",
            "iter: 934470  x: [ 3.99995765 15.99966118]  f(x): 1.7937486421929367e-09  grad at x: [ 8.05619093e-05 -2.06580098e-05]  gradient norm: 8.316835092536277e-05\n",
            "iter: 934471  x: [ 3.99995765 15.99966118]  f(x): 1.7936958396054677e-09  grad at x: [-2.58296800e-06 -1.02650974e-05]  gradient norm: 1.0585081446406227e-05\n",
            "iter: 934472  x: [ 3.99995765 15.99966119]  f(x): 1.7936392246031497e-09  grad at x: [ 8.06086311e-05 -2.06635268e-05]  gradient norm: 8.321497913285787e-05\n",
            "iter: 934473  x: [ 3.99995765 15.99966119]  f(x): 1.7935863637911484e-09  grad at x: [-2.58365724e-06 -1.02646882e-05]  gradient norm: 1.0584852761924374e-05\n",
            "iter: 934474  x: [ 3.99995765 15.9996612 ]  f(x): 1.7935298136625296e-09  grad at x: [ 8.06553092e-05 -2.06690383e-05]  gradient norm: 8.32615640913064e-05\n",
            "iter: 934475  x: [ 3.99995765 15.9996612 ]  f(x): 1.7934768946653817e-09  grad at x: [-2.58434656e-06 -1.02642789e-05]  gradient norm: 1.0584624152508585e-05\n",
            "iter: 934476  x: [ 3.99995765 15.99966121]  f(x): 1.7934204094423576e-09  grad at x: [ 8.07020018e-05 -2.06745517e-05]  gradient norm: 8.330816399106381e-05\n",
            "iter: 934477  x: [ 3.99995765 15.99966121]  f(x): 1.7933674322096289e-09  grad at x: [-2.58505051e-06 -1.02638678e-05]  gradient norm: 1.058439740831066e-05\n",
            "iter: 934478  x: [ 3.99995765 15.99966122]  f(x): 1.7933110131642448e-09  grad at x: [ 8.07496548e-05 -2.06801851e-05]  gradient norm: 8.335572448282115e-05\n",
            "iter: 934479  x: [ 3.99995765 15.99966122]  f(x): 1.7932579764600487e-09  grad at x: [-2.58573999e-06 -1.02634585e-05]  gradient norm: 1.0584168950144846e-05\n",
            "iter: 934480  x: [ 3.99995766 15.99966123]  f(x): 1.7932016223865473e-09  grad at x: [ 8.07963472e-05 -2.06856985e-05]  gradient norm: 8.340232517458806e-05\n",
            "iter: 934481  x: [ 3.99995766 15.99966123]  f(x): 1.793148527360492e-09  grad at x: [-2.58642954e-06 -1.02630493e-05]  gradient norm: 1.0583940566889119e-05\n",
            "iter: 934482  x: [ 3.99995766 15.99966124]  f(x): 1.7930922384010904e-09  grad at x: [ 8.08430978e-05 -2.06912191e-05]  gradient norm: 8.344898445152749e-05\n",
            "iter: 934483  x: [ 3.99995766 15.99966124]  f(x): 1.7930390849494127e-09  grad at x: [-2.58714828e-06 -1.02626364e-05]  gradient norm: 1.0583715845663247e-05\n",
            "iter: 934484  x: [ 3.99995766 15.99966125]  f(x): 1.7929828633998667e-09  grad at x: [ 8.08916673e-05 -2.06969671e-05]  gradient norm: 8.349746273656565e-05\n",
            "iter: 934485  x: [ 3.99995766 15.99966125]  f(x): 1.792929649225357e-09  grad at x: [-2.58786710e-06 -1.02622234e-05]  gradient norm: 1.0583491203914596e-05\n",
            "iter: 934486  x: [ 3.99995766 15.99966126]  f(x): 1.792873495120363e-09  grad at x: [ 8.09402513e-05 -2.07027169e-05]  gradient norm: 8.35459559943953e-05\n",
            "iter: 934487  x: [ 3.99995766 15.99966126]  f(x): 1.7928202201686402e-09  grad at x: [-2.58857144e-06 -1.02618123e-05]  gradient norm: 1.058326484590947e-05\n",
            "iter: 934488  x: [ 3.99995766 15.99966127]  f(x): 1.7927641324481534e-09  grad at x: [ 8.09879329e-05 -2.07083540e-05]  gradient norm: 8.359354762555013e-05\n",
            "iter: 934489  x: [ 3.99995766 15.99966127]  f(x): 1.7927107978165624e-09  grad at x: [-2.58926131e-06 -1.02614031e-05]  gradient norm: 1.0583036768653215e-05\n",
            "iter: 934490  x: [ 3.99995766 15.99966128]  f(x): 1.7926547752713842e-09  grad at x: [ 8.10346541e-05 -2.07138710e-05]  gradient norm: 8.364017940509495e-05\n",
            "iter: 934491  x: [ 3.99995766 15.99966128]  f(x): 1.7926013821141336e-09  grad at x: [-2.58998037e-06 -1.02609902e-05]  gradient norm: 1.0582812361952323e-05\n",
            "iter: 934492  x: [ 3.99995766 15.99966129]  f(x): 1.7925454271549142e-09  grad at x: [ 8.10832524e-05 -2.07196226e-05]  gradient norm: 8.368868845786933e-05\n",
            "iter: 934493  x: [ 3.99995766 15.99966129]  f(x): 1.7924919730963545e-09  grad at x: [-2.59067040e-06 -1.02605809e-05]  gradient norm: 1.0582584437073397e-05\n",
            "iter: 934494  x: [ 3.99995767 15.9996613 ]  f(x): 1.792436083453099e-09  grad at x: [ 8.11300025e-05 -2.07251433e-05]  gradient norm: 8.373535012659174e-05\n",
            "iter: 934495  x: [ 3.99995766 15.9996613 ]  f(x): 1.7923825707652186e-09  grad at x: [-2.59138961e-06 -1.02601680e-05]  gradient norm: 1.0582360187320135e-05\n",
            "iter: 934496  x: [ 3.99995767 15.99966131]  f(x): 1.7923267487769166e-09  grad at x: [ 8.11786151e-05 -2.07308967e-05]  gradient norm: 8.378387455393862e-05\n",
            "iter: 934497  x: [ 3.99995767 15.99966131]  f(x): 1.792273175099894e-09  grad at x: [-2.59209435e-06 -1.02597569e-05]  gradient norm: 1.0582134216025461e-05\n",
            "iter: 934498  x: [ 3.99995767 15.99966132]  f(x): 1.792217419703259e-09  grad at x: [ 8.12263255e-05 -2.07365374e-05]  gradient norm: 8.383149730769197e-05\n",
            "iter: 934499  x: [ 3.99995767 15.99966132]  f(x): 1.7921637861376756e-09  grad at x: [-2.59278461e-06 -1.02593476e-05]  gradient norm: 1.0581906520192929e-05\n",
            "iter: 934500  x: [ 3.99995767 15.99966134]  f(x): 1.7921080961200652e-09  grad at x: [ 8.12730754e-05 -2.07420580e-05]  gradient norm: 8.387816015863086e-05\n",
            "iter: 934501  x: [ 3.99995767 15.99966134]  f(x): 1.7920544038235834e-09  grad at x: [-2.59350406e-06 -1.02589347e-05]  gradient norm: 1.0581682505800095e-05\n",
            "iter: 934502  x: [ 3.99995767 15.99966135]  f(x): 1.7919987816025092e-09  grad at x: [ 8.13217024e-05 -2.07478133e-05]  gradient norm: 8.392670036899942e-05\n",
            "iter: 934503  x: [ 3.99995767 15.99966135]  f(x): 1.7919450281926097e-09  grad at x: [-2.59419448e-06 -1.02585254e-05]  gradient norm: 1.0581454962550433e-05\n",
            "iter: 934504  x: [ 3.99995767 15.99966136]  f(x): 1.791889471491398e-09  grad at x: [ 8.13684812e-05 -2.07533376e-05]  gradient norm: 8.39733931052726e-05\n",
            "iter: 934505  x: [ 3.99995767 15.99966136]  f(x): 1.7918356592467515e-09  grad at x: [-2.59491409e-06 -1.02581125e-05]  gradient norm: 1.058123110531393e-05\n",
            "iter: 934506  x: [ 3.99995767 15.99966137]  f(x): 1.7917801703750531e-09  grad at x: [ 8.14170935e-05 -2.07590911e-05]  gradient norm: 8.40219195832898e-05\n",
            "iter: 934507  x: [ 3.99995767 15.99966137]  f(x): 1.791726296965177e-09  grad at x: [-2.59561922e-06 -1.02577014e-05]  gradient norm: 1.0581005521247594e-05\n",
            "iter: 934508  x: [ 3.99995767 15.99966138]  f(x): 1.7916708748925976e-09  grad at x: [ 8.14648326e-05 -2.07647354e-05]  gradient norm: 8.40695734412916e-05\n",
            "iter: 934509  x: [ 3.99995767 15.99966138]  f(x): 1.7916169413669547e-09  grad at x: [-2.59632443e-06 -1.02572903e-05]  gradient norm: 1.0580780014732667e-05\n",
            "iter: 934510  x: [ 3.99995768 15.99966139]  f(x): 1.7915615860540091e-09  grad at x: [ 8.15125425e-05 -2.07703761e-05]  gradient norm: 8.411719859628436e-05\n",
            "iter: 934511  x: [ 3.99995767 15.99966139]  f(x): 1.7915075924335579e-09  grad at x: [-2.59704428e-06 -1.02568774e-05]  gradient norm: 1.058055639405061e-05\n",
            "iter: 934512  x: [ 3.99995768 15.9996614 ]  f(x): 1.7914523051287106e-09  grad at x: [ 8.15611982e-05 -2.07761350e-05]  gradient norm: 8.416576995628238e-05\n",
            "iter: 934513  x: [ 3.99995768 15.9996614 ]  f(x): 1.791398250181749e-09  grad at x: [-2.59773509e-06 -1.02564682e-05]  gradient norm: 1.058032923422203e-05\n",
            "iter: 934514  x: [ 3.99995768 15.99966141]  f(x): 1.7913430285647027e-09  grad at x: [ 8.16079911e-05 -2.07816611e-05]  gradient norm: 8.421247920181656e-05\n",
            "iter: 934515  x: [ 3.99995768 15.99966141]  f(x): 1.7912889145941556e-09  grad at x: [-2.59844054e-06 -1.02560571e-05]  gradient norm: 1.0580103960267729e-05\n",
            "iter: 934516  x: [ 3.99995768 15.99966142]  f(x): 1.7912337598764885e-09  grad at x: [ 8.16557153e-05 -2.07873036e-05]  gradient norm: 8.42601200986862e-05\n",
            "iter: 934517  x: [ 3.99995768 15.99966142]  f(x): 1.791179585688691e-09  grad at x: [-2.59914607e-06 -1.02556460e-05]  gradient norm: 1.0579878763947778e-05\n",
            "iter: 934518  x: [ 3.99995768 15.99966143]  f(x): 1.7911244979409732e-09  grad at x: [ 8.17034686e-05 -2.07929497e-05]  gradient norm: 8.43077904937318e-05\n",
            "iter: 934519  x: [ 3.99995768 15.99966143]  f(x): 1.7910702634468327e-09  grad at x: [-2.59986623e-06 -1.02552331e-05]  gradient norm: 1.0579655457861605e-05\n",
            "iter: 934520  x: [ 3.99995768 15.99966144]  f(x): 1.791015243847089e-09  grad at x: [ 8.17521240e-05 -2.07987086e-05]  gradient norm: 8.43563634734754e-05\n",
            "iter: 934521  x: [ 3.99995768 15.99966144]  f(x): 1.790960947868276e-09  grad at x: [-2.60060102e-06 -1.02548183e-05]  gradient norm: 1.0579434045766214e-05\n",
            "iter: 934522  x: [ 3.99995768 15.99966145]  f(x): 1.7909059976691946e-09  grad at x: [ 8.18017398e-05 -2.08045876e-05]  gradient norm: 8.440589726809682e-05\n",
            "iter: 934523  x: [ 3.99995768 15.99966145]  f(x): 1.790851638987993e-09  grad at x: [-2.60129223e-06 -1.02544091e-05]  gradient norm: 1.0579207270498738e-05\n",
            "iter: 934524  x: [ 3.99995768 15.99966146]  f(x): 1.790796754682473e-09  grad at x: [ 8.18485614e-05 -2.08101173e-05]  gradient norm: 8.445263756363547e-05\n",
            "iter: 934525  x: [ 3.99995768 15.99966146]  f(x): 1.7907423367521854e-09  grad at x: [-2.60201262e-06 -1.02539962e-05]  gradient norm: 1.0578984202942817e-05\n",
            "iter: 934526  x: [ 3.99995769 15.99966147]  f(x): 1.7906875207373243e-09  grad at x: [ 8.18972457e-05 -2.08158799e-05]  gradient norm: 8.45012408703419e-05\n",
            "iter: 934527  x: [ 3.99995768 15.99966147]  f(x): 1.7906330412151932e-09  grad at x: [-2.60271854e-06 -1.02535851e-05]  gradient norm: 1.0578759398128518e-05\n",
            "iter: 934528  x: [ 3.99995769 15.99966148]  f(x): 1.7905782923803248e-09  grad at x: [ 8.19450276e-05 -2.08215297e-05]  gradient norm: 8.454894236422685e-05\n",
            "iter: 934529  x: [ 3.99995769 15.99966148]  f(x): 1.7905237523220681e-09  grad at x: [-2.60345365e-06 -1.02531703e-05]  gradient norm: 1.0578538307609364e-05\n",
            "iter: 934530  x: [ 3.99995769 15.99966149]  f(x): 1.790469073032027e-09  grad at x: [ 8.19946431e-05 -2.08274087e-05]  gradient norm: 8.459847781707834e-05\n",
            "iter: 934531  x: [ 3.99995769 15.99966149]  f(x): 1.7904144701259902e-09  grad at x: [-2.60414518e-06 -1.02527611e-05]  gradient norm: 1.0578311840918494e-05\n",
            "iter: 934532  x: [ 3.99995769 15.9996615 ]  f(x): 1.7903734972907014e-09  grad at x: [ 3.97186596e-05 -1.55428497e-05]  gradient norm: 4.265151931598301e-05\n",
            "iter: 934533  x: [ 3.99995769 15.9996615 ]  f(x): 1.7903589815384887e-09  grad at x: [-1.94321193e-06 -1.03352122e-05]  gradient norm: 1.0516305626484233e-05\n",
            "iter: 934534  x: [ 3.9999577  15.99966154]  f(x): 1.7901391257595688e-09  grad at x: [ 1.64800419e-04 -3.11764888e-05]  gradient norm: 0.00016772343801849506\n",
            "iter: 934535  x: [ 3.99995769 15.99966154]  f(x): 1.7899787834483472e-09  grad at x: [ 8.04509047e-05 -2.06330024e-05]  gradient norm: 8.305461367944746e-05\n",
            "iter: 934536  x: [ 3.99995769 15.99966154]  f(x): 1.7899261246500396e-09  grad at x: [-2.57984065e-06 -1.02543563e-05]  gradient norm: 1.0573901887849629e-05\n",
            "iter: 934537  x: [ 3.9999577  15.99966155]  f(x): 1.789869595749357e-09  grad at x: [ 8.04975365e-05 -2.06385084e-05]  gradient norm: 8.310115171406757e-05\n",
            "iter: 934538  x: [ 3.99995769 15.99966155]  f(x): 1.7898168789170333e-09  grad at x: [-2.58053261e-06 -1.02539470e-05]  gradient norm: 1.0573673836770994e-05\n",
            "iter: 934539  x: [ 3.9999577  15.99966156]  f(x): 1.789760415010885e-09  grad at x: [ 8.05443865e-05 -2.06440418e-05]  gradient norm: 8.314790836614182e-05\n",
            "iter: 934540  x: [ 3.9999577  15.99966156]  f(x): 1.7897076398620387e-09  grad at x: [-2.58122464e-06 -1.02535378e-05]  gradient norm: 1.0573445861196828e-05\n",
            "iter: 934541  x: [ 3.9999577  15.99966157]  f(x): 1.7896512410192419e-09  grad at x: [ 8.05912656e-05 -2.06495788e-05]  gradient norm: 8.319469451164343e-05\n",
            "iter: 934542  x: [ 3.9999577  15.99966157]  f(x): 1.7895984074483228e-09  grad at x: [-2.58194586e-06 -1.02531249e-05]  gradient norm: 1.0573221540325353e-05\n",
            "iter: 934543  x: [ 3.9999577  15.99966158]  f(x): 1.7895420760303224e-09  grad at x: [ 8.06400072e-05 -2.06553486e-05]  gradient norm: 8.324334325426945e-05\n",
            "iter: 934544  x: [ 3.9999577  15.99966158]  f(x): 1.7894891817302218e-09  grad at x: [-2.58265261e-06 -1.02527138e-05]  gradient norm: 1.0572995508625295e-05\n",
            "iter: 934545  x: [ 3.9999577  15.99966159]  f(x): 1.789432916607914e-09  grad at x: [ 8.06878175e-05 -2.06610021e-05]  gradient norm: 8.329106132018564e-05\n",
            "iter: 934546  x: [ 3.9999577  15.99966159]  f(x): 1.7893799626516448e-09  grad at x: [-2.58335943e-06 -1.02523027e-05]  gradient norm: 1.0572769554417838e-05\n",
            "iter: 934547  x: [ 3.9999577 15.9996616]  f(x): 1.789323763859444e-09  grad at x: [ 8.07356276e-05 -2.06666555e-05]  gradient norm: 8.333877979782033e-05\n",
            "iter: 934548  x: [ 3.9999577 15.9996616]  f(x): 1.7892707502680694e-09  grad at x: [-2.58405178e-06 -1.02518934e-05]  gradient norm: 1.0572541885096266e-05\n",
            "iter: 934549  x: [ 3.9999577  15.99966161]  f(x): 1.7892146167100322e-09  grad at x: [ 8.07825355e-05 -2.06721961e-05]  gradient norm: 8.338559665799213e-05\n",
            "iter: 934550  x: [ 3.9999577  15.99966161]  f(x): 1.7891615445427668e-09  grad at x: [-2.58475877e-06 -1.02514823e-05]  gradient norm: 1.0572316085288182e-05\n",
            "iter: 934551  x: [ 3.9999577  15.99966162]  f(x): 1.7891054773821685e-09  grad at x: [ 8.08303600e-05 -2.06778514e-05]  gradient norm: 8.343333049824726e-05\n",
            "iter: 934552  x: [ 3.9999577  15.99966162]  f(x): 1.7890523454742855e-09  grad at x: [-2.58545128e-06 -1.02510730e-05]  gradient norm: 1.057208856804596e-05\n",
            "iter: 934553  x: [ 3.99995771 15.99966163]  f(x): 1.7889963436155512e-09  grad at x: [ 8.08772532e-05 -2.06833902e-05]  gradient norm: 8.348013360459438e-05\n",
            "iter: 934554  x: [ 3.9999577  15.99966163]  f(x): 1.7889431530816773e-09  grad at x: [-2.58614387e-06 -1.02506638e-05]  gradient norm: 1.0571861126668817e-05\n",
            "iter: 934555  x: [ 3.99995771 15.99966164]  f(x): 1.7888872165562689e-09  grad at x: [ 8.09241753e-05 -2.06889326e-05]  gradient norm: 8.35269662015104e-05\n",
            "iter: 934556  x: [ 3.99995771 15.99966164]  f(x): 1.7888339673270713e-09  grad at x: [-2.58683653e-06 -1.02502545e-05]  gradient norm: 1.0571633760525356e-05\n",
            "iter: 934557  x: [ 3.99995771 15.99966165]  f(x): 1.7887780962056842e-09  grad at x: [ 8.09710974e-05 -2.06944751e-05]  gradient norm: 8.357379919073472e-05\n",
            "iter: 934558  x: [ 3.99995771 15.99966165]  f(x): 1.788724788267085e-09  grad at x: [-2.58754383e-06 -1.02498434e-05]  gradient norm: 1.0571408268464133e-05\n",
            "iter: 934559  x: [ 3.99995771 15.99966166]  f(x): 1.788668983678878e-09  grad at x: [ 8.10189216e-05 -2.07001303e-05]  gradient norm: 8.362153464274921e-05\n",
            "iter: 934560  x: [ 3.99995771 15.99966166]  f(x): 1.7886156158444927e-09  grad at x: [-2.58825121e-06 -1.02494323e-05]  gradient norm: 1.0571182854040141e-05\n",
            "iter: 934561  x: [ 3.99995771 15.99966167]  f(x): 1.7885598779334646e-09  grad at x: [ 8.10668040e-05 -2.07057928e-05]  gradient norm: 8.36693287021062e-05\n",
            "iter: 934562  x: [ 3.99995771 15.99966167]  f(x): 1.7885064501147587e-09  grad at x: [-2.58894411e-06 -1.02490230e-05]  gradient norm: 1.0570955717149438e-05\n",
            "iter: 934563  x: [ 3.99995771 15.99966168]  f(x): 1.7884507776348885e-09  grad at x: [ 8.11136967e-05 -2.07113317e-05]  gradient norm: 8.371613377849011e-05\n",
            "iter: 934564  x: [ 3.99995771 15.99966168]  f(x): 1.7883972910218097e-09  grad at x: [-2.58963709e-06 -1.02486138e-05]  gradient norm: 1.0570728656008813e-05\n",
            "iter: 934565  x: [ 3.99995771 15.99966169]  f(x): 1.7883416841158329e-09  grad at x: [ 8.11606476e-05 -2.07168778e-05]  gradient norm: 8.376299744398124e-05\n",
            "iter: 934566  x: [ 3.99995771 15.99966169]  f(x): 1.7882881386040523e-09  grad at x: [-2.59035926e-06 -1.02482009e-05]  gradient norm: 1.0570505275377903e-05\n",
            "iter: 934567  x: [ 3.99995771 15.9996617 ]  f(x): 1.788232599576058e-09  grad at x: [ 8.12094319e-05 -2.07226531e-05]  gradient norm: 8.381169481104557e-05\n",
            "iter: 934568  x: [ 3.99995771 15.9996617 ]  f(x): 1.7881789928406765e-09  grad at x: [-2.59106695e-06 -1.02477898e-05]  gradient norm: 1.0570280171279498e-05\n",
            "iter: 934569  x: [ 3.99995772 15.99966171]  f(x): 1.7881235206271855e-09  grad at x: [ 8.12573140e-05 -2.07283156e-05]  gradient norm: 8.385949048502109e-05\n",
            "iter: 934570  x: [ 3.99995772 15.99966171]  f(x): 1.7880698537507315e-09  grad at x: [-2.59177472e-06 -1.02473787e-05]  gradient norm: 1.0570055145357433e-05\n",
            "iter: 934571  x: [ 3.99995772 15.99966172]  f(x): 1.7880144483487048e-09  grad at x: [ 8.13051960e-05 -2.07339781e-05]  gradient norm: 8.390728656560995e-05\n",
            "iter: 934572  x: [ 3.99995772 15.99966172]  f(x): 1.787960721314558e-09  grad at x: [-2.59246802e-06 -1.02469694e-05]  gradient norm: 1.0569828391240163e-05\n",
            "iter: 934573  x: [ 3.99995772 15.99966173]  f(x): 1.78790538158491e-09  grad at x: [ 8.13521320e-05 -2.07395224e-05]  gradient norm: 8.395413726280047e-05\n",
            "iter: 934574  x: [ 3.99995772 15.99966173]  f(x): 1.7878515955330023e-09  grad at x: [-2.59317595e-06 -1.02465583e-05]  gradient norm: 1.0569603519778283e-05\n",
            "iter: 934575  x: [ 3.99995772 15.99966174]  f(x): 1.7877963227568663e-09  grad at x: [ 8.14000429e-05 -2.07451885e-05]  gradient norm: 8.40019632390603e-05\n",
            "iter: 934576  x: [ 3.99995772 15.99966174]  f(x): 1.7877424764239617e-09  grad at x: [-2.59388395e-06 -1.02461472e-05]  gradient norm: 1.0569378726337275e-05\n",
            "iter: 934577  x: [ 3.99995772 15.99966175]  f(x): 1.7876872705621733e-09  grad at x: [ 8.14479246e-05 -2.07508510e-05]  gradient norm: 8.404976051724248e-05\n",
            "iter: 934578  x: [ 3.99995772 15.99966175]  f(x): 1.7876333639677782e-09  grad at x: [-2.59457749e-06 -1.02457379e-05]  gradient norm: 1.0569152201749063e-05\n",
            "iter: 934579  x: [ 3.99995772 15.99966176]  f(x): 1.7875782239522546e-09  grad at x: [ 8.14949040e-05 -2.07564008e-05]  gradient norm: 8.409665603827201e-05\n",
            "iter: 934580  x: [ 3.99995772 15.99966176]  f(x): 1.7875242581846504e-09  grad at x: [-2.5953002e-06 -1.0245325e-05]  gradient norm: 1.0568929373383225e-05\n",
            "iter: 934581  x: [ 3.99995772 15.99966177]  f(x): 1.7874691863650854e-09  grad at x: [ 8.15437461e-05 -2.07621833e-05]  gradient norm: 8.414541448087759e-05\n",
            "iter: 934582  x: [ 3.99995772 15.99966177]  f(x): 1.7874151590355719e-09  grad at x: [-2.59602300e-06 -1.02449121e-05]  gradient norm: 1.0568706625071357e-05\n",
            "iter: 934583  x: [ 3.99995773 15.99966178]  f(x): 1.7873601554854478e-09  grad at x: [ 8.15925880e-05 -2.07679659e-05]  gradient norm: 8.419417334005928e-05\n",
            "iter: 934584  x: [ 3.99995772 15.99966178]  f(x): 1.7873060665759855e-09  grad at x: [-2.59673132e-06 -1.02445010e-05]  gradient norm: 1.0568482144788656e-05\n",
            "iter: 934585  x: [ 3.99995773 15.99966179]  f(x): 1.787251130115276e-09  grad at x: [ 8.16404985e-05 -2.07736321e-05]  gradient norm: 8.424200132985785e-05\n",
            "iter: 934586  x: [ 3.99995773 15.99966179]  f(x): 1.7871969807680364e-09  grad at x: [-2.59742517e-06 -1.02440918e-05]  gradient norm: 1.0568255929084123e-05\n",
            "iter: 934587  x: [ 3.99995773 15.9996618 ]  f(x): 1.7871421102528586e-09  grad at x: [ 8.16874631e-05 -2.07791800e-05]  gradient norm: 8.428888387018291e-05\n",
            "iter: 934588  x: [ 3.99995773 15.9996618 ]  f(x): 1.7870879015943766e-09  grad at x: [-2.59814820e-06 -1.02436788e-05]  gradient norm: 1.0568033418183074e-05\n",
            "iter: 934589  x: [ 3.99995773 15.99966181]  f(x): 1.7870330994537208e-09  grad at x: [ 8.17363193e-05 -2.07849644e-05]  gradient norm: 8.433765850358535e-05\n",
            "iter: 934590  x: [ 3.99995773 15.99966182]  f(x): 1.7869788291092918e-09  grad at x: [-2.59885676e-06 -1.02432678e-05]  gradient norm: 1.056780917233853e-05\n",
            "iter: 934591  x: [ 3.99995773 15.99966183]  f(x): 1.7869240941986589e-09  grad at x: [ 8.17842442e-05 -2.07906323e-05]  gradient norm: 8.438550223738872e-05\n",
            "iter: 934592  x: [ 3.99995773 15.99966183]  f(x): 1.7868697632567348e-09  grad at x: [-2.59956540e-06 -1.02428567e-05]  gradient norm: 1.0567585004244859e-05\n",
            "iter: 934593  x: [ 3.99995773 15.99966184]  f(x): 1.786815095683989e-09  grad at x: [ 8.18322126e-05 -2.07963058e-05]  gradient norm: 8.443339002282034e-05\n",
            "iter: 934594  x: [ 3.99995773 15.99966184]  f(x): 1.7867607040739462e-09  grad at x: [-2.60027411e-06 -1.02424456e-05]  gradient norm: 1.0567360914359656e-05\n",
            "iter: 934595  x: [ 3.99995773 15.99966185]  f(x): 1.7867061037634622e-09  grad at x: [ 8.18801227e-05 -2.08019719e-05]  gradient norm: 8.448121999791655e-05\n",
            "iter: 934596  x: [ 3.99995773 15.99966185]  f(x): 1.7866516515424263e-09  grad at x: [-2.60099746e-06 -1.02420327e-05]  gradient norm: 1.056713872147805e-05\n",
            "iter: 934597  x: [ 3.99995773 15.99966186]  f(x): 1.7865971197846011e-09  grad at x: [ 8.19290078e-05 -2.08077599e-05]  gradient norm: 8.453002536275894e-05\n",
            "iter: 934598  x: [ 3.99995773 15.99966186]  f(x): 1.786556233965475e-09  grad at x: [ 3.96636216e-05 -1.55246871e-05]  gradient norm: 4.259364728574474e-05\n",
            "iter: 934599  x: [ 3.99995773 15.99966186]  f(x): 1.7865417570846002e-09  grad at x: [-1.94094390e-06 -1.03242128e-05]  gradient norm: 1.0505076524089705e-05\n",
            "iter: 934600  x: [ 3.99995774 15.9996619 ]  f(x): 1.7863222420034713e-09  grad at x: [ 1.64574049e-04 -3.11369113e-05]  gradient norm: 0.00016749365591932924\n",
            "iter: 934601  x: [ 3.99995774 15.9996619 ]  f(x): 1.7861623386082929e-09  grad at x: [ 8.03401941e-05 -2.06078821e-05]  gradient norm: 8.294113327081515e-05\n",
            "iter: 934602  x: [ 3.99995774 15.9996619 ]  f(x): 1.786109823107549e-09  grad at x: [-2.57669585e-06 -1.02434678e-05]  gradient norm: 1.0562575203974244e-05\n",
            "iter: 934603  x: [ 3.99995774 15.99966191]  f(x): 1.7860533833545814e-09  grad at x: [ 8.03865030e-05 -2.06133482e-05]  gradient norm: 8.298734834405905e-05\n",
            "iter: 934604  x: [ 3.99995774 15.99966191]  f(x): 1.786000810295477e-09  grad at x: [-2.57739057e-06 -1.02430586e-05]  gradient norm: 1.0562347796527899e-05\n",
            "iter: 934605  x: [ 3.99995774 15.99966192]  f(x): 1.7859444356928702e-09  grad at x: [ 8.0433554e-05 -2.0618907e-05]  gradient norm: 8.303430576005588e-05\n",
            "iter: 934606  x: [ 3.99995774 15.99966192]  f(x): 1.7858918041507417e-09  grad at x: [-2.57808536e-06 -1.02426493e-05]  gradient norm: 1.0562120464816165e-05\n",
            "iter: 934607  x: [ 3.99995774 15.99966193]  f(x): 1.7858354947318109e-09  grad at x: [ 8.04806049e-05 -2.06244658e-05]  gradient norm: 8.308126357816597e-05\n",
            "iter: 934608  x: [ 3.99995774 15.99966193]  f(x): 1.7857828046548434e-09  grad at x: [-2.57879478e-06 -1.02422382e-05]  gradient norm: 1.056189499812774e-05\n",
            "iter: 934609  x: [ 3.99995774 15.99966194]  f(x): 1.7857265616154957e-09  grad at x: [ 8.05285871e-05 -2.06301411e-05]  gradient norm: 8.312915289134078e-05\n",
            "iter: 934610  x: [ 3.99995774 15.99966194]  f(x): 1.7856738117881398e-09  grad at x: [-2.57950428e-06 -1.02418271e-05]  gradient norm: 1.0561669609367685e-05\n",
            "iter: 934611  x: [ 3.99995775 15.99966195]  f(x): 1.7856176351630416e-09  grad at x: [ 8.05765692e-05 -2.06358163e-05]  gradient norm: 8.317704262479193e-05\n",
            "iter: 934612  x: [ 3.99995774 15.99966195]  f(x): 1.7855648256060513e-09  grad at x: [-2.58019931e-06 -1.02414178e-05]  gradient norm: 1.056144250776599e-05\n",
            "iter: 934613  x: [ 3.99995775 15.99966196]  f(x): 1.7855087142659123e-09  grad at x: [ 8.06236199e-05 -2.06413752e-05]  gradient norm: 8.322400165879181e-05\n",
            "iter: 934614  x: [ 3.99995775 15.99966196]  f(x): 1.7854558460525496e-09  grad at x: [-2.58089441e-06 -1.02410086e-05]  gradient norm: 1.0561215481763786e-05\n",
            "iter: 934615  x: [ 3.99995775 15.99966197]  f(x): 1.7853998001031887e-09  grad at x: [ 8.06707142e-05 -2.06469394e-05]  gradient norm: 8.327100473891191e-05\n",
            "iter: 934616  x: [ 3.99995775 15.99966197]  f(x): 1.785346873166006e-09  grad at x: [-2.58161870e-06 -1.02405957e-05]  gradient norm: 1.0560992118769372e-05\n",
            "iter: 934617  x: [ 3.99995775 15.99966198]  f(x): 1.7852908948980195e-09  grad at x: [ 8.07196419e-05 -2.06527329e-05]  gradient norm: 8.331984138382441e-05\n",
            "iter: 934618  x: [ 3.99995775 15.99966198]  f(x): 1.7852379069256326e-09  grad at x: [-2.58232852e-06 -1.02401846e-05]  gradient norm: 1.0560767041495065e-05\n",
            "iter: 934619  x: [ 3.99995775 15.99966199]  f(x): 1.7851819952099142e-09  grad at x: [ 8.07676237e-05 -2.06584082e-05]  gradient norm: 8.336773277100955e-05\n",
            "iter: 934620  x: [ 3.99995775 15.99966199]  f(x): 1.785128947331125e-09  grad at x: [-2.58302386e-06 -1.02397753e-05]  gradient norm: 1.056054024670032e-05\n",
            "iter: 934621  x: [ 3.99995775 15.999662  ]  f(x): 1.7850731011074524e-09  grad at x: [ 8.08147323e-05 -2.06639743e-05]  gradient norm: 8.341475161847675e-05\n",
            "iter: 934622  x: [ 3.99995775 15.999662  ]  f(x): 1.7850199944015143e-09  grad at x: [-2.58371928e-06 -1.02393660e-05]  gradient norm: 1.0560313528238574e-05\n",
            "iter: 934623  x: [ 3.99995775 15.99966201]  f(x): 1.784964213667375e-09  grad at x: [ 8.08618117e-05 -2.06695368e-05]  gradient norm: 8.346174176445703e-05\n",
            "iter: 934624  x: [ 3.99995775 15.99966201]  f(x): 1.784911048118307e-09  grad at x: [-2.58442933e-06 -1.02389549e-05]  gradient norm: 1.056008868338337e-05\n",
            "iter: 934625  x: [ 3.99995775 15.99966202]  f(x): 1.7848553340750605e-09  grad at x: [ 8.09098223e-05 -2.06752156e-05]  gradient norm: 8.350966347156237e-05\n",
            "iter: 934626  x: [ 3.99995775 15.99966202]  f(x): 1.7848021084618642e-09  grad at x: [-2.58513946e-06 -1.02385438e-05]  gradient norm: 1.0559863916622737e-05\n",
            "iter: 934627  x: [ 3.99995776 15.99966203]  f(x): 1.7847464611801713e-09  grad at x: [ 8.09578620e-05 -2.06808982e-05]  gradient norm: 8.355761469147516e-05\n",
            "iter: 934628  x: [ 3.99995775 15.99966203]  f(x): 1.7846931754694049e-09  grad at x: [-2.58584967e-06 -1.02381327e-05]  gradient norm: 1.055963922819493e-05\n",
            "iter: 934629  x: [ 3.99995776 15.99966204]  f(x): 1.7846375949840138e-09  grad at x: [ 8.10059016e-05 -2.06865807e-05]  gradient norm: 8.360556632173996e-05\n",
            "iter: 934630  x: [ 3.99995776 15.99966204]  f(x): 1.7845842491406234e-09  grad at x: [-2.58655996e-06 -1.02377217e-05]  gradient norm: 1.05594146181209e-05\n",
            "iter: 934631  x: [ 3.99995776 15.99966205]  f(x): 1.7845287354862816e-09  grad at x: [ 8.10539412e-05 -2.06922632e-05]  gradient norm: 8.36535183632346e-05\n",
            "iter: 934632  x: [ 3.99995776 15.99966205]  f(x): 1.7844753294376953e-09  grad at x: [-2.58727033e-06 -1.02373106e-05]  gradient norm: 1.0559190086421597e-05\n",
            "iter: 934633  x: [ 3.99995776 15.99966206]  f(x): 1.7844198826491524e-09  grad at x: [ 8.11019806e-05 -2.06979457e-05]  gradient norm: 8.37014708151177e-05\n",
            "iter: 934634  x: [ 3.99995776 15.99966206]  f(x): 1.7843664163978357e-09  grad at x: [-2.58798077e-06 -1.02368995e-05]  gradient norm: 1.0558965632900287e-05\n",
            "iter: 934635  x: [ 3.99995776 15.99966207]  f(x): 1.784311036509839e-09  grad at x: [ 8.11500200e-05 -2.07036283e-05]  gradient norm: 8.374942367482862e-05\n",
            "iter: 934636  x: [ 3.99995776 15.99966207]  f(x): 1.7842575100014063e-09  grad at x: [-2.58867674e-06 -1.02364902e-05]  gradient norm: 1.0558739453362058e-05\n",
            "iter: 934637  x: [ 3.99995776 15.99966208]  f(x): 1.7842021958766097e-09  grad at x: [ 8.11971279e-05 -2.07091944e-05]  gradient norm: 8.379644572195241e-05\n",
            "iter: 934638  x: [ 3.99995776 15.99966208]  f(x): 1.7841486102492517e-09  grad at x: [-2.58938734e-06 -1.02360791e-05]  gradient norm: 1.0558515155388326e-05\n",
            "iter: 934639  x: [ 3.99995776 15.99966209]  f(x): 1.7840933630931001e-09  grad at x: [ 8.12451817e-05 -2.07148787e-05]  gradient norm: 8.384441393954419e-05\n",
            "iter: 934640  x: [ 3.99995776 15.99966209]  f(x): 1.7840397171399192e-09  grad at x: [-2.59008347e-06 -1.02356698e-05]  gradient norm: 1.0558289129499972e-05\n",
            "iter: 934641  x: [ 3.99995777 15.9996621 ]  f(x): 1.7839845358873509e-09  grad at x: [ 8.12923331e-05 -2.07204503e-05]  gradient norm: 8.389148042620732e-05\n",
            "iter: 934642  x: [ 3.99995776 15.9996621 ]  f(x): 1.7839308306924356e-09  grad at x: [-2.59077968e-06 -1.02352606e-05]  gradient norm: 1.0558063179715258e-05\n",
            "iter: 934643  x: [ 3.99995777 15.99966211]  f(x): 1.7838757153400915e-09  grad at x: [ 8.133947e-05 -2.072602e-05]  gradient norm: 8.393853275012617e-05\n",
            "iter: 934644  x: [ 3.99995777 15.99966211]  f(x): 1.7838219508883146e-09  grad at x: [-2.59149052e-06 -1.02348495e-05]  gradient norm: 1.055783911478293e-05\n",
            "iter: 934645  x: [ 3.99995777 15.99966212]  f(x): 1.783766902607591e-09  grad at x: [ 8.13875235e-05 -2.07317044e-05]  gradient norm: 8.398650216819405e-05\n",
            "iter: 934646  x: [ 3.99995777 15.99966212]  f(x): 1.7837130777079217e-09  grad at x: [-2.59220144e-06 -1.02344384e-05]  gradient norm: 1.055761512815316e-05\n",
            "iter: 934647  x: [ 3.99995777 15.99966213]  f(x): 1.783658096607264e-09  grad at x: [ 8.14356061e-05 -2.07373923e-05]  gradient norm: 8.403450109435983e-05\n",
            "iter: 934648  x: [ 3.99995777 15.99966213]  f(x): 1.7836042111884648e-09  grad at x: [-2.59291243e-06 -1.02340273e-05]  gradient norm: 1.0557391220282999e-05\n",
            "iter: 934649  x: [ 3.99995777 15.99966214]  f(x): 1.7835492973020215e-09  grad at x: [ 8.14837031e-05 -2.07430821e-05]  gradient norm: 8.408251497429284e-05\n",
            "iter: 934650  x: [ 3.99995777 15.99966215]  f(x): 1.7834953513114594e-09  grad at x: [-2.59363806e-06 -1.02336144e-05]  gradient norm: 1.0557169202555308e-05\n",
            "iter: 934651  x: [ 3.99995777 15.99966216]  f(x): 1.7834405057778427e-09  grad at x: [ 8.15326877e-05 -2.07488829e-05]  gradient norm: 8.413141688651446e-05\n",
            "iter: 934652  x: [ 3.99995777 15.99966216]  f(x): 1.7833864980754505e-09  grad at x: [-2.59434921e-06 -1.02332033e-05]  gradient norm: 1.0556945452484154e-05\n",
            "iter: 934653  x: [ 3.99995777 15.99966217]  f(x): 1.7833317198263643e-09  grad at x: [ 8.15807846e-05 -2.07545727e-05]  gradient norm: 8.417943158211642e-05\n",
            "iter: 934654  x: [ 3.99995777 15.99966217]  f(x): 1.7832776514801334e-09  grad at x: [-2.59504589e-06 -1.02327940e-05]  gradient norm: 1.0556719966821809e-05\n",
            "iter: 934655  x: [ 3.99995777 15.99966218]  f(x): 1.7832229394090773e-09  grad at x: [ 8.16279646e-05 -2.07601479e-05]  gradient norm: 8.422652992903439e-05\n",
            "iter: 934656  x: [ 3.99995777 15.99966218]  f(x): 1.783168811545685e-09  grad at x: [-2.59577175e-06 -1.02323811e-05]  gradient norm: 1.0556498187957598e-05\n",
            "iter: 934657  x: [ 3.99995778 15.99966219]  f(x): 1.7831141680070436e-09  grad at x: [ 8.16769926e-05 -2.07659541e-05]  gradient norm: 8.427547672765232e-05\n",
            "iter: 934658  x: [ 3.99995777 15.99966219]  f(x): 1.7830599782513199e-09  grad at x: [-2.59648314e-06 -1.02319700e-05]  gradient norm: 1.055627467376248e-05\n",
            "iter: 934659  x: [ 3.99995778 15.9996622 ]  f(x): 1.7830054021011105e-09  grad at x: [ 8.17251038e-05 -2.07716457e-05]  gradient norm: 8.432350717794035e-05\n",
            "iter: 934660  x: [ 3.99995778 15.9996622 ]  f(x): 1.7829511515785585e-09  grad at x: [-2.59719461e-06 -1.02315589e-05]  gradient norm: 1.0556051237797629e-05\n",
            "iter: 934661  x: [ 3.99995778 15.99966221]  f(x): 1.7828966428891374e-09  grad at x: [ 8.17732149e-05 -2.07773373e-05]  gradient norm: 8.437153802842724e-05\n",
            "iter: 934662  x: [ 3.99995778 15.99966221]  f(x): 1.7828423315646004e-09  grad at x: [-2.59790616e-06 -1.02311478e-05]  gradient norm: 1.0555827880520817e-05\n",
            "iter: 934663  x: [ 3.99995778 15.99966222]  f(x): 1.7827878903702366e-09  grad at x: [ 8.18213405e-05 -2.07830308e-05]  gradient norm: 8.441958382842695e-05\n",
            "iter: 934664  x: [ 3.99995778 15.99966222]  f(x): 1.7827335181909668e-09  grad at x: [-2.59863234e-06 -1.02307349e-05]  gradient norm: 1.0555606421400667e-05\n",
            "iter: 934665  x: [ 3.99995778 15.99966222]  f(x): 1.782692722714022e-09  grad at x: [ 3.9635868e-05 -1.5509786e-05]  gradient norm: 4.256237174513715e-05\n",
            "iter: 934666  x: [ 3.99995778 15.99966222]  f(x): 1.782678267659696e-09  grad at x: [-1.93908435e-06 -1.03130133e-05]  gradient norm: 1.0493726253721276e-05\n",
            "iter: 934667  x: [ 3.99995779 15.99966226]  f(x): 1.7824593846388622e-09  grad at x: [ 1.64458230e-04 -3.11110034e-05]  gradient norm: 0.00016737503994906095\n",
            "iter: 934668  x: [ 3.99995779 15.99966226]  f(x): 1.7822997078444733e-09  grad at x: [ 8.02839221e-05 -2.05894175e-05]  gradient norm: 8.288203820315505e-05\n",
            "iter: 934669  x: [ 3.99995778 15.99966226]  f(x): 1.782247267754042e-09  grad at x: [-2.57442535e-06 -1.02323211e-05]  gradient norm: 1.0551211327056333e-05\n",
            "iter: 934670  x: [ 3.99995779 15.99966227]  f(x): 1.7821909912907234e-09  grad at x: [ 8.03326439e-05 -2.05951856e-05]  gradient norm: 8.293066584311698e-05\n",
            "iter: 934671  x: [ 3.99995779 15.99966227]  f(x): 1.7821384907067701e-09  grad at x: [-2.57513741e-06 -1.02319100e-05]  gradient norm: 1.0550986426305622e-05\n",
            "iter: 934672  x: [ 3.99995779 15.99966228]  f(x): 1.7820822806781265e-09  grad at x: [ 8.03807835e-05 -2.06008808e-05]  gradient norm: 8.29787119901462e-05\n",
            "iter: 934673  x: [ 3.99995779 15.99966228]  f(x): 1.7820297202967073e-09  grad at x: [-2.57583499e-06 -1.02315007e-05]  gradient norm: 1.0550759815403861e-05\n",
            "iter: 934674  x: [ 3.99995779 15.99966229]  f(x): 1.7819735756130853e-09  grad at x: [ 8.04280062e-05 -2.06064615e-05]  gradient norm: 8.302584201570897e-05\n",
            "iter: 934675  x: [ 3.99995779 15.99966229]  f(x): 1.7819209565235494e-09  grad at x: [-2.57651810e-06 -1.02310933e-05]  gradient norm: 1.055053149072461e-05\n",
            "iter: 934676  x: [ 3.99995779 15.9996623 ]  f(x): 1.7818648760566996e-09  grad at x: [ 8.04742976e-05 -2.06119257e-05]  gradient norm: 8.307204134245825e-05\n",
            "iter: 934677  x: [ 3.99995779 15.9996623 ]  f(x): 1.7818121993699627e-09  grad at x: [-2.57723039e-06 -1.02306822e-05]  gradient norm: 1.055030682227854e-05\n",
            "iter: 934678  x: [ 3.99995779 15.99966231]  f(x): 1.7817561855494604e-09  grad at x: [ 8.05224952e-05 -2.06176283e-05]  gradient norm: 8.312014692281573e-05\n",
            "iter: 934679  x: [ 3.99995779 15.99966231]  f(x): 1.7817034488719918e-09  grad at x: [-2.57794276e-06 -1.02302711e-05]  gradient norm: 1.0550082232255638e-05\n",
            "iter: 934680  x: [ 3.99995779 15.99966232]  f(x): 1.781647501623766e-09  grad at x: [ 8.05706345e-05 -2.06233235e-05]  gradient norm: 8.316819473109446e-05\n",
            "iter: 934681  x: [ 3.99995779 15.99966233]  f(x): 1.7815947050100143e-09  grad at x: [-2.57864066e-06 -1.02298618e-05]  gradient norm: 1.054985592764222e-05\n",
            "iter: 934682  x: [ 3.99995779 15.99966234]  f(x): 1.781538823277558e-09  grad at x: [ 8.06178860e-05 -2.06289078e-05]  gradient norm: 8.321535547450298e-05\n",
            "iter: 934683  x: [ 3.99995779 15.99966234]  f(x): 1.7814859677837257e-09  grad at x: [-2.57932408e-06 -1.02294543e-05]  gradient norm: 1.0549627905460921e-05\n",
            "iter: 934684  x: [ 3.9999578  15.99966235]  f(x): 1.7814301504361355e-09  grad at x: [ 8.06642062e-05 -2.06343757e-05]  gradient norm: 8.326158548035719e-05\n",
            "iter: 934685  x: [ 3.99995779 15.99966235]  f(x): 1.7813772371757972e-09  grad at x: [-2.58003669e-06 -1.02290433e-05]  gradient norm: 1.0549403547773845e-05\n",
            "iter: 934686  x: [ 3.9999578  15.99966236]  f(x): 1.7813214866123608e-09  grad at x: [ 8.07124035e-05 -2.06400782e-05]  gradient norm: 8.330969271300315e-05\n",
            "iter: 934687  x: [ 3.9999578  15.99966236]  f(x): 1.781268513222267e-09  grad at x: [-2.58074937e-06 -1.02286322e-05]  gradient norm: 1.0549179269027591e-05\n",
            "iter: 934688  x: [ 3.9999578  15.99966237]  f(x): 1.7812128294412886e-09  grad at x: [ 8.07605861e-05 -2.06457789e-05]  gradient norm: 8.335778581503591e-05\n",
            "iter: 934689  x: [ 3.9999578  15.99966237]  f(x): 1.7811597959046604e-09  grad at x: [-2.58147669e-06 -1.02282193e-05]  gradient norm: 1.0548956866171392e-05\n",
            "iter: 934690  x: [ 3.9999578  15.99966238]  f(x): 1.7811041800709762e-09  grad at x: [ 8.08096855e-05 -2.06515942e-05]  gradient norm: 8.340679594827878e-05\n",
            "iter: 934691  x: [ 3.9999578  15.99966238]  f(x): 1.7810510852215282e-09  grad at x: [-2.58218953e-06 -1.02278082e-05]  gradient norm: 1.0548732745593144e-05\n",
            "iter: 934692  x: [ 3.9999578  15.99966239]  f(x): 1.7809955362768037e-09  grad at x: [ 8.08578971e-05 -2.06572986e-05]  gradient norm: 8.345491899156928e-05\n",
            "iter: 934693  x: [ 3.9999578  15.99966239]  f(x): 1.780942381172566e-09  grad at x: [-2.58288789e-06 -1.02273989e-05]  gradient norm: 1.0548506904036397e-05\n",
            "iter: 934694  x: [ 3.9999578 15.9996624]  f(x): 1.7808868979838737e-09  grad at x: [ 8.09051773e-05 -2.06628865e-05]  gradient norm: 8.350211126635221e-05\n",
            "iter: 934695  x: [ 3.9999578 15.9996624]  f(x): 1.7808336837404501e-09  grad at x: [-2.58361545e-06 -1.02269860e-05]  gradient norm: 1.0548284740382661e-05\n",
            "iter: 934696  x: [ 3.9999578  15.99966241]  f(x): 1.780778268679415e-09  grad at x: [ 8.09543055e-05 -2.06687055e-05]  gradient norm: 8.355115177260714e-05\n",
            "iter: 934697  x: [ 3.9999578  15.99966241]  f(x): 1.7807249929612112e-09  grad at x: [-2.58434308e-06 -1.02265731e-05]  gradient norm: 1.0548062657980846e-05\n",
            "iter: 934698  x: [ 3.9999578  15.99966242]  f(x): 1.7806696460626893e-09  grad at x: [ 8.10034627e-05 -2.06745281e-05]  gradient norm: 8.36002218106668e-05\n",
            "iter: 934699  x: [ 3.9999578  15.99966242]  f(x): 1.7806163088152314e-09  grad at x: [-2.58505623e-06 -1.02261620e-05]  gradient norm: 1.0547838853333151e-05\n",
            "iter: 934700  x: [ 3.99995781 15.99966243]  f(x): 1.78056102894636e-09  grad at x: [ 8.10516740e-05 -2.06802324e-05]  gradient norm: 8.364834652058039e-05\n",
            "iter: 934701  x: [ 3.9999578  15.99966243]  f(x): 1.7805076313022063e-09  grad at x: [-2.58575491e-06 -1.02257527e-05]  gradient norm: 1.0547613323398978e-05\n",
            "iter: 934702  x: [ 3.99995781 15.99966244]  f(x): 1.7804524173273063e-09  grad at x: [ 8.10989539e-05 -2.06858203e-05]  gradient norm: 8.369554042243515e-05\n",
            "iter: 934703  x: [ 3.99995781 15.99966244]  f(x): 1.7803989604229797e-09  grad at x: [-2.58646823e-06 -1.02253416e-05]  gradient norm: 1.0547389675420526e-05\n",
            "iter: 934704  x: [ 3.99995781 15.99966245]  f(x): 1.7803438135830857e-09  grad at x: [ 8.11471941e-05 -2.06915283e-05]  gradient norm: 8.374369504656056e-05\n",
            "iter: 934705  x: [ 3.99995781 15.99966245]  f(x): 1.7802902961761005e-09  grad at x: [-2.58716707e-06 -1.02249323e-05]  gradient norm: 1.0547164299812944e-05\n",
            "iter: 934706  x: [ 3.99995781 15.99966246]  f(x): 1.7802352153342194e-09  grad at x: [ 8.11945029e-05 -2.06971199e-05]  gradient norm: 8.379091884549819e-05\n",
            "iter: 934707  x: [ 3.99995781 15.99966246]  f(x): 1.7801816385442506e-09  grad at x: [-2.58789509e-06 -1.02245194e-05]  gradient norm: 1.0546942615351173e-05\n",
            "iter: 934708  x: [ 3.99995781 15.99966247]  f(x): 1.7801266260434206e-09  grad at x: [ 8.12436453e-05 -2.07029407e-05]  gradient norm: 8.383997642781991e-05\n",
            "iter: 934709  x: [ 3.99995781 15.99966247]  f(x): 1.7800729875623034e-09  grad at x: [-2.58859409e-06 -1.02241102e-05]  gradient norm: 1.0546717395444453e-05\n",
            "iter: 934710  x: [ 3.99995781 15.99966248]  f(x): 1.780018041164284e-09  grad at x: [ 8.12909830e-05 -2.07085359e-05]  gradient norm: 8.38872301304478e-05\n",
            "iter: 934711  x: [ 3.99995781 15.99966248]  f(x): 1.7799643432129412e-09  grad at x: [-2.58930771e-06 -1.02236991e-05]  gradient norm: 1.0546494061494895e-05\n",
            "iter: 934712  x: [ 3.99995781 15.99966249]  f(x): 1.779909464089417e-09  grad at x: [ 8.13392229e-05 -2.07142439e-05]  gradient norm: 8.393538638522753e-05\n",
            "iter: 934713  x: [ 3.99995781 15.99966249]  f(x): 1.7798557054947108e-09  grad at x: [-2.59000687e-06 -1.02232898e-05]  gradient norm: 1.0546268995862501e-05\n",
            "iter: 934714  x: [ 3.99995781 15.9996625 ]  f(x): 1.779800892505962e-09  grad at x: [ 8.13865314e-05 -2.07198354e-05]  gradient norm: 8.39826117760249e-05\n",
            "iter: 934715  x: [ 3.99995781 15.9996625 ]  f(x): 1.7797470744084586e-09  grad at x: [-2.59072065e-06 -1.02228787e-05]  gradient norm: 1.0546045818832718e-05\n",
            "iter: 934716  x: [ 3.99995782 15.99966251]  f(x): 1.7796923287997712e-09  grad at x: [ 8.14348003e-05 -2.07255471e-05]  gradient norm: 8.403079793956283e-05\n",
            "iter: 934717  x: [ 3.99995781 15.99966251]  f(x): 1.7796384499527308e-09  grad at x: [-2.59141996e-06 -1.02224694e-05]  gradient norm: 1.0545820907775389e-05\n",
            "iter: 934718  x: [ 3.99995782 15.99966252]  f(x): 1.7795837705462449e-09  grad at x: [ 8.14821232e-05 -2.07311405e-05]  gradient norm: 8.407803866932466e-05\n",
            "iter: 934719  x: [ 3.99995782 15.99966252]  f(x): 1.7795298321272232e-09  grad at x: [-2.5921048e-06 -1.0222062e-05]  gradient norm: 1.0545594259924833e-05\n",
            "iter: 934720  x: [ 3.99995782 15.99966253]  f(x): 1.7794752178167043e-09  grad at x: [ 8.15285292e-05 -2.07366193e-05]  gradient norm: 8.412436304058124e-05\n",
            "iter: 934721  x: [ 3.99995782 15.99966253]  f(x): 1.779421220914626e-09  grad at x: [-2.59281882e-06 -1.02216509e-05]  gradient norm: 1.0545371316134527e-05\n",
            "iter: 934722  x: [ 3.99995782 15.99966254]  f(x): 1.7793666741242062e-09  grad at x: [ 8.15768124e-05 -2.07423327e-05]  gradient norm: 8.417256494608524e-05\n",
            "iter: 934723  x: [ 3.99995782 15.99966254]  f(x): 1.779312616350951e-09  grad at x: [-2.59353292e-06 -1.02212398e-05]  gradient norm: 1.054514845166351e-05\n",
            "iter: 934724  x: [ 3.99995782 15.99966255]  f(x): 1.7792581370788784e-09  grad at x: [ 8.16250810e-05 -2.07480443e-05]  gradient norm: 8.422075270672498e-05\n",
            "iter: 934725  x: [ 3.99995782 15.99966255]  f(x): 1.7792040184165854e-09  grad at x: [-2.59423255e-06 -1.02208305e-05]  gradient norm: 1.0544923848929784e-05\n",
            "iter: 934726  x: [ 3.99995782 15.99966256]  f(x): 1.779149605555395e-09  grad at x: [ 8.16724472e-05 -2.07536432e-05]  gradient norm: 8.426803864829775e-05\n",
            "iter: 934727  x: [ 3.99995782 15.99966256]  f(x): 1.7790954271123775e-09  grad at x: [-2.59494680e-06 -1.02204194e-05]  gradient norm: 1.0544701141191685e-05\n",
            "iter: 934728  x: [ 3.99995782 15.99966257]  f(x): 1.7790410818390404e-09  grad at x: [ 8.17207156e-05 -2.07593548e-05]  gradient norm: 8.431622720558881e-05\n",
            "iter: 934729  x: [ 3.99995782 15.99966257]  f(x): 1.7789868424368719e-09  grad at x: [-2.59564659e-06 -1.02200102e-05]  gradient norm: 1.0544476693499635e-05\n",
            "iter: 934730  x: [ 3.99995782 15.99966258]  f(x): 1.7789461277320613e-09  grad at x: [ 3.95862321e-05 -1.54924837e-05]  gradient norm: 4.25098438338622e-05\n",
            "iter: 934731  x: [ 3.99995782 15.99966258]  f(x): 1.778931708033241e-09  grad at x: [-1.93692945e-06 -1.03021848e-05]  gradient norm: 1.0482686093005424e-05\n",
            "iter: 934732  x: [ 3.99995783 15.99966262]  f(x): 1.7787132090954178e-09  grad at x: [ 1.64255263e-04 -3.10745363e-05]  gradient norm: 0.0001671688315025562\n",
            "iter: 934733  x: [ 3.99995783 15.99966262]  f(x): 1.778553925451851e-09  grad at x: [ 8.01847257e-05 -2.05659217e-05]  gradient norm: 8.27801145523738e-05\n",
            "iter: 934734  x: [ 3.99995783 15.99966262]  f(x): 1.7785016139609756e-09  grad at x: [-2.57146627e-06 -1.02215945e-05]  gradient norm: 1.0540086942216387e-05\n",
            "iter: 934735  x: [ 3.99995783 15.99966263]  f(x): 1.7784454356413876e-09  grad at x: [ 8.02320186e-05 -2.05715114e-05]  gradient norm: 8.282731371749358e-05\n",
            "iter: 934736  x: [ 3.99995783 15.99966263]  f(x): 1.7783930655171157e-09  grad at x: [-2.57215193e-06 -1.02211870e-05]  gradient norm: 1.0539859109087191e-05\n",
            "iter: 934737  x: [ 3.99995783 15.99966264]  f(x): 1.7783369514761348e-09  grad at x: [ 8.02784821e-05 -2.05769975e-05]  gradient norm: 8.287368404540717e-05\n",
            "iter: 934738  x: [ 3.99995783 15.99966264]  f(x): 1.7782845236829866e-09  grad at x: [-2.57286677e-06 -1.02207759e-05]  gradient norm: 1.0539634927149114e-05\n",
            "iter: 934739  x: [ 3.99995783 15.99966265]  f(x): 1.7782284763090138e-09  grad at x: [ 8.03268226e-05 -2.05827182e-05]  gradient norm: 8.292193149179268e-05\n",
            "iter: 934740  x: [ 3.99995783 15.99966265]  f(x): 1.7781759884945973e-09  grad at x: [-2.57358169e-06 -1.02203649e-05]  gradient norm: 1.0539410824264282e-05\n",
            "iter: 934741  x: [ 3.99995783 15.99966266]  f(x): 1.778120007786251e-09  grad at x: [ 8.03751486e-05 -2.05884371e-05]  gradient norm: 8.29701648171573e-05\n",
            "iter: 934742  x: [ 3.99995783 15.99966266]  f(x): 1.7780674599323458e-09  grad at x: [-2.57428214e-06 -1.02199556e-05]  gradient norm: 1.0539185009912098e-05\n",
            "iter: 934743  x: [ 3.99995784 15.99966267]  f(x): 1.7780115447637395e-09  grad at x: [ 8.04225431e-05 -2.05940396e-05]  gradient norm: 8.301746745877336e-05\n",
            "iter: 934744  x: [ 3.99995783 15.99966267]  f(x): 1.7779589379970714e-09  grad at x: [-2.57499722e-06 -1.02195445e-05]  gradient norm: 1.0538961063883769e-05\n",
            "iter: 934745  x: [ 3.99995784 15.99966268]  f(x): 1.7779030895994843e-09  grad at x: [ 8.04708980e-05 -2.05997621e-05]  gradient norm: 8.30657307228771e-05\n",
            "iter: 934746  x: [ 3.99995784 15.99966268]  f(x): 1.7778504226691743e-09  grad at x: [-2.57571238e-06 -1.02191334e-05]  gradient norm: 1.0538737196971804e-05\n",
            "iter: 934747  x: [ 3.99995784 15.99966269]  f(x): 1.7777946410420632e-09  grad at x: [ 8.05192237e-05 -2.06054810e-05]  gradient norm: 8.311396531289822e-05\n",
            "iter: 934748  x: [ 3.99995784 15.99966269]  f(x): 1.7777419139665055e-09  grad at x: [-2.57641306e-06 -1.02187241e-05]  gradient norm: 1.0538511614951928e-05\n",
            "iter: 934749  x: [ 3.99995784 15.9996627 ]  f(x): 1.7776861980177174e-09  grad at x: [ 8.05666471e-05 -2.06110872e-05]  gradient norm: 8.31612982901173e-05\n",
            "iter: 934750  x: [ 3.99995784 15.9996627 ]  f(x): 1.7776334118899047e-09  grad at x: [-2.57712837e-06 -1.02183130e-05]  gradient norm: 1.0538287904804775e-05\n",
            "iter: 934751  x: [ 3.99995784 15.99966271]  f(x): 1.7775777627804474e-09  grad at x: [ 8.06149872e-05 -2.06168079e-05]  gradient norm: 8.320954826598086e-05\n",
            "iter: 934752  x: [ 3.99995784 15.99966271]  f(x): 1.7775249164379248e-09  grad at x: [-2.57782921e-06 -1.02179038e-05]  gradient norm: 1.053806247785225e-05\n",
            "iter: 934753  x: [ 3.99995784 15.99966272]  f(x): 1.7774693330751614e-09  grad at x: [ 8.06624104e-05 -2.06224140e-05]  gradient norm: 8.325688205935824e-05\n",
            "iter: 934754  x: [ 3.99995784 15.99966272]  f(x): 1.7774164276102623e-09  grad at x: [-2.57851558e-06 -1.02174963e-05]  gradient norm: 1.0537835330667261e-05\n",
            "iter: 934755  x: [ 3.99995784 15.99966273]  f(x): 1.777360908898766e-09  grad at x: [ 8.07089313e-05 -2.06279074e-05]  gradient norm: 8.330331419041155e-05\n",
            "iter: 934756  x: [ 3.99995784 15.99966273]  f(x): 1.7773079454077574e-09  grad at x: [-2.57921658e-06 -1.02170870e-05]  gradient norm: 1.053761005627644e-05\n",
            "iter: 934757  x: [ 3.99995784 15.99966274]  f(x): 1.77725249251001e-09  grad at x: [ 8.07563544e-05 -2.06335135e-05]  gradient norm: 8.33506487808959e-05\n",
            "iter: 934758  x: [ 3.99995784 15.99966274]  f(x): 1.7771994698108144e-09  grad at x: [-2.57991766e-06 -1.02166778e-05]  gradient norm: 1.053738485895313e-05\n",
            "iter: 934759  x: [ 3.99995785 15.99966275]  f(x): 1.7771440827965545e-09  grad at x: [ 8.08038065e-05 -2.06391232e-05]  gradient norm: 8.339801287015383e-05\n",
            "iter: 934760  x: [ 3.99995785 15.99966275]  f(x): 1.7770910008384243e-09  grad at x: [-2.58063336e-06 -1.02162667e-05]  gradient norm: 1.0537161538773885e-05\n",
            "iter: 934761  x: [ 3.99995785 15.99966276]  f(x): 1.7770356809086905e-09  grad at x: [ 8.08521898e-05 -2.06448494e-05]  gradient norm: 8.34463085514252e-05\n",
            "iter: 934762  x: [ 3.99995785 15.99966276]  f(x): 1.7769825384891388e-09  grad at x: [-2.58133460e-06 -1.02158574e-05]  gradient norm: 1.0536936496507636e-05\n",
            "iter: 934763  x: [ 3.99995785 15.99966277]  f(x): 1.776927284511356e-09  grad at x: [ 8.08996418e-05 -2.06504592e-05]  gradient norm: 8.349367345154352e-05\n",
            "iter: 934764  x: [ 3.99995785 15.99966277]  f(x): 1.7768740827456534e-09  grad at x: [-2.58206501e-06 -1.02154445e-05]  gradient norm: 1.0536715136070865e-05\n",
            "iter: 934765  x: [ 3.99995785 15.99966278]  f(x): 1.7768188971274322e-09  grad at x: [ 8.09489709e-05 -2.06563036e-05]  gradient norm: 8.354291571674289e-05\n",
            "iter: 934766  x: [ 3.99995785 15.99966278]  f(x): 1.7767656336428127e-09  grad at x: [-2.58276640e-06 -1.02150352e-05]  gradient norm: 1.0536490249804857e-05\n",
            "iter: 934767  x: [ 3.99995785 15.99966279]  f(x): 1.7767105140456893e-09  grad at x: [ 8.09964227e-05 -2.06619134e-05]  gradient norm: 8.359028143166591e-05\n",
            "iter: 934768  x: [ 3.99995785 15.99966279]  f(x): 1.776657191163312e-09  grad at x: [-2.58348242e-06 -1.02146241e-05]  gradient norm: 1.0536267245572443e-05\n",
            "iter: 934769  x: [ 3.99995785 15.9996628 ]  f(x): 1.7766021388270507e-09  grad at x: [ 8.10448348e-05 -2.06676432e-05]  gradient norm: 8.363860787146065e-05\n",
            "iter: 934770  x: [ 3.99995785 15.9996628 ]  f(x): 1.7765487552875577e-09  grad at x: [-2.58419852e-06 -1.02142130e-05]  gradient norm: 1.0536044320272665e-05\n",
            "iter: 934771  x: [ 3.99995785 15.99966281]  f(x): 1.7764937702474573e-09  grad at x: [ 8.10932469e-05 -2.06733730e-05]  gradient norm: 8.36869347269033e-05\n",
            "iter: 934772  x: [ 3.99995785 15.99966281]  f(x): 1.7764403260345389e-09  grad at x: [-2.58492925e-06 -1.02138001e-05]  gradient norm: 1.0535823281441311e-05\n",
            "iter: 934773  x: [ 3.99995786 15.99966282]  f(x): 1.7763854094971628e-09  grad at x: [ 8.11425902e-05 -2.06792192e-05]  gradient norm: 8.373619324179702e-05\n",
            "iter: 934774  x: [ 3.99995785 15.99966282]  f(x): 1.776331903402805e-09  grad at x: [-2.58564551e-06 -1.02133890e-05]  gradient norm: 1.0535600515821709e-05\n",
            "iter: 934775  x: [ 3.99995786 15.99966283]  f(x): 1.776277054196128e-09  grad at x: [ 8.11909876e-05 -2.06849472e-05]  gradient norm: 8.37845063826613e-05\n",
            "iter: 934776  x: [ 3.99995786 15.99966283]  f(x): 1.7762234873920519e-09  grad at x: [-2.58634729e-06 -1.02129798e-05]  gradient norm: 1.0535376020357217e-05\n",
            "iter: 934777  x: [ 3.99995786 15.99966284]  f(x): 1.7761687044154652e-09  grad at x: [ 8.12384681e-05 -2.06905606e-05]  gradient norm: 8.383190322617491e-05\n",
            "iter: 934778  x: [ 3.99995786 15.99966284]  f(x): 1.7761150779849835e-09  grad at x: [-2.58707826e-06 -1.02125668e-05]  gradient norm: 1.0535155222680217e-05\n",
            "iter: 934779  x: [ 3.99995786 15.99966285]  f(x): 1.7760603636190654e-09  grad at x: [ 8.12878112e-05 -2.06964069e-05]  gradient norm: 8.388116300528607e-05\n",
            "iter: 934780  x: [ 3.99995786 15.99966286]  f(x): 1.7760066751982906e-09  grad at x: [-2.58779475e-06 -1.02121558e-05]  gradient norm: 1.0534932694982351e-05\n",
            "iter: 934781  x: [ 3.99995786 15.99966287]  f(x): 1.7759520283418193e-09  grad at x: [ 8.13362520e-05 -2.07021403e-05]  gradient norm: 8.392952103514794e-05\n",
            "iter: 934782  x: [ 3.99995786 15.99966287]  f(x): 1.77589827903167e-09  grad at x: [-2.58849677e-06 -1.02117465e-05]  gradient norm: 1.0534708434424143e-05\n",
            "iter: 934783  x: [ 3.99995786 15.99966288]  f(x): 1.775843698545282e-09  grad at x: [ 8.13837614e-05 -2.07077574e-05]  gradient norm: 8.397694818853956e-05\n",
            "iter: 934784  x: [ 3.99995786 15.99966288]  f(x): 1.7757898894859664e-09  grad at x: [-2.58921342e-06 -1.02113354e-05]  gradient norm: 1.0534486064419518e-05\n",
            "iter: 934785  x: [ 3.99995786 15.99966289]  f(x): 1.7757353765790167e-09  grad at x: [ 8.14322020e-05 -2.07134908e-05]  gradient norm: 8.402530703084873e-05\n",
            "iter: 934786  x: [ 3.99995786 15.99966289]  f(x): 1.7756815065415898e-09  grad at x: [-2.58993015e-06 -1.02109243e-05]  gradient norm: 1.0534263773951736e-05\n",
            "iter: 934787  x: [ 3.99995786 15.9996629 ]  f(x): 1.7756270612494192e-09  grad at x: [ 8.14806425e-05 -2.07192243e-05]  gradient norm: 8.407366628257187e-05\n",
            "iter: 934788  x: [ 3.99995786 15.9996629 ]  f(x): 1.7755731302175262e-09  grad at x: [-2.59066150e-06 -1.02105114e-05]  gradient norm: 1.0534043378476656e-05\n",
            "iter: 934789  x: [ 3.99995787 15.99966291]  f(x): 1.7755187537522392e-09  grad at x: [ 8.15300143e-05 -2.07250741e-05]  gradient norm: 8.412295725701883e-05\n",
            "iter: 934790  x: [ 3.99995786 15.99966291]  f(x): 1.7754647605123219e-09  grad at x: [-2.59137839e-06 -1.02101003e-05]  gradient norm: 1.0533821247808635e-05\n",
            "iter: 934791  x: [ 3.99995787 15.99966292]  f(x): 1.77541045173318e-09  grad at x: [ 8.15784547e-05 -2.07308076e-05]  gradient norm: 8.417131733388223e-05\n",
            "iter: 934792  x: [ 3.99995787 15.99966292]  f(x): 1.7753563974256738e-09  grad at x: [-2.5920808e-06 -1.0209691e-05]  gradient norm: 1.0533597378888373e-05\n",
            "iter: 934793  x: [ 3.99995787 15.99966293]  f(x): 1.7753021552261245e-09  grad at x: [ 8.16259928e-05 -2.07364283e-05]  gradient norm: 8.421877558768057e-05\n",
            "iter: 934794  x: [ 3.99995787 15.99966293]  f(x): 1.7752480409402936e-09  grad at x: [-2.59281239e-06 -1.02092781e-05]  gradient norm: 1.053337722507587e-05\n",
            "iter: 934795  x: [ 3.99995787 15.99966293]  f(x): 1.77520740972553e-09  grad at x: [ 3.95412760e-05 -1.54757781e-05]  gradient norm: 4.2461891333248304e-05\n",
            "iter: 934796  x: [ 3.99995787 15.99966293]  f(x): 1.7751930224205523e-09  grad at x: [-1.93482423e-06 -1.02913618e-05]  gradient norm: 1.0471660477936152e-05\n",
            "iter: 934797  x: [ 3.99995788 15.99966297]  f(x): 1.7749749377097803e-09  grad at x: [ 1.64064746e-04 -3.10396372e-05]  gradient norm: 0.00016697514818675893\n",
            "iter: 934798  x: [ 3.99995787 15.99966297]  f(x): 1.7748160229101663e-09  grad at x: [ 8.00916497e-05 -2.05432025e-05]  gradient norm: 8.26843124529562e-05\n",
            "iter: 934799  x: [ 3.99995787 15.99966297]  f(x): 1.774763832251503e-09  grad at x: [-2.56862962e-06 -1.02108643e-05]  gradient norm: 1.0528988905072679e-05\n",
            "iter: 934800  x: [ 3.99995788 15.99966298]  f(x): 1.7747077614459205e-09  grad at x: [ 8.01391583e-05 -2.05488195e-05]  gradient norm: 8.27317271294235e-05\n",
            "iter: 934801  x: [ 3.99995787 15.99966298]  f(x): 1.7746555119406333e-09  grad at x: [-2.56934709e-06 -1.02104532e-05]  gradient norm: 1.0528765297146323e-05\n",
            "iter: 934802  x: [ 3.99995788 15.99966299]  f(x): 1.774599507862306e-09  grad at x: [ 8.01876563e-05 -2.05545603e-05]  gradient norm: 8.278013149124384e-05\n",
            "iter: 934803  x: [ 3.99995788 15.99966299]  f(x): 1.7745471982460625e-09  grad at x: [-2.57005009e-06 -1.02100439e-05]  gradient norm: 1.0528539980278468e-05\n",
            "iter: 934804  x: [ 3.99995788 15.999663  ]  f(x): 1.7744912597720379e-09  grad at x: [ 8.02352229e-05 -2.05601846e-05]  gradient norm: 8.28276051963433e-05\n",
            "iter: 934805  x: [ 3.99995788 15.999663  ]  f(x): 1.7744388911493502e-09  grad at x: [-2.57075316e-06 -1.02096346e-05]  gradient norm: 1.052831474030688e-05\n",
            "iter: 934806  x: [ 3.99995788 15.99966301]  f(x): 1.774383018313692e-09  grad at x: [ 8.02827894e-05 -2.05658089e-05]  gradient norm: 8.287507931222947e-05\n",
            "iter: 934807  x: [ 3.99995788 15.99966301]  f(x): 1.7743305906694726e-09  grad at x: [-2.57147087e-06 -1.02092235e-05]  gradient norm: 1.0528091368279599e-05\n",
            "iter: 934808  x: [ 3.99995788 15.99966302]  f(x): 1.7742747846659706e-09  grad at x: [ 8.03312872e-05 -2.05715496e-05]  gradient norm: 8.292348494810845e-05\n",
            "iter: 934809  x: [ 3.99995788 15.99966302]  f(x): 1.7742222968049847e-09  grad at x: [-2.57217410e-06 -1.02088143e-05]  gradient norm: 1.0527866283894005e-05\n",
            "iter: 934810  x: [ 3.99995788 15.99966303]  f(x): 1.774166556544344e-09  grad at x: [ 8.03788827e-05 -2.05771776e-05]  gradient norm: 8.297098899236305e-05\n",
            "iter: 934811  x: [ 3.99995788 15.99966303]  f(x): 1.7741140095374494e-09  grad at x: [-2.57287741e-06 -1.02084050e-05]  gradient norm: 1.0527641276900584e-05\n",
            "iter: 934812  x: [ 3.99995788 15.99966304]  f(x): 1.7740583350180572e-09  grad at x: [ 8.04264489e-05 -2.05828019e-05]  gradient norm: 8.301846435003906e-05\n",
            "iter: 934813  x: [ 3.99995788 15.99966305]  f(x): 1.7740057288858404e-09  grad at x: [-2.57359535e-06 -1.02079939e-05]  gradient norm: 1.0527418140743438e-05\n",
            "iter: 934814  x: [ 3.99995788 15.99966306]  f(x): 1.7739501213392652e-09  grad at x: [ 8.04749756e-05 -2.05885462e-05]  gradient norm: 8.306690034985274e-05\n",
            "iter: 934815  x: [ 3.99995788 15.99966306]  f(x): 1.7738974548487128e-09  grad at x: [-2.57429882e-06 -1.02075846e-05]  gradient norm: 1.052719328946097e-05\n",
            "iter: 934816  x: [ 3.99995789 15.99966307]  f(x): 1.773841913147965e-09  grad at x: [ 8.05225708e-05 -2.05941742e-05]  gradient norm: 8.311440563019927e-05\n",
            "iter: 934817  x: [ 3.99995788 15.99966307]  f(x): 1.773789187407631e-09  grad at x: [-2.57500237e-06 -1.02071754e-05]  gradient norm: 1.0526968515415854e-05\n",
            "iter: 934818  x: [ 3.99995789 15.99966308]  f(x): 1.7737337115868153e-09  grad at x: [ 8.05701660e-05 -2.05998022e-05]  gradient norm: 8.316191132027436e-05\n",
            "iter: 934819  x: [ 3.99995789 15.99966308]  f(x): 1.7736809265815682e-09  grad at x: [-2.57572055e-06 -1.02067643e-05]  gradient norm: 1.0526745615534015e-05\n",
            "iter: 934820  x: [ 3.99995789 15.99966309]  f(x): 1.7736255178385962e-09  grad at x: [ 8.06186924e-05 -2.06055465e-05]  gradient norm: 8.321034857856296e-05\n",
            "iter: 934821  x: [ 3.99995789 15.99966309]  f(x): 1.773572672369078e-09  grad at x: [-2.57642425e-06 -1.02063550e-05]  gradient norm: 1.0526520997324717e-05\n",
            "iter: 934822  x: [ 3.99995789 15.9996631 ]  f(x): 1.7735173296107435e-09  grad at x: [ 8.06663165e-05 -2.06111781e-05]  gradient norm: 8.325788418964524e-05\n",
            "iter: 934823  x: [ 3.99995789 15.9996631 ]  f(x): 1.7734644247528715e-09  grad at x: [-2.57715714e-06 -1.02059421e-05]  gradient norm: 1.0526300054613646e-05\n",
            "iter: 934824  x: [ 3.99995789 15.99966311]  f(x): 1.7734091503078358e-09  grad at x: [ 8.07157741e-05 -2.06170389e-05]  gradient norm: 8.33072534663802e-05\n",
            "iter: 934825  x: [ 3.99995789 15.99966311]  f(x): 1.7733561837496324e-09  grad at x: [-2.57787555e-06 -1.02055310e-05]  gradient norm: 1.0526077393617467e-05\n",
            "iter: 934826  x: [ 3.99995789 15.99966312]  f(x): 1.7733009765247323e-09  grad at x: [ 8.07643294e-05 -2.06227869e-05]  gradient norm: 8.335572109472567e-05\n",
            "iter: 934827  x: [ 3.99995789 15.99966312]  f(x): 1.7732479493590575e-09  grad at x: [-2.57857949e-06 -1.02051217e-05]  gradient norm: 1.0525853010615434e-05\n",
            "iter: 934828  x: [ 3.99995789 15.99966313]  f(x): 1.773192808223238e-09  grad at x: [ 8.08119532e-05 -2.06284185e-05]  gradient norm: 8.340325794625611e-05\n",
            "iter: 934829  x: [ 3.99995789 15.99966313]  f(x): 1.773139721563861e-09  grad at x: [-2.57931261e-06 -1.02047088e-05]  gradient norm: 1.0525632310223727e-05\n",
            "iter: 934830  x: [ 3.99995789 15.99966314]  f(x): 1.7730846488857634e-09  grad at x: [ 8.08614397e-05 -2.06342829e-05]  gradient norm: 8.345265761594995e-05\n",
            "iter: 934831  x: [ 3.99995789 15.99966314]  f(x): 1.7730315003807234e-09  grad at x: [-2.58003126e-06 -1.02042977e-05]  gradient norm: 1.0525409887868269e-05\n",
            "iter: 934832  x: [ 3.9999579  15.99966315]  f(x): 1.7729764950652244e-09  grad at x: [ 8.09100239e-05 -2.06400346e-05]  gradient norm: 8.350115560875923e-05\n",
            "iter: 934833  x: [ 3.99995789 15.99966315]  f(x): 1.7729232857912158e-09  grad at x: [-2.58074998e-06 -1.02038866e-05]  gradient norm: 1.0525187545319601e-05\n",
            "iter: 934834  x: [ 3.9999579  15.99966316]  f(x): 1.7728683478379157e-09  grad at x: [ 8.09585788e-05 -2.06457826e-05]  gradient norm: 8.354962491994227e-05\n",
            "iter: 934835  x: [ 3.9999579  15.99966316]  f(x): 1.7728150778324329e-09  grad at x: [-2.58146879e-06 -1.02034755e-05]  gradient norm: 1.0524965282381133e-05\n",
            "iter: 934836  x: [ 3.9999579  15.99966317]  f(x): 1.7727602072761307e-09  grad at x: [ 8.10071483e-05 -2.06515324e-05]  gradient norm: 8.359810920200252e-05\n",
            "iter: 934837  x: [ 3.9999579  15.99966317]  f(x): 1.7727068764655285e-09  grad at x: [-2.58215857e-06 -1.02030681e-05]  gradient norm: 1.0524739485437373e-05\n",
            "iter: 934838  x: [ 3.9999579  15.99966318]  f(x): 1.7726520710384405e-09  grad at x: [ 8.10538695e-05 -2.06570512e-05]  gradient norm: 8.364474596416906e-05\n",
            "iter: 934839  x: [ 3.9999579  15.99966318]  f(x): 1.7725986816924938e-09  grad at x: [-2.58287753e-06 -1.02026570e-05]  gradient norm: 1.0524517379575949e-05\n",
            "iter: 934840  x: [ 3.9999579  15.99966319]  f(x): 1.7725439437688056e-09  grad at x: [ 8.11024534e-05 -2.06628029e-05]  gradient norm: 8.36932456146885e-05\n",
            "iter: 934841  x: [ 3.9999579  15.99966319]  f(x): 1.7724904935300045e-09  grad at x: [-2.58358201e-06 -1.02022477e-05]  gradient norm: 1.0524293544610898e-05\n",
            "iter: 934842  x: [ 3.9999579 15.9996632]  f(x): 1.7724358219739027e-09  grad at x: [ 8.11501058e-05 -2.06684381e-05]  gradient norm: 8.374081442008086e-05\n",
            "iter: 934843  x: [ 3.9999579 15.9996632]  f(x): 1.772382311959635e-09  grad at x: [-2.58428658e-06 -1.02018384e-05]  gradient norm: 1.0524069787153168e-05\n",
            "iter: 934844  x: [ 3.9999579  15.99966321]  f(x): 1.7723277068053064e-09  grad at x: [ 8.11977581e-05 -2.06740733e-05]  gradient norm: 8.378838362203331e-05\n",
            "iter: 934845  x: [ 3.9999579  15.99966321]  f(x): 1.7722741370003527e-09  grad at x: [-2.58500578e-06 -1.02014274e-05]  gradient norm: 1.0523847918385142e-05\n",
            "iter: 934846  x: [ 3.9999579  15.99966322]  f(x): 1.7722195994907828e-09  grad at x: [ 8.12463708e-05 -2.06798286e-05]  gradient norm: 8.383691360468904e-05\n",
            "iter: 934847  x: [ 3.9999579  15.99966322]  f(x): 1.7721659686507075e-09  grad at x: [-2.58571050e-06 -1.02010181e-05]  gradient norm: 1.0523624317305909e-05\n",
            "iter: 934848  x: [ 3.99995791 15.99966323]  f(x): 1.7721114976480826e-09  grad at x: [ 8.12940521e-05 -2.06854675e-05]  gradient norm: 8.388451271198804e-05\n",
            "iter: 934849  x: [ 3.9999579  15.99966323]  f(x): 1.7720578068922762e-09  grad at x: [-2.58641530e-06 -1.02006088e-05]  gradient norm: 1.0523400793796195e-05\n",
            "iter: 934850  x: [ 3.99995791 15.99966324]  f(x): 1.7720034024314556e-09  grad at x: [ 8.13417188e-05 -2.06911045e-05]  gradient norm: 8.393209766617003e-05\n",
            "iter: 934851  x: [ 3.99995791 15.99966324]  f(x): 1.7719496517440249e-09  grad at x: [-2.58713473e-06 -1.02001977e-05]  gradient norm: 1.052317916231006e-05\n",
            "iter: 934852  x: [ 3.99995791 15.99966325]  f(x): 1.7718953150333564e-09  grad at x: [ 8.13903312e-05 -2.06968598e-05]  gradient norm: 8.398062886962614e-05\n",
            "iter: 934853  x: [ 3.99995791 15.99966325]  f(x): 1.7718415031863841e-09  grad at x: [-2.58785424e-06 -1.01997866e-05]  gradient norm: 1.0522957610841547e-05\n",
            "iter: 934854  x: [ 3.99995791 15.99966326]  f(x): 1.7717872342976303e-09  grad at x: [ 8.14389727e-05 -2.07026187e-05]  gradient norm: 8.402918959019659e-05\n",
            "iter: 934855  x: [ 3.99995791 15.99966326]  f(x): 1.7717333612564372e-09  grad at x: [-2.58857383e-06 -1.01993755e-05]  gradient norm: 1.0522736139193434e-05\n",
            "iter: 934856  x: [ 3.99995791 15.99966327]  f(x): 1.77167916015226e-09  grad at x: [ 8.14875705e-05 -2.07083722e-05]  gradient norm: 8.407770706794189e-05\n",
            "iter: 934857  x: [ 3.99995791 15.99966327]  f(x): 1.771625225898379e-09  grad at x: [-2.58930805e-06 -1.01989626e-05]  gradient norm: 1.0522516565372078e-05\n",
            "iter: 934858  x: [ 3.99995791 15.99966328]  f(x): 1.7715710938642067e-09  grad at x: [ 8.15371432e-05 -2.07142475e-05]  gradient norm: 8.412719994256002e-05\n",
            "iter: 934859  x: [ 3.99995791 15.99966328]  f(x): 1.771517097148143e-09  grad at x: [-2.59002780e-06 -1.01985515e-05]  gradient norm: 1.0522295254532739e-05\n",
            "iter: 934860  x: [ 3.99995791 15.99966329]  f(x): 1.7714630330072243e-09  grad at x: [ 8.15857554e-05 -2.07200028e-05]  gradient norm: 8.41757327997427e-05\n",
            "iter: 934861  x: [ 3.99995791 15.99966329]  f(x): 1.7714224892608628e-09  grad at x: [ 3.94974966e-05 -1.54590707e-05]  gradient norm: 4.241503393186542e-05\n",
            "iter: 934862  x: [ 3.99995791 15.99966329]  f(x): 1.771408133621473e-09  grad at x: [-1.93275017e-06 -1.02803860e-05]  gradient norm: 1.0460490454330313e-05\n",
            "iter: 934863  x: [ 3.99995792 15.99966333]  f(x): 1.7711905071572025e-09  grad at x: [ 1.63887077e-04 -3.10061951e-05]  gradient norm: 0.00016679435921592136\n",
            "iter: 934864  x: [ 3.99995792 15.99966333]  f(x): 1.7710319362590833e-09  grad at x: [ 8.00048873e-05 -2.05211236e-05]  gradient norm: 8.259478494996747e-05\n",
            "iter: 934865  x: [ 3.99995792 15.99966333]  f(x): 1.7709798585238369e-09  grad at x: [-2.56588247e-06 -1.01999740e-05]  gradient norm: 1.0517757468989551e-05\n",
            "iter: 934866  x: [ 3.99995792 15.99966334]  f(x): 1.7709239067135948e-09  grad at x: [ 8.00532226e-05 -2.05268443e-05]  gradient norm: 8.264302619282588e-05\n",
            "iter: 934867  x: [ 3.99995792 15.99966334]  f(x): 1.770871769185009e-09  grad at x: [-2.56658814e-06 -1.01995647e-05]  gradient norm: 1.0517532742730131e-05\n",
            "iter: 934868  x: [ 3.99995792 15.99966335]  f(x): 1.7708158830441669e-09  grad at x: [ 8.01009466e-05 -2.05324886e-05]  gradient norm: 8.269065684242553e-05\n",
            "iter: 934869  x: [ 3.99995792 15.99966335]  f(x): 1.7707636864156644e-09  grad at x: [-2.56730843e-06 -1.01991536e-05]  gradient norm: 1.0517309882215556e-05\n",
            "iter: 934870  x: [ 3.99995792 15.99966336]  f(x): 1.7707078671721288e-09  grad at x: [ 8.01496164e-05 -2.05382512e-05]  gradient norm: 8.273923354866314e-05\n",
            "iter: 934871  x: [ 3.99995792 15.99966336]  f(x): 1.770655610251737e-09  grad at x: [-2.56801425e-06 -1.01987443e-05]  gradient norm: 1.0517085311946112e-05\n",
            "iter: 934872  x: [ 3.99995792 15.99966337]  f(x): 1.770599856783369e-09  grad at x: [ 8.01973548e-05 -2.05438973e-05]  gradient norm: 8.278687958865876e-05\n",
            "iter: 934873  x: [ 3.99995792 15.99966337]  f(x): 1.7705475406748076e-09  grad at x: [-2.56872014e-06 -1.01983351e-05]  gradient norm: 1.051686081948531e-05\n",
            "iter: 934874  x: [ 3.99995793 15.99966338]  f(x): 1.7704918530159211e-09  grad at x: [ 8.02450931e-05 -2.05495435e-05]  gradient norm: 8.28345260458646e-05\n",
            "iter: 934875  x: [ 3.99995792 15.99966338]  f(x): 1.7704394777026904e-09  grad at x: [-2.56941157e-06 -1.01979276e-05]  gradient norm: 1.0516634613185351e-05\n",
            "iter: 934876  x: [ 3.99995793 15.99966339]  f(x): 1.7703838547640932e-09  grad at x: [ 8.02919291e-05 -2.05550768e-05]  gradient norm: 8.288127089892377e-05\n",
            "iter: 934877  x: [ 3.99995793 15.99966339]  f(x): 1.7703314213181087e-09  grad at x: [-2.57013217e-06 -1.01975165e-05]  gradient norm: 1.0516412067639109e-05\n",
            "iter: 934878  x: [ 3.99995793 15.9996634 ]  f(x): 1.7702758654533249e-09  grad at x: [ 8.03406132e-05 -2.05608412e-05]  gradient norm: 8.292986384728623e-05\n",
            "iter: 934879  x: [ 3.99995793 15.9996634 ]  f(x): 1.7702233715558486e-09  grad at x: [-2.57082375e-06 -1.01971091e-05]  gradient norm: 1.05161860144543e-05\n",
            "iter: 934880  x: [ 3.99995793 15.99966341]  f(x): 1.7701678804421617e-09  grad at x: [ 8.03874345e-05 -2.05663728e-05]  gradient norm: 8.297659496122735e-05\n",
            "iter: 934881  x: [ 3.99995793 15.99966341]  f(x): 1.7701153283612654e-09  grad at x: [-2.57152996e-06 -1.01966998e-05]  gradient norm: 1.0515961831698912e-05\n",
            "iter: 934882  x: [ 3.99995793 15.99966342]  f(x): 1.7700599032293954e-09  grad at x: [ 8.04352016e-05 -2.05720225e-05]  gradient norm: 8.302427215936671e-05\n",
            "iter: 934883  x: [ 3.99995793 15.99966343]  f(x): 1.7700072917702851e-09  grad at x: [-2.57222170e-06 -1.01962924e-05]  gradient norm: 1.0515735930862518e-05\n",
            "iter: 934884  x: [ 3.99995793 15.99966343]  f(x): 1.7699519314927247e-09  grad at x: [ 8.04820373e-05 -2.05775559e-05]  gradient norm: 8.307101861766781e-05\n",
            "iter: 934885  x: [ 3.99995793 15.99966344]  f(x): 1.7698992617656349e-09  grad at x: [-2.57294262e-06 -1.01958813e-05]  gradient norm: 1.0515513699512314e-05\n",
            "iter: 934886  x: [ 3.99995793 15.99966345]  f(x): 1.7698439687362244e-09  grad at x: [ 8.05307647e-05 -2.05833257e-05]  gradient norm: 8.311965689024955e-05\n",
            "iter: 934887  x: [ 3.99995793 15.99966345]  f(x): 1.7697912383639828e-09  grad at x: [-2.57364906e-06 -1.01954720e-05]  gradient norm: 1.051528974990528e-05\n",
            "iter: 934888  x: [ 3.99995793 15.99966346]  f(x): 1.7697360114194727e-09  grad at x: [ 8.05785316e-05 -2.05889755e-05]  gradient norm: 8.316733532335315e-05\n",
            "iter: 934889  x: [ 3.99995793 15.99966346]  f(x): 1.7696832215650262e-09  grad at x: [-2.57434103e-06 -1.01950645e-05]  gradient norm: 1.0515064079236732e-05\n",
            "iter: 934890  x: [ 3.99995794 15.99966347]  f(x): 1.7696280595750962e-09  grad at x: [ 8.06253816e-05 -2.05945107e-05]  gradient norm: 8.32140975347579e-05\n",
            "iter: 934891  x: [ 3.99995793 15.99966347]  f(x): 1.769575211350352e-09  grad at x: [-2.57503308e-06 -1.01946571e-05]  gradient norm: 1.0514838484192742e-05\n",
            "iter: 934892  x: [ 3.99995794 15.99966348]  f(x): 1.7695201144212218e-09  grad at x: [ 8.06722606e-05 -2.06000495e-05]  gradient norm: 8.326088923619913e-05\n",
            "iter: 934893  x: [ 3.99995794 15.99966348]  f(x): 1.7694672077208027e-09  grad at x: [-2.57575432e-06 -1.01942460e-05]  gradient norm: 1.0514616567371973e-05\n",
            "iter: 934894  x: [ 3.99995794 15.99966349]  f(x): 1.7694121781794083e-09  grad at x: [ 8.07209877e-05 -2.06058194e-05]  gradient norm: 8.330952917143878e-05\n",
            "iter: 934895  x: [ 3.99995794 15.99966349]  f(x): 1.7693592106749349e-09  grad at x: [-2.57647563e-06 -1.01938349e-05]  gradient norm: 1.0514394730565569e-05\n",
            "iter: 934896  x: [ 3.99995794 15.9996635 ]  f(x): 1.7693042485570428e-09  grad at x: [ 8.07697147e-05 -2.06115892e-05]  gradient norm: 8.335816953384135e-05\n",
            "iter: 934897  x: [ 3.99995794 15.9996635 ]  f(x): 1.7692512202305544e-09  grad at x: [-2.57718246e-06 -1.01934256e-05]  gradient norm: 1.0514171170171537e-05\n",
            "iter: 934898  x: [ 3.99995794 15.99966351]  f(x): 1.7691963244053067e-09  grad at x: [ 8.08175103e-05 -2.06172426e-05]  gradient norm: 8.340587910442466e-05\n",
            "iter: 934899  x: [ 3.99995794 15.99966351]  f(x): 1.7691432363885023e-09  grad at x: [-2.57790393e-06 -1.01930145e-05]  gradient norm: 1.0513949492567326e-05\n",
            "iter: 934900  x: [ 3.99995794 15.99966352]  f(x): 1.7690884080568747e-09  grad at x: [ 8.08662517e-05 -2.06230143e-05]  gradient norm: 8.345453485437062e-05\n",
            "iter: 934901  x: [ 3.99995794 15.99966352]  f(x): 1.7690352591280814e-09  grad at x: [-2.57859637e-06 -1.01926071e-05]  gradient norm: 1.051372428364158e-05\n",
            "iter: 934902  x: [ 3.99995794 15.99966353]  f(x): 1.7689804960272422e-09  grad at x: [ 8.09131304e-05 -2.06285531e-05]  gradient norm: 8.350132856230816e-05\n",
            "iter: 934903  x: [ 3.99995794 15.99966353]  f(x): 1.76892728845128e-09  grad at x: [-2.5793180e-06 -1.0192196e-05]  gradient norm: 1.0513502763780224e-05\n",
            "iter: 934904  x: [ 3.99995794 15.99966354]  f(x): 1.7688725929509074e-09  grad at x: [ 8.09618862e-05 -2.06343266e-05]  gradient norm: 8.354999968986654e-05\n",
            "iter: 934905  x: [ 3.99995794 15.99966354]  f(x): 1.7688193243566527e-09  grad at x: [-2.58003970e-06 -1.01917849e-05]  gradient norm: 1.0513281324256546e-05\n",
            "iter: 934906  x: [ 3.99995795 15.99966355]  f(x): 1.7687646964925555e-09  grad at x: [ 8.10106419e-05 -2.06401000e-05]  gradient norm: 8.359867124081423e-05\n",
            "iter: 934907  x: [ 3.99995794 15.99966355]  f(x): 1.768711366862002e-09  grad at x: [-2.58074693e-06 -1.01913756e-05]  gradient norm: 1.051305815598897e-05\n",
            "iter: 934908  x: [ 3.99995795 15.99966356]  f(x): 1.7686568055359426e-09  grad at x: [ 8.10584953e-05 -2.06457607e-05]  gradient norm: 8.364644105273718e-05\n",
            "iter: 934909  x: [ 3.99995795 15.99966356]  f(x): 1.7686034159681707e-09  grad at x: [-2.58146879e-06 -1.01909645e-05]  gradient norm: 1.0512836875660056e-05\n",
            "iter: 934910  x: [ 3.99995795 15.99966357]  f(x): 1.7685489223126475e-09  grad at x: [ 8.11072363e-05 -2.06515324e-05]  gradient norm: 8.36950988831625e-05\n",
            "iter: 934911  x: [ 3.99995795 15.99966357]  f(x): 1.7684954716544619e-09  grad at x: [-2.58216162e-06 -1.01905571e-05]  gradient norm: 1.0512612053371064e-05\n",
            "iter: 934912  x: [ 3.99995795 15.99966358]  f(x): 1.7684410434358353e-09  grad at x: [ 8.11541437e-05 -2.06570749e-05]  gradient norm: 8.374192367992555e-05\n",
            "iter: 934913  x: [ 3.99995795 15.99966358]  f(x): 1.7683875339228671e-09  grad at x: [-2.58288364e-06 -1.01901460e-05]  gradient norm: 1.051239093143054e-05\n",
            "iter: 934914  x: [ 3.99995795 15.99966359]  f(x): 1.7683331735177565e-09  grad at x: [ 8.12029282e-05 -2.06628520e-05]  gradient norm: 8.379062598263095e-05\n",
            "iter: 934915  x: [ 3.99995795 15.99966359]  f(x): 1.7682796027719394e-09  grad at x: [-2.58360573e-06 -1.01897349e-05]  gradient norm: 1.051216988971538e-05\n",
            "iter: 934916  x: [ 3.99995795 15.9996636 ]  f(x): 1.768225310216196e-09  grad at x: [ 8.12517127e-05 -2.06686291e-05]  gradient norm: 8.383932870326795e-05\n",
            "iter: 934917  x: [ 3.99995795 15.9996636 ]  f(x): 1.768171678238725e-09  grad at x: [-2.58432790e-06 -1.01893238e-05]  gradient norm: 1.0511948928246754e-05\n",
            "iter: 934918  x: [ 3.99995795 15.99966361]  f(x): 1.768117453531473e-09  grad at x: [ 8.13004825e-05 -2.06744044e-05]  gradient norm: 8.38880172896181e-05\n",
            "iter: 934919  x: [ 3.99995795 15.99966361]  f(x): 1.7680637602663267e-09  grad at x: [-2.58503560e-06 -1.01889145e-05]  gradient norm: 1.0511726231568825e-05\n",
            "iter: 934920  x: [ 3.99995795 15.99966362]  f(x): 1.7680096023059747e-09  grad at x: [ 8.13483354e-05 -2.06800651e-05]  gradient norm: 8.393578953065623e-05\n",
            "iter: 934921  x: [ 3.99995795 15.99966362]  f(x): 1.7679558488929377e-09  grad at x: [-2.58575793e-06 -1.01885034e-05]  gradient norm: 1.0511505429766013e-05\n",
            "iter: 934922  x: [ 3.99995796 15.99966363]  f(x): 1.7679017589616956e-09  grad at x: [ 8.13971633e-05 -2.06858476e-05]  gradient norm: 8.398453714747056e-05\n",
            "iter: 934923  x: [ 3.99995795 15.99966363]  f(x): 1.76784794409901e-09  grad at x: [-2.58648034e-06 -1.01880923e-05]  gradient norm: 1.0511284708054687e-05\n",
            "iter: 934924  x: [ 3.99995796 15.99966364]  f(x): 1.767793922159867e-09  grad at x: [ 8.14459474e-05 -2.06916247e-05]  gradient norm: 8.403324152086974e-05\n",
            "iter: 934925  x: [ 3.99995796 15.99966364]  f(x): 1.7677400459023397e-09  grad at x: [-2.58718827e-06 -1.01876831e-05]  gradient norm: 1.0511062248108016e-05\n",
            "iter: 934926  x: [ 3.99995796 15.99966365]  f(x): 1.7676860908143472e-09  grad at x: [ 8.14938146e-05 -2.06972873e-05]  gradient norm: 8.408102952226996e-05\n",
            "iter: 934927  x: [ 3.99995796 15.99966365]  f(x): 1.7676456382157046e-09  grad at x: [ 3.94529519e-05 -1.54422796e-05]  gradient norm: 4.236743340563337e-05\n",
            "iter: 934928  x: [ 3.99995796 15.99966365]  f(x): 1.767631314700775e-09  grad at x: [-1.93062645e-06 -1.02694285e-05]  gradient norm: 1.0449329134275565e-05\n",
            "iter: 934929  x: [ 3.99995796 15.99966369]  f(x): 1.7674141117482277e-09  grad at x: [ 1.63696186e-04 -3.09711122e-05]  gradient norm: 0.0001666002737552465\n",
            "iter: 934930  x: [ 3.99995796 15.99966369]  f(x): 1.7672559096270128e-09  grad at x: [ 7.99116405e-05 -2.04982462e-05]  gradient norm: 8.249877809654865e-05\n",
            "iter: 934931  x: [ 3.99995796 15.99966369]  f(x): 1.7672039527406645e-09  grad at x: [-2.56301291e-06 -1.01891110e-05]  gradient norm: 1.0506522629110891e-05\n",
            "iter: 934932  x: [ 3.99995796 15.9996637 ]  f(x): 1.7671481096624827e-09  grad at x: [ 7.99593328e-05 -2.05038868e-05]  gradient norm: 8.25463764977066e-05\n",
            "iter: 934933  x: [ 3.99995796 15.9996637 ]  f(x): 1.7670960938369449e-09  grad at x: [-2.56372131e-06 -1.01887017e-05]  gradient norm: 1.050629856137242e-05\n",
            "iter: 934934  x: [ 3.99995797 15.99966371]  f(x): 1.767040316631144e-09  grad at x: [ 8.00072578e-05 -2.05095566e-05]  gradient norm: 8.259420808516901e-05\n",
            "iter: 934935  x: [ 3.99995797 15.99966371]  f(x): 1.7669882415102855e-09  grad at x: [-2.56442979e-06 -1.01882924e-05]  gradient norm: 1.0506074571642653e-05\n",
            "iter: 934936  x: [ 3.99995797 15.99966372]  f(x): 1.7669325301750086e-09  grad at x: [ 8.00551681e-05 -2.05152246e-05]  gradient norm: 8.264202554617711e-05\n",
            "iter: 934937  x: [ 3.99995797 15.99966372]  f(x): 1.7668803957977198e-09  grad at x: [-2.56513835e-06 -1.01878832e-05]  gradient norm: 1.050585066015925e-05\n",
            "iter: 934938  x: [ 3.99995797 15.99966373]  f(x): 1.7668247503310765e-09  grad at x: [ 8.01030639e-05 -2.05208908e-05]  gradient norm: 8.268982887771307e-05\n",
            "iter: 934939  x: [ 3.99995797 15.99966373]  f(x): 1.766772556642375e-09  grad at x: [-2.56583243e-06 -1.01874757e-05]  gradient norm: 1.0505625036328235e-05\n",
            "iter: 934940  x: [ 3.99995797 15.99966374]  f(x): 1.7667169759582467e-09  grad at x: [ 8.01500427e-05 -2.05264423e-05]  gradient norm: 8.273671607345287e-05\n",
            "iter: 934941  x: [ 3.99995797 15.99966374]  f(x): 1.7666647240631872e-09  grad at x: [-2.56652660e-06 -1.01870683e-05]  gradient norm: 1.0505399488407114e-05\n",
            "iter: 934942  x: [ 3.99995797 15.99966375]  f(x): 1.766609208266879e-09  grad at x: [ 8.01970652e-05 -2.05319993e-05]  gradient norm: 8.27836473131522e-05\n",
            "iter: 934943  x: [ 3.99995797 15.99966375]  f(x): 1.7665568980790902e-09  grad at x: [-2.56723539e-06 -1.01866590e-05]  gradient norm: 1.0505175808738588e-05\n",
            "iter: 934944  x: [ 3.99995797 15.99966376]  f(x): 1.7665014482537406e-09  grad at x: [ 8.02449607e-05 -2.05376655e-05]  gradient norm: 8.283145188391297e-05\n",
            "iter: 934945  x: [ 3.99995797 15.99966376]  f(x): 1.766449078670548e-09  grad at x: [-2.56794426e-06 -1.01862497e-05]  gradient norm: 1.0504952207399626e-05\n",
            "iter: 934946  x: [ 3.99995797 15.99966377]  f(x): 1.7663936949228513e-09  grad at x: [ 8.02928998e-05 -2.05433371e-05]  gradient norm: 8.28793005173372e-05\n",
            "iter: 934947  x: [ 3.99995797 15.99966377]  f(x): 1.7663412658372595e-09  grad at x: [-2.56865321e-06 -1.01858404e-05]  gradient norm: 1.0504728684194051e-05\n",
            "iter: 934948  x: [ 3.99995798 15.99966378]  f(x): 1.7662859482383248e-09  grad at x: [ 8.03408533e-05 -2.05490105e-05]  gradient norm: 8.292716411450247e-05\n",
            "iter: 934949  x: [ 3.99995797 15.99966378]  f(x): 1.7662334595981574e-09  grad at x: [-2.56937679e-06 -1.01854293e-05]  gradient norm: 1.0504507034975764e-05\n",
            "iter: 934950  x: [ 3.99995798 15.99966379]  f(x): 1.7661782092701015e-09  grad at x: [ 8.03897091e-05 -2.05547967e-05]  gradient norm: 8.297593018189285e-05\n",
            "iter: 934951  x: [ 3.99995798 15.99966379]  f(x): 1.7661256599325658e-09  grad at x: [-2.57007134e-06 -1.01850219e-05]  gradient norm: 1.0504281872483628e-05\n",
            "iter: 934952  x: [ 3.99995798 15.9996638 ]  f(x): 1.7660704746611866e-09  grad at x: [ 8.04367457e-05 -2.05603556e-05]  gradient norm: 8.302287801055656e-05\n",
            "iter: 934953  x: [ 3.99995798 15.9996638 ]  f(x): 1.766017866842466e-09  grad at x: [-2.57079508e-06 -1.01846108e-05]  gradient norm: 1.0504060381819324e-05\n",
            "iter: 934954  x: [ 3.99995798 15.99966381]  f(x): 1.7659627489490631e-09  grad at x: [ 8.04856158e-05 -2.05661436e-05]  gradient norm: 8.307165947417773e-05\n",
            "iter: 934955  x: [ 3.99995798 15.99966381]  f(x): 1.7659100803264161e-09  grad at x: [-2.57151889e-06 -1.01841997e-05]  gradient norm: 1.0503838971357897e-05\n",
            "iter: 934956  x: [ 3.99995798 15.99966382]  f(x): 1.7658550299192779e-09  grad at x: [ 8.05345295e-05 -2.05719371e-05]  gradient norm: 8.31204850174076e-05\n",
            "iter: 934957  x: [ 3.99995798 15.99966383]  f(x): 1.7658023004022054e-09  grad at x: [-2.57222823e-06 -1.01837904e-05]  gradient norm: 1.0503615841532773e-05\n",
            "iter: 934958  x: [ 3.99995798 15.99966383]  f(x): 1.765747316281002e-09  grad at x: [ 8.05824826e-05 -2.05776105e-05]  gradient norm: 8.316835070617959e-05\n",
            "iter: 934959  x: [ 3.99995798 15.99966384]  f(x): 1.7656945270514422e-09  grad at x: [-2.57293765e-06 -1.01833812e-05]  gradient norm: 1.0503392789966349e-05\n",
            "iter: 934960  x: [ 3.99995798 15.99966385]  f(x): 1.765639609287365e-09  grad at x: [ 8.06304503e-05 -2.05832857e-05]  gradient norm: 8.321623135640616e-05\n",
            "iter: 934961  x: [ 3.99995798 15.99966385]  f(x): 1.7655867602738253e-09  grad at x: [-2.57364715e-06 -1.01829719e-05]  gradient norm: 1.0503169816679454e-05\n",
            "iter: 934962  x: [ 3.99995798 15.99966386]  f(x): 1.7655319089380958e-09  grad at x: [ 8.06784324e-05 -2.05889628e-05]  gradient norm: 8.326412696594207e-05\n",
            "iter: 934963  x: [ 3.99995798 15.99966386]  f(x): 1.7654790000882849e-09  grad at x: [-2.57437128e-06 -1.01825608e-05]  gradient norm: 1.0502948725209567e-05\n",
            "iter: 934964  x: [ 3.99995799 15.99966387]  f(x): 1.765424216307712e-09  grad at x: [ 8.07273166e-05 -2.05947526e-05]  gradient norm: 8.331292510175469e-05\n",
            "iter: 934965  x: [ 3.99995798 15.99966387]  f(x): 1.7653712464560587e-09  grad at x: [-2.57508093e-06 -1.01821515e-05]  gradient norm: 1.050272590941889e-05\n",
            "iter: 934966  x: [ 3.99995799 15.99966388]  f(x): 1.7653165291731084e-09  grad at x: [ 8.07753132e-05 -2.06004315e-05]  gradient norm: 8.336083609225679e-05\n",
            "iter: 934967  x: [ 3.99995799 15.99966388]  f(x): 1.7652634994333933e-09  grad at x: [-2.57579066e-06 -1.01817423e-05]  gradient norm: 1.050250317240589e-05\n",
            "iter: 934968  x: [ 3.99995799 15.99966389]  f(x): 1.765208848682754e-09  grad at x: [ 8.08233096e-05 -2.06061104e-05]  gradient norm: 8.340874749200118e-05\n",
            "iter: 934969  x: [ 3.99995799 15.99966389]  f(x): 1.7651557589645838e-09  grad at x: [-2.57651503e-06 -1.01813312e-05]  gradient norm: 1.0502282320352724e-05\n",
            "iter: 934970  x: [ 3.99995799 15.9996639 ]  f(x): 1.7651011759123972e-09  grad at x: [ 8.08722082e-05 -2.06119021e-05]  gradient norm: 8.345756144018773e-05\n",
            "iter: 934971  x: [ 3.99995799 15.9996639 ]  f(x): 1.7650480250674167e-09  grad at x: [-2.57723947e-06 -1.01809201e-05]  gradient norm: 1.0502061548889297e-05\n",
            "iter: 934972  x: [ 3.99995799 15.99966391]  f(x): 1.7649935098215793e-09  grad at x: [ 8.09211649e-05 -2.06177010e-05]  gradient norm: 8.350643401540441e-05\n",
            "iter: 934973  x: [ 3.99995799 15.99966391]  f(x): 1.7649402977596754e-09  grad at x: [-2.57794944e-06 -1.01805108e-05]  gradient norm: 1.0501839049214032e-05\n",
            "iter: 934974  x: [ 3.99995799 15.99966392]  f(x): 1.7648858491149467e-09  grad at x: [ 8.09691465e-05 -2.06233781e-05]  gradient norm: 8.355433210498669e-05\n",
            "iter: 934975  x: [ 3.99995799 15.99966392]  f(x): 1.764832577022974e-09  grad at x: [-2.57865948e-06 -1.01801015e-05]  gradient norm: 1.0501616627964659e-05\n",
            "iter: 934976  x: [ 3.99995799 15.99966393]  f(x): 1.7647781950873121e-09  grad at x: [ 8.10171572e-05 -2.06290588e-05]  gradient norm: 8.360225970173343e-05\n",
            "iter: 934977  x: [ 3.99995799 15.99966393]  f(x): 1.7647248628570118e-09  grad at x: [-2.57936960e-06 -1.01796923e-05]  gradient norm: 1.0501394284943858e-05\n",
            "iter: 934978  x: [ 3.99995799 15.99966394]  f(x): 1.7646705476644727e-09  grad at x: [ 8.10651823e-05 -2.06347413e-05]  gradient norm: 8.365020225471702e-05\n",
            "iter: 934979  x: [ 3.99995799 15.99966394]  f(x): 1.76461715527957e-09  grad at x: [-2.58006525e-06 -1.01792848e-05]  gradient norm: 1.050117020852633e-05\n",
            "iter: 934980  x: [ 3.999958   15.99966395]  f(x): 1.7645629056580757e-09  grad at x: [ 8.11122470e-05 -2.06403038e-05]  gradient norm: 8.369718482325376e-05\n",
            "iter: 934981  x: [ 3.99995799 15.99966395]  f(x): 1.764509454255329e-09  grad at x: [-2.58080464e-06 -1.01788719e-05]  gradient norm: 1.0500951648176341e-05\n",
            "iter: 934982  x: [ 3.999958   15.99966396]  f(x): 1.7644552737886675e-09  grad at x: [ 8.11621346e-05 -2.06462191e-05]  gradient norm: 8.374699076434059e-05\n",
            "iter: 934983  x: [ 3.999958   15.99966396]  f(x): 1.7644017598009262e-09  grad at x: [-2.5815441e-06 -1.0178459e-05]  gradient norm: 1.0500733170790917e-05\n",
            "iter: 934984  x: [ 3.999958   15.99966397]  f(x): 1.7643476485626753e-09  grad at x: [ 8.12120513e-05 -2.06521381e-05]  gradient norm: 8.37968262489039e-05\n",
            "iter: 934985  x: [ 3.999958   15.99966397]  f(x): 1.7642940719341404e-09  grad at x: [-2.58226909e-06 -1.01780479e-05]  gradient norm: 1.0500512960709116e-05\n",
            "iter: 934986  x: [ 3.999958   15.99966398]  f(x): 1.7642400287528677e-09  grad at x: [ 8.12610075e-05 -2.06579371e-05]  gradient norm: 8.38457017548316e-05\n",
            "iter: 934987  x: [ 3.999958   15.99966398]  f(x): 1.7641863906365899e-09  grad at x: [-2.58299416e-06 -1.01776368e-05]  gradient norm: 1.0500292831605223e-05\n",
            "iter: 934988  x: [ 3.999958   15.99966399]  f(x): 1.7641324155484039e-09  grad at x: [ 8.13099636e-05 -2.06637360e-05]  gradient norm: 8.389457768162707e-05\n",
            "iter: 934989  x: [ 3.999958   15.99966399]  f(x): 1.7640787159260528e-09  grad at x: [-2.58370475e-06 -1.01772275e-05]  gradient norm: 1.050007096560974e-05\n",
            "iter: 934990  x: [ 3.999958 15.999664]  f(x): 1.764024807792199e-09  grad at x: [ 8.13580028e-05 -2.06694203e-05]  gradient norm: 8.394253724638227e-05\n",
            "iter: 934991  x: [ 3.999958 15.999664]  f(x): 1.7639710477660705e-09  grad at x: [-2.58442997e-06 -1.01768164e-05]  gradient norm: 1.0499850996974371e-05\n",
            "iter: 934992  x: [ 3.999958   15.99966401]  f(x): 1.7639172078697142e-09  grad at x: [ 8.14070024e-05 -2.06752247e-05]  gradient norm: 8.39914576540803e-05\n",
            "iter: 934993  x: [ 3.999958   15.99966401]  f(x): 1.7638768414156062e-09  grad at x: [ 3.94109163e-05 -1.54258141e-05]  gradient norm: 4.232228802768329e-05\n",
            "iter: 934994  x: [ 3.999958   15.99966401]  f(x): 1.763862548387054e-09  grad at x: [-1.92859851e-06 -1.02584709e-05]  gradient norm: 1.0438185509254965e-05\n",
            "iter: 934995  x: [ 3.99995801 15.99966405]  f(x): 1.7636458289639605e-09  grad at x: [ 1.63529705e-04 -3.09390925e-05]  gradient norm: 0.0001664307423788649\n",
            "iter: 934996  x: [ 3.99995801 15.99966405]  f(x): 1.7634879486892337e-09  grad at x: [ 7.98304055e-05 -2.04768821e-05]  gradient norm: 8.241478226673379e-05\n",
            "iter: 934997  x: [ 3.99995801 15.99966405]  f(x): 1.763436097642397e-09  grad at x: [-2.56034097e-06 -1.01782352e-05]  gradient norm: 1.0495323651624834e-05\n",
            "iter: 934998  x: [ 3.99995801 15.99966406]  f(x): 1.7633803785469177e-09  grad at x: [ 7.98780076e-05 -2.04825119e-05]  gradient norm: 8.246229076820938e-05\n",
            "iter: 934999  x: [ 3.99995801 15.99966406]  f(x): 1.763328468711373e-09  grad at x: [-2.56103756e-06 -1.01778278e-05]  gradient norm: 1.049509846932013e-05\n",
            "iter: 935000  x: [ 3.99995801 15.99966407]  f(x): 1.7632728144367405e-09  grad at x: [ 7.99251586e-05 -2.04880853e-05]  gradient norm: 8.250934869483552e-05\n",
            "iter: 935001  x: [ 3.99995801 15.99966407]  f(x): 1.7632208463661024e-09  grad at x: [-2.56174877e-06 -1.01774185e-05]  gradient norm: 1.0494875151608518e-05\n",
            "iter: 935002  x: [ 3.99995801 15.99966408]  f(x): 1.7631652580639606e-09  grad at x: [ 7.99732263e-05 -2.04937733e-05]  gradient norm: 8.255732356752504e-05\n",
            "iter: 935003  x: [ 3.99995801 15.99966408]  f(x): 1.7631132305678527e-09  grad at x: [-2.56244552e-06 -1.01770111e-05]  gradient norm: 1.0494650123001106e-05\n",
            "iter: 935004  x: [ 3.99995801 15.99966409]  f(x): 1.763057707190562e-09  grad at x: [ 8.00203917e-05 -2.04993485e-05]  gradient norm: 8.260439686383396e-05\n",
            "iter: 935005  x: [ 3.99995801 15.99966409]  f(x): 1.7630056213366774e-09  grad at x: [-2.56317144e-06 -1.01766000e-05]  gradient norm: 1.049442875146458e-05\n",
            "iter: 935006  x: [ 3.99995801 15.9996641 ]  f(x): 1.7629501652287415e-09  grad at x: [ 8.00694343e-05 -2.05051583e-05]  gradient norm: 8.265334732668076e-05\n",
            "iter: 935007  x: [ 3.99995801 15.9996641 ]  f(x): 1.7628980186892157e-09  grad at x: [-2.56388289e-06 -1.01761907e-05]  gradient norm: 1.0494205669290924e-05\n",
            "iter: 935008  x: [ 3.99995802 15.99966411]  f(x): 1.7628426286946464e-09  grad at x: [ 8.01175163e-05 -2.05108481e-05]  gradient norm: 8.270133801750446e-05\n",
            "iter: 935009  x: [ 3.99995802 15.99966411]  f(x): 1.7627904225890134e-09  grad at x: [-2.56460897e-06 -1.01757796e-05]  gradient norm: 1.0493984458149262e-05\n",
            "iter: 935010  x: [ 3.99995802 15.99966412]  f(x): 1.7627350999355574e-09  grad at x: [ 8.01665587e-05 -2.05166580e-05]  gradient norm: 8.27502893528773e-05\n",
            "iter: 935011  x: [ 3.99995802 15.99966412]  f(x): 1.7626828330719219e-09  grad at x: [-2.56532058e-06 -1.01753703e-05]  gradient norm: 1.0493761534201297e-05\n",
            "iter: 935012  x: [ 3.99995802 15.99966413]  f(x): 1.7626275766013375e-09  grad at x: [ 8.02146551e-05 -2.05223496e-05]  gradient norm: 8.279829544576348e-05\n",
            "iter: 935013  x: [ 3.99995802 15.99966413]  f(x): 1.7625752501014902e-09  grad at x: [-2.56604682e-06 -1.01749592e-05]  gradient norm: 1.049354048332207e-05\n",
            "iter: 935014  x: [ 3.99995802 15.99966414]  f(x): 1.7625200610802545e-09  grad at x: [ 8.02637119e-05 -2.05281613e-05]  gradient norm: 8.284726219903149e-05\n",
            "iter: 935015  x: [ 3.99995802 15.99966414]  f(x): 1.7624676737135672e-09  grad at x: [-2.56675858e-06 -1.01745500e-05]  gradient norm: 1.0493317717683935e-05\n",
            "iter: 935016  x: [ 3.99995802 15.99966415]  f(x): 1.7624125509455836e-09  grad at x: [ 8.03118082e-05 -2.05338529e-05]  gradient norm: 8.289526914060517e-05\n",
            "iter: 935017  x: [ 3.99995802 15.99966415]  f(x): 1.7623601038897773e-09  grad at x: [-2.56747042e-06 -1.01741407e-05]  gradient norm: 1.04930950306842e-05\n",
            "iter: 935018  x: [ 3.99995802 15.99966416]  f(x): 1.762305047482855e-09  grad at x: [ 8.03599335e-05 -2.05395481e-05]  gradient norm: 8.294330559703132e-05\n",
            "iter: 935019  x: [ 3.99995802 15.99966416]  f(x): 1.7622525406478927e-09  grad at x: [-2.56816779e-06 -1.01737332e-05]  gradient norm: 1.0492870624365552e-05\n",
            "iter: 935020  x: [ 3.99995802 15.99966417]  f(x): 1.7621975494388709e-09  grad at x: [ 8.04071273e-05 -2.05451270e-05]  gradient norm: 8.299041130156322e-05\n",
            "iter: 935021  x: [ 3.99995802 15.99966417]  f(x): 1.7621449839514676e-09  grad at x: [-2.56887979e-06 -1.01733240e-05]  gradient norm: 1.0492648093608836e-05\n",
            "iter: 935022  x: [ 3.99995803 15.99966418]  f(x): 1.7620900591360766e-09  grad at x: [ 8.04552379e-05 -2.05508204e-05]  gradient norm: 8.303843403645512e-05\n",
            "iter: 935023  x: [ 3.99995802 15.99966418]  f(x): 1.7620374338182746e-09  grad at x: [-2.56959187e-06 -1.01729147e-05]  gradient norm: 1.0492425641553128e-05\n",
            "iter: 935024  x: [ 3.99995803 15.99966419]  f(x): 1.7619825755036398e-09  grad at x: [ 8.05033921e-05 -2.05565193e-05]  gradient norm: 8.308650083602669e-05\n",
            "iter: 935025  x: [ 3.99995803 15.99966419]  f(x): 1.7619298902660834e-09  grad at x: [-2.57028947e-06 -1.01725072e-05]  gradient norm: 1.049220146697129e-05\n",
            "iter: 935026  x: [ 3.99995803 15.9996642 ]  f(x): 1.7618750972512799e-09  grad at x: [ 8.05505857e-05 -2.05620981e-05]  gradient norm: 8.31336077536242e-05\n",
            "iter: 935027  x: [ 3.99995803 15.9996642 ]  f(x): 1.7618223532584528e-09  grad at x: [-2.5710017e-06 -1.0172098e-05]  gradient norm: 1.0491979171283402e-05\n",
            "iter: 935028  x: [ 3.99995803 15.99966421]  f(x): 1.761767626849337e-09  grad at x: [ 8.05987688e-05 -2.05678007e-05]  gradient norm: 8.318170447647977e-05\n",
            "iter: 935029  x: [ 3.99995803 15.99966421]  f(x): 1.7617148228323633e-09  grad at x: [-2.57172857e-06 -1.01716869e-05]  gradient norm: 1.0491758758018965e-05\n",
            "iter: 935030  x: [ 3.99995803 15.99966422]  f(x): 1.7616601641191508e-09  grad at x: [ 8.06478250e-05 -2.05736123e-05]  gradient norm: 8.323067462762914e-05\n",
            "iter: 935031  x: [ 3.99995803 15.99966422]  f(x): 1.7616072989490942e-09  grad at x: [-2.57244096e-06 -1.01712776e-05]  gradient norm: 1.0491536620976563e-05\n",
            "iter: 935032  x: [ 3.99995803 15.99966423]  f(x): 1.761552706876301e-09  grad at x: [ 8.06959788e-05 -2.05793112e-05]  gradient norm: 8.32787430859497e-05\n",
            "iter: 935033  x: [ 3.99995803 15.99966423]  f(x): 1.7614997816467644e-09  grad at x: [-2.57316798e-06 -1.01708665e-05]  gradient norm: 1.049131636861454e-05\n",
            "iter: 935034  x: [ 3.99995803 15.99966424]  f(x): 1.7614452573775762e-09  grad at x: [ 8.07450639e-05 -2.05851265e-05]  gradient norm: 8.332774318999333e-05\n",
            "iter: 935035  x: [ 3.99995803 15.99966425]  f(x): 1.7613922708866551e-09  grad at x: [-2.57388052e-06 -1.01704572e-05]  gradient norm: 1.0491094390301895e-05\n",
            "iter: 935036  x: [ 3.99995803 15.99966426]  f(x): 1.7613378133277151e-09  grad at x: [ 8.07932322e-05 -2.05908273e-05]  gradient norm: 8.337582703206709e-05\n",
            "iter: 935037  x: [ 3.99995803 15.99966426]  f(x): 1.761284766705741e-09  grad at x: [-2.57457859e-06 -1.01700498e-05]  gradient norm: 1.0490870682984776e-05\n",
            "iter: 935038  x: [ 3.99995804 15.99966427]  f(x): 1.7612303747250828e-09  grad at x: [ 8.08404690e-05 -2.05964116e-05]  gradient norm: 8.342298003432301e-05\n",
            "iter: 935039  x: [ 3.99995803 15.99966427]  f(x): 1.76117726906759e-09  grad at x: [-2.57529130e-06 -1.01696405e-05]  gradient norm: 1.0490648861290501e-05\n",
            "iter: 935040  x: [ 3.99995804 15.99966428]  f(x): 1.7611229438663808e-09  grad at x: [ 8.08886371e-05 -2.06021123e-05]  gradient norm: 8.347106469072527e-05\n",
            "iter: 935041  x: [ 3.99995804 15.99966428]  f(x): 1.761069778008032e-09  grad at x: [-2.57598952e-06 -1.01692331e-05]  gradient norm: 1.0490425308457917e-05\n",
            "iter: 935042  x: [ 3.99995804 15.99966429]  f(x): 1.7610155184888945e-09  grad at x: [ 8.09359029e-05 -2.06077002e-05]  gradient norm: 8.351824758783426e-05\n",
            "iter: 935043  x: [ 3.99995804 15.99966429]  f(x): 1.760962293490638e-09  grad at x: [-2.57670238e-06 -1.01688238e-05]  gradient norm: 1.0490203643465182e-05\n",
            "iter: 935044  x: [ 3.99995804 15.9996643 ]  f(x): 1.7609081008201718e-09  grad at x: [ 8.09840708e-05 -2.06134009e-05]  gradient norm: 8.356633305208705e-05\n",
            "iter: 935045  x: [ 3.99995804 15.9996643 ]  f(x): 1.7608548155512352e-09  grad at x: [-2.57740077e-06 -1.01684163e-05]  gradient norm: 1.048998024541797e-05\n",
            "iter: 935046  x: [ 3.99995804 15.99966431]  f(x): 1.7608006886307497e-09  grad at x: [ 8.10313364e-05 -2.06189889e-05]  gradient norm: 8.361351674002204e-05\n",
            "iter: 935047  x: [ 3.99995804 15.99966431]  f(x): 1.760747344154542e-09  grad at x: [-2.57814289e-06 -1.01680034e-05]  gradient norm: 1.0489762363834495e-05\n",
            "iter: 935048  x: [ 3.99995804 15.99966432]  f(x): 1.760693286528572e-09  grad at x: [ 8.1081396e-05 -2.0624926e-05]  gradient norm: 8.366349470700285e-05\n",
            "iter: 935049  x: [ 3.99995804 15.99966432]  f(x): 1.7606398793352383e-09  grad at x: [-2.57887053e-06 -1.01675923e-05]  gradient norm: 1.0489542751455762e-05\n",
            "iter: 935050  x: [ 3.99995804 15.99966433]  f(x): 1.7605858898705315e-09  grad at x: [ 8.11305241e-05 -2.06307468e-05]  gradient norm: 8.371254181054329e-05\n",
            "iter: 935051  x: [ 3.99995804 15.99966433]  f(x): 1.760532421056901e-09  grad at x: [-2.57961281e-06 -1.01671794e-05]  gradient norm: 1.0489325035868745e-05\n",
            "iter: 935052  x: [ 3.99995804 15.99966434]  f(x): 1.7604785009975993e-09  grad at x: [ 8.11806126e-05 -2.06366876e-05]  gradient norm: 8.376254975438931e-05\n",
            "iter: 935053  x: [ 3.99995804 15.99966434]  f(x): 1.7604249693553517e-09  grad at x: [-2.58034061e-06 -1.01667683e-05]  gradient norm: 1.0489105587053672e-05\n",
            "iter: 935054  x: [ 3.99995805 15.99966435]  f(x): 1.7603711175307637e-09  grad at x: [ 8.12297406e-05 -2.06425084e-05]  gradient norm: 8.381159771377875e-05\n",
            "iter: 935055  x: [ 3.99995804 15.99966435]  f(x): 1.76031752419417e-09  grad at x: [-2.58108304e-06 -1.01663554e-05]  gradient norm: 1.0488888037112924e-05\n",
            "iter: 935056  x: [ 3.99995805 15.99966436]  f(x): 1.7602637418498898e-09  grad at x: [ 8.12798290e-05 -2.06484492e-05]  gradient norm: 8.386160653211585e-05\n",
            "iter: 935057  x: [ 3.99995805 15.99966436]  f(x): 1.760210085609174e-09  grad at x: [-2.58181100e-06 -1.01659443e-05]  gradient norm: 1.0488668751947486e-05\n",
            "iter: 935058  x: [ 3.99995805 15.99966436]  f(x): 1.760169798660229e-09  grad at x: [ 3.93735729e-05 -1.54101072e-05]  gradient norm: 4.228178855994542e-05\n",
            "iter: 935059  x: [ 3.99995805 15.99966436]  f(x): 1.7601555331532007e-09  grad at x: [-1.92662237e-06 -1.02476788e-05]  gradient norm: 1.0427214133206442e-05\n",
            "iter: 935060  x: [ 3.99995805 15.9996644 ]  f(x): 1.7599393027505166e-09  grad at x: [ 1.63371133e-04 -3.09082334e-05]  gradient norm: 0.0001662691972790935\n",
            "iter: 935061  x: [ 3.99995805 15.9996644 ]  f(x): 1.7597817288291016e-09  grad at x: [ 7.97530333e-05 -2.04561729e-05]  gradient norm: 8.233469090316912e-05\n",
            "iter: 935062  x: [ 3.99995805 15.9996644 ]  f(x): 1.7597299786321047e-09  grad at x: [-2.55774977e-06 -1.01675214e-05]  gradient norm: 1.0484301369456844e-05\n",
            "iter: 935063  x: [ 3.99995805 15.99966441]  f(x): 1.7596743846461236e-09  grad at x: [ 7.98004872e-05 -2.04617845e-05]  gradient norm: 8.238205138049689e-05\n",
            "iter: 935064  x: [ 3.99995805 15.99966441]  f(x): 1.759622575917126e-09  grad at x: [-2.55846360e-06 -1.01671121e-05]  gradient norm: 1.0484078639590453e-05\n",
            "iter: 935065  x: [ 3.99995806 15.99966442]  f(x): 1.7595670480109663e-09  grad at x: [ 7.98487270e-05 -2.04674943e-05]  gradient norm: 8.243019786922679e-05\n",
            "iter: 935066  x: [ 3.99995805 15.99966442]  f(x): 1.7595151797571943e-09  grad at x: [-2.55914841e-06 -1.01667065e-05]  gradient norm: 1.0483852411966177e-05\n",
            "iter: 935067  x: [ 3.99995806 15.99966443]  f(x): 1.7594597156953259e-09  grad at x: [ 7.98951185e-05 -2.04729731e-05]  gradient norm: 8.247649715721072e-05\n",
            "iter: 935068  x: [ 3.99995806 15.99966443]  f(x): 1.7594077901350861e-09  grad at x: [-2.55984785e-06 -1.01662990e-05]  gradient norm: 1.0483628048473584e-05\n",
            "iter: 935069  x: [ 3.99995806 15.99966444]  f(x): 1.7593523911040192e-09  grad at x: [ 7.99424412e-05 -2.04785683e-05]  gradient norm: 8.252372793425528e-05\n",
            "iter: 935070  x: [ 3.99995806 15.99966444]  f(x): 1.7593004070685622e-09  grad at x: [-2.56054736e-06 -1.01658916e-05]  gradient norm: 1.048340376155442e-05\n",
            "iter: 935071  x: [ 3.99995806 15.99966445]  f(x): 1.7592450731020099e-09  grad at x: [ 7.99897639e-05 -2.04841635e-05]  gradient norm: 8.257095912007328e-05\n",
            "iter: 935072  x: [ 3.99995806 15.99966445]  f(x): 1.7591930305392641e-09  grad at x: [-2.56126151e-06 -1.01654823e-05]  gradient norm: 1.0483181342910812e-05\n",
            "iter: 935073  x: [ 3.99995806 15.99966446]  f(x): 1.7591377628619681e-09  grad at x: [ 8.00380470e-05 -2.04898788e-05]  gradient norm: 8.2619150928101e-05\n",
            "iter: 935074  x: [ 3.99995806 15.99966447]  f(x): 1.7590856605830077e-09  grad at x: [-2.56196118e-06 -1.01650749e-05]  gradient norm: 1.04829572107141e-05\n",
            "iter: 935075  x: [ 3.99995806 15.99966447]  f(x): 1.7590304580383452e-09  grad at x: [ 8.00853695e-05 -2.04954740e-05]  gradient norm: 8.266638293999253e-05\n",
            "iter: 935076  x: [ 3.99995806 15.99966448]  f(x): 1.758978297163379e-09  grad at x: [-2.56267548e-06 -1.01646656e-05]  gradient norm: 1.0482734949015096e-05\n",
            "iter: 935077  x: [ 3.99995806 15.99966449]  f(x): 1.7589231609774909e-09  grad at x: [ 8.01336524e-05 -2.05011893e-05]  gradient norm: 8.271457558947449e-05\n",
            "iter: 935078  x: [ 3.99995806 15.99966449]  f(x): 1.7588709403161904e-09  grad at x: [-2.56337531e-06 -1.01642581e-05]  gradient norm: 1.0482510971623714e-05\n",
            "iter: 935079  x: [ 3.99995806 15.9996645 ]  f(x): 1.7588158693666619e-09  grad at x: [ 8.01810039e-05 -2.05067881e-05]  gradient norm: 8.276183752000882e-05\n",
            "iter: 935080  x: [ 3.99995806 15.9996645 ]  f(x): 1.7587635900050304e-09  grad at x: [-2.56408977e-06 -1.01638489e-05]  gradient norm: 1.0482288866952769e-05\n",
            "iter: 935081  x: [ 3.99995807 15.99966451]  f(x): 1.758708585483815e-09  grad at x: [ 8.02292867e-05 -2.05125034e-05]  gradient norm: 8.281003100778107e-05\n",
            "iter: 935082  x: [ 3.99995806 15.99966451]  f(x): 1.7586562462657089e-09  grad at x: [-2.56478975e-06 -1.01634414e-05]  gradient norm: 1.0482065044666937e-05\n",
            "iter: 935083  x: [ 3.99995807 15.99966452]  f(x): 1.7586013070490341e-09  grad at x: [ 8.02766380e-05 -2.05181022e-05]  gradient norm: 8.285729375674706e-05\n",
            "iter: 935084  x: [ 3.99995807 15.99966452]  f(x): 1.7585489090798705e-09  grad at x: [-2.56548981e-06 -1.01630339e-05]  gradient norm: 1.048184129909857e-05\n",
            "iter: 935085  x: [ 3.99995807 15.99966453]  f(x): 1.7584940352007045e-09  grad at x: [ 8.03240038e-05 -2.05237029e-05]  gradient norm: 8.290457145845328e-05\n",
            "iter: 935086  x: [ 3.99995807 15.99966453]  f(x): 1.7584415784291627e-09  grad at x: [-2.56620450e-06 -1.01626247e-05]  gradient norm: 1.0481619429575629e-05\n",
            "iter: 935087  x: [ 3.99995807 15.99966454]  f(x): 1.7583867711187531e-09  grad at x: [ 8.03723009e-05 -2.05294200e-05]  gradient norm: 8.295278074221903e-05\n",
            "iter: 935088  x: [ 3.99995807 15.99966454]  f(x): 1.758334254349391e-09  grad at x: [-2.56690472e-06 -1.01622172e-05]  gradient norm: 1.0481395839019715e-05\n",
            "iter: 935089  x: [ 3.99995807 15.99966455]  f(x): 1.7582795124447138e-09  grad at x: [ 8.04196665e-05 -2.05350207e-05]  gradient norm: 8.300005925789229e-05\n",
            "iter: 935090  x: [ 3.99995807 15.99966455]  f(x): 1.758226936804151e-09  grad at x: [-2.56761957e-06 -1.01618079e-05]  gradient norm: 1.0481174126733387e-05\n",
            "iter: 935091  x: [ 3.99995807 15.99966456]  f(x): 1.7581722615735445e-09  grad at x: [ 8.04679925e-05 -2.05407414e-05]  gradient norm: 8.304829847306397e-05\n",
            "iter: 935092  x: [ 3.99995807 15.99966456]  f(x): 1.7581196258111954e-09  grad at x: [-2.56833450e-06 -1.01613987e-05]  gradient norm: 1.0480952493647548e-05\n",
            "iter: 935093  x: [ 3.99995807 15.99966457]  f(x): 1.7580650172533365e-09  grad at x: [ 8.05163039e-05 -2.05464603e-05]  gradient norm: 8.309652355566045e-05\n",
            "iter: 935094  x: [ 3.99995807 15.99966457]  f(x): 1.7580123213702239e-09  grad at x: [-2.56904950e-06 -1.01609894e-05]  gradient norm: 1.0480730939783214e-05\n",
            "iter: 935095  x: [ 3.99995807 15.99966458]  f(x): 1.7579577795195367e-09  grad at x: [ 8.05646298e-05 -2.05521810e-05]  gradient norm: 8.314476360777558e-05\n",
            "iter: 935096  x: [ 3.99995807 15.99966458]  f(x): 1.757905023462888e-09  grad at x: [-2.56977914e-06 -1.01605783e-05]  gradient norm: 1.0480511269760203e-05\n",
            "iter: 935097  x: [ 3.99995808 15.99966459]  f(x): 1.757850549555444e-09  grad at x: [ 8.06138869e-05 -2.05580182e-05]  gradient norm: 8.31939353033018e-05\n",
            "iter: 935098  x: [ 3.99995807 15.99966459]  f(x): 1.7577977321249855e-09  grad at x: [-2.5704943e-06 -1.0160169e-05]  gradient norm: 1.0480289875504107e-05\n",
            "iter: 935099  x: [ 3.99995808 15.9996646 ]  f(x): 1.7577433249957508e-09  grad at x: [ 8.06622126e-05 -2.05637389e-05]  gradient norm: 8.324217619806479e-05\n",
            "iter: 935100  x: [ 3.99995808 15.9996646 ]  f(x): 1.7576904473201202e-09  grad at x: [-2.57122409e-06 -1.01597579e-05]  gradient norm: 1.0480070367356193e-05\n",
            "iter: 935101  x: [ 3.99995808 15.99966461]  f(x): 1.7576361082423921e-09  grad at x: [ 8.07114987e-05 -2.05695796e-05]  gradient norm: 8.329137785175955e-05\n",
            "iter: 935102  x: [ 3.99995808 15.99966461]  f(x): 1.757583169084087e-09  grad at x: [-2.57193941e-06 -1.01593487e-05]  gradient norm: 1.0479849132792999e-05\n",
            "iter: 935103  x: [ 3.99995808 15.99966462]  f(x): 1.757528896855626e-09  grad at x: [ 8.07598242e-05 -2.05753004e-05]  gradient norm: 8.333961958594884e-05\n",
            "iter: 935104  x: [ 3.99995808 15.99966462]  f(x): 1.7574758973973959e-09  grad at x: [-2.5726257e-06 -1.0158943e-05]  gradient norm: 1.0479624359519939e-05\n",
            "iter: 935105  x: [ 3.99995808 15.99966463]  f(x): 1.7574216897571183e-09  grad at x: [ 8.08063016e-05 -2.05807901e-05]  gradient norm: 8.338601376358855e-05\n",
            "iter: 935106  x: [ 3.99995808 15.99966463]  f(x): 1.757368632224798e-09  grad at x: [-2.57334117e-06 -1.01585338e-05]  gradient norm: 1.0479403281208044e-05\n",
            "iter: 935107  x: [ 3.99995808 15.99966464]  f(x): 1.7573144915759165e-09  grad at x: [ 8.08546560e-05 -2.05865144e-05]  gradient norm: 8.343428540834575e-05\n",
            "iter: 935108  x: [ 3.99995808 15.99966464]  f(x): 1.7572613736212736e-09  grad at x: [-2.57407128e-06 -1.01581227e-05]  gradient norm: 1.0479184093696746e-05\n",
            "iter: 935109  x: [ 3.99995808 15.99966465]  f(x): 1.7572073011295494e-09  grad at x: [ 8.09039418e-05 -2.05923552e-05]  gradient norm: 8.348348874581166e-05\n",
            "iter: 935110  x: [ 3.99995808 15.99966465]  f(x): 1.7571541215481482e-09  grad at x: [-2.57478691e-06 -1.01577134e-05]  gradient norm: 1.0478963175246071e-05\n",
            "iter: 935111  x: [ 3.99995808 15.99966466]  f(x): 1.7571001161189397e-09  grad at x: [ 8.09522961e-05 -2.05980796e-05]  gradient norm: 8.353176122569538e-05\n",
            "iter: 935112  x: [ 3.99995808 15.99966466]  f(x): 1.7570468760434959e-09  grad at x: [-2.57551717e-06 -1.01573023e-05]  gradient norm: 1.0478744149864706e-05\n",
            "iter: 935113  x: [ 3.99995809 15.99966467]  f(x): 1.7569929388439514e-09  grad at x: [ 8.10015817e-05 -2.06039203e-05]  gradient norm: 8.358096541285058e-05\n",
            "iter: 935114  x: [ 3.99995808 15.99966467]  f(x): 1.7569396370866856e-09  grad at x: [-2.57621840e-06 -1.01568949e-05]  gradient norm: 1.0478521576816425e-05\n",
            "iter: 935115  x: [ 3.99995809 15.99966468]  f(x): 1.7568857658503104e-09  grad at x: [ 8.10490191e-05 -2.06095301e-05]  gradient norm: 8.36283219671141e-05\n",
            "iter: 935116  x: [ 3.99995809 15.99966468]  f(x): 1.7568324046424775e-09  grad at x: [-2.57694882e-06 -1.01564838e-05]  gradient norm: 1.0478302712308193e-05\n",
            "iter: 935117  x: [ 3.99995809 15.99966469]  f(x): 1.7567786017808278e-09  grad at x: [ 8.10983337e-05 -2.06153745e-05]  gradient norm: 8.36775560962939e-05\n",
            "iter: 935118  x: [ 3.99995809 15.99966469]  f(x): 1.7567251787658428e-09  grad at x: [-2.57769386e-06 -1.01560709e-05]  gradient norm: 1.0478085746510651e-05\n",
            "iter: 935119  x: [ 3.99995809 15.9996647 ]  f(x): 1.756671445449587e-09  grad at x: [ 8.11485795e-05 -2.06213354e-05]  gradient norm: 8.372772197563666e-05\n",
            "iter: 935120  x: [ 3.99995809 15.9996647 ]  f(x): 1.7566179594361508e-09  grad at x: [-2.57840988e-06 -1.01556616e-05]  gradient norm: 1.0477865228635464e-05\n",
            "iter: 935121  x: [ 3.99995809 15.99966471]  f(x): 1.756564293360021e-09  grad at x: [ 8.11969480e-05 -2.06270615e-05]  gradient norm: 8.377601108084209e-05\n",
            "iter: 935122  x: [ 3.99995809 15.99966471]  f(x): 1.7565107466362066e-09  grad at x: [-2.57914053e-06 -1.01552505e-05]  gradient norm: 1.0477646609295406e-05\n",
            "iter: 935123  x: [ 3.99995809 15.99966472]  f(x): 1.7564705452300773e-09  grad at x: [ 3.93335754e-05 -1.53940800e-05]  gradient norm: 4.2238700931899766e-05\n",
            "iter: 935124  x: [ 3.99995809 15.99966472]  f(x): 1.7564563088257671e-09  grad at x: [-1.92460812e-06 -1.02369031e-05]  gradient norm: 1.0416251804141841e-05\n",
            "iter: 935125  x: [ 3.9999581  15.99966476]  f(x): 1.7562405402555023e-09  grad at x: [ 1.63202310e-04 -3.08761046e-05]  gradient norm: 0.00016609734453806985\n",
            "iter: 935126  x: [ 3.9999581  15.99966476]  f(x): 1.7560832919328944e-09  grad at x: [ 7.96706496e-05 -2.04348489e-05]  gradient norm: 8.224959243844465e-05\n",
            "iter: 935127  x: [ 3.9999581  15.99966476]  f(x): 1.7560316487041247e-09  grad at x: [-2.55509134e-06 -1.01568276e-05]  gradient norm: 1.047328209098231e-05\n",
            "iter: 935128  x: [ 3.9999581  15.99966477]  f(x): 1.7559761739457287e-09  grad at x: [ 7.97185374e-05 -2.04405151e-05]  gradient norm: 8.229738676176811e-05\n",
            "iter: 935129  x: [ 3.9999581  15.99966477]  f(x): 1.7559244716804343e-09  grad at x: [-2.55580786e-06 -1.01564183e-05]  gradient norm: 1.0473060020219625e-05\n",
            "iter: 935130  x: [ 3.9999581  15.99966478]  f(x): 1.7558690631759864e-09  grad at x: [ 7.97669636e-05 -2.04462485e-05]  gradient norm: 8.234571979059747e-05\n",
            "iter: 935131  x: [ 3.9999581  15.99966478]  f(x): 1.7558173012206345e-09  grad at x: [-2.55650991e-06 -1.01560108e-05]  gradient norm: 1.0472836240763983e-05\n",
            "iter: 935132  x: [ 3.9999581  15.99966479]  f(x): 1.755761957853156e-09  grad at x: [ 7.98144584e-05 -2.04518656e-05]  gradient norm: 8.239312216122914e-05\n",
            "iter: 935133  x: [ 3.9999581  15.99966479]  f(x): 1.7557101373063835e-09  grad at x: [-2.55721204e-06 -1.01556034e-05]  gradient norm: 1.047261253831086e-05\n",
            "iter: 935134  x: [ 3.9999581 15.9996648]  f(x): 1.7556548591098362e-09  grad at x: [ 7.98619531e-05 -2.04574826e-05]  gradient norm: 8.244052494523766e-05\n",
            "iter: 935135  x: [ 3.9999581 15.9996648]  f(x): 1.7556029799193417e-09  grad at x: [-2.55792880e-06 -1.01551941e-05]  gradient norm: 1.0472390703564359e-05\n",
            "iter: 935136  x: [ 3.9999581  15.99966481]  f(x): 1.7555477680813403e-09  grad at x: [ 7.99103791e-05 -2.04632161e-05]  gradient norm: 8.24888592491405e-05\n",
            "iter: 935137  x: [ 3.9999581  15.99966481]  f(x): 1.7554958290772503e-09  grad at x: [-2.55864564e-06 -1.01547848e-05]  gradient norm: 1.0472168948268447e-05\n",
            "iter: 935138  x: [ 3.9999581  15.99966482]  f(x): 1.7554406836331185e-09  grad at x: [ 7.99588050e-05 -2.04689495e-05]  gradient norm: 8.25371939847823e-05\n",
            "iter: 935139  x: [ 3.9999581  15.99966482]  f(x): 1.7553886847798096e-09  grad at x: [-2.55936255e-06 -1.01543756e-05]  gradient norm: 1.0471947272444223e-05\n",
            "iter: 935140  x: [ 3.99995811 15.99966483]  f(x): 1.755333605800402e-09  grad at x: [ 8.00072599e-05 -2.04746866e-05]  gradient norm: 8.258555824669756e-05\n",
            "iter: 935141  x: [ 3.9999581  15.99966483]  f(x): 1.7552815470086823e-09  grad at x: [-2.56009410e-06 -1.01539645e-05]  gradient norm: 1.047172746991545e-05\n",
            "iter: 935142  x: [ 3.99995811 15.99966484]  f(x): 1.755226535649541e-09  grad at x: [ 8.00566170e-05 -2.04805365e-05]  gradient norm: 8.263482497523355e-05\n",
            "iter: 935143  x: [ 3.99995811 15.99966484]  f(x): 1.755174415798507e-09  grad at x: [-2.56078207e-06 -1.01535588e-05]  gradient norm: 1.0471502364407277e-05\n",
            "iter: 935144  x: [ 3.99995811 15.99966485]  f(x): 1.7551194686626737e-09  grad at x: [ 8.01032091e-05 -2.04860407e-05]  gradient norm: 8.268132781234367e-05\n",
            "iter: 935145  x: [ 3.99995811 15.99966485]  f(x): 1.7550672911140466e-09  grad at x: [-2.56148466e-06 -1.01531514e-05]  gradient norm: 1.0471279129828377e-05\n",
            "iter: 935146  x: [ 3.99995811 15.99966486]  f(x): 1.7550124093912527e-09  grad at x: [ 8.01507324e-05 -2.04916614e-05]  gradient norm: 8.272876219523988e-05\n",
            "iter: 935147  x: [ 3.99995811 15.99966486]  f(x): 1.7549601729550035e-09  grad at x: [-2.56220189e-06 -1.01527421e-05]  gradient norm: 1.0471057769672892e-05\n",
            "iter: 935148  x: [ 3.99995811 15.99966487]  f(x): 1.7549053578726206e-09  grad at x: [ 8.01992161e-05 -2.04974021e-05]  gradient norm: 8.277715724844165e-05\n",
            "iter: 935149  x: [ 3.99995811 15.99966487]  f(x): 1.7548530613571484e-09  grad at x: [-2.56290465e-06 -1.01523347e-05]  gradient norm: 1.047083469114665e-05\n",
            "iter: 935150  x: [ 3.99995811 15.99966488]  f(x): 1.7547983117565076e-09  grad at x: [ 8.02467393e-05 -2.05030228e-05]  gradient norm: 8.282459245573987e-05\n",
            "iter: 935151  x: [ 3.99995811 15.99966488]  f(x): 1.7547459562841125e-09  grad at x: [-2.56362203e-06 -1.01519254e-05]  gradient norm: 1.0470613489059824e-05\n",
            "iter: 935152  x: [ 3.99995811 15.99966489]  f(x): 1.754691273358332e-09  grad at x: [ 8.02951938e-05 -2.05087599e-05]  gradient norm: 8.287295924978986e-05\n",
            "iter: 935153  x: [ 3.99995811 15.99966489]  f(x): 1.7546388577536311e-09  grad at x: [-2.56433949e-06 -1.01515161e-05]  gradient norm: 1.0470392366591865e-05\n",
            "iter: 935154  x: [ 3.99995811 15.9996649 ]  f(x): 1.7545842415373154e-09  grad at x: [ 8.03436627e-05 -2.05144988e-05]  gradient norm: 8.292134101868255e-05\n",
            "iter: 935155  x: [ 3.99995811 15.9996649 ]  f(x): 1.7545317657462334e-09  grad at x: [-2.56504248e-06 -1.01511087e-05]  gradient norm: 1.047016952208286e-05\n",
            "iter: 935156  x: [ 3.99995812 15.99966491]  f(x): 1.7544772151871846e-09  grad at x: [ 8.03912293e-05 -2.05201250e-05]  gradient norm: 8.296882111125621e-05\n",
            "iter: 935157  x: [ 3.99995811 15.99966491]  f(x): 1.7544246802819306e-09  grad at x: [-2.56577465e-06 -1.01506976e-05]  gradient norm: 1.0469950360379342e-05\n",
            "iter: 935158  x: [ 3.99995812 15.99966492]  f(x): 1.7543701977000957e-09  grad at x: [ 8.04406440e-05 -2.05259821e-05]  gradient norm: 8.301814947403138e-05\n",
            "iter: 935159  x: [ 3.99995812 15.99966492]  f(x): 1.7543176013581448e-09  grad at x: [-2.56647779e-06 -1.01502901e-05]  gradient norm: 1.0469727673217981e-05\n",
            "iter: 935160  x: [ 3.99995812 15.99966493]  f(x): 1.7542631844665758e-09  grad at x: [ 8.04881959e-05 -2.05316064e-05]  gradient norm: 8.306561584271125e-05\n",
            "iter: 935161  x: [ 3.99995812 15.99966493]  f(x): 1.7542105289576856e-09  grad at x: [-2.56719557e-06 -1.01498808e-05]  gradient norm: 1.0469506868111972e-05\n",
            "iter: 935162  x: [ 3.99995812 15.99966494]  f(x): 1.7541561789887357e-09  grad at x: [ 8.05367081e-05 -2.05373508e-05]  gradient norm: 8.311404294181927e-05\n",
            "iter: 935163  x: [ 3.99995812 15.99966494]  f(x): 1.7541034631163135e-09  grad at x: [-2.56789887e-06 -1.01494734e-05]  gradient norm: 1.0469284336859995e-05\n",
            "iter: 935164  x: [ 3.99995812 15.99966495]  f(x): 1.7540491789064147e-09  grad at x: [ 8.05842599e-05 -2.05429751e-05]  gradient norm: 8.316151012413948e-05\n",
            "iter: 935165  x: [ 3.99995812 15.99966495]  f(x): 1.75399640379767e-09  grad at x: [-2.56861680e-06 -1.01490641e-05]  gradient norm: 1.046906369033428e-05\n",
            "iter: 935166  x: [ 3.99995812 15.99966496]  f(x): 1.7539421865805818e-09  grad at x: [ 8.06327720e-05 -2.05487195e-05]  gradient norm: 8.320993805199189e-05\n",
            "iter: 935167  x: [ 3.99995812 15.99966496]  f(x): 1.7538893510194852e-09  grad at x: [-2.56933480e-06 -1.01486548e-05]  gradient norm: 1.0468843123356987e-05\n",
            "iter: 935168  x: [ 3.99995812 15.99966497]  f(x): 1.753835200794146e-09  grad at x: [ 8.06812695e-05 -2.05544620e-05]  gradient norm: 8.325835184961617e-05\n",
            "iter: 935169  x: [ 3.99995812 15.99966497]  f(x): 1.7537823047622912e-09  grad at x: [-2.57003834e-06 -1.01482474e-05]  gradient norm: 1.0468620826777448e-05\n",
            "iter: 935170  x: [ 3.99995812 15.99966498]  f(x): 1.753728220471894e-09  grad at x: [ 8.07288646e-05 -2.05600918e-05]  gradient norm: 8.330586390434311e-05\n",
            "iter: 935171  x: [ 3.99995812 15.99966498]  f(x): 1.7536752650460988e-09  grad at x: [-2.57077105e-06 -1.01478363e-05]  gradient norm: 1.0468402228567606e-05\n",
            "iter: 935172  x: [ 3.99995813 15.99966499]  f(x): 1.7536212490201473e-09  grad at x: [ 8.07783079e-05 -2.05659526e-05]  gradient norm: 8.33552243488905e-05\n",
            "iter: 935173  x: [ 3.99995812 15.99966499]  f(x): 1.7535682318694674e-09  grad at x: [-2.57150385e-06 -1.01474252e-05]  gradient norm: 1.0468183712422813e-05\n",
            "iter: 935174  x: [ 3.99995813 15.999665  ]  f(x): 1.7535142841441553e-09  grad at x: [ 8.08277656e-05 -2.05718152e-05]  gradient norm: 8.340459978028581e-05\n",
            "iter: 935175  x: [ 3.99995813 15.999665  ]  f(x): 1.7534612052129305e-09  grad at x: [-2.57222217e-06 -1.01470159e-05]  gradient norm: 1.0467963465611356e-05\n",
            "iter: 935176  x: [ 3.99995813 15.99966501]  f(x): 1.7534073246583825e-09  grad at x: [ 8.08762773e-05 -2.05775596e-05]  gradient norm: 8.345302980334884e-05\n",
            "iter: 935177  x: [ 3.99995813 15.99966501]  f(x): 1.7533541850773324e-09  grad at x: [-2.57295512e-06 -1.01466048e-05]  gradient norm: 1.0467745112314774e-05\n",
            "iter: 935178  x: [ 3.99995813 15.99966502]  f(x): 1.7533003729695665e-09  grad at x: [ 8.09257639e-05 -2.05834258e-05]  gradient norm: 8.350243519415358e-05\n",
            "iter: 935179  x: [ 3.99995813 15.99966502]  f(x): 1.7532471714984223e-09  grad at x: [-2.57367359e-06 -1.01461956e-05]  gradient norm: 1.0467525026594747e-05\n",
            "iter: 935180  x: [ 3.99995813 15.99966503]  f(x): 1.7531934266690005e-09  grad at x: [ 8.09743046e-05 -2.05891738e-05]  gradient norm: 8.355089515878913e-05\n",
            "iter: 935181  x: [ 3.99995813 15.99966503]  f(x): 1.7531401644398525e-09  grad at x: [-2.57440670e-06 -1.01457845e-05]  gradient norm: 1.0467306836450218e-05\n",
            "iter: 935182  x: [ 3.99995813 15.99966504]  f(x): 1.7530864880571412e-09  grad at x: [ 8.10237620e-05 -2.05950364e-05]  gradient norm: 8.360027230096246e-05\n",
            "iter: 935183  x: [ 3.99995813 15.99966504]  f(x): 1.753033163918205e-09  grad at x: [-2.57511078e-06 -1.01453770e-05]  gradient norm: 1.0467085094263678e-05\n",
            "iter: 935184  x: [ 3.99995813 15.99966505]  f(x): 1.7529795537153576e-09  grad at x: [ 8.10713711e-05 -2.06006680e-05]  gradient norm: 8.364780177484763e-05\n",
            "iter: 935185  x: [ 3.99995813 15.99966505]  f(x): 1.7529261699163015e-09  grad at x: [-2.57582949e-06 -1.01449677e-05]  gradient norm: 1.0466865247913095e-05\n",
            "iter: 935186  x: [ 3.99995814 15.99966506]  f(x): 1.752872627170897e-09  grad at x: [ 8.11199552e-05 -2.06064215e-05]  gradient norm: 8.36963066315658e-05\n",
            "iter: 935187  x: [ 3.99995813 15.99966506]  f(x): 1.7528191824518645e-09  grad at x: [-2.57654828e-06 -1.01445585e-05]  gradient norm: 1.046664548154012e-05\n",
            "iter: 935188  x: [ 3.99995814 15.99966507]  f(x): 1.752779067863745e-09  grad at x: [ 3.92959882e-05 -1.53783658e-05]  gradient norm: 4.219797178874871e-05\n",
            "iter: 935189  x: [ 3.99995813 15.99966507]  f(x): 1.7527648590492297e-09  grad at x: [-1.92265751e-06 -1.02261311e-05]  gradient norm: 1.040530481184487e-05\n",
            "iter: 935190  x: [ 3.99995814 15.99966511]  f(x): 1.7525495913036651e-09  grad at x: [ 1.63049606e-04 -3.08460021e-05]  gradient norm: 0.00016594170594490655\n",
            "iter: 935191  x: [ 3.99995814 15.99966511]  f(x): 1.7523926375636697e-09  grad at x: [ 7.95961623e-05 -2.04145235e-05]  gradient norm: 8.217239090640089e-05\n",
            "iter: 935192  x: [ 3.99995814 15.99966511]  f(x): 1.7523410914170707e-09  grad at x: [-2.55254020e-06 -1.01461319e-05]  gradient norm: 1.0462287226163104e-05\n",
            "iter: 935193  x: [ 3.99995814 15.99966512]  f(x): 1.7522857439646264e-09  grad at x: [ 7.96433926e-05 -2.04201078e-05]  gradient norm: 8.221952805852095e-05\n",
            "iter: 935194  x: [ 3.99995814 15.99966512]  f(x): 1.7522341396724814e-09  grad at x: [-2.55324487e-06 -1.01457244e-05]  gradient norm: 1.0462064034887126e-05\n",
            "iter: 935195  x: [ 3.99995814 15.99966513]  f(x): 1.7521788574295693e-09  grad at x: [ 7.96910449e-05 -2.04257449e-05]  gradient norm: 8.226708751618252e-05\n",
            "iter: 935196  x: [ 3.99995814 15.99966513]  f(x): 1.7521271944442672e-09  grad at x: [-2.55393505e-06 -1.01453188e-05]  gradient norm: 1.0461839132373613e-05\n",
            "iter: 935197  x: [ 3.99995814 15.99966514]  f(x): 1.7520719763301808e-09  grad at x: [ 7.97377803e-05 -2.04312673e-05]  gradient norm: 8.231373084903968e-05\n",
            "iter: 935198  x: [ 3.99995814 15.99966514]  f(x): 1.7520202557332637e-09  grad at x: [-2.55463987e-06 -1.01449114e-05]  gradient norm: 1.0461616095113557e-05\n",
            "iter: 935199  x: [ 3.99995815 15.99966515]  f(x): 1.751965102933604e-09  grad at x: [ 7.97854324e-05 -2.04369044e-05]  gradient norm: 8.236129113213509e-05\n",
            "iter: 935200  x: [ 3.99995814 15.99966515]  f(x): 1.751913323558328e-09  grad at x: [-2.55537387e-06 -1.01445003e-05]  gradient norm: 1.0461396716832831e-05\n",
            "iter: 935201  x: [ 3.99995815 15.99966516]  f(x): 1.7518582384469874e-09  grad at x: [ 7.98349907e-05 -2.04427797e-05]  gradient norm: 8.241075769723971e-05\n",
            "iter: 935202  x: [ 3.99995815 15.99966516]  f(x): 1.7518063979168923e-09  grad at x: [-2.55607885e-06 -1.01440928e-05]  gradient norm: 1.0461173836939872e-05\n",
            "iter: 935203  x: [ 3.99995815 15.99966517]  f(x): 1.7517513781525722e-09  grad at x: [ 7.98826426e-05 -2.04484168e-05]  gradient norm: 8.245831883176291e-05\n",
            "iter: 935204  x: [ 3.99995815 15.99966517]  f(x): 1.7516994787917725e-09  grad at x: [-2.55679845e-06 -1.01436835e-05]  gradient norm: 1.0460952827851177e-05\n",
            "iter: 935205  x: [ 3.99995815 15.99966518]  f(x): 1.7516445255989263e-09  grad at x: [ 7.99312404e-05 -2.04541720e-05]  gradient norm: 8.250682605641694e-05\n",
            "iter: 935206  x: [ 3.99995815 15.99966518]  f(x): 1.7515925662006887e-09  grad at x: [-2.55751813e-06 -1.01432743e-05]  gradient norm: 1.0460731898500064e-05\n",
            "iter: 935207  x: [ 3.99995815 15.99966519]  f(x): 1.7515376796504144e-09  grad at x: [ 7.99798672e-05 -2.04599310e-05]  gradient norm: 8.255536281053948e-05\n",
            "iter: 935208  x: [ 3.99995815 15.99966519]  f(x): 1.7514856601241892e-09  grad at x: [-2.55822334e-06 -1.01428668e-05]  gradient norm: 1.0460509253833567e-05\n",
            "iter: 935209  x: [ 3.99995815 15.9996652 ]  f(x): 1.751430839133156e-09  grad at x: [ 8.00275771e-05 -2.04655753e-05]  gradient norm: 8.260298340109509e-05\n",
            "iter: 935210  x: [ 3.99995815 15.9996652 ]  f(x): 1.7513787605822639e-09  grad at x: [-2.55895773e-06 -1.01424557e-05]  gradient norm: 1.0460290279529153e-05\n",
            "iter: 935211  x: [ 3.99995815 15.99966521]  f(x): 1.751324007460364e-09  grad at x: [ 8.00771351e-05 -2.04714506e-05]  gradient norm: 8.265245216535043e-05\n",
            "iter: 935212  x: [ 3.99995815 15.99966521]  f(x): 1.7512718675723419e-09  grad at x: [-2.55966310e-06 -1.01420483e-05]  gradient norm: 1.046006779287393e-05\n",
            "iter: 935213  x: [ 3.99995815 15.99966522]  f(x): 1.7512171800068262e-09  grad at x: [ 8.01248157e-05 -2.04770913e-05]  gradient norm: 8.270004450018646e-05\n",
            "iter: 935214  x: [ 3.99995815 15.99966522]  f(x): 1.7511649810772442e-09  grad at x: [-2.56038309e-06 -1.01416390e-05]  gradient norm: 1.045984718222499e-05\n",
            "iter: 935215  x: [ 3.99995816 15.99966523]  f(x): 1.751110360296097e-09  grad at x: [ 8.01734422e-05 -2.04828502e-05]  gradient norm: 8.27485829681084e-05\n",
            "iter: 935216  x: [ 3.99995815 15.99966523]  f(x): 1.7510581011135507e-09  grad at x: [-2.56107406e-06 -1.01412334e-05]  gradient norm: 1.0459623052663784e-05\n",
            "iter: 935217  x: [ 3.99995816 15.99966524]  f(x): 1.7510035448362958e-09  grad at x: [ 8.02202059e-05 -2.04883763e-05]  gradient norm: 8.279525949760882e-05\n",
            "iter: 935218  x: [ 3.99995816 15.99966524]  f(x): 1.7509512276640851e-09  grad at x: [-2.56177966e-06 -1.01408259e-05]  gradient norm: 1.0459400799150165e-05\n",
            "iter: 935219  x: [ 3.99995816 15.99966525]  f(x): 1.7508967371179886e-09  grad at x: [ 8.02679300e-05 -2.04940225e-05]  gradient norm: 8.284289671210988e-05\n",
            "iter: 935220  x: [ 3.99995816 15.99966525]  f(x): 1.7508443607285498e-09  grad at x: [-2.56249988e-06 -1.01404166e-05]  gradient norm: 1.0459180425194661e-05\n",
            "iter: 935221  x: [ 3.99995816 15.99966526]  f(x): 1.7507899371437202e-09  grad at x: [ 8.03165998e-05 -2.04997868e-05]  gradient norm: 8.289148008543956e-05\n",
            "iter: 935222  x: [ 3.99995816 15.99966526]  f(x): 1.7507375003246598e-09  grad at x: [-2.56322019e-06 -1.01400074e-05]  gradient norm: 1.0458960131580229e-05\n",
            "iter: 935223  x: [ 3.99995816 15.99966527]  f(x): 1.7506831436639309e-09  grad at x: [ 8.03652405e-05 -2.05055476e-05]  gradient norm: 8.29400347853498e-05\n",
            "iter: 935224  x: [ 3.99995816 15.99966527]  f(x): 1.750630646452116e-09  grad at x: [-2.56394057e-06 -1.01395981e-05]  gradient norm: 1.0458739917892807e-05\n",
            "iter: 935225  x: [ 3.99995816 15.99966528]  f(x): 1.750576356787566e-09  grad at x: [ 8.04138957e-05 -2.05113101e-05]  gradient norm: 8.298860446016648e-05\n",
            "iter: 935226  x: [ 3.99995816 15.99966528]  f(x): 1.7505237990914693e-09  grad at x: [-2.56464648e-06 -1.01391906e-05]  gradient norm: 1.0458517979161176e-05\n",
            "iter: 935227  x: [ 3.99995816 15.99966529]  f(x): 1.7504695752972938e-09  grad at x: [ 8.04616195e-05 -2.05169563e-05]  gradient norm: 8.303624333160555e-05\n",
            "iter: 935228  x: [ 3.99995816 15.99966529]  f(x): 1.750416958261571e-09  grad at x: [-2.56535247e-06 -1.01387832e-05]  gradient norm: 1.0458296118631096e-05\n",
            "iter: 935229  x: [ 3.99995817 15.9996653 ]  f(x): 1.7503628004078185e-09  grad at x: [ 8.05093723e-05 -2.05226061e-05]  gradient norm: 8.308391171076395e-05\n",
            "iter: 935230  x: [ 3.99995816 15.9996653 ]  f(x): 1.7503101239441116e-09  grad at x: [-2.56607309e-06 -1.01383739e-05]  gradient norm: 1.0458076143063048e-05\n",
            "iter: 935231  x: [ 3.99995817 15.99966531]  f(x): 1.7502560331921698e-09  grad at x: [ 8.05580272e-05 -2.05283686e-05]  gradient norm: 8.313248263793696e-05\n",
            "iter: 935232  x: [ 3.99995817 15.99966531]  f(x): 1.750203296156803e-09  grad at x: [-2.56679378e-06 -1.01379646e-05]  gradient norm: 1.0457856247724064e-05\n",
            "iter: 935233  x: [ 3.99995817 15.99966532]  f(x): 1.7501492725781318e-09  grad at x: [ 8.06067112e-05 -2.05341348e-05]  gradient norm: 8.318108308968052e-05\n",
            "iter: 935234  x: [ 3.99995817 15.99966532]  f(x): 1.7500964748633298e-09  grad at x: [-2.56754366e-06 -1.01375517e-05]  gradient norm: 1.0457640051495191e-05\n",
            "iter: 935235  x: [ 3.99995817 15.99966533]  f(x): 1.7500425208220907e-09  grad at x: [ 8.06572578e-05 -2.05401338e-05]  gradient norm: 8.323154649221285e-05\n",
            "iter: 935236  x: [ 3.99995817 15.99966533]  f(x): 1.7499896601162789e-09  grad at x: [-2.56824996e-06 -1.01371443e-05]  gradient norm: 1.045741850835026e-05\n",
            "iter: 935237  x: [ 3.99995817 15.99966534]  f(x): 1.749935772156181e-09  grad at x: [ 8.07050103e-05 -2.05457836e-05]  gradient norm: 8.327921653091761e-05\n",
            "iter: 935238  x: [ 3.99995817 15.99966534]  f(x): 1.7498828518804748e-09  grad at x: [-2.56897089e-06 -1.01367350e-05]  gradient norm: 1.0457198854720049e-05\n",
            "iter: 935239  x: [ 3.99995817 15.99966535]  f(x): 1.7498290312373205e-09  grad at x: [ 8.07537231e-05 -2.05515535e-05]  gradient norm: 8.332784735690205e-05\n",
            "iter: 935240  x: [ 3.99995817 15.99966535]  f(x): 1.7497760501736266e-09  grad at x: [-2.56969190e-06 -1.01363257e-05]  gradient norm: 1.0456979281403799e-05\n",
            "iter: 935241  x: [ 3.99995817 15.99966536]  f(x): 1.74972229684728e-09  grad at x: [ 8.08024068e-05 -2.05573197e-05]  gradient norm: 8.337644949816014e-05\n",
            "iter: 935242  x: [ 3.99995817 15.99966536]  f(x): 1.7496692549774295e-09  grad at x: [-2.57042753e-06 -1.01359146e-05]  gradient norm: 1.0456761602531172e-05\n",
            "iter: 935243  x: [ 3.99995817 15.99966537]  f(x): 1.7496155702065012e-09  grad at x: [ 8.08520508e-05 -2.05632059e-05]  gradient norm: 8.342601246326654e-05\n",
            "iter: 935244  x: [ 3.99995817 15.99966537]  f(x): 1.749562466290445e-09  grad at x: [-2.57114870e-06 -1.01355054e-05]  gradient norm: 1.0456542190801077e-05\n",
            "iter: 935245  x: [ 3.99995818 15.99966538]  f(x): 1.7495088489443779e-09  grad at x: [ 8.09007634e-05 -2.05689757e-05]  gradient norm: 8.34746445532237e-05\n",
            "iter: 935246  x: [ 3.99995817 15.99966538]  f(x): 1.7494556841315207e-09  grad at x: [-2.57186994e-06 -1.01350961e-05]  gradient norm: 1.0456322859448643e-05\n",
            "iter: 935247  x: [ 3.99995818 15.99966539]  f(x): 1.7494021342095142e-09  grad at x: [ 8.09494614e-05 -2.05747438e-05]  gradient norm: 8.352326251000605e-05\n",
            "iter: 935248  x: [ 3.99995818 15.99966539]  f(x): 1.7493489084812119e-09  grad at x: [-2.57257671e-06 -1.01346886e-05]  gradient norm: 1.045610179126597e-05\n",
            "iter: 935249  x: [ 3.99995818 15.9996654 ]  f(x): 1.7492954248864804e-09  grad at x: [ 8.09972425e-05 -2.05803972e-05]  gradient norm: 8.35709641055028e-05\n",
            "iter: 935250  x: [ 3.99995818 15.99966541]  f(x): 1.7492421393583654e-09  grad at x: [-2.57328355e-06 -1.01342812e-05]  gradient norm: 1.0455880801078502e-05\n",
            "iter: 935251  x: [ 3.99995818 15.99966542]  f(x): 1.7491887221252869e-09  grad at x: [ 8.10450235e-05 -2.05860506e-05]  gradient norm: 8.361866609827152e-05\n",
            "iter: 935252  x: [ 3.99995818 15.99966542]  f(x): 1.7491353767266791e-09  grad at x: [-2.57401958e-06 -1.01338701e-05]  gradient norm: 1.0455663527976464e-05\n",
            "iter: 935253  x: [ 3.99995818 15.99966542]  f(x): 1.7490953499408693e-09  grad at x: [ 3.92603311e-05 -1.53629044e-05]  gradient norm: 4.2159132182143426e-05\n",
            "iter: 935254  x: [ 3.99995818 15.99966542]  f(x): 1.749081167493846e-09  grad at x: [-1.92072681e-06 -1.02153681e-05]  gradient norm: 1.0394370435368873e-05\n",
            "iter: 935255  x: [ 3.99995819 15.99966546]  f(x): 1.7488664111270734e-09  grad at x: [ 1.62901713e-04 -3.08165127e-05]  gradient norm: 0.00016579090888894641\n",
            "iter: 935256  x: [ 3.99995818 15.99966546]  f(x): 1.7487097426012164e-09  grad at x: [ 7.95240708e-05 -2.03945092e-05]  gradient norm: 8.20975873343545e-05\n",
            "iter: 935257  x: [ 3.99995818 15.99966546]  f(x): 1.7486582904814725e-09  grad at x: [-2.55005262e-06 -1.01354399e-05]  gradient norm: 1.0451311395668296e-05\n",
            "iter: 935258  x: [ 3.99995819 15.99966547]  f(x): 1.7486030748351519e-09  grad at x: [ 7.95722152e-05 -2.04002081e-05]  gradient norm: 8.214563852534221e-05\n",
            "iter: 935259  x: [ 3.99995818 15.99966547]  f(x): 1.74855156351219e-09  grad at x: [-2.55074541e-06 -1.01350342e-05]  gradient norm: 1.045108708699874e-05\n",
            "iter: 935260  x: [ 3.99995819 15.99966548]  f(x): 1.748496412072843e-09  grad at x: [ 7.96190935e-05 -2.04057487e-05]  gradient norm: 8.219242445056205e-05\n",
            "iter: 935261  x: [ 3.99995819 15.99966548]  f(x): 1.7484448430501351e-09  grad at x: [-2.55145284e-06 -1.01346268e-05]  gradient norm: 1.0450864642766981e-05\n",
            "iter: 935262  x: [ 3.99995819 15.99966549]  f(x): 1.7483897570001164e-09  grad at x: [ 7.96669177e-05 -2.04114076e-05]  gradient norm: 8.224015642272948e-05\n",
            "iter: 935263  x: [ 3.99995819 15.99966549]  f(x): 1.7483381290938784e-09  grad at x: [-2.55214579e-06 -1.01342212e-05]  gradient norm: 1.0450640486849746e-05\n",
            "iter: 935264  x: [ 3.99995819 15.9996655 ]  f(x): 1.7482831073530668e-09  grad at x: [ 7.97138249e-05 -2.04169519e-05]  gradient norm: 8.228697225994465e-05\n",
            "iter: 935265  x: [ 3.99995819 15.9996655 ]  f(x): 1.748231421662256e-09  grad at x: [-2.55283882e-06 -1.01338155e-05]  gradient norm: 1.0450416406910887e-05\n",
            "iter: 935266  x: [ 3.99995819 15.99966551]  f(x): 1.74817646426377e-09  grad at x: [ 7.97607321e-05 -2.04224962e-05]  gradient norm: 8.233378849884082e-05\n",
            "iter: 935267  x: [ 3.99995819 15.99966551]  f(x): 1.7481247207369688e-09  grad at x: [-2.55354648e-06 -1.01334081e-05]  gradient norm: 1.0450194194713251e-05\n",
            "iter: 935268  x: [ 3.99995819 15.99966552]  f(x): 1.7480698288660928e-09  grad at x: [ 7.98085705e-05 -2.04281569e-05]  gradient norm: 8.238153626018046e-05\n",
            "iter: 935269  x: [ 3.99995819 15.99966552]  f(x): 1.7480180262997194e-09  grad at x: [-2.55428332e-06 -1.01329970e-05]  gradient norm: 1.044997564687241e-05\n",
            "iter: 935270  x: [ 3.99995819 15.99966553]  f(x): 1.747963202332945e-09  grad at x: [ 7.98582861e-05 -2.04340522e-05]  gradient norm: 8.243116124853903e-05\n",
            "iter: 935271  x: [ 3.99995819 15.99966553]  f(x): 1.7479113384042102e-09  grad at x: [-2.55500569e-06 -1.01325877e-05]  gradient norm: 1.0449755387687696e-05\n",
            "iter: 935272  x: [ 3.9999582  15.99966554]  f(x): 1.7478565812243912e-09  grad at x: [ 7.99070848e-05 -2.04398330e-05]  gradient norm: 8.247987010163135e-05\n",
            "iter: 935273  x: [ 3.99995819 15.99966554]  f(x): 1.7478046570141437e-09  grad at x: [-2.55574269e-06 -1.01321766e-05]  gradient norm: 1.044953700407077e-05\n",
            "iter: 935274  x: [ 3.9999582  15.99966555]  f(x): 1.7477499678114281e-09  grad at x: [ 7.99568148e-05 -2.04457301e-05]  gradient norm: 8.252951053818417e-05\n",
            "iter: 935275  x: [ 3.9999582  15.99966555]  f(x): 1.7476979821460851e-09  grad at x: [-2.55645066e-06 -1.01317692e-05]  gradient norm: 1.0449315110007975e-05\n",
            "iter: 935276  x: [ 3.9999582  15.99966556]  f(x): 1.7476433586122811e-09  grad at x: [ 8.00046529e-05 -2.04513908e-05]  gradient norm: 8.257726001488775e-05\n",
            "iter: 935277  x: [ 3.9999582  15.99966556]  f(x): 1.747591313782873e-09  grad at x: [-2.55717326e-06 -1.01313599e-05]  gradient norm: 1.0449095091989888e-05\n",
            "iter: 935278  x: [ 3.9999582  15.99966557]  f(x): 1.7475367571436368e-09  grad at x: [ 8.00534514e-05 -2.04571716e-05]  gradient norm: 8.262597017107382e-05\n",
            "iter: 935279  x: [ 3.9999582  15.99966557]  f(x): 1.74748465192421e-09  grad at x: [-2.55791049e-06 -1.01309488e-05]  gradient norm: 1.0448876952949362e-05\n",
            "iter: 935280  x: [ 3.9999582  15.99966558]  f(x): 1.7474301634073411e-09  grad at x: [ 8.01032102e-05 -2.04630724e-05]  gradient norm: 8.267564103617021e-05\n",
            "iter: 935281  x: [ 3.9999582  15.99966558]  f(x): 1.747377996586659e-09  grad at x: [-2.55861870e-06 -1.01305413e-05]  gradient norm: 1.0448655297051613e-05\n",
            "iter: 935282  x: [ 3.9999582  15.99966559]  f(x): 1.7473235738797867e-09  grad at x: [ 8.01510772e-05 -2.04687367e-05]  gradient norm: 8.272342088292538e-05\n",
            "iter: 935283  x: [ 3.9999582  15.99966559]  f(x): 1.7472713477530616e-09  grad at x: [-2.55934154e-06 -1.01301321e-05]  gradient norm: 1.0448435520173764e-05\n",
            "iter: 935284  x: [ 3.9999582 15.9996656]  f(x): 1.7472169920476582e-09  grad at x: [ 8.01998900e-05 -2.04745193e-05]  gradient norm: 8.277214688600183e-05\n",
            "iter: 935285  x: [ 3.9999582 15.9996656]  f(x): 1.7471647054219839e-09  grad at x: [-2.56004990e-06 -1.01297246e-05]  gradient norm: 1.0448214021627458e-05\n",
            "iter: 935286  x: [ 3.9999582  15.99966561]  f(x): 1.7471104155962788e-09  grad at x: [ 8.02477569e-05 -2.04801836e-05]  gradient norm: 8.281992756626252e-05\n",
            "iter: 935287  x: [ 3.9999582  15.99966561]  f(x): 1.7470580696122587e-09  grad at x: [-2.56075834e-06 -1.01293172e-05]  gradient norm: 1.0447992601675575e-05\n",
            "iter: 935288  x: [ 3.99995821 15.99966562]  f(x): 1.7470038457364148e-09  grad at x: [ 8.02956527e-05 -2.04858516e-05]  gradient norm: 8.286773775725213e-05\n",
            "iter: 935289  x: [ 3.9999582  15.99966562]  f(x): 1.7469514403055937e-09  grad at x: [-2.56148140e-06 -1.01289079e-05]  gradient norm: 1.0447773064113836e-05\n",
            "iter: 935290  x: [ 3.99995821 15.99966563]  f(x): 1.7468972835739322e-09  grad at x: [ 8.03444798e-05 -2.04916360e-05]  gradient norm: 8.29164795818243e-05\n",
            "iter: 935291  x: [ 3.99995821 15.99966563]  f(x): 1.746844817500555e-09  grad at x: [-2.56219000e-06 -1.01285004e-05]  gradient norm: 1.0447551801856566e-05\n",
            "iter: 935292  x: [ 3.99995821 15.99966564]  f(x): 1.7467907267885299e-09  grad at x: [ 8.03923756e-05 -2.04973039e-05]  gradient norm: 8.296429060214519e-05\n",
            "iter: 935293  x: [ 3.99995821 15.99966564]  f(x): 1.7467382012159734e-09  grad at x: [-2.56289867e-06 -1.01280930e-05]  gradient norm: 1.0447330618038823e-05\n",
            "iter: 935294  x: [ 3.99995821 15.99966565]  f(x): 1.7466841765938543e-09  grad at x: [ 8.04403003e-05 -2.05029755e-05]  gradient norm: 8.301213113549572e-05\n",
            "iter: 935295  x: [ 3.99995821 15.99966565]  f(x): 1.7466315914335595e-09  grad at x: [-2.56362198e-06 -1.01276837e-05]  gradient norm: 1.0447111319982758e-05\n",
            "iter: 935296  x: [ 3.99995821 15.99966566]  f(x): 1.7465776340620176e-09  grad at x: [ 8.04891272e-05 -2.05087599e-05]  gradient norm: 8.306087422307163e-05\n",
            "iter: 935297  x: [ 3.99995821 15.99966567]  f(x): 1.746524988151878e-09  grad at x: [-2.56433080e-06 -1.01272763e-05]  gradient norm: 1.0446890293985203e-05\n",
            "iter: 935298  x: [ 3.99995821 15.99966567]  f(x): 1.7464710969400803e-09  grad at x: [ 8.05370517e-05 -2.05144315e-05]  gradient norm: 8.310871557974168e-05\n",
            "iter: 935299  x: [ 3.99995821 15.99966568]  f(x): 1.7464183913717698e-09  grad at x: [-2.56505426e-06 -1.01268670e-05]  gradient norm: 1.0446671156004489e-05\n",
            "iter: 935300  x: [ 3.99995821 15.99966569]  f(x): 1.7463645675175061e-09  grad at x: [ 8.05859076e-05 -2.05202196e-05]  gradient norm: 8.315748861308453e-05\n",
            "iter: 935301  x: [ 3.99995821 15.99966569]  f(x): 1.7463118011109264e-09  grad at x: [-2.56577780e-06 -1.01264577e-05]  gradient norm: 1.0446452098760673e-05\n",
            "iter: 935302  x: [ 3.99995821 15.9996657 ]  f(x): 1.7462580446501582e-09  grad at x: [ 8.06347633e-05 -2.05260076e-05]  gradient norm: 8.320626206875071e-05\n",
            "iter: 935303  x: [ 3.99995821 15.9996657 ]  f(x): 1.7462052173499217e-09  grad at x: [-2.56648686e-06 -1.01260503e-05]  gradient norm: 1.044623131030802e-05\n",
            "iter: 935304  x: [ 3.99995822 15.99966571]  f(x): 1.746151527154025e-09  grad at x: [ 8.06826877e-05 -2.05316792e-05]  gradient norm: 8.325410466315955e-05\n",
            "iter: 935305  x: [ 3.99995821 15.99966571]  f(x): 1.7460986400895977e-09  grad at x: [-2.56721055e-06 -1.01256410e-05]  gradient norm: 1.0446012413266302e-05\n",
            "iter: 935306  x: [ 3.99995822 15.99966572]  f(x): 1.7460450173942815e-09  grad at x: [ 8.07315724e-05 -2.05374708e-05]  gradient norm: 8.330290805933962e-05\n",
            "iter: 935307  x: [ 3.99995822 15.99966572]  f(x): 1.7459920693296576e-09  grad at x: [-2.56794887e-06 -1.01252299e-05]  gradient norm: 1.044579541144548e-05\n",
            "iter: 935308  x: [ 3.99995822 15.99966573]  f(x): 1.7459385153010282e-09  grad at x: [ 8.07813593e-05 -2.05433753e-05]  gradient norm: 8.335261407730917e-05\n",
            "iter: 935309  x: [ 3.99995822 15.99966573]  f(x): 1.7458855050866494e-09  grad at x: [-2.56865817e-06 -1.01248224e-05]  gradient norm: 1.0445574861605957e-05\n",
            "iter: 935310  x: [ 3.99995822 15.99966574]  f(x): 1.7458320174646148e-09  grad at x: [ 8.08293125e-05 -2.05490505e-05]  gradient norm: 8.340048701382477e-05\n",
            "iter: 935311  x: [ 3.99995822 15.99966574]  f(x): 1.7457789473434295e-09  grad at x: [-2.56938209e-06 -1.01244132e-05]  gradient norm: 1.0445356207029982e-05\n",
            "iter: 935312  x: [ 3.99995822 15.99966575]  f(x): 1.7457255273299698e-09  grad at x: [ 8.08781970e-05 -2.05548422e-05]  gradient norm: 8.344929167475926e-05\n",
            "iter: 935313  x: [ 3.99995822 15.99966575]  f(x): 1.745672396099701e-09  grad at x: [-2.57012065e-06 -1.01240021e-05]  gradient norm: 1.0445139450655414e-05\n",
            "iter: 935314  x: [ 3.99995822 15.99966576]  f(x): 1.7456190448988786e-09  grad at x: [ 8.09280127e-05 -2.05607503e-05]  gradient norm: 8.349902808447854e-05\n",
            "iter: 935315  x: [ 3.99995822 15.99966576]  f(x): 1.7455658513540255e-09  grad at x: [-2.57084473e-06 -1.01235928e-05]  gradient norm: 1.044492095851071e-05\n",
            "iter: 935316  x: [ 3.99995822 15.99966577]  f(x): 1.745512567834483e-09  grad at x: [ 8.09768970e-05 -2.05665419e-05]  gradient norm: 8.354783359220425e-05\n",
            "iter: 935317  x: [ 3.99995822 15.99966577]  f(x): 1.7454726266490617e-09  grad at x: [ 3.92026713e-05 -1.53448636e-05]  gradient norm: 4.209886316706386e-05\n",
            "iter: 935318  x: [ 3.99995822 15.99966577]  f(x): 1.7454584840692194e-09  grad at x: [-1.91847562e-06 -1.02048161e-05]  gradient norm: 1.0383584210285648e-05\n",
            "iter: 935319  x: [ 3.99995823 15.99966581]  f(x): 1.745244003340092e-09  grad at x: [ 1.62665314e-04 -3.07761311e-05]  gradient norm: 0.00016555112367763294\n",
            "iter: 935320  x: [ 3.99995823 15.99966581]  f(x): 1.7450877874784267e-09  grad at x: [ 7.94083814e-05 -2.03692161e-05]  gradient norm: 8.197924132299019e-05\n",
            "iter: 935321  x: [ 3.99995823 15.99966581]  f(x): 1.7450364829328587e-09  grad at x: [-2.54688057e-06 -1.01250043e-05]  gradient norm: 1.0440417302902342e-05\n",
            "iter: 935322  x: [ 3.99995823 15.99966582]  f(x): 1.7449813398820218e-09  grad at x: [ 7.94558684e-05 -2.03748332e-05]  gradient norm: 8.202663496028318e-05\n",
            "iter: 935323  x: [ 3.99995823 15.99966582]  f(x): 1.7449299770167074e-09  grad at x: [-2.54759056e-06 -1.01245969e-05]  gradient norm: 1.0440195387247099e-05\n",
            "iter: 935324  x: [ 3.99995823 15.99966583]  f(x): 1.7448748994351935e-09  grad at x: [ 7.95038500e-05 -2.03805121e-05]  gradient norm: 8.207452365023403e-05\n",
            "iter: 935325  x: [ 3.99995823 15.99966583]  f(x): 1.7448234775965394e-09  grad at x: [-2.54828608e-06 -1.01241912e-05]  gradient norm: 1.0439971762131658e-05\n",
            "iter: 935326  x: [ 3.99995823 15.99966584]  f(x): 1.7447684643705228e-09  grad at x: [ 7.95509002e-05 -2.03860745e-05]  gradient norm: 8.212148168066512e-05\n",
            "iter: 935327  x: [ 3.99995823 15.99966584]  f(x): 1.7447169846731887e-09  grad at x: [-2.54899623e-06 -1.01237838e-05]  gradient norm: 1.0439750002493998e-05\n",
            "iter: 935328  x: [ 3.99995823 15.99966585]  f(x): 1.744662037020512e-09  grad at x: [ 7.95989107e-05 -2.03917571e-05]  gradient norm: 8.216940030938017e-05\n",
            "iter: 935329  x: [ 3.99995823 15.99966585]  f(x): 1.7446104982463585e-09  grad at x: [-2.54972101e-06 -1.01233745e-05]  gradient norm: 1.0439530111434693e-05\n",
            "iter: 935330  x: [ 3.99995823 15.99966586]  f(x): 1.7445556173516015e-09  grad at x: [ 7.96478526e-05 -2.03975560e-05]  gradient norm: 8.22182504675854e-05\n",
            "iter: 935331  x: [ 3.99995823 15.99966586]  f(x): 1.74450401831462e-09  grad at x: [-2.55043131e-06 -1.01229671e-05]  gradient norm: 1.0439308509879086e-05\n",
            "iter: 935332  x: [ 3.99995824 15.99966587]  f(x): 1.7444492030633173e-09  grad at x: [ 7.96958630e-05 -2.04032385e-05]  gradient norm: 8.226616995496875e-05\n",
            "iter: 935333  x: [ 3.99995823 15.99966587]  f(x): 1.744397544896789e-09  grad at x: [-2.55114170e-06 -1.01225596e-05]  gradient norm: 1.0439086986737864e-05\n",
            "iter: 935334  x: [ 3.99995824 15.99966588]  f(x): 1.7443427953236557e-09  grad at x: [ 7.97438733e-05 -2.04089210e-05]  gradient norm: 8.231408986316927e-05\n",
            "iter: 935335  x: [ 3.99995824 15.99966588]  f(x): 1.7442910779745865e-09  grad at x: [-2.55186671e-06 -1.01221503e-05]  gradient norm: 1.0438867335989919e-05\n",
            "iter: 935336  x: [ 3.99995824 15.99966589]  f(x): 1.7442363952662594e-09  grad at x: [ 7.97928149e-05 -2.04147200e-05]  gradient norm: 8.236294132940023e-05\n",
            "iter: 935337  x: [ 3.99995824 15.99966589]  f(x): 1.7441846175465823e-09  grad at x: [-2.55257725e-06 -1.01217429e-05]  gradient norm: 1.0438645971056641e-05\n",
            "iter: 935338  x: [ 3.99995824 15.9996659 ]  f(x): 1.7441300006219954e-09  grad at x: [ 7.98408542e-05 -2.04204061e-05]  gradient norm: 8.241089118859066e-05\n",
            "iter: 935339  x: [ 3.99995824 15.9996659 ]  f(x): 1.7440781636315916e-09  grad at x: [-2.55328786e-06 -1.01213354e-05]  gradient norm: 1.0438424685034832e-05\n",
            "iter: 935340  x: [ 3.99995824 15.99966591]  f(x): 1.7440236124537394e-09  grad at x: [ 7.98888497e-05 -2.04260868e-05]  gradient norm: 8.245879782134661e-05\n",
            "iter: 935341  x: [ 3.99995824 15.99966591]  f(x): 1.743971716192225e-09  grad at x: [-2.55399856e-06 -1.01209280e-05]  gradient norm: 1.043820347751102e-05\n",
            "iter: 935342  x: [ 3.99995824 15.99966592]  f(x): 1.7439172308675977e-09  grad at x: [ 7.99368889e-05 -2.04317730e-05]  gradient norm: 8.250674852191395e-05\n",
            "iter: 935343  x: [ 3.99995824 15.99966592]  f(x): 1.7438652752472987e-09  grad at x: [-2.55472388e-06 -1.01205187e-05]  gradient norm: 1.0437984146449224e-05\n",
            "iter: 935344  x: [ 3.99995824 15.99966593]  f(x): 1.743810856965316e-09  grad at x: [ 7.99858593e-05 -2.04375756e-05]  gradient norm: 8.255563081258516e-05\n",
            "iter: 935345  x: [ 3.99995824 15.99966593]  f(x): 1.7437588408133588e-09  grad at x: [-2.55542018e-06 -1.01201131e-05]  gradient norm: 1.043776129825793e-05\n",
            "iter: 935346  x: [ 3.99995824 15.99966594]  f(x): 1.743704487299454e-09  grad at x: [ 8.00329669e-05 -2.04431453e-05]  gradient norm: 8.26026511801252e-05\n",
            "iter: 935347  x: [ 3.99995824 15.99966594]  f(x): 1.7436524128732638e-09  grad at x: [-2.55613110e-06 -1.01197056e-05]  gradient norm: 1.0437540326787848e-05\n",
            "iter: 935348  x: [ 3.99995825 15.99966595]  f(x): 1.7435981253887448e-09  grad at x: [ 8.00810495e-05 -2.04488369e-05]  gradient norm: 8.265064678465864e-05\n",
            "iter: 935349  x: [ 3.99995824 15.99966595]  f(x): 1.7435459914267172e-09  grad at x: [-2.55685666e-06 -1.01192963e-05]  gradient norm: 1.0437321235143168e-05\n",
            "iter: 935350  x: [ 3.99995825 15.99966596]  f(x): 1.7434917710911924e-09  grad at x: [ 8.01300196e-05 -2.04546395e-05]  gradient norm: 8.269953035404554e-05\n",
            "iter: 935351  x: [ 3.99995825 15.99966596]  f(x): 1.7434395764734225e-09  grad at x: [-2.55759685e-06 -1.01188853e-05]  gradient norm: 1.0437104026924834e-05\n",
            "iter: 935352  x: [ 3.99995825 15.99966597]  f(x): 1.7433854245160506e-09  grad at x: [ 8.01799501e-05 -2.04605622e-05]  gradient norm: 8.274937466465266e-05\n",
            "iter: 935353  x: [ 3.99995825 15.99966597]  f(x): 1.7433331680119472e-09  grad at x: [-2.55832256e-06 -1.01184760e-05]  gradient norm: 1.043688509850489e-05\n",
            "iter: 935354  x: [ 3.99995825 15.99966598]  f(x): 1.743279083312185e-09  grad at x: [ 8.02289492e-05 -2.04663684e-05]  gradient norm: 8.279828820968236e-05\n",
            "iter: 935355  x: [ 3.99995825 15.99966598]  f(x): 1.7432267660431297e-09  grad at x: [-2.55906290e-06 -1.01180649e-05]  gradient norm: 1.0436668055598869e-05\n",
            "iter: 935356  x: [ 3.99995825 15.99966599]  f(x): 1.7431727497959763e-09  grad at x: [ 8.02788796e-05 -2.04722910e-05]  gradient norm: 8.284813341530386e-05\n",
            "iter: 935357  x: [ 3.99995825 15.99966599]  f(x): 1.7431203705655373e-09  grad at x: [-2.55978877e-06 -1.01176556e-05]  gradient norm: 1.0436449290271943e-05\n",
            "iter: 935358  x: [ 3.99995825 15.999666  ]  f(x): 1.7430664216490444e-09  grad at x: [ 8.03278786e-05 -2.04780972e-05]  gradient norm: 8.28970478349278e-05\n",
            "iter: 935359  x: [ 3.99995825 15.999666  ]  f(x): 1.743013981597981e-09  grad at x: [-2.56051471e-06 -1.01172463e-05]  gradient norm: 1.0436230605854055e-05\n",
            "iter: 935360  x: [ 3.99995825 15.99966601]  f(x): 1.7429601000119378e-09  grad at x: [ 8.03768629e-05 -2.04839016e-05]  gradient norm: 8.294594813634653e-05\n",
            "iter: 935361  x: [ 3.99995825 15.99966601]  f(x): 1.7429075991210534e-09  grad at x: [-2.56122619e-06 -1.01168389e-05]  gradient norm: 1.0436010194572608e-05\n",
            "iter: 935362  x: [ 3.99995825 15.99966602]  f(x): 1.7428537838128226e-09  grad at x: [ 8.04249594e-05 -2.04895950e-05]  gradient norm: 8.299396126639442e-05\n",
            "iter: 935363  x: [ 3.99995825 15.99966602]  f(x): 1.7428012231355949e-09  grad at x: [-2.56195229e-06 -1.01164296e-05]  gradient norm: 1.043579167113286e-05\n",
            "iter: 935364  x: [ 3.99995826 15.99966603]  f(x): 1.742747475301609e-09  grad at x: [ 8.04739873e-05 -2.04954049e-05]  gradient norm: 8.304290606888405e-05\n",
            "iter: 935365  x: [ 3.99995826 15.99966603]  f(x): 1.7426948536401712e-09  grad at x: [-2.56266391e-06 -1.01160222e-05]  gradient norm: 1.0435571418648878e-05\n",
            "iter: 935366  x: [ 3.99995826 15.99966604]  f(x): 1.7426411721543633e-09  grad at x: [ 8.05220837e-05 -2.05010983e-05]  gradient norm: 8.30909200310794e-05\n",
            "iter: 935367  x: [ 3.99995826 15.99966604]  f(x): 1.7425884906356227e-09  grad at x: [-2.56339017e-06 -1.01156129e-05]  gradient norm: 1.0435353056490142e-05\n",
            "iter: 935368  x: [ 3.99995826 15.99966605]  f(x): 1.7425348766958045e-09  grad at x: [ 8.05711113e-05 -2.05069082e-05]  gradient norm: 8.313986568032627e-05\n",
            "iter: 935369  x: [ 3.99995826 15.99966605]  f(x): 1.7424821341205143e-09  grad at x: [-2.56410195e-06 -1.01152054e-05]  gradient norm: 1.0435132962669586e-05\n",
            "iter: 935370  x: [ 3.99995826 15.99966606]  f(x): 1.7424285865992397e-09  grad at x: [ 8.06192076e-05 -2.05126016e-05]  gradient norm: 8.318788046949816e-05\n",
            "iter: 935371  x: [ 3.99995826 15.99966606]  f(x): 1.7423757840956876e-09  grad at x: [-2.56482837e-06 -1.01147962e-05]  gradient norm: 1.0434914761658518e-05\n",
            "iter: 935372  x: [ 3.99995826 15.99966607]  f(x): 1.7423223042285946e-09  grad at x: [ 8.06682496e-05 -2.05184133e-05]  gradient norm: 8.323684151669205e-05\n",
            "iter: 935373  x: [ 3.99995826 15.99966607]  f(x): 1.7422694405608456e-09  grad at x: [-2.56556941e-06 -1.01143851e-05]  gradient norm: 1.0434698456408575e-05\n",
            "iter: 935374  x: [ 3.99995826 15.99966608]  f(x): 1.7422160295486213e-09  grad at x: [ 8.07182375e-05 -2.05243432e-05]  gradient norm: 8.328674884691754e-05\n",
            "iter: 935375  x: [ 3.99995826 15.99966608]  f(x): 1.7421631035336584e-09  grad at x: [-2.56631053e-06 -1.01139740e-05]  gradient norm: 1.0434482234721331e-05\n",
            "iter: 935376  x: [ 3.99995826 15.99966609]  f(x): 1.7421097613775015e-09  grad at x: [ 8.07682108e-05 -2.05302713e-05]  gradient norm: 8.333664206835351e-05\n",
            "iter: 935377  x: [ 3.99995826 15.99966609]  f(x): 1.7420567729767568e-09  grad at x: [-2.56705173e-06 -1.01135629e-05]  gradient norm: 1.0434266096618636e-05\n",
            "iter: 935378  x: [ 3.99995827 15.9996661 ]  f(x): 1.7420034997149044e-09  grad at x: [ 8.08181694e-05 -2.05361976e-05]  gradient norm: 8.338652118135582e-05\n",
            "iter: 935379  x: [ 3.99995826 15.9996661 ]  f(x): 1.74195044890781e-09  grad at x: [-2.56777845e-06 -1.01131536e-05]  gradient norm: 1.0434048223552801e-05\n",
            "iter: 935380  x: [ 3.99995827 15.99966611]  f(x): 1.7418972434825266e-09  grad at x: [ 8.08672548e-05 -2.05420147e-05]  gradient norm: 8.343552760791751e-05\n",
            "iter: 935381  x: [ 3.99995827 15.99966611]  f(x): 1.7418441313276611e-09  grad at x: [-2.56851980e-06 -1.01127425e-05]  gradient norm: 1.043383225132272e-05\n",
            "iter: 935382  x: [ 3.99995827 15.99966612]  f(x): 1.741804268865708e-09  grad at x: [ 3.91743394e-05 -1.53303408e-05]  gradient norm: 4.206718698610342e-05\n",
            "iter: 935383  x: [ 3.99995827 15.99966612]  f(x): 1.741790148044645e-09  grad at x: [-1.91665584e-06 -1.01940623e-05]  gradient norm: 1.03726792669734e-05\n",
            "iter: 935384  x: [ 3.99995827 15.99966616]  f(x): 1.7415762457626316e-09  grad at x: [ 1.62545381e-04 -3.07501596e-05]  gradient norm: 0.00016542845349826405\n",
            "iter: 935385  x: [ 3.99995827 15.99966616]  f(x): 1.7414202614915401e-09  grad at x: [ 7.93500618e-05 -2.03509462e-05]  gradient norm: 8.191821118623363e-05\n",
            "iter: 935386  x: [ 3.99995827 15.99966616]  f(x): 1.741369033801989e-09  grad at x: [-2.54460575e-06 -1.01143087e-05]  gradient norm: 1.04294898474558e-05\n",
            "iter: 935387  x: [ 3.99995827 15.99966617]  f(x): 1.741314038386782e-09  grad at x: [ 7.93981136e-05 -2.03566342e-05]  gradient norm: 8.196616985001327e-05\n",
            "iter: 935388  x: [ 3.99995827 15.99966617]  f(x): 1.7412627517356711e-09  grad at x: [-2.54530387e-06 -1.01139030e-05]  gradient norm: 1.0429266829218198e-05\n",
            "iter: 935389  x: [ 3.99995827 15.99966618]  f(x): 1.7412078207617029e-09  grad at x: [ 7.94453213e-05 -2.03622167e-05]  gradient norm: 8.201328514840015e-05\n",
            "iter: 935390  x: [ 3.99995827 15.99966618]  f(x): 1.7411564761371268e-09  grad at x: [-2.54600207e-06 -1.01134974e-05]  gradient norm: 1.0429043887585004e-05\n",
            "iter: 935391  x: [ 3.99995828 15.99966619]  f(x): 1.7411016097094347e-09  grad at x: [ 7.94925725e-05 -2.03678046e-05]  gradient norm: 8.206044450111754e-05\n",
            "iter: 935392  x: [ 3.99995827 15.99966619]  f(x): 1.7410502070251558e-09  grad at x: [-2.5467149e-06 -1.0113090e-05]  gradient norm: 1.042882281243656e-05\n",
            "iter: 935393  x: [ 3.99995828 15.9996662 ]  f(x): 1.7409954062903536e-09  grad at x: [ 7.95407259e-05 -2.03735053e-05]  gradient norm: 8.210850626991024e-05\n",
            "iter: 935394  x: [ 3.99995828 15.9996662 ]  f(x): 1.7409439443994618e-09  grad at x: [-2.54744236e-06 -1.01126807e-05]  gradient norm: 1.0428603606887863e-05\n",
            "iter: 935395  x: [ 3.99995828 15.99966621]  f(x): 1.7408892105768412e-09  grad at x: [ 7.95898397e-05 -2.03793261e-05]  gradient norm: 8.215752867412129e-05\n",
            "iter: 935396  x: [ 3.99995828 15.99966621]  f(x): 1.7408376882586175e-09  grad at x: [-2.54815534e-06 -1.01122732e-05]  gradient norm: 1.0428382690746492e-05\n",
            "iter: 935397  x: [ 3.99995828 15.99966622]  f(x): 1.7407830202348114e-09  grad at x: [ 7.96380221e-05 -2.03850304e-05]  gradient norm: 8.220562040454771e-05\n",
            "iter: 935398  x: [ 3.99995828 15.99966622]  f(x): 1.740731438621419e-09  grad at x: [-2.54886841e-06 -1.01118658e-05]  gradient norm: 1.0428161853696841e-05\n",
            "iter: 935399  x: [ 3.99995828 15.99966623]  f(x): 1.7406768364313952e-09  grad at x: [ 7.96862044e-05 -2.03907348e-05]  gradient norm: 8.225371256093174e-05\n",
            "iter: 935400  x: [ 3.99995828 15.99966623]  f(x): 1.7406251954505128e-09  grad at x: [-2.54958155e-06 -1.01114583e-05]  gradient norm: 1.0427941095325655e-05\n",
            "iter: 935401  x: [ 3.99995828 15.99966624]  f(x): 1.7405706591292414e-09  grad at x: [ 7.97343866e-05 -2.03964391e-05]  gradient norm: 8.230180514238937e-05\n",
            "iter: 935402  x: [ 3.99995828 15.99966624]  f(x): 1.7405189587646968e-09  grad at x: [-2.55030932e-06 -1.01110491e-05]  gradient norm: 1.0427722211509208e-05\n",
            "iter: 935403  x: [ 3.99995828 15.99966625]  f(x): 1.7404644894989152e-09  grad at x: [ 7.97835000e-05 -2.04022599e-05]  gradient norm: 8.235082929667401e-05\n",
            "iter: 935404  x: [ 3.99995828 15.99966625]  f(x): 1.7404127285625422e-09  grad at x: [-2.55102261e-06 -1.01106416e-05]  gradient norm: 1.0427501612530784e-05\n",
            "iter: 935405  x: [ 3.99995828 15.99966626]  f(x): 1.740358325271587e-09  grad at x: [ 7.98317112e-05 -2.04079679e-05]  gradient norm: 8.239895183462263e-05\n",
            "iter: 935406  x: [ 3.99995828 15.99966626]  f(x): 1.7403065048448848e-09  grad at x: [-2.55175054e-06 -1.01102323e-05]  gradient norm: 1.0427282889944216e-05\n",
            "iter: 935407  x: [ 3.99995829 15.99966627]  f(x): 1.7402521687169182e-09  grad at x: [ 7.98808536e-05 -2.04137923e-05]  gradient norm: 8.244800596270686e-05\n",
            "iter: 935408  x: [ 3.99995828 15.99966627]  f(x): 1.740200287628253e-09  grad at x: [-2.55244944e-06 -1.01098267e-05]  gradient norm: 1.04270606516877e-05\n",
            "iter: 935409  x: [ 3.99995829 15.99966628]  f(x): 1.7401460163919828e-09  grad at x: [ 7.99281333e-05 -2.04193839e-05]  gradient norm: 8.249519818033417e-05\n",
            "iter: 935410  x: [ 3.99995829 15.99966628]  f(x): 1.7400940768775658e-09  grad at x: [-2.55317752e-06 -1.01094174e-05]  gradient norm: 1.042684208972543e-05\n",
            "iter: 935411  x: [ 3.99995829 15.99966629]  f(x): 1.7400398728756743e-09  grad at x: [ 7.99772755e-05 -2.04252083e-05]  gradient norm: 8.254425317004483e-05\n",
            "iter: 935412  x: [ 3.99995829 15.99966629]  f(x): 1.7399878726093517e-09  grad at x: [-2.55389113e-06 -1.01090100e-05]  gradient norm: 1.042662180824654e-05\n",
            "iter: 935413  x: [ 3.99995829 15.9996663 ]  f(x): 1.7399337347230146e-09  grad at x: [ 8.00254864e-05 -2.04309163e-05]  gradient norm: 8.25923774055333e-05\n",
            "iter: 935414  x: [ 3.99995829 15.9996663 ]  f(x): 1.7398816748244484e-09  grad at x: [-2.55461936e-06 -1.01086007e-05]  gradient norm: 1.0426403407683623e-05\n",
            "iter: 935415  x: [ 3.99995829 15.99966631]  f(x): 1.7398276042445773e-09  grad at x: [ 8.00746285e-05 -2.04367407e-05]  gradient norm: 8.26414332642981e-05\n",
            "iter: 935416  x: [ 3.99995829 15.99966631]  f(x): 1.7397754835214244e-09  grad at x: [-2.55533313e-06 -1.01081932e-05]  gradient norm: 1.0426183285633383e-05\n",
            "iter: 935417  x: [ 3.99995829 15.99966632]  f(x): 1.739721479163395e-09  grad at x: [ 8.01228682e-05 -2.04424523e-05]  gradient norm: 8.268958744848726e-05\n",
            "iter: 935418  x: [ 3.99995829 15.99966632]  f(x): 1.7396692987190726e-09  grad at x: [-2.55604697e-06 -1.01077858e-05]  gradient norm: 1.0425963242885297e-05\n",
            "iter: 935419  x: [ 3.99995829 15.99966633]  f(x): 1.7396153605816133e-09  grad at x: [ 8.01710934e-05 -2.04481621e-05]  gradient norm: 8.273772750091943e-05\n",
            "iter: 935420  x: [ 3.99995829 15.99966633]  f(x): 1.7395631203800506e-09  grad at x: [-2.55676088e-06 -1.01073783e-05]  gradient norm: 1.0425743279024816e-05\n",
            "iter: 935421  x: [ 3.9999583  15.99966634]  f(x): 1.739509248570862e-09  grad at x: [ 8.02193476e-05 -2.04538755e-05]  gradient norm: 8.27858970725948e-05\n",
            "iter: 935422  x: [ 3.99995829 15.99966634]  f(x): 1.7394569485231525e-09  grad at x: [-2.55748943e-06 -1.01069691e-05]  gradient norm: 1.0425525201042347e-05\n",
            "iter: 935423  x: [ 3.9999583  15.99966635]  f(x): 1.739403144199618e-09  grad at x: [ 8.02685185e-05 -2.04597036e-05]  gradient norm: 8.283498374927314e-05\n",
            "iter: 935424  x: [ 3.9999583  15.99966635]  f(x): 1.7393507831289934e-09  grad at x: [-2.55821806e-06 -1.01065598e-05]  gradient norm: 1.0425307204439302e-05\n",
            "iter: 935425  x: [ 3.9999583  15.99966636]  f(x): 1.7392970463275498e-09  grad at x: [ 8.03176893e-05 -2.04655316e-05]  gradient norm: 8.288407086157883e-05\n",
            "iter: 935426  x: [ 3.9999583  15.99966636]  f(x): 1.739244624234319e-09  grad at x: [-2.55894676e-06 -1.01061505e-05]  gradient norm: 1.0425089289236989e-05\n",
            "iter: 935427  x: [ 3.9999583  15.99966637]  f(x): 1.7391909549550352e-09  grad at x: [ 8.03668455e-05 -2.04713579e-05]  gradient norm: 8.293314385626056e-05\n",
            "iter: 935428  x: [ 3.9999583  15.99966637]  f(x): 1.739138471801791e-09  grad at x: [-2.55967554e-06 -1.01057412e-05]  gradient norm: 1.0424871455674792e-05\n",
            "iter: 935429  x: [ 3.9999583  15.99966638]  f(x): 1.7390848701531702e-09  grad at x: [ 8.04160453e-05 -2.04771895e-05]  gradient norm: 8.298226093503625e-05\n",
            "iter: 935430  x: [ 3.9999583  15.99966638]  f(x): 1.7390323258490654e-09  grad at x: [-2.56038985e-06 -1.01053338e-05]  gradient norm: 1.0424651892734291e-05\n",
            "iter: 935431  x: [ 3.9999583  15.99966639]  f(x): 1.7389787907425238e-09  grad at x: [ 8.04643282e-05 -2.04829066e-05]  gradient norm: 8.303046172304619e-05\n",
            "iter: 935432  x: [ 3.9999583  15.99966639]  f(x): 1.738926186376982e-09  grad at x: [-2.56111878e-06 -1.01049245e-05]  gradient norm: 1.0424434220953597e-05\n",
            "iter: 935433  x: [ 3.9999583 15.9996664]  f(x): 1.738872718973372e-09  grad at x: [ 8.05135278e-05 -2.04887383e-05]  gradient norm: 8.307957965716658e-05\n",
            "iter: 935434  x: [ 3.9999583 15.9996664]  f(x): 1.738820053403194e-09  grad at x: [-2.56184780e-06 -1.01045152e-05]  gradient norm: 1.0424216631095426e-05\n",
            "iter: 935435  x: [ 3.9999583  15.99966641]  f(x): 1.7387666537025867e-09  grad at x: [ 8.05627128e-05 -2.04945682e-05]  gradient norm: 8.31286834700628e-05\n",
            "iter: 935436  x: [ 3.9999583  15.99966641]  f(x): 1.7387139268903677e-09  grad at x: [-2.56257689e-06 -1.01041060e-05]  gradient norm: 1.042399912252646e-05\n",
            "iter: 935437  x: [ 3.99995831 15.99966642]  f(x): 1.738660594965638e-09  grad at x: [ 8.06119122e-05 -2.05003998e-05]  gradient norm: 8.317780226307002e-05\n",
            "iter: 935438  x: [ 3.9999583  15.99966642]  f(x): 1.7386078068561566e-09  grad at x: [-2.56329150e-06 -1.01036985e-05]  gradient norm: 1.04237798803952e-05\n",
            "iter: 935439  x: [ 3.99995831 15.99966643]  f(x): 1.7385545416518018e-09  grad at x: [ 8.06602239e-05 -2.05061206e-05]  gradient norm: 8.322603382898828e-05\n",
            "iter: 935440  x: [ 3.99995831 15.99966643]  f(x): 1.7385016933014015e-09  grad at x: [-2.56402075e-06 -1.01032892e-05]  gradient norm: 1.0423562534214693e-05\n",
            "iter: 935441  x: [ 3.99995831 15.99966644]  f(x): 1.738448495945213e-09  grad at x: [ 8.07094232e-05 -2.05119522e-05]  gradient norm: 8.327515347051775e-05\n",
            "iter: 935442  x: [ 3.99995831 15.99966644]  f(x): 1.7383955862437527e-09  grad at x: [-2.56475007e-06 -1.01028800e-05]  gradient norm: 1.0423345269605687e-05\n",
            "iter: 935443  x: [ 3.99995831 15.99966645]  f(x): 1.7383424567716251e-09  grad at x: [ 8.07586370e-05 -2.05177857e-05]  gradient norm: 8.332428809191366e-05\n",
            "iter: 935444  x: [ 3.99995831 15.99966645]  f(x): 1.7382894856458815e-09  grad at x: [-2.56547948e-06 -1.01024707e-05]  gradient norm: 1.0423128086808107e-05\n",
            "iter: 935445  x: [ 3.99995831 15.99966646]  f(x): 1.7382364241307735e-09  grad at x: [ 8.08078653e-05 -2.05236211e-05]  gradient norm: 8.33734376909857e-05\n",
            "iter: 935446  x: [ 3.99995831 15.99966646]  f(x): 1.738196649520951e-09  grad at x: [ 3.91208209e-05 -1.53128403e-05]  gradient norm: 4.201097124977982e-05\n",
            "iter: 935447  x: [ 3.99995831 15.99966646]  f(x): 1.7381825659303696e-09  grad at x: [-1.91445451e-06 -1.01835267e-05]  gradient norm: 1.0361918345467821e-05\n",
            "iter: 935448  x: [ 3.99995832 15.9996665 ]  f(x): 1.7379689674272097e-09  grad at x: [ 1.62321185e-04 -3.07113260e-05]  gradient norm: 0.00016520094645496432\n",
            "iter: 935449  x: [ 3.99995832 15.9996665 ]  f(x): 1.737813411712842e-09  grad at x: [ 7.92403617e-05 -2.03264244e-05]  gradient norm: 8.180585834171356e-05\n",
            "iter: 935450  x: [ 3.99995831 15.9996665 ]  f(x): 1.7377623239009925e-09  grad at x: [-2.54154175e-06 -1.01038822e-05]  gradient norm: 1.0418630939308004e-05\n",
            "iter: 935451  x: [ 3.99995832 15.99966651]  f(x): 1.73770740875067e-09  grad at x: [ 7.92884836e-05 -2.03321215e-05]  gradient norm: 8.185388691409107e-05\n",
            "iter: 935452  x: [ 3.99995832 15.99966652]  f(x): 1.7376562619382977e-09  grad at x: [-2.54228617e-06 -1.01034711e-05]  gradient norm: 1.041841389386905e-05\n",
            "iter: 935453  x: [ 3.99995832 15.99966652]  f(x): 1.7376014148200089e-09  grad at x: [ 7.93386719e-05 -2.03380769e-05]  gradient norm: 8.190398174790516e-05\n",
            "iter: 935454  x: [ 3.99995832 15.99966653]  f(x): 1.7375502064692138e-09  grad at x: [-2.54300156e-06 -1.01030637e-05]  gradient norm: 1.0418193356272599e-05\n",
            "iter: 935455  x: [ 3.99995832 15.99966654]  f(x): 1.7374954251277728e-09  grad at x: [ 7.93870119e-05 -2.03438012e-05]  gradient norm: 8.195222942493499e-05\n",
            "iter: 935456  x: [ 3.99995832 15.99966654]  f(x): 1.73744415745755e-09  grad at x: [-2.54371703e-06 -1.01026562e-05]  gradient norm: 1.0417972897935637e-05\n",
            "iter: 935457  x: [ 3.99995832 15.99966655]  f(x): 1.7373894419290314e-09  grad at x: [ 7.94353373e-05 -2.03495238e-05]  gradient norm: 8.200046298824896e-05\n",
            "iter: 935458  x: [ 3.99995832 15.99966655]  f(x): 1.7373381149209562e-09  grad at x: [-2.54441802e-06 -1.01022506e-05]  gradient norm: 1.0417750728629473e-05\n",
            "iter: 935459  x: [ 3.99995832 15.99966656]  f(x): 1.737283464129206e-09  grad at x: [ 7.94827458e-05 -2.03551317e-05]  gradient norm: 8.204778042403297e-05\n",
            "iter: 935460  x: [ 3.99995832 15.99966656]  f(x): 1.73723207887821e-09  grad at x: [-2.5451191e-06 -1.0101845e-05]  gradient norm: 1.0417528636644767e-05\n",
            "iter: 935461  x: [ 3.99995832 15.99966657]  f(x): 1.7371774928200514e-09  grad at x: [ 7.95301543e-05 -2.03607397e-05]  gradient norm: 8.209509827401088e-05\n",
            "iter: 935462  x: [ 3.99995832 15.99966657]  f(x): 1.7371260492919956e-09  grad at x: [-2.54582025e-06 -1.01014393e-05]  gradient norm: 1.0417306621785188e-05\n",
            "iter: 935463  x: [ 3.99995832 15.99966658]  f(x): 1.7370715280374504e-09  grad at x: [ 7.95775772e-05 -2.03663494e-05]  gradient norm: 8.214243108587328e-05\n",
            "iter: 935464  x: [ 3.99995832 15.99966658]  f(x): 1.7370200261631484e-09  grad at x: [-2.54655058e-06 -1.01010301e-05]  gradient norm: 1.0417088271338659e-05\n",
            "iter: 935465  x: [ 3.99995833 15.99966659]  f(x): 1.7369655720813061e-09  grad at x: [ 7.96268773e-05 -2.03721938e-05]  gradient norm: 8.219164112335795e-05\n",
            "iter: 935466  x: [ 3.99995832 15.99966659]  f(x): 1.7369140095272589e-09  grad at x: [-2.54728099e-06 -1.01006208e-05]  gradient norm: 1.0416870002494695e-05\n",
            "iter: 935467  x: [ 3.99995833 15.9996666 ]  f(x): 1.7368596225823509e-09  grad at x: [ 7.96761482e-05 -2.03780346e-05]  gradient norm: 8.224082251236623e-05\n",
            "iter: 935468  x: [ 3.99995833 15.9996666 ]  f(x): 1.7368079993470153e-09  grad at x: [-2.54801147e-06 -1.01002115e-05]  gradient norm: 1.0416651815491938e-05\n",
            "iter: 935469  x: [ 3.99995833 15.99966661]  f(x): 1.7367536796118385e-09  grad at x: [ 7.97254336e-05 -2.03838772e-05]  gradient norm: 8.229001889629252e-05\n",
            "iter: 935470  x: [ 3.99995833 15.99966661]  f(x): 1.7367019956400627e-09  grad at x: [-2.54872749e-06 -1.00998041e-05]  gradient norm: 1.041643191321073e-05\n",
            "iter: 935471  x: [ 3.99995833 15.99966662]  f(x): 1.736647742035029e-09  grad at x: [ 7.97738166e-05 -2.03896070e-05]  gradient norm: 8.233831366256265e-05\n",
            "iter: 935472  x: [ 3.99995833 15.99966662]  f(x): 1.7365959984240449e-09  grad at x: [-2.54941447e-06 -1.00994002e-05]  gradient norm: 1.0416208494351276e-05\n",
            "iter: 935473  x: [ 3.99995833 15.99966663]  f(x): 1.7365418086798345e-09  grad at x: [ 7.9820337e-05 -2.0395104e-05]  gradient norm: 8.238474651493257e-05\n",
            "iter: 935474  x: [ 3.99995833 15.99966663]  f(x): 1.7364900076459764e-09  grad at x: [-2.55014519e-06 -1.00989910e-05]  gradient norm: 1.0415990548046694e-05\n",
            "iter: 935475  x: [ 3.99995833 15.99966664]  f(x): 1.7364358852540377e-09  grad at x: [ 7.98696512e-05 -2.04009502e-05]  gradient norm: 8.243397329568244e-05\n",
            "iter: 935476  x: [ 3.99995833 15.99966664]  f(x): 1.7363840233403107e-09  grad at x: [-2.55086143e-06 -1.00985835e-05]  gradient norm: 1.0415770883001336e-05\n",
            "iter: 935477  x: [ 3.99995833 15.99966665]  f(x): 1.7363299671836231e-09  grad at x: [ 7.99180340e-05 -2.04066801e-05]  gradient norm: 8.248226933272348e-05\n",
            "iter: 935478  x: [ 3.99995833 15.99966665]  f(x): 1.7362780455258211e-09  grad at x: [-2.55157776e-06 -1.00981761e-05]  gradient norm: 1.041555129788146e-05\n",
            "iter: 935479  x: [ 3.99995833 15.99966666]  f(x): 1.736224055639648e-09  grad at x: [ 7.99664168e-05 -2.04124099e-05]  gradient norm: 8.253056579178798e-05\n",
            "iter: 935480  x: [ 3.99995833 15.99966666]  f(x): 1.7361720741652023e-09  grad at x: [-2.55229416e-06 -1.00977686e-05]  gradient norm: 1.041533179227313e-05\n",
            "iter: 935481  x: [ 3.99995834 15.99966667]  f(x): 1.736118150584809e-09  grad at x: [ 8.00147995e-05 -2.04181397e-05]  gradient norm: 8.257886267543735e-05\n",
            "iter: 935482  x: [ 3.99995833 15.99966667]  f(x): 1.7360661092772295e-09  grad at x: [-2.55302519e-06 -1.00973593e-05]  gradient norm: 1.0415114169977647e-05\n",
            "iter: 935483  x: [ 3.99995834 15.99966668]  f(x): 1.7360122532291683e-09  grad at x: [ 8.00641425e-05 -2.04239896e-05]  gradient norm: 8.262812029870624e-05\n",
            "iter: 935484  x: [ 3.99995834 15.99966668]  f(x): 1.7359601508604725e-09  grad at x: [-2.55374174e-06 -1.00969519e-05]  gradient norm: 1.0414894824783509e-05\n",
            "iter: 935485  x: [ 3.99995834 15.99966669]  f(x): 1.7359063611894272e-09  grad at x: [ 8.01125250e-05 -2.04297194e-05]  gradient norm: 8.267641803655015e-05\n",
            "iter: 935486  x: [ 3.99995834 15.99966669]  f(x): 1.7358541988966997e-09  grad at x: [-2.55445838e-06 -1.00965444e-05]  gradient norm: 1.041467555916411e-05\n",
            "iter: 935487  x: [ 3.99995834 15.9996667 ]  f(x): 1.7358004756735344e-09  grad at x: [ 8.01609366e-05 -2.04354528e-05]  gradient norm: 8.27247452951422e-05\n",
            "iter: 935488  x: [ 3.99995834 15.9996667 ]  f(x): 1.735748253404685e-09  grad at x: [-2.55518964e-06 -1.00961352e-05]  gradient norm: 1.0414458180054808e-05\n",
            "iter: 935489  x: [ 3.99995834 15.99966671]  f(x): 1.7356945978225137e-09  grad at x: [ 8.02102794e-05 -2.04413027e-05]  gradient norm: 8.277400421873695e-05\n",
            "iter: 935490  x: [ 3.99995834 15.99966671]  f(x): 1.735642314400931e-09  grad at x: [-2.55589188e-06 -1.00957295e-05]  gradient norm: 1.0414237266951426e-05\n",
            "iter: 935491  x: [ 3.99995834 15.99966672]  f(x): 1.7355887242150865e-09  grad at x: [ 8.02577885e-05 -2.04469234e-05]  gradient norm: 8.282143017572684e-05\n",
            "iter: 935492  x: [ 3.99995834 15.99966672]  f(x): 1.7355363818324755e-09  grad at x: [-2.55663785e-06 -1.00953184e-05]  gradient norm: 1.0414021858910692e-05\n",
            "iter: 935493  x: [ 3.99995834 15.99966673]  f(x): 1.7354828605188304e-09  grad at x: [ 8.03080625e-05 -2.04528897e-05]  gradient norm: 8.28716212165339e-05\n",
            "iter: 935494  x: [ 3.99995834 15.99966673]  f(x): 1.7354304557337559e-09  grad at x: [-2.55736934e-06 -1.00949092e-05]  gradient norm: 1.0413804724746307e-05\n",
            "iter: 935495  x: [ 3.99995834 15.99966674]  f(x): 1.7353770022061955e-09  grad at x: [ 8.03574342e-05 -2.04587432e-05]  gradient norm: 8.292091054552162e-05\n",
            "iter: 935496  x: [ 3.99995834 15.99966674]  f(x): 1.7353245361224061e-09  grad at x: [-2.55807181e-06 -1.00945035e-05]  gradient norm: 1.04135840496866e-05\n",
            "iter: 935497  x: [ 3.99995835 15.99966675]  f(x): 1.7352711480607781e-09  grad at x: [ 8.04049140e-05 -2.04643602e-05]  gradient norm: 8.296830864443887e-05\n",
            "iter: 935498  x: [ 3.99995834 15.99966675]  f(x): 1.7352186229454719e-09  grad at x: [-2.55881801e-06 -1.00940924e-05]  gradient norm: 1.0413368889656682e-05\n",
            "iter: 935499  x: [ 3.99995835 15.99966676]  f(x): 1.735165303903265e-09  grad at x: [ 8.04552169e-05 -2.04703301e-05]  gradient norm: 8.301853011318441e-05\n",
            "iter: 935500  x: [ 3.99995835 15.99966676]  f(x): 1.7351127162553146e-09  grad at x: [-2.55953519e-06 -1.00936850e-05]  gradient norm: 1.041315018674931e-05\n",
            "iter: 935501  x: [ 3.99995835 15.99966677]  f(x): 1.7350594639103233e-09  grad at x: [ 8.05036425e-05 -2.04760654e-05]  gradient norm: 8.306687488606192e-05\n",
            "iter: 935502  x: [ 3.99995835 15.99966677]  f(x): 1.735006816015777e-09  grad at x: [-2.56025244e-06 -1.00932775e-05]  gradient norm: 1.0412931563585504e-05\n",
            "iter: 935503  x: [ 3.99995835 15.99966678]  f(x): 1.7349536305118692e-09  grad at x: [ 8.05521261e-05 -2.04818080e-05]  gradient norm: 8.311527828033532e-05\n",
            "iter: 935504  x: [ 3.99995835 15.99966678]  f(x): 1.7349009222456298e-09  grad at x: [-2.56098433e-06 -1.00928683e-05]  gradient norm: 1.0412714836290453e-05\n",
            "iter: 935505  x: [ 3.99995835 15.99966679]  f(x): 1.7348478047093907e-09  grad at x: [ 8.06014974e-05 -2.04876615e-05]  gradient norm: 8.31645697503314e-05\n",
            "iter: 935506  x: [ 3.99995835 15.99966679]  f(x): 1.7347950349434398e-09  grad at x: [-2.56170174e-06 -1.00924608e-05]  gradient norm: 1.0412496374007216e-05\n",
            "iter: 935507  x: [ 3.99995835 15.9996668 ]  f(x): 1.734741984246957e-09  grad at x: [ 8.06499519e-05 -2.04934004e-05]  gradient norm: 8.321294487753769e-05\n",
            "iter: 935508  x: [ 3.99995835 15.9996668 ]  f(x): 1.7346891540909833e-09  grad at x: [-2.56241922e-06 -1.00920533e-05]  gradient norm: 1.0412277991312217e-05\n",
            "iter: 935509  x: [ 3.99995835 15.99966681]  f(x): 1.7346361703066175e-09  grad at x: [ 8.06984062e-05 -2.04991393e-05]  gradient norm: 8.326132041677692e-05\n",
            "iter: 935510  x: [ 3.99995835 15.99966681]  f(x): 1.734583279724956e-09  grad at x: [-2.56313679e-06 -1.00916459e-05]  gradient norm: 1.0412059688882183e-05\n",
            "iter: 935511  x: [ 3.99995835 15.99966681]  f(x): 1.7345435829727642e-09  grad at x: [ 3.90918691e-05 -1.52982630e-05]  gradient norm: 4.197869793498297e-05\n",
            "iter: 935512  x: [ 3.99995835 15.99966682]  f(x): 1.7345295214782488e-09  grad at x: [-1.91262886e-06 -1.01727965e-05]  gradient norm: 1.0351035556188134e-05\n",
            "iter: 935513  x: [ 3.99995836 15.99966685]  f(x): 1.7343164928020248e-09  grad at x: [ 1.62199003e-04 -3.06850961e-05]  gradient norm: 0.00016507601775903922\n",
            "iter: 935514  x: [ 3.99995836 15.99966686]  f(x): 1.7341611724049689e-09  grad at x: [ 7.91809130e-05 -2.03080363e-05]  gradient norm: 8.17437050391766e-05\n",
            "iter: 935515  x: [ 3.99995836 15.99966686]  f(x): 1.7341101626614787e-09  grad at x: [-2.53924649e-06 -1.00932120e-05]  gradient norm: 1.040772319042183e-05\n",
            "iter: 935516  x: [ 3.99995836 15.99966687]  f(x): 1.7340553925502657e-09  grad at x: [ 7.92292505e-05 -2.03137606e-05]  gradient norm: 8.179194948088349e-05\n",
            "iter: 935517  x: [ 3.99995836 15.99966687]  f(x): 1.7340043236253997e-09  grad at x: [-2.53994992e-06 -1.00928064e-05]  gradient norm: 1.0407501465381535e-05\n",
            "iter: 935518  x: [ 3.99995836 15.99966688]  f(x): 1.7339496182279994e-09  grad at x: [ 7.92768021e-05 -2.03193867e-05]  gradient norm: 8.183940875765312e-05\n",
            "iter: 935519  x: [ 3.99995836 15.99966688]  f(x): 1.7338984910368472e-09  grad at x: [-2.54065344e-06 -1.00924008e-05]  gradient norm: 1.0407279817837035e-05\n",
            "iter: 935520  x: [ 3.99995836 15.99966689]  f(x): 1.7338438504595206e-09  grad at x: [ 7.93243827e-05 -2.03250165e-05]  gradient norm: 8.188689754844458e-05\n",
            "iter: 935521  x: [ 3.99995836 15.99966689]  f(x): 1.7337926649145815e-09  grad at x: [-2.54137158e-06 -1.00919933e-05]  gradient norm: 1.0407060037627216e-05\n",
            "iter: 935522  x: [ 3.99995836 15.9996669 ]  f(x): 1.7337380902650905e-09  grad at x: [ 7.93728655e-05 -2.03307591e-05]  gradient norm: 8.193528876240944e-05\n",
            "iter: 935523  x: [ 3.99995836 15.9996669 ]  f(x): 1.7336868452392524e-09  grad at x: [-2.54208980e-06 -1.00915859e-05]  gradient norm: 1.0406840337160786e-05\n",
            "iter: 935524  x: [ 3.99995837 15.99966691]  f(x): 1.733632336660533e-09  grad at x: [ 7.94214064e-05 -2.03365089e-05]  gradient norm: 8.198373860610375e-05\n",
            "iter: 935525  x: [ 3.99995836 15.99966691]  f(x): 1.7335810320296197e-09  grad at x: [-2.54282265e-06 -1.00911766e-05]  gradient norm: 1.0406622508524275e-05\n",
            "iter: 935526  x: [ 3.99995837 15.99966692]  f(x): 1.733526590633032e-09  grad at x: [ 7.94708350e-05 -2.03423697e-05]  gradient norm: 8.203307635834078e-05\n",
            "iter: 935527  x: [ 3.99995837 15.99966692]  f(x): 1.7334752252842582e-09  grad at x: [-2.54354103e-06 -1.00907691e-05]  gradient norm: 1.0406402968938505e-05\n",
            "iter: 935528  x: [ 3.99995837 15.99966693]  f(x): 1.7334208499578035e-09  grad at x: [ 7.95193467e-05 -2.03481159e-05]  gradient norm: 8.208149798276577e-05\n",
            "iter: 935529  x: [ 3.99995837 15.99966693]  f(x): 1.7333694249849472e-09  grad at x: [-2.54425948e-06 -1.00903617e-05]  gradient norm: 1.0406183509159552e-05\n",
            "iter: 935530  x: [ 3.99995837 15.99966694]  f(x): 1.7333151158363948e-09  grad at x: [ 7.95678873e-05 -2.03538657e-05]  gradient norm: 8.212994913900747e-05\n",
            "iter: 935531  x: [ 3.99995837 15.99966694]  f(x): 1.7332636311683685e-09  grad at x: [-2.54497801e-06 -1.00899542e-05]  gradient norm: 1.0405964129425692e-05\n",
            "iter: 935532  x: [ 3.99995837 15.99966695]  f(x): 1.7332093881608833e-09  grad at x: [ 7.96163989e-05 -2.03596119e-05]  gradient norm: 8.217837162970639e-05\n",
            "iter: 935533  x: [ 3.99995837 15.99966695]  f(x): 1.7331578437793267e-09  grad at x: [-2.54571117e-06 -1.00895450e-05]  gradient norm: 1.0405746625647558e-05\n",
            "iter: 935534  x: [ 3.99995837 15.99966696]  f(x): 1.733103668170778e-09  grad at x: [ 7.96658707e-05 -2.03654781e-05]  gradient norm: 8.222775480550029e-05\n",
            "iter: 935535  x: [ 3.99995837 15.99966696]  f(x): 1.7330520628712949e-09  grad at x: [-2.54641531e-06 -1.00891393e-05]  gradient norm: 1.0405525609526207e-05\n",
            "iter: 935536  x: [ 3.99995837 15.99966697]  f(x): 1.732997952324688e-09  grad at x: [ 7.97134508e-05 -2.03711079e-05]  gradient norm: 8.227524700264247e-05\n",
            "iter: 935537  x: [ 3.99995837 15.99966697]  f(x): 1.7329462884081316e-09  grad at x: [-2.54711952e-06 -1.00887337e-05]  gradient norm: 1.0405304670870683e-05\n",
            "iter: 935538  x: [ 3.99995837 15.99966698]  f(x): 1.7328922430291774e-09  grad at x: [ 7.97610744e-05 -2.03767431e-05]  gradient norm: 8.23227832584768e-05\n",
            "iter: 935539  x: [ 3.99995837 15.99966698]  f(x): 1.7328405204085942e-09  grad at x: [-2.54783836e-06 -1.00883262e-05]  gradient norm: 1.0405085609762475e-05\n",
            "iter: 935540  x: [ 3.99995838 15.99966699]  f(x): 1.732786541383547e-09  grad at x: [ 7.98096292e-05 -2.03824948e-05]  gradient norm: 8.237125110856989e-05\n",
            "iter: 935541  x: [ 3.99995837 15.99966699]  f(x): 1.7327347588533357e-09  grad at x: [-2.54855728e-06 -1.00879188e-05]  gradient norm: 1.0404866628587558e-05\n",
            "iter: 935542  x: [ 3.99995838 15.999667  ]  f(x): 1.7326808462177155e-09  grad at x: [ 7.98581840e-05 -2.03882464e-05]  gradient norm: 8.241971938845682e-05\n",
            "iter: 935543  x: [ 3.99995838 15.999667  ]  f(x): 1.7326290037420618e-09  grad at x: [-2.54927628e-06 -1.00875113e-05]  gradient norm: 1.040464772714938e-05\n",
            "iter: 935544  x: [ 3.99995838 15.99966701]  f(x): 1.7325751575676156e-09  grad at x: [ 7.99067533e-05 -2.03939999e-05]  gradient norm: 8.246820264700742e-05\n",
            "iter: 935545  x: [ 3.99995838 15.99966701]  f(x): 1.7325232551114465e-09  grad at x: [-2.54999535e-06 -1.00871039e-05]  gradient norm: 1.0404428906121855e-05\n",
            "iter: 935546  x: [ 3.99995838 15.99966702]  f(x): 1.7324694753612386e-09  grad at x: [ 7.99552933e-05 -2.03997497e-05]  gradient norm: 8.251665723232215e-05\n",
            "iter: 935547  x: [ 3.99995838 15.99966702]  f(x): 1.732417512906307e-09  grad at x: [-2.55072906e-06 -1.00866946e-05]  gradient norm: 1.0404211969196496e-05\n",
            "iter: 935548  x: [ 3.99995838 15.99966703]  f(x): 1.7323638008787328e-09  grad at x: [ 8.00048229e-05 -2.04056232e-05]  gradient norm: 8.256610166507795e-05\n",
            "iter: 935549  x: [ 3.99995838 15.99966703]  f(x): 1.7323117771812338e-09  grad at x: [-2.55146284e-06 -1.00862853e-05]  gradient norm: 1.0403995114757259e-05\n",
            "iter: 935550  x: [ 3.99995838 15.99966704]  f(x): 1.7322581328051995e-09  grad at x: [ 8.00542941e-05 -2.04114895e-05]  gradient norm: 8.261548833913403e-05\n",
            "iter: 935551  x: [ 3.99995838 15.99966704]  f(x): 1.7322060478989645e-09  grad at x: [-2.55219670e-06 -1.00858761e-05]  gradient norm: 1.0403778342607961e-05\n",
            "iter: 935552  x: [ 3.99995838 15.99966705]  f(x): 1.7321524713194715e-09  grad at x: [ 8.01038235e-05 -2.04173630e-05]  gradient norm: 8.266493365970937e-05\n",
            "iter: 935553  x: [ 3.99995838 15.99966705]  f(x): 1.7321003250771196e-09  grad at x: [-2.55291608e-06 -1.00854686e-05]  gradient norm: 1.0403559845257659e-05\n",
            "iter: 935554  x: [ 3.99995838 15.99966706]  f(x): 1.732046815101606e-09  grad at x: [ 8.01523924e-05 -2.04231164e-05]  gradient norm: 8.271341907299913e-05\n",
            "iter: 935555  x: [ 3.99995838 15.99966706]  f(x): 1.7319946086974881e-09  grad at x: [-2.55363554e-06 -1.00850611e-05]  gradient norm: 1.040334142798882e-05\n",
            "iter: 935556  x: [ 3.99995839 15.99966707]  f(x): 1.7319411653977842e-09  grad at x: [ 8.02009758e-05 -2.04288717e-05]  gradient norm: 8.276191945901498e-05\n",
            "iter: 935557  x: [ 3.99995838 15.99966707]  f(x): 1.731888898778823e-09  grad at x: [-2.55436964e-06 -1.00846519e-05]  gradient norm: 1.0403124900784289e-05\n",
            "iter: 935558  x: [ 3.99995839 15.99966708]  f(x): 1.731835523348849e-09  grad at x: [ 8.02504904e-05 -2.04347434e-05]  gradient norm: 8.281135153293574e-05\n",
            "iter: 935559  x: [ 3.99995839 15.99966708]  f(x): 1.731783195301782e-09  grad at x: [-2.55510380e-06 -1.00842426e-05]  gradient norm: 1.040290845573739e-05\n",
            "iter: 935560  x: [ 3.99995839 15.99966709]  f(x): 1.731729887814153e-09  grad at x: [ 8.03000340e-05 -2.04406188e-05]  gradient norm: 8.286081315102034e-05\n",
            "iter: 935561  x: [ 3.99995839 15.99966709]  f(x): 1.7316774982839826e-09  grad at x: [-2.55582350e-06 -1.00838351e-05]  gradient norm: 1.0402690281289639e-05\n",
            "iter: 935562  x: [ 3.99995839 15.9996671 ]  f(x): 1.7316242575802484e-09  grad at x: [ 8.03486171e-05 -2.04463740e-05]  gradient norm: 8.290931481899208e-05\n",
            "iter: 935563  x: [ 3.99995839 15.9996671 ]  f(x): 1.7315718077072163e-09  grad at x: [-2.55654327e-06 -1.00834277e-05]  gradient norm: 1.040247218700808e-05\n",
            "iter: 935564  x: [ 3.99995839 15.99966711]  f(x): 1.731518633858643e-09  grad at x: [ 8.03972293e-05 -2.04521330e-05]  gradient norm: 8.295784600992262e-05\n",
            "iter: 935565  x: [ 3.99995839 15.99966711]  f(x): 1.7314661236081466e-09  grad at x: [-2.55726312e-06 -1.00830202e-05]  gradient norm: 1.0402254173132141e-05\n",
            "iter: 935566  x: [ 3.99995839 15.99966712]  f(x): 1.7314130166503364e-09  grad at x: [ 8.04458413e-05 -2.04578919e-05]  gradient norm: 8.300637761938983e-05\n",
            "iter: 935567  x: [ 3.99995839 15.99966712]  f(x): 1.731360445931609e-09  grad at x: [-2.5579976e-06 -1.0082611e-05]  gradient norm: 1.0402038054829692e-05\n",
            "iter: 935568  x: [ 3.99995839 15.99966713]  f(x): 1.7313074070620025e-09  grad at x: [ 8.04953846e-05 -2.04637672e-05]  gradient norm: 8.305584096008356e-05\n",
            "iter: 935569  x: [ 3.99995839 15.99966713]  f(x): 1.73125477473104e-09  grad at x: [-2.55870305e-06 -1.00822053e-05]  gradient norm: 1.0401818386026818e-05\n",
            "iter: 935570  x: [ 3.99995839 15.99966714]  f(x): 1.7312018016973384e-09  grad at x: [ 8.05430943e-05 -2.04694134e-05]  gradient norm: 8.310347119713076e-05\n",
            "iter: 935571  x: [ 3.99995839 15.99966714]  f(x): 1.7311491099535504e-09  grad at x: [-2.55945224e-06 -1.00817942e-05]  gradient norm: 1.0401604248274969e-05\n",
            "iter: 935572  x: [ 3.9999584  15.99966715]  f(x): 1.7310962062438911e-09  grad at x: [ 8.05935688e-05 -2.04754051e-05]  gradient norm: 8.315386672043138e-05\n",
            "iter: 935573  x: [ 3.99995839 15.99966715]  f(x): 1.7310434516514375e-09  grad at x: [-2.56017240e-06 -1.00813868e-05]  gradient norm: 1.0401386557811838e-05\n",
            "iter: 935574  x: [ 3.9999584  15.99966716]  f(x): 1.730990615012171e-09  grad at x: [ 8.06422097e-05 -2.04811677e-05]  gradient norm: 8.320242912076847e-05\n",
            "iter: 935575  x: [ 3.9999584  15.99966716]  f(x): 1.7309510034099896e-09  grad at x: [ 3.90406440e-05 -1.52810717e-05]  gradient norm: 4.192473056591018e-05\n",
            "iter: 935576  x: [ 3.9999584  15.99966716]  f(x): 1.7309369776421543e-09  grad at x: [-1.91047702e-06 -1.01622772e-05]  gradient norm: 1.0340299867399896e-05\n",
            "iter: 935577  x: [ 3.9999584 15.9996672]  f(x): 1.7307242804660342e-09  grad at x: [ 1.61986909e-04 -3.06477978e-05]  gradient norm: 0.00016486068678664843\n",
            "iter: 935578  x: [ 3.9999584 15.9996672]  f(x): 1.7305693649123907e-09  grad at x: [ 7.90772026e-05 -2.02842857e-05]  gradient norm: 8.163734570009396e-05\n",
            "iter: 935579  x: [ 3.9999584 15.9996672]  f(x): 1.7305184873893018e-09  grad at x: [-2.53629016e-06 -1.00827947e-05]  gradient norm: 1.039689937050445e-05\n",
            "iter: 935580  x: [ 3.9999584  15.99966721]  f(x): 1.7304638051722744e-09  grad at x: [ 7.91263378e-05 -2.02901101e-05]  gradient norm: 8.168638750968258e-05\n",
            "iter: 935581  x: [ 3.9999584  15.99966721]  f(x): 1.7304128675634417e-09  grad at x: [-2.53699623e-06 -1.00823891e-05]  gradient norm: 1.0396678263660626e-05\n",
            "iter: 935582  x: [ 3.9999584  15.99966722]  f(x): 1.7303582502185952e-09  grad at x: [ 7.91740760e-05 -2.02957599e-05]  gradient norm: 8.173403315558071e-05\n",
            "iter: 935583  x: [ 3.9999584  15.99966722]  f(x): 1.7303072541762115e-09  grad at x: [-2.53773149e-06 -1.00819798e-05]  gradient norm: 1.0396460811116792e-05\n",
            "iter: 935584  x: [ 3.99995841 15.99966723]  f(x): 1.7302527040253784e-09  grad at x: [ 7.92236767e-05 -2.03016425e-05]  gradient norm: 8.178354139850812e-05\n",
            "iter: 935585  x: [ 3.9999584  15.99966723]  f(x): 1.7302016472440989e-09  grad at x: [-2.53845226e-06 -1.00815723e-05]  gradient norm: 1.0396241651782116e-05\n",
            "iter: 935586  x: [ 3.99995841 15.99966724]  f(x): 1.7301471631798986e-09  grad at x: [ 7.92723461e-05 -2.03074087e-05]  gradient norm: 8.183211900544368e-05\n",
            "iter: 935587  x: [ 3.99995841 15.99966724]  f(x): 1.7300960467668077e-09  grad at x: [-2.53915857e-06 -1.00811667e-05]  gradient norm: 1.039602078232411e-05\n",
            "iter: 935588  x: [ 3.99995841 15.99966725]  f(x): 1.7300416276437036e-09  grad at x: [ 7.93200694e-05 -2.03130567e-05]  gradient norm: 8.18797513955676e-05\n",
            "iter: 935589  x: [ 3.99995841 15.99966725]  f(x): 1.7299904527082272e-09  grad at x: [-2.53987950e-06 -1.00807592e-05]  gradient norm: 1.0395801782283222e-05\n",
            "iter: 935590  x: [ 3.99995841 15.99966726]  f(x): 1.7299360997785302e-09  grad at x: [ 7.93687532e-05 -2.03188247e-05]  gradient norm: 8.192834442080991e-05\n",
            "iter: 935591  x: [ 3.99995841 15.99966726]  f(x): 1.7298848651229125e-09  grad at x: [-2.54060051e-06 -1.00803518e-05]  gradient norm: 1.039558286269695e-05\n",
            "iter: 935592  x: [ 3.99995841 15.99966727]  f(x): 1.7298305783853932e-09  grad at x: [ 7.94174369e-05 -2.03245927e-05]  gradient norm: 8.197693788382583e-05\n",
            "iter: 935593  x: [ 3.99995841 15.99966727]  f(x): 1.7297792839545924e-09  grad at x: [-2.54130704e-06 -1.00799462e-05]  gradient norm: 1.039536222949912e-05\n",
            "iter: 935594  x: [ 3.99995841 15.99966728]  f(x): 1.7297250623346992e-09  grad at x: [ 7.94651891e-05 -2.03302443e-05]  gradient norm: 8.202460064969223e-05\n",
            "iter: 935595  x: [ 3.99995841 15.99966728]  f(x): 1.7296737092589457e-09  grad at x: [-2.54201365e-06 -1.00795405e-05]  gradient norm: 1.0395141674581542e-05\n",
            "iter: 935596  x: [ 3.99995841 15.99966729]  f(x): 1.729619552790206e-09  grad at x: [ 7.95129558e-05 -2.03358977e-05]  gradient norm: 8.207227838187995e-05\n",
            "iter: 935597  x: [ 3.99995841 15.99966729]  f(x): 1.7295681409808338e-09  grad at x: [-2.54273490e-06 -1.00791331e-05]  gradient norm: 1.0394922993597694e-05\n",
            "iter: 935598  x: [ 3.99995842 15.9996673 ]  f(x): 1.729514050846172e-09  grad at x: [ 7.95616538e-05 -2.03416676e-05]  gradient norm: 8.212088768669854e-05\n",
            "iter: 935599  x: [ 3.99995841 15.9996673 ]  f(x): 1.7294625791569004e-09  grad at x: [-2.54347077e-06 -1.00787238e-05]  gradient norm: 1.039470619014223e-05\n",
            "iter: 935600  x: [ 3.99995842 15.99966731]  f(x): 1.729408556541313e-09  grad at x: [ 7.96112830e-05 -2.03475538e-05]  gradient norm: 8.217042858769971e-05\n",
            "iter: 935601  x: [ 3.99995842 15.99966731]  f(x): 1.7293570237857204e-09  grad at x: [-2.54419217e-06 -1.00783163e-05]  gradient norm: 1.0394487671160006e-05\n",
            "iter: 935602  x: [ 3.99995842 15.99966732]  f(x): 1.7293030675755887e-09  grad at x: [ 7.96599954e-05 -2.03533255e-05]  gradient norm: 8.221905331903913e-05\n",
            "iter: 935603  x: [ 3.99995842 15.99966732]  f(x): 1.7292514748311938e-09  grad at x: [-2.54492819e-06 -1.00779071e-05]  gradient norm: 1.039427103178997e-05\n",
            "iter: 935604  x: [ 3.99995842 15.99966733]  f(x): 1.7291975862498665e-09  grad at x: [ 7.97096391e-05 -2.03592135e-05]  gradient norm: 8.226860966543102e-05\n",
            "iter: 935605  x: [ 3.99995842 15.99966733]  f(x): 1.7291459323467321e-09  grad at x: [-2.54563519e-06 -1.00775014e-05]  gradient norm: 1.0394050874310472e-05\n",
            "iter: 935606  x: [ 3.99995842 15.99966734]  f(x): 1.7290921090917093e-09  grad at x: [ 7.97574200e-05 -2.03648688e-05]  gradient norm: 8.231630408294543e-05\n",
            "iter: 935607  x: [ 3.99995842 15.99966734]  f(x): 1.7290403962783355e-09  grad at x: [-2.54635682e-06 -1.00770940e-05]  gradient norm: 1.0393832596485477e-05\n",
            "iter: 935608  x: [ 3.99995842 15.99966735]  f(x): 1.728986639608405e-09  grad at x: [ 7.98061612e-05 -2.03706441e-05]  gradient norm: 8.236495921140651e-05\n",
            "iter: 935609  x: [ 3.99995842 15.99966735]  f(x): 1.7289348666626421e-09  grad at x: [-2.54709308e-06 -1.00766847e-05]  gradient norm: 1.039361620191211e-05\n",
            "iter: 935610  x: [ 3.99995842 15.99966736]  f(x): 1.7288811776939429e-09  grad at x: [ 7.98558046e-05 -2.03765321e-05]  gradient norm: 8.241451688245901e-05\n",
            "iter: 935611  x: [ 3.99995842 15.99966736]  f(x): 1.7288293434803267e-09  grad at x: [-2.54782942e-06 -1.00762754e-05]  gradient norm: 1.0393399890047916e-05\n",
            "iter: 935612  x: [ 3.99995842 15.99966737]  f(x): 1.728775722322423e-09  grad at x: [ 7.99054771e-05 -2.03824238e-05]  gradient norm: 8.246410410134895e-05\n",
            "iter: 935613  x: [ 3.99995842 15.99966737]  f(x): 1.7287238267489931e-09  grad at x: [-2.54855128e-06 -1.00758680e-05]  gradient norm: 1.0393181856028241e-05\n",
            "iter: 935614  x: [ 3.99995843 15.99966738]  f(x): 1.7286702722842218e-09  grad at x: [ 7.99542326e-05 -2.03882009e-05]  gradient norm: 8.251277509104804e-05\n",
            "iter: 935615  x: [ 3.99995842 15.99966738]  f(x): 1.728618316469477e-09  grad at x: [-2.54928777e-06 -1.00754587e-05]  gradient norm: 1.039296570872464e-05\n",
            "iter: 935616  x: [ 3.99995843 15.99966739]  f(x): 1.728564829816737e-09  grad at x: [ 8.00038758e-05 -2.03940890e-05]  gradient norm: 8.25623340958699e-05\n",
            "iter: 935617  x: [ 3.99995843 15.99966739]  f(x): 1.728512812603425e-09  grad at x: [-2.55000979e-06 -1.00750513e-05]  gradient norm: 1.039274783683028e-05\n",
            "iter: 935618  x: [ 3.99995843 15.9996674 ]  f(x): 1.728459392752352e-09  grad at x: [ 8.00526458e-05 -2.03998679e-05]  gradient norm: 8.261102050218427e-05\n",
            "iter: 935619  x: [ 3.99995843 15.9996674 ]  f(x): 1.7284073151886017e-09  grad at x: [-2.55074643e-06 -1.00746420e-05]  gradient norm: 1.0392531853955411e-05\n",
            "iter: 935620  x: [ 3.99995843 15.99966741]  f(x): 1.728353963258773e-09  grad at x: [ 8.01023179e-05 -2.04057596e-05]  gradient norm: 8.26606094902568e-05\n",
            "iter: 935621  x: [ 3.99995843 15.99966741]  f(x): 1.7283018242235782e-09  grad at x: [-2.55146860e-06 -1.00742345e-05]  gradient norm: 1.0392314144489666e-05\n",
            "iter: 935622  x: [ 3.99995843 15.99966742]  f(x): 1.7282485391315055e-09  grad at x: [ 8.01510732e-05 -2.04115368e-05]  gradient norm: 8.270928220738182e-05\n",
            "iter: 935623  x: [ 3.99995843 15.99966742]  f(x): 1.7281963396722697e-09  grad at x: [-2.55220540e-06 -1.00738253e-05]  gradient norm: 1.0392098326129409e-05\n",
            "iter: 935624  x: [ 3.99995843 15.99966743]  f(x): 1.7281431226476726e-09  grad at x: [ 8.02007743e-05 -2.04174321e-05]  gradient norm: 8.275890117630544e-05\n",
            "iter: 935625  x: [ 3.99995843 15.99966743]  f(x): 1.7280908615891991e-09  grad at x: [-2.55294228e-06 -1.00734160e-05]  gradient norm: 1.039188259084738e-05\n",
            "iter: 935626  x: [ 3.99995843 15.99966744]  f(x): 1.7280377125967535e-09  grad at x: [ 8.02504461e-05 -2.04233238e-05]  gradient norm: 8.280849148564256e-05\n",
            "iter: 935627  x: [ 3.99995843 15.99966744]  f(x): 1.727985389918122e-09  grad at x: [-2.55366469e-06 -1.00730085e-05]  gradient norm: 1.0391665125418112e-05\n",
            "iter: 935628  x: [ 3.99995843 15.99966745]  f(x): 1.7279323079442196e-09  grad at x: [ 8.02992448e-05 -2.04291064e-05]  gradient norm: 8.285720915101471e-05\n",
            "iter: 935629  x: [ 3.99995843 15.99966745]  f(x): 1.7278799246967982e-09  grad at x: [-2.55440172e-06 -1.00725993e-05]  gradient norm: 1.0391449554779776e-05\n",
            "iter: 935630  x: [ 3.99995844 15.99966746]  f(x): 1.7278269108644564e-09  grad at x: [ 8.03489457e-05 -2.04350017e-05]  gradient norm: 8.29068294369666e-05\n",
            "iter: 935631  x: [ 3.99995843 15.99966746]  f(x): 1.7277744659237987e-09  grad at x: [-2.55512428e-06 -1.00721918e-05]  gradient norm: 1.0391232251993024e-05\n",
            "iter: 935632  x: [ 3.99995844 15.99966747]  f(x): 1.7277215191461224e-09  grad at x: [ 8.03977297e-05 -2.04407825e-05]  gradient norm: 8.295553340452615e-05\n",
            "iter: 935633  x: [ 3.99995844 15.99966747]  f(x): 1.727669013563045e-09  grad at x: [-2.55586147e-06 -1.00717825e-05]  gradient norm: 1.0391016846084294e-05\n",
            "iter: 935634  x: [ 3.99995844 15.99966748]  f(x): 1.7276161350733506e-09  grad at x: [ 8.04474595e-05 -2.04466814e-05]  gradient norm: 8.300518366471955e-05\n",
            "iter: 935635  x: [ 3.99995844 15.99966748]  f(x): 1.7275635676511604e-09  grad at x: [-2.55661329e-06 -1.00713714e-05]  gradient norm: 1.0390803340718683e-05\n",
            "iter: 935636  x: [ 3.99995844 15.99966749]  f(x): 1.7275107585759178e-09  grad at x: [ 8.04980914e-05 -2.04526932e-05]  gradient norm: 8.305573658941202e-05\n",
            "iter: 935637  x: [ 3.99995844 15.9996675 ]  f(x): 1.7274581281855794e-09  grad at x: [-2.55732152e-06 -1.00709658e-05]  gradient norm: 1.0390584464932473e-05\n",
            "iter: 935638  x: [ 3.99995844 15.9996675 ]  f(x): 1.727405385147884e-09  grad at x: [ 8.05459729e-05 -2.04583612e-05]  gradient norm: 8.310353961409937e-05\n",
            "iter: 935639  x: [ 3.99995844 15.99966751]  f(x): 1.7273658675746481e-09  grad at x: [ 3.89939570e-05 -1.52644589e-05]  gradient norm: 4.187520012309009e-05\n",
            "iter: 935640  x: [ 3.99995844 15.99966751]  f(x): 1.7273518746770154e-09  grad at x: [-1.90841461e-06 -1.01517580e-05]  gradient norm: 1.0329580703113786e-05\n",
            "iter: 935641  x: [ 3.99995845 15.99966754]  f(x): 1.727139564644138e-09  grad at x: [ 1.61797601e-04 -3.06133588e-05]  gradient norm: 0.00016466827684695202\n",
            "iter: 935642  x: [ 3.99995845 15.99966755]  f(x): 1.7269850103943083e-09  grad at x: [ 7.89846807e-05 -2.02619449e-05]  gradient norm: 8.15421743496062e-05\n",
            "iter: 935643  x: [ 3.99995844 15.99966755]  f(x): 1.726934251235449e-09  grad at x: [-2.53348147e-06 -1.00723701e-05]  gradient norm: 1.0386104514199697e-05\n",
            "iter: 935644  x: [ 3.99995845 15.99966756]  f(x): 1.7268796681112583e-09  grad at x: [ 7.90327947e-05 -2.02676420e-05]  gradient norm: 8.159019515021117e-05\n",
            "iter: 935645  x: [ 3.99995845 15.99966756]  f(x): 1.7268288501505551e-09  grad at x: [-2.53420472e-06 -1.00719626e-05]  gradient norm: 1.0385885822381286e-05\n",
            "iter: 935646  x: [ 3.99995845 15.99966757]  f(x): 1.7267743331697618e-09  grad at x: [ 7.90816216e-05 -2.02734282e-05]  gradient norm: 8.163892923620513e-05\n",
            "iter: 935647  x: [ 3.99995845 15.99966757]  f(x): 1.726723455530066e-09  grad at x: [-2.53492805e-06 -1.00715552e-05]  gradient norm: 1.0385667211387325e-05\n",
            "iter: 935648  x: [ 3.99995845 15.99966758]  f(x): 1.726669004691688e-09  grad at x: [ 7.91304485e-05 -2.02792144e-05]  gradient norm: 8.168766377068161e-05\n",
            "iter: 935649  x: [ 3.99995845 15.99966758]  f(x): 1.7266180673367788e-09  grad at x: [-2.53565146e-06 -1.00711477e-05]  gradient norm: 1.0385448681022396e-05\n",
            "iter: 935650  x: [ 3.99995845 15.99966759]  f(x): 1.7265636827127768e-09  grad at x: [ 7.91792898e-05 -2.02850024e-05]  gradient norm: 8.173641329563013e-05\n",
            "iter: 935651  x: [ 3.99995845 15.99966759]  f(x): 1.72651268555251e-09  grad at x: [-2.53638950e-06 -1.00707384e-05]  gradient norm: 1.038523202141243e-05\n",
            "iter: 935652  x: [ 3.99995845 15.9996676 ]  f(x): 1.726458368287465e-09  grad at x: [ 7.92290333e-05 -2.02909032e-05]  gradient norm: 8.178606527534827e-05\n",
            "iter: 935653  x: [ 3.99995845 15.9996676 ]  f(x): 1.7264073102127455e-09  grad at x: [-2.53711306e-06 -1.00703310e-05]  gradient norm: 1.0385013653492177e-05\n",
            "iter: 935654  x: [ 3.99995845 15.99966761]  f(x): 1.7263530592698497e-09  grad at x: [ 7.92779036e-05 -2.02966949e-05]  gradient norm: 8.183484479562002e-05\n",
            "iter: 935655  x: [ 3.99995845 15.99966761]  f(x): 1.7263019413171884e-09  grad at x: [-2.53782215e-06 -1.00699253e-05]  gradient norm: 1.0384793573914194e-05\n",
            "iter: 935656  x: [ 3.99995845 15.99966762]  f(x): 1.7262477555519974e-09  grad at x: [ 7.93258134e-05 -2.03023665e-05]  gradient norm: 8.188266453786651e-05\n",
            "iter: 935657  x: [ 3.99995845 15.99966762]  f(x): 1.726196578829769e-09  grad at x: [-2.53854587e-06 -1.00695179e-05]  gradient norm: 1.0384575366277789e-05\n",
            "iter: 935658  x: [ 3.99995846 15.99966763]  f(x): 1.7261424594227423e-09  grad at x: [ 7.93746544e-05 -2.03081545e-05]  gradient norm: 8.193141583453316e-05\n",
            "iter: 935659  x: [ 3.99995845 15.99966763]  f(x): 1.7260912227859681e-09  grad at x: [-2.53925511e-06 -1.00691122e-05]  gradient norm: 1.0384355445017086e-05\n",
            "iter: 935660  x: [ 3.99995846 15.99966764]  f(x): 1.7260371686617442e-09  grad at x: [ 7.94225931e-05 -2.03138297e-05]  gradient norm: 8.1979265528612e-05\n",
            "iter: 935661  x: [ 3.99995846 15.99966764]  f(x): 1.7259858731866171e-09  grad at x: [-2.53997898e-06 -1.00687048e-05]  gradient norm: 1.0384137397966254e-05\n",
            "iter: 935662  x: [ 3.99995846 15.99966765]  f(x): 1.72593188552707e-09  grad at x: [ 7.94714631e-05 -2.03196214e-05]  gradient norm: 8.202804679617689e-05\n",
            "iter: 935663  x: [ 3.99995846 15.99966765]  f(x): 1.7258805299945234e-09  grad at x: [-2.54071748e-06 -1.00682955e-05]  gradient norm: 1.038392122851693e-05\n",
            "iter: 935664  x: [ 3.99995846 15.99966766]  f(x): 1.72582660998361e-09  grad at x: [ 7.95212643e-05 -2.03255295e-05]  gradient norm: 8.207775966433944e-05\n",
            "iter: 935665  x: [ 3.99995846 15.99966766]  f(x): 1.7257751932451632e-09  grad at x: [-2.54144151e-06 -1.00678881e-05]  gradient norm: 1.0383703344166536e-05\n",
            "iter: 935666  x: [ 3.99995846 15.99966767]  f(x): 1.7257213397716e-09  grad at x: [ 7.95701342e-05 -2.03313211e-05]  gradient norm: 8.212654181730082e-05\n",
            "iter: 935667  x: [ 3.99995846 15.99966767]  f(x): 1.7256698629203575e-09  grad at x: [-2.54216561e-06 -1.00674806e-05]  gradient norm: 1.0383485540636504e-05\n",
            "iter: 935668  x: [ 3.99995846 15.99966768]  f(x): 1.7256160760201334e-09  grad at x: [ 7.96190039e-05 -2.03371128e-05]  gradient norm: 8.217532441035102e-05\n",
            "iter: 935669  x: [ 3.99995846 15.99966768]  f(x): 1.725564539037695e-09  grad at x: [-2.54287524e-06 -1.00670750e-05]  gradient norm: 1.038326601775264e-05\n",
            "iter: 935670  x: [ 3.99995846 15.99966769]  f(x): 1.7255108175959947e-09  grad at x: [ 7.96669568e-05 -2.03427899e-05]  gradient norm: 8.222319079870091e-05\n",
            "iter: 935671  x: [ 3.99995846 15.99966769]  f(x): 1.7254592215611154e-09  grad at x: [-2.54359950e-06 -1.00666675e-05]  gradient norm: 1.0383048375020502e-05\n",
            "iter: 935672  x: [ 3.99995846 15.9996677 ]  f(x): 1.7254055668001968e-09  grad at x: [ 7.97158409e-05 -2.03485833e-05]  gradient norm: 8.227198880287249e-05\n",
            "iter: 935673  x: [ 3.99995846 15.9996677 ]  f(x): 1.7253539105260896e-09  grad at x: [-2.54430929e-06 -1.00662619e-05]  gradient norm: 1.0382829010531304e-05\n",
            "iter: 935674  x: [ 3.99995847 15.99966771]  f(x): 1.7253003213298053e-09  grad at x: [ 7.97638082e-05 -2.03542622e-05]  gradient norm: 8.231987058620726e-05\n",
            "iter: 935675  x: [ 3.99995846 15.99966771]  f(x): 1.7252486059155714e-09  grad at x: [-2.54504825e-06 -1.00658526e-05]  gradient norm: 1.0382613332012113e-05\n",
            "iter: 935676  x: [ 3.99995847 15.99966772]  f(x): 1.7251950846227985e-09  grad at x: [ 7.98136381e-05 -2.03601739e-05]  gradient norm: 8.236961521633396e-05\n",
            "iter: 935677  x: [ 3.99995847 15.99966772]  f(x): 1.7251433077102573e-09  grad at x: [-2.54580185e-06 -1.00654415e-05]  gradient norm: 1.0382399541402377e-05\n",
            "iter: 935678  x: [ 3.99995847 15.99966773]  f(x): 1.7250898555112685e-09  grad at x: [ 7.98643993e-05 -2.03662021e-05]  gradient norm: 8.242029152658048e-05\n",
            "iter: 935679  x: [ 3.99995847 15.99966773]  f(x): 1.7250380159634932e-09  grad at x: [-2.54652642e-06 -1.00650341e-05]  gradient norm: 1.0382182224583653e-05\n",
            "iter: 935680  x: [ 3.99995847 15.99966774]  f(x): 1.724984630625534e-09  grad at x: [ 7.99133267e-05 -2.03720010e-05]  gradient norm: 8.246913493521575e-05\n",
            "iter: 935681  x: [ 3.99995847 15.99966774]  f(x): 1.7249327306392242e-09  grad at x: [-2.54725107e-06 -1.00646266e-05]  gradient norm: 1.0381964988734366e-05\n",
            "iter: 935682  x: [ 3.99995847 15.99966775]  f(x): 1.7248794121628585e-09  grad at x: [ 7.99622251e-05 -2.03777963e-05]  gradient norm: 8.251794967614523e-05\n",
            "iter: 935683  x: [ 3.99995847 15.99966775]  f(x): 1.7248274517371564e-09  grad at x: [-2.54797579e-06 -1.00642192e-05]  gradient norm: 1.0381747833875777e-05\n",
            "iter: 935684  x: [ 3.99995847 15.99966776]  f(x): 1.72477420015774e-09  grad at x: [ 8.00111378e-05 -2.03835934e-05]  gradient norm: 8.256677939928354e-05\n",
            "iter: 935685  x: [ 3.99995847 15.99966776]  f(x): 1.7247221792391192e-09  grad at x: [-2.54871514e-06 -1.00638099e-05]  gradient norm: 1.038153256926272e-05\n",
            "iter: 935686  x: [ 3.99995847 15.99966777]  f(x): 1.7246689958207739e-09  grad at x: [ 8.00610110e-05 -2.03895106e-05]  gradient norm: 8.261656991540039e-05\n",
            "iter: 935687  x: [ 3.99995847 15.99966777]  f(x): 1.7246169131805732e-09  grad at x: [-2.54944002e-06 -1.00634024e-05]  gradient norm: 1.0381315577574627e-05\n",
            "iter: 935688  x: [ 3.99995847 15.99966778]  f(x): 1.7245637967682298e-09  grad at x: [ 8.01099382e-05 -2.03953095e-05]  gradient norm: 8.26654150582546e-05\n",
            "iter: 935689  x: [ 3.99995847 15.99966778]  f(x): 1.7245116535623548e-09  grad at x: [-2.55017953e-06 -1.00629932e-05]  gradient norm: 1.0381100478664073e-05\n",
            "iter: 935690  x: [ 3.99995848 15.99966779]  f(x): 1.7244586053128777e-09  grad at x: [ 8.01597821e-05 -2.04012231e-05]  gradient norm: 8.271517735858318e-05\n",
            "iter: 935691  x: [ 3.99995847 15.99966779]  f(x): 1.7244064003640289e-09  grad at x: [-2.55089001e-06 -1.00625875e-05]  gradient norm: 1.0380881837820135e-05\n",
            "iter: 935692  x: [ 3.99995848 15.9996678 ]  f(x): 1.7243534180356606e-09  grad at x: [ 8.02077778e-05 -2.04069056e-05]  gradient norm: 8.276309207528691e-05\n",
            "iter: 935693  x: [ 3.99995848 15.9996678 ]  f(x): 1.72430115356856e-09  grad at x: [-2.55161512e-06 -1.00621801e-05]  gradient norm: 1.0380665089359905e-05\n",
            "iter: 935694  x: [ 3.99995848 15.99966781]  f(x): 1.7242482384263085e-09  grad at x: [ 8.02567484e-05 -2.04127100e-05]  gradient norm: 8.281198215421121e-05\n",
            "iter: 935695  x: [ 3.99995848 15.99966781]  f(x): 1.7241959132125361e-09  grad at x: [-2.55235486e-06 -1.00617708e-05]  gradient norm: 1.0380450237118408e-05\n",
            "iter: 935696  x: [ 3.99995848 15.99966782]  f(x): 1.724143066415383e-09  grad at x: [ 8.03066357e-05 -2.04186290e-05]  gradient norm: 8.286178941734964e-05\n",
            "iter: 935697  x: [ 3.99995848 15.99966782]  f(x): 1.7240906792766561e-09  grad at x: [-2.55309468e-06 -1.00613615e-05]  gradient norm: 1.0380235468289192e-05\n",
            "iter: 935698  x: [ 3.99995848 15.99966783]  f(x): 1.7240379008258413e-09  grad at x: [ 8.03565084e-05 -2.04245462e-05]  gradient norm: 8.291158257198679e-05\n",
            "iter: 935699  x: [ 3.99995848 15.99966783]  f(x): 1.7239854517606264e-09  grad at x: [-2.55383457e-06 -1.00609523e-05]  gradient norm: 1.0380020782893954e-05\n",
            "iter: 935700  x: [ 3.99995848 15.99966784]  f(x): 1.7239327417299404e-09  grad at x: [ 8.04063955e-05 -2.04304652e-05]  gradient norm: 8.296139072188783e-05\n",
            "iter: 935701  x: [ 3.99995848 15.99966784]  f(x): 1.723880230664153e-09  grad at x: [-2.55457454e-06 -1.00605430e-05]  gradient norm: 1.0379806180954398e-05\n",
            "iter: 935702  x: [ 3.99995848 15.99966785]  f(x): 1.7238275891274188e-09  grad at x: [ 8.04562972e-05 -2.04363860e-05]  gradient norm: 8.301121386654768e-05\n",
            "iter: 935703  x: [ 3.99995848 15.99966785]  f(x): 1.723775016004813e-09  grad at x: [-2.55530004e-06 -1.00601355e-05]  gradient norm: 1.037958984302385e-05\n",
            "iter: 935704  x: [ 3.99995848 15.99966785]  f(x): 1.723735569750515e-09  grad at x: [ 3.89749764e-05 -1.52511620e-05]  gradient norm: 4.185267886764408e-05\n",
            "iter: 935705  x: [ 3.99995848 15.99966785]  f(x): 1.7237215927607171e-09  grad at x: [-1.90674612e-06 -1.01410424e-05]  gradient norm: 1.0318741252711015e-05\n",
            "iter: 935706  x: [ 3.99995849 15.99966789]  f(x): 1.7235099465785284e-09  grad at x: [ 1.61715033e-04 -3.05921149e-05]  gradient norm: 0.00016458319854578075\n",
            "iter: 935707  x: [ 3.99995849 15.99966789]  f(x): 1.723355552225608e-09  grad at x: [ 7.89447348e-05 -2.02460287e-05]  gradient norm: 8.149952659554474e-05\n",
            "iter: 935708  x: [ 3.99995849 15.9996679 ]  f(x): 1.723304847025099e-09  grad at x: [-2.53147429e-06 -1.00616980e-05]  gradient norm: 1.0375265284826641e-05\n",
            "iter: 935709  x: [ 3.99995849 15.9996679 ]  f(x): 1.7232504300396872e-09  grad at x: [ 7.89917110e-05 -2.02515839e-05]  gradient norm: 8.154641049859452e-05\n",
            "iter: 935710  x: [ 3.99995849 15.99966791]  f(x): 1.7231996674578781e-09  grad at x: [-2.53221477e-06 -1.00612888e-05]  gradient norm: 1.0375049082362867e-05\n",
            "iter: 935711  x: [ 3.99995849 15.99966791]  f(x): 1.7231453179227597e-09  grad at x: [ 7.90416413e-05 -2.02575084e-05]  gradient norm: 8.159624809345153e-05\n",
            "iter: 935712  x: [ 3.99995849 15.99966792]  f(x): 1.723094494325891e-09  grad at x: [-2.53294076e-06 -1.00608813e-05]  gradient norm: 1.0374831174442462e-05\n",
            "iter: 935713  x: [ 3.99995849 15.99966793]  f(x): 1.7230402111359342e-09  grad at x: [ 7.90906547e-05 -2.02633182e-05]  gradient norm: 8.16451696102912e-05\n",
            "iter: 935714  x: [ 3.99995849 15.99966793]  f(x): 1.7229893276109713e-09  grad at x: [-2.53366684e-06 -1.00604739e-05]  gradient norm: 1.0374613347622582e-05\n",
            "iter: 935715  x: [ 3.99995849 15.99966794]  f(x): 1.7229351107312293e-09  grad at x: [ 7.91396243e-05 -2.02691226e-05]  gradient norm: 8.169404793179778e-05\n",
            "iter: 935716  x: [ 3.99995849 15.99966794]  f(x): 1.7228841673306953e-09  grad at x: [-2.53437844e-06 -1.00600682e-05]  gradient norm: 1.0374393811096302e-05\n",
            "iter: 935717  x: [ 3.9999585  15.99966795]  f(x): 1.722830015725266e-09  grad at x: [ 7.91877062e-05 -2.02748161e-05]  gradient norm: 8.174203923192666e-05\n",
            "iter: 935718  x: [ 3.99995849 15.99966795]  f(x): 1.7227790134668983e-09  grad at x: [-2.53509011e-06 -1.00596626e-05]  gradient norm: 1.0374174353261313e-05\n",
            "iter: 935719  x: [ 3.9999585  15.99966796]  f(x): 1.722724927170607e-09  grad at x: [ 7.92357880e-05 -2.02805095e-05]  gradient norm: 8.179003095905901e-05\n",
            "iter: 935720  x: [ 3.9999585  15.99966796]  f(x): 1.7226738660014169e-09  grad at x: [-2.53581642e-06 -1.00592551e-05]  gradient norm: 1.0373956767615383e-05\n",
            "iter: 935721  x: [ 3.9999585  15.99966797]  f(x): 1.7226198462297167e-09  grad at x: [ 7.92848156e-05 -2.02863212e-05]  gradient norm: 8.183896879512344e-05\n",
            "iter: 935722  x: [ 3.9999585  15.99966797]  f(x): 1.7225687249708224e-09  grad at x: [-2.53655736e-06 -1.00588459e-05]  gradient norm: 1.037374105799774e-05\n",
            "iter: 935723  x: [ 3.9999585  15.99966798]  f(x): 1.7225147728683758e-09  grad at x: [ 7.93347745e-05 -2.02922492e-05]  gradient norm: 8.188883821564056e-05\n",
            "iter: 935724  x: [ 3.9999585  15.99966798]  f(x): 1.7224635903547e-09  grad at x: [-2.53726927e-06 -1.00584402e-05]  gradient norm: 1.0373521840336087e-05\n",
            "iter: 935725  x: [ 3.9999585  15.99966799]  f(x): 1.7224097036679378e-09  grad at x: [ 7.93828561e-05 -2.02979427e-05]  gradient norm: 8.193683124982724e-05\n",
            "iter: 935726  x: [ 3.9999585  15.99966799]  f(x): 1.7223584621538813e-09  grad at x: [-2.53798125e-06 -1.00580346e-05]  gradient norm: 1.0373302701666713e-05\n",
            "iter: 935727  x: [ 3.9999585 15.999668 ]  f(x): 1.722304640952904e-09  grad at x: [ 7.94309667e-05 -2.03036398e-05]  gradient norm: 8.198485380731972e-05\n",
            "iter: 935728  x: [ 3.9999585 15.999668 ]  f(x): 1.7222533403680734e-09  grad at x: [-2.53869332e-06 -1.00576290e-05]  gradient norm: 1.0373083642227906e-05\n",
            "iter: 935729  x: [ 3.9999585  15.99966801]  f(x): 1.7221995846877486e-09  grad at x: [ 7.94790772e-05 -2.03093368e-05]  gradient norm: 8.203287678791573e-05\n",
            "iter: 935730  x: [ 3.9999585  15.99966801]  f(x): 1.7221482249791167e-09  grad at x: [-2.53942001e-06 -1.00572215e-05]  gradient norm: 1.037286646046638e-05\n",
            "iter: 935731  x: [ 3.9999585  15.99966802]  f(x): 1.7220945360384444e-09  grad at x: [ 7.95281335e-05 -2.03151521e-05]  gradient norm: 8.208184592079258e-05\n",
            "iter: 935732  x: [ 3.9999585  15.99966802]  f(x): 1.7220431160235772e-09  grad at x: [-2.54016133e-06 -1.00568122e-05]  gradient norm: 1.0372651160223959e-05\n",
            "iter: 935733  x: [ 3.99995851 15.99966803]  f(x): 1.7219894949353824e-09  grad at x: [ 7.95780920e-05 -2.03210802e-05]  gradient norm: 8.213171758146163e-05\n",
            "iter: 935734  x: [ 3.9999585  15.99966803]  f(x): 1.7219380134810403e-09  grad at x: [-2.54087363e-06 -1.00564066e-05]  gradient norm: 1.037243234127585e-05\n",
            "iter: 935735  x: [ 3.99995851 15.99966804]  f(x): 1.7218844580201493e-09  grad at x: [ 7.96262023e-05 -2.03267773e-05]  gradient norm: 8.217974185522359e-05\n",
            "iter: 935736  x: [ 3.99995851 15.99966804]  f(x): 1.721832917352339e-09  grad at x: [-2.5415860e-06 -1.0056001e-05]  gradient norm: 1.0372213601207541e-05\n",
            "iter: 935737  x: [ 3.99995851 15.99966805]  f(x): 1.7217794275890028e-09  grad at x: [ 7.96743416e-05 -2.03324780e-05]  gradient norm: 8.222779565159512e-05\n",
            "iter: 935738  x: [ 3.99995851 15.99966805]  f(x): 1.7217278276383093e-09  grad at x: [-2.54232755e-06 -1.00555917e-05]  gradient norm: 1.0371998547206972e-05\n",
            "iter: 935739  x: [ 3.99995851 15.99966806]  f(x): 1.7216744058736779e-09  grad at x: [ 7.97243145e-05 -2.03384079e-05]  gradient norm: 8.227768319770803e-05\n",
            "iter: 935740  x: [ 3.99995851 15.99966806]  f(x): 1.721622744337529e-09  grad at x: [-2.54306919e-06 -1.00551824e-05]  gradient norm: 1.0371783576862752e-05\n",
            "iter: 935741  x: [ 3.99995851 15.99966807]  f(x): 1.7215693906446819e-09  grad at x: [ 7.97743163e-05 -2.03443415e-05]  gradient norm: 8.232760029884817e-05\n",
            "iter: 935742  x: [ 3.99995851 15.99966807]  f(x): 1.7215176674497052e-09  grad at x: [-2.54381090e-06 -1.00547732e-05]  gradient norm: 1.0371568690196662e-05\n",
            "iter: 935743  x: [ 3.99995851 15.99966808]  f(x): 1.7214643818301888e-09  grad at x: [ 7.98243035e-05 -2.03502732e-05]  gradient norm: 8.237750330589418e-05\n",
            "iter: 935744  x: [ 3.99995851 15.99966808]  f(x): 1.721412596955554e-09  grad at x: [-2.54453813e-06 -1.00543657e-05]  gradient norm: 1.0371352080186977e-05\n",
            "iter: 935745  x: [ 3.99995851 15.99966809]  f(x): 1.7213593784018768e-09  grad at x: [ 7.98734175e-05 -2.03560958e-05]  gradient norm: 8.242653372505681e-05\n",
            "iter: 935746  x: [ 3.99995851 15.99966809]  f(x): 1.7213075328927622e-09  grad at x: [-2.54527999e-06 -1.00539564e-05]  gradient norm: 1.0371137360010283e-05\n",
            "iter: 935747  x: [ 3.99995851 15.9996681 ]  f(x): 1.7212543825232689e-09  grad at x: [ 7.99234191e-05 -2.03620293e-05]  gradient norm: 8.247645218096785e-05\n",
            "iter: 935748  x: [ 3.99995851 15.9996681 ]  f(x): 1.7212024752599045e-09  grad at x: [-2.54600738e-06 -1.00535490e-05]  gradient norm: 1.0370920914253474e-05\n",
            "iter: 935749  x: [ 3.99995852 15.99966811]  f(x): 1.7211493919579237e-09  grad at x: [ 7.99724893e-05 -2.03678464e-05]  gradient norm: 8.252543982721902e-05\n",
            "iter: 935750  x: [ 3.99995851 15.99966811]  f(x): 1.7210974240388277e-09  grad at x: [-2.54673485e-06 -1.00531415e-05]  gradient norm: 1.0370704549981416e-05\n",
            "iter: 935751  x: [ 3.99995852 15.99966812]  f(x): 1.7210444078761855e-09  grad at x: [ 8.00215886e-05 -2.03736672e-05]  gradient norm: 8.257445700893466e-05\n",
            "iter: 935752  x: [ 3.99995852 15.99966812]  f(x): 1.720992379229238e-09  grad at x: [-2.54746239e-06 -1.00527341e-05]  gradient norm: 1.0370488267215468e-05\n",
            "iter: 935753  x: [ 3.99995852 15.99966813]  f(x): 1.7209394302422667e-09  grad at x: [ 8.00706877e-05 -2.03794880e-05]  gradient norm: 8.262347462239878e-05\n",
            "iter: 935754  x: [ 3.99995852 15.99966813]  f(x): 1.7208873408308421e-09  grad at x: [-2.54819001e-06 -1.00523266e-05]  gradient norm: 1.0370272066195238e-05\n",
            "iter: 935755  x: [ 3.99995852 15.99966814]  f(x): 1.720834459019662e-09  grad at x: [ 8.01197722e-05 -2.03853069e-05]  gradient norm: 8.267247811731001e-05\n",
            "iter: 935756  x: [ 3.99995852 15.99966814]  f(x): 1.7207823088422146e-09  grad at x: [-2.54888861e-06 -1.00519228e-05]  gradient norm: 1.0370052319096086e-05\n",
            "iter: 935757  x: [ 3.99995852 15.99966815]  f(x): 1.720729491965092e-09  grad at x: [ 8.01670085e-05 -2.03908949e-05]  gradient norm: 8.271963399624686e-05\n",
            "iter: 935758  x: [ 3.99995852 15.99966815]  f(x): 1.7206772832463383e-09  grad at x: [-2.54960183e-06 -1.00515172e-05]  gradient norm: 1.036983446402004e-05\n",
            "iter: 935759  x: [ 3.99995852 15.99966816]  f(x): 1.720624532566523e-09  grad at x: [ 8.02152198e-05 -2.03966047e-05]  gradient norm: 8.276776523232946e-05\n",
            "iter: 935760  x: [ 3.99995852 15.99966816]  f(x): 1.7205722640797629e-09  grad at x: [-2.55032968e-06 -1.00511097e-05]  gradient norm: 1.0369618504100148e-05\n",
            "iter: 935761  x: [ 3.99995852 15.99966817]  f(x): 1.7205195807188762e-09  grad at x: [ 8.02643186e-05 -2.04024254e-05]  gradient norm: 8.281678454189716e-05\n",
            "iter: 935762  x: [ 3.99995852 15.99966817]  f(x): 1.7204672513053534e-09  grad at x: [-2.55107216e-06 -1.00507004e-05]  gradient norm: 1.0369404442749812e-05\n",
            "iter: 935763  x: [ 3.99995852 15.99966818]  f(x): 1.7204146364946011e-09  grad at x: [ 8.03143778e-05 -2.04083663e-05]  gradient norm: 8.286676470673822e-05\n",
            "iter: 935764  x: [ 3.99995852 15.99966818]  f(x): 1.7203622449406717e-09  grad at x: [-2.55181472e-06 -1.00502912e-05]  gradient norm: 1.0369190465315706e-05\n",
            "iter: 935765  x: [ 3.99995853 15.99966819]  f(x): 1.7203096987178367e-09  grad at x: [ 8.03644369e-05 -2.04143071e-05]  gradient norm: 8.291674531855482e-05\n",
            "iter: 935766  x: [ 3.99995852 15.99966819]  f(x): 1.7202572449854247e-09  grad at x: [-2.55255736e-06 -1.00498819e-05]  gradient norm: 1.0368976571819631e-05\n",
            "iter: 935767  x: [ 3.99995853 15.99966819]  f(x): 1.7202178766486982e-09  grad at x: [ 3.8930962e-05 -1.5235064e-05]  gradient norm: 4.180582468989609e-05\n",
            "iter: 935768  x: [ 3.99995853 15.99966819]  f(x): 1.7202039307705833e-09  grad at x: [-1.90474691e-06 -1.01306960e-05]  gradient norm: 1.0308203592873665e-05\n",
            "iter: 935769  x: [ 3.99995853 15.99966823]  f(x): 1.7199926826434297e-09  grad at x: [ 1.61536314e-04 -3.05591802e-05]  gradient norm: 0.00016440147279665946\n",
            "iter: 935770  x: [ 3.99995853 15.99966823]  f(x): 1.7198386290319307e-09  grad at x: [ 7.88574324e-05 -2.02245210e-05]  gradient norm: 8.140961791807233e-05\n",
            "iter: 935771  x: [ 3.99995853 15.99966823]  f(x): 1.7197880354991832e-09  grad at x: [-2.52881594e-06 -1.00514353e-05]  gradient norm: 1.036466409729543e-05\n",
            "iter: 935772  x: [ 3.99995853 15.99966824]  f(x): 1.7197337237964294e-09  grad at x: [ 7.89063415e-05 -2.02303181e-05]  gradient norm: 8.14584341386525e-05\n",
            "iter: 935773  x: [ 3.99995853 15.99966824]  f(x): 1.7196830705990494e-09  grad at x: [-2.52952989e-06 -1.00510297e-05]  gradient norm: 1.036444494536813e-05\n",
            "iter: 935774  x: [ 3.99995853 15.99966825]  f(x): 1.719628824126447e-09  grad at x: [ 7.89545519e-05 -2.02360279e-05]  gradient norm: 8.15065524942212e-05\n",
            "iter: 935775  x: [ 3.99995853 15.99966825]  f(x): 1.7195781121064506e-09  grad at x: [-2.53024392e-06 -1.00506240e-05]  gradient norm: 1.036422587251208e-05\n",
            "iter: 935776  x: [ 3.99995854 15.99966826]  f(x): 1.719523930934973e-09  grad at x: [ 7.90027769e-05 -2.02417395e-05]  gradient norm: 8.155468583243004e-05\n",
            "iter: 935777  x: [ 3.99995853 15.99966826]  f(x): 1.7194731600210942e-09  grad at x: [-2.53095803e-06 -1.00502184e-05]  gradient norm: 1.0364006879181879e-05\n",
            "iter: 935778  x: [ 3.99995854 15.99966827]  f(x): 1.719419044220884e-09  grad at x: [ 7.90510309e-05 -2.02474548e-05]  gradient norm: 8.160284869928225e-05\n",
            "iter: 935779  x: [ 3.99995854 15.99966827]  f(x): 1.7193682143248341e-09  grad at x: [-2.53168677e-06 -1.00498110e-05]  gradient norm: 1.0363789755843053e-05\n",
            "iter: 935780  x: [ 3.99995854 15.99966828]  f(x): 1.7193141650737708e-09  grad at x: [ 7.91002016e-05 -2.02532847e-05]  gradient norm: 8.165192856228099e-05\n",
            "iter: 935781  x: [ 3.99995854 15.99966828]  f(x): 1.719263275053082e-09  grad at x: [-2.53240104e-06 -1.00494053e-05]  gradient norm: 1.0363570922305892e-05\n",
            "iter: 935782  x: [ 3.99995854 15.99966829]  f(x): 1.719209291244119e-09  grad at x: [ 7.91484555e-05 -2.02589999e-05]  gradient norm: 8.17000923047166e-05\n",
            "iter: 935783  x: [ 3.99995854 15.99966829]  f(x): 1.719158342187692e-09  grad at x: [-2.53311538e-06 -1.00489997e-05]  gradient norm: 1.0363352167923865e-05\n",
            "iter: 935784  x: [ 3.99995854 15.9996683 ]  f(x): 1.7191044238559078e-09  grad at x: [ 7.91967092e-05 -2.02647152e-05]  gradient norm: 8.174825647727472e-05\n",
            "iter: 935785  x: [ 3.99995854 15.9996683 ]  f(x): 1.7190534157105206e-09  grad at x: [-2.53384435e-06 -1.00485922e-05]  gradient norm: 1.0363135287387045e-05\n",
            "iter: 935786  x: [ 3.99995854 15.99966831]  f(x): 1.7189995640350136e-09  grad at x: [ 7.92458943e-05 -2.02705469e-05]  gradient norm: 8.17973522196376e-05\n",
            "iter: 935787  x: [ 3.99995854 15.99966832]  f(x): 1.718948495639126e-09  grad at x: [-2.53457339e-06 -1.00481848e-05]  gradient norm: 1.0362918488292412e-05\n",
            "iter: 935788  x: [ 3.99995854 15.99966832]  f(x): 1.718894710656358e-09  grad at x: [ 7.92950792e-05 -2.02763786e-05]  gradient norm: 8.18464484107315e-05\n",
            "iter: 935789  x: [ 3.99995854 15.99966833]  f(x): 1.718843581973215e-09  grad at x: [-2.53530252e-06 -1.00477773e-05]  gradient norm: 1.0362701770878491e-05\n",
            "iter: 935790  x: [ 3.99995854 15.99966833]  f(x): 1.7187898637196478e-09  grad at x: [ 7.93442641e-05 -2.02822102e-05]  gradient norm: 8.189554504789073e-05\n",
            "iter: 935791  x: [ 3.99995854 15.99966834]  f(x): 1.718738674712494e-09  grad at x: [-2.53603172e-06 -1.00473699e-05]  gradient norm: 1.0362485135384087e-05\n",
            "iter: 935792  x: [ 3.99995855 15.99966835]  f(x): 1.7186850232598478e-09  grad at x: [ 7.93934780e-05 -2.02880456e-05]  gradient norm: 8.194467123033016e-05\n",
            "iter: 935793  x: [ 3.99995854 15.99966835]  f(x): 1.7186337738566698e-09  grad at x: [-2.53676100e-06 -1.00469624e-05]  gradient norm: 1.0362268581395971e-05\n",
            "iter: 935794  x: [ 3.99995855 15.99966836]  f(x): 1.7185801891701202e-09  grad at x: [ 7.94426482e-05 -2.02938754e-05]  gradient norm: 8.19937542111653e-05\n",
            "iter: 935795  x: [ 3.99995855 15.99966836]  f(x): 1.7185288794054493e-09  grad at x: [-2.53749036e-06 -1.00465550e-05]  gradient norm: 1.0362052109152883e-05\n",
            "iter: 935796  x: [ 3.99995855 15.99966837]  f(x): 1.7184753615927988e-09  grad at x: [ 7.94918619e-05 -2.02997107e-05]  gradient norm: 8.204288128348474e-05\n",
            "iter: 935797  x: [ 3.99995855 15.99966837]  f(x): 1.718423991358539e-09  grad at x: [-2.53821979e-06 -1.00461475e-05]  gradient norm: 1.0361835718893829e-05\n",
            "iter: 935798  x: [ 3.99995855 15.99966838]  f(x): 1.7183705404562923e-09  grad at x: [ 7.95410756e-05 -2.03055461e-05]  gradient norm: 8.209200879869672e-05\n",
            "iter: 935799  x: [ 3.99995855 15.99966838]  f(x): 1.7183191097156458e-09  grad at x: [-2.53894930e-06 -1.00457401e-05]  gradient norm: 1.0361619410205184e-05\n",
            "iter: 935800  x: [ 3.99995855 15.99966839]  f(x): 1.7182657257956536e-09  grad at x: [ 7.95903183e-05 -2.03113850e-05]  gradient norm: 8.214116585891381e-05\n",
            "iter: 935801  x: [ 3.99995855 15.99966839]  f(x): 1.7182142344764763e-09  grad at x: [-2.53967889e-06 -1.00453326e-05]  gradient norm: 1.0361403183325892e-05\n",
            "iter: 935802  x: [ 3.99995855 15.9996684 ]  f(x): 1.7181609175399191e-09  grad at x: [ 7.96395318e-05 -2.03172203e-05]  gradient norm: 8.219029425911985e-05\n",
            "iter: 935803  x: [ 3.99995855 15.9996684 ]  f(x): 1.7181093656217662e-09  grad at x: [-2.5403940e-06 -1.0044927e-05]  gradient norm: 1.03611852338421e-05\n",
            "iter: 935804  x: [ 3.99995855 15.99966841]  f(x): 1.7180561145548448e-09  grad at x: [ 7.96878139e-05 -2.03229392e-05]  gradient norm: 8.223849187803297e-05\n",
            "iter: 935805  x: [ 3.99995855 15.99966841]  f(x): 1.7180045031701946e-09  grad at x: [-2.54110919e-06 -1.00445213e-05]  gradient norm: 1.0360967363745002e-05\n",
            "iter: 935806  x: [ 3.99995855 15.99966842]  f(x): 1.7179513180434394e-09  grad at x: [ 7.97361250e-05 -2.03286618e-05]  gradient norm: 8.228671901991162e-05\n",
            "iter: 935807  x: [ 3.99995855 15.99966842]  f(x): 1.7178996471214674e-09  grad at x: [-2.54182446e-06 -1.00441157e-05]  gradient norm: 1.0360749573491219e-05\n",
            "iter: 935808  x: [ 3.99995856 15.99966843]  f(x): 1.7178465279700418e-09  grad at x: [ 7.97844361e-05 -2.03343843e-05]  gradient norm: 8.233494658398161e-05\n",
            "iter: 935809  x: [ 3.99995855 15.99966843]  f(x): 1.717794797475292e-09  grad at x: [-2.54253980e-06 -1.00437101e-05]  gradient norm: 1.0360531862666048e-05\n",
            "iter: 935810  x: [ 3.99995856 15.99966844]  f(x): 1.7177417443343584e-09  grad at x: [ 7.98327471e-05 -2.03401069e-05]  gradient norm: 8.238317456764571e-05\n",
            "iter: 935811  x: [ 3.99995856 15.99966844]  f(x): 1.717689954231375e-09  grad at x: [-2.54325523e-06 -1.00433044e-05]  gradient norm: 1.0360314231726376e-05\n",
            "iter: 935812  x: [ 3.99995856 15.99966845]  f(x): 1.7176369671360962e-09  grad at x: [ 7.98810580e-05 -2.03458294e-05]  gradient norm: 8.243140297003005e-05\n",
            "iter: 935813  x: [ 3.99995856 15.99966845]  f(x): 1.7175851173894236e-09  grad at x: [-2.54397072e-06 -1.00428988e-05]  gradient norm: 1.0360096680257239e-05\n",
            "iter: 935814  x: [ 3.99995856 15.99966846]  f(x): 1.717532196410458e-09  grad at x: [ 7.99293979e-05 -2.03515556e-05]  gradient norm: 8.2479660893585e-05\n",
            "iter: 935815  x: [ 3.99995856 15.99966846]  f(x): 1.717480286931305e-09  grad at x: [-2.54470085e-06 -1.00424913e-05]  gradient norm: 1.0359881019835037e-05\n",
            "iter: 935816  x: [ 3.99995856 15.99966847]  f(x): 1.7174274332227615e-09  grad at x: [ 7.99786400e-05 -2.03573945e-05]  gradient norm: 8.252882141380256e-05\n",
            "iter: 935817  x: [ 3.99995856 15.99966847]  f(x): 1.7173754628745667e-09  grad at x: [-2.54543106e-06 -1.00420839e-05]  gradient norm: 1.0359665441174713e-05\n",
            "iter: 935818  x: [ 3.99995856 15.99966848]  f(x): 1.7173226765085322e-09  grad at x: [ 8.00279111e-05 -2.03632371e-05]  gradient norm: 8.257801146878542e-05\n",
            "iter: 935819  x: [ 3.99995856 15.99966848]  f(x): 1.7172706452189157e-09  grad at x: [-2.54616134e-06 -1.00416764e-05]  gradient norm: 1.0359449944734122e-05\n",
            "iter: 935820  x: [ 3.99995856 15.99966849]  f(x): 1.7172179262319808e-09  grad at x: [ 8.00771821e-05 -2.03690797e-05]  gradient norm: 8.262720196118076e-05\n",
            "iter: 935821  x: [ 3.99995856 15.99966849]  f(x): 1.7171658339640588e-09  grad at x: [-2.5468917e-06 -1.0041269e-05]  gradient norm: 1.035923453009819e-05\n",
            "iter: 935822  x: [ 3.99995856 15.9996685 ]  f(x): 1.7171131823928139e-09  grad at x: [ 8.01264531e-05 -2.03749223e-05]  gradient norm: 8.267639288663132e-05\n",
            "iter: 935823  x: [ 3.99995856 15.9996685 ]  f(x): 1.7170610291097025e-09  grad at x: [-2.54762214e-06 -1.00408615e-05]  gradient norm: 1.0359019197506612e-05\n",
            "iter: 935824  x: [ 3.99995857 15.99966851]  f(x): 1.717008444990738e-09  grad at x: [ 8.01757239e-05 -2.03807649e-05]  gradient norm: 8.27255842442249e-05\n",
            "iter: 935825  x: [ 3.99995856 15.99966851]  f(x): 1.716956230655554e-09  grad at x: [-2.54835265e-06 -1.00404541e-05]  gradient norm: 1.035880394719935e-05\n",
            "iter: 935826  x: [ 3.99995857 15.99966852]  f(x): 1.7169037140610876e-09  grad at x: [ 8.02250239e-05 -2.03866111e-05]  gradient norm: 8.27748051398136e-05\n",
            "iter: 935827  x: [ 3.99995857 15.99966852]  f(x): 1.7168514385834854e-09  grad at x: [-2.54909780e-06 -1.00400448e-05]  gradient norm: 1.0358590596712316e-05\n",
            "iter: 935828  x: [ 3.99995857 15.99966853]  f(x): 1.7167989906731327e-09  grad at x: [ 8.02752259e-05 -2.03925701e-05]  gradient norm: 8.282492869530176e-05\n",
            "iter: 935829  x: [ 3.99995857 15.99966853]  f(x): 1.7167466529110397e-09  grad at x: [-2.54984302e-06 -1.00396355e-05]  gradient norm: 1.0358377330626025e-05\n",
            "iter: 935830  x: [ 3.99995857 15.99966853]  f(x): 1.7167073628158003e-09  grad at x: [ 3.88878070e-05 -1.52190842e-05]  gradient norm: 4.175981387134286e-05\n",
            "iter: 935831  x: [ 3.99995857 15.99966853]  f(x): 1.7166934474658382e-09  grad at x: [-1.90276148e-06 -1.01203586e-05]  gradient norm: 1.0297677418851518e-05\n",
            "iter: 935832  x: [ 3.99995858 15.99966857]  f(x): 1.7164826042572842e-09  grad at x: [ 1.61360841e-04 -3.05266622e-05]  gradient norm: 0.00016422301382260093\n",
            "iter: 935833  x: [ 3.99995857 15.99966857]  f(x): 1.7163288848861248e-09  grad at x: [ 7.87717314e-05 -2.02032243e-05]  gradient norm: 8.132131297670776e-05\n",
            "iter: 935834  x: [ 3.99995857 15.99966857]  f(x): 1.7162784009507445e-09  grad at x: [-2.52614225e-06 -1.00411853e-05]  gradient norm: 1.0354071518726975e-05\n",
            "iter: 935835  x: [ 3.99995858 15.99966858]  f(x): 1.7162241928999957e-09  grad at x: [ 7.88199103e-05 -2.02089304e-05]  gradient norm: 8.136939924023827e-05\n",
            "iter: 935836  x: [ 3.99995857 15.99966858]  f(x): 1.7161736502607929e-09  grad at x: [-2.52684424e-06 -1.00407815e-05]  gradient norm: 1.0353851202952215e-05\n",
            "iter: 935837  x: [ 3.99995858 15.99966859]  f(x): 1.7161195064353214e-09  grad at x: [ 7.88673470e-05 -2.02145438e-05]  gradient norm: 8.141674398180952e-05\n",
            "iter: 935838  x: [ 3.99995858 15.99966859]  f(x): 1.7160689059507323e-09  grad at x: [-2.52756085e-06 -1.00403759e-05]  gradient norm: 1.0353632752975168e-05\n",
            "iter: 935839  x: [ 3.99995858 15.9996686 ]  f(x): 1.7160148275587846e-09  grad at x: [ 7.89157440e-05 -2.02202773e-05]  gradient norm: 8.14650493299738e-05\n",
            "iter: 935840  x: [ 3.99995858 15.9996686 ]  f(x): 1.7159641680381066e-09  grad at x: [-2.52827755e-06 -1.00399702e-05]  gradient norm: 1.0353414382968437e-05\n",
            "iter: 935841  x: [ 3.99995858 15.99966861]  f(x): 1.7159101551149734e-09  grad at x: [ 7.89641409e-05 -2.02260107e-05]  gradient norm: 8.151335511616811e-05\n",
            "iter: 935842  x: [ 3.99995858 15.99966861]  f(x): 1.7158594365226228e-09  grad at x: [-2.52899432e-06 -1.00395646e-05]  gradient norm: 1.0353196092736362e-05\n",
            "iter: 935843  x: [ 3.99995858 15.99966862]  f(x): 1.7158054891035948e-09  grad at x: [ 7.90125378e-05 -2.02317442e-05]  gradient norm: 8.15616613394782e-05\n",
            "iter: 935844  x: [ 3.99995858 15.99966862]  f(x): 1.715754711403988e-09  grad at x: [-2.52971116e-06 -1.00391590e-05]  gradient norm: 1.035297788208301e-05\n",
            "iter: 935845  x: [ 3.99995858 15.99966863]  f(x): 1.7157008295594663e-09  grad at x: [ 7.90609637e-05 -2.02374813e-05]  gradient norm: 8.160999709420149e-05\n",
            "iter: 935846  x: [ 3.99995858 15.99966863]  f(x): 1.7156499926640763e-09  grad at x: [-2.53044264e-06 -1.00387515e-05]  gradient norm: 1.0352761544443839e-05\n",
            "iter: 935847  x: [ 3.99995858 15.99966864]  f(x): 1.7155961775363365e-09  grad at x: [ 7.91102917e-05 -2.02433312e-05]  gradient norm: 8.16592353159753e-05\n",
            "iter: 935848  x: [ 3.99995858 15.99966864]  f(x): 1.715545280320429e-09  grad at x: [-2.5311742e-06 -1.0038344e-05]  gradient norm: 1.0352545288679682e-05\n",
            "iter: 935849  x: [ 3.99995858 15.99966865]  f(x): 1.715491531981303e-09  grad at x: [ 7.91596488e-05 -2.02491847e-05]  gradient norm: 8.170850308844822e-05\n",
            "iter: 935850  x: [ 3.99995858 15.99966865]  f(x): 1.7154405743727529e-09  grad at x: [-2.53190583e-06 -1.00379366e-05]  gradient norm: 1.0352329115029085e-05\n",
            "iter: 935851  x: [ 3.99995859 15.99966866]  f(x): 1.7153868928589618e-09  grad at x: [ 7.92090058e-05 -2.02550382e-05]  gradient norm: 8.175777131201022e-05\n",
            "iter: 935852  x: [ 3.99995858 15.99966866]  f(x): 1.7153358748385847e-09  grad at x: [-2.53262298e-06 -1.00375310e-05]  gradient norm: 1.0352111227338036e-05\n",
            "iter: 935853  x: [ 3.99995859 15.99966867]  f(x): 1.715282259006683e-09  grad at x: [ 7.92574168e-05 -2.02607735e-05]  gradient norm: 8.180609428157062e-05\n",
            "iter: 935854  x: [ 3.99995859 15.99966867]  f(x): 1.715231181663017e-09  grad at x: [-2.53334022e-06 -1.00371253e-05]  gradient norm: 1.0351893419331307e-05\n",
            "iter: 935855  x: [ 3.99995859 15.99966868]  f(x): 1.7151776315843191e-09  grad at x: [ 7.93058423e-05 -2.02665105e-05]  gradient norm: 8.185443223052225e-05\n",
            "iter: 935856  x: [ 3.99995859 15.99966868]  f(x): 1.7151264948825423e-09  grad at x: [-2.53405753e-06 -1.00367197e-05]  gradient norm: 1.0351675691029802e-05\n",
            "iter: 935857  x: [ 3.99995859 15.99966869]  f(x): 1.7150730105923808e-09  grad at x: [ 7.93542677e-05 -2.02722476e-05]  gradient norm: 8.190277061077559e-05\n",
            "iter: 935858  x: [ 3.99995859 15.99966869]  f(x): 1.7150218144968677e-09  grad at x: [-2.53477491e-06 -1.00363141e-05]  gradient norm: 1.035145804288941e-05\n",
            "iter: 935859  x: [ 3.99995859 15.9996687 ]  f(x): 1.7149683960658372e-09  grad at x: [ 7.94027222e-05 -2.02779884e-05]  gradient norm: 8.19511385204085e-05\n",
            "iter: 935860  x: [ 3.99995859 15.9996687 ]  f(x): 1.7149171404878726e-09  grad at x: [-2.53550693e-06 -1.00359066e-05]  gradient norm: 1.0351242275359234e-05\n",
            "iter: 935861  x: [ 3.99995859 15.99966871]  f(x): 1.7148637890982755e-09  grad at x: [ 7.94521079e-05 -2.02838455e-05]  gradient norm: 8.20004380521667e-05\n",
            "iter: 935862  x: [ 3.99995859 15.99966871]  f(x): 1.714812472873093e-09  grad at x: [-2.53623903e-06 -1.00354991e-05]  gradient norm: 1.035102659028873e-05\n",
            "iter: 935863  x: [ 3.99995859 15.99966872]  f(x): 1.7147591885616933e-09  grad at x: [ 7.95014936e-05 -2.02897027e-05]  gradient norm: 8.204973803340608e-05\n",
            "iter: 935864  x: [ 3.99995859 15.99966872]  f(x): 1.714707811652236e-09  grad at x: [-2.53697120e-06 -1.00350917e-05]  gradient norm: 1.0350810987264256e-05\n",
            "iter: 935865  x: [ 3.99995859 15.99966873]  f(x): 1.7146545944557972e-09  grad at x: [ 7.95508791e-05 -2.02955598e-05]  gradient norm: 8.209903845801859e-05\n",
            "iter: 935866  x: [ 3.99995859 15.99966873]  f(x): 1.7146031568060566e-09  grad at x: [-2.53768889e-06 -1.00346861e-05]  gradient norm: 1.0350593662246568e-05\n",
            "iter: 935867  x: [ 3.9999586  15.99966874]  f(x): 1.7145500056483772e-09  grad at x: [ 7.95993478e-05 -2.03013024e-05]  gradient norm: 8.214742265847159e-05\n",
            "iter: 935868  x: [ 3.99995859 15.99966874]  f(x): 1.714498508354342e-09  grad at x: [-2.53843577e-06 -1.00342768e-05]  gradient norm: 1.035038002809222e-05\n",
            "iter: 935869  x: [ 3.9999586  15.99966875]  f(x): 1.7144454255341914e-09  grad at x: [ 7.96496646e-05 -2.03072759e-05]  gradient norm: 8.219765519586365e-05\n",
            "iter: 935870  x: [ 3.9999586  15.99966875]  f(x): 1.7143938662956722e-09  grad at x: [-2.53918272e-06 -1.00338675e-05]  gradient norm: 1.0350166478564206e-05\n",
            "iter: 935871  x: [ 3.9999586  15.99966876]  f(x): 1.7143408518866242e-09  grad at x: [ 7.97000103e-05 -2.03132531e-05]  gradient norm: 8.224791729677376e-05\n",
            "iter: 935872  x: [ 3.9999586  15.99966876]  f(x): 1.714289230611932e-09  grad at x: [-2.53994431e-06 -1.00334564e-05]  gradient norm: 1.0349954821658895e-05\n",
            "iter: 935873  x: [ 3.9999586  15.99966877]  f(x): 1.7142362858033838e-09  grad at x: [ 7.97512874e-05 -2.03193467e-05]  gradient norm: 8.22991111120376e-05\n",
            "iter: 935874  x: [ 3.9999586  15.99966877]  f(x): 1.7141846013195247e-09  grad at x: [-2.54067686e-06 -1.00330490e-05]  gradient norm: 1.034973963347505e-05\n",
            "iter: 935875  x: [ 3.9999586  15.99966878]  f(x): 1.7141317238473529e-09  grad at x: [ 7.98007017e-05 -2.03252075e-05]  gradient norm: 8.234844288476934e-05\n",
            "iter: 935876  x: [ 3.9999586  15.99966879]  f(x): 1.7140799784371062e-09  grad at x: [-2.54139495e-06 -1.00326433e-05]  gradient norm: 1.0349522717867489e-05\n",
            "iter: 935877  x: [ 3.9999586  15.99966879]  f(x): 1.7140271671494253e-09  grad at x: [ 7.98491700e-05 -2.03309501e-05]  gradient norm: 8.239682927792411e-05\n",
            "iter: 935878  x: [ 3.9999586 15.9996688]  f(x): 1.713975361910919e-09  grad at x: [-2.54214221e-06 -1.00322341e-05]  gradient norm: 1.034930950452647e-05\n",
            "iter: 935879  x: [ 3.9999586 15.9996688]  f(x): 1.7139226191857944e-09  grad at x: [ 7.98995154e-05 -2.03369273e-05]  gradient norm: 8.244709320179557e-05\n",
            "iter: 935880  x: [ 3.9999586  15.99966881]  f(x): 1.7138707517751859e-09  grad at x: [-2.54286045e-06 -1.00318284e-05]  gradient norm: 1.0349092751272707e-05\n",
            "iter: 935881  x: [ 3.9999586  15.99966882]  f(x): 1.7138180753428692e-09  grad at x: [ 7.99479981e-05 -2.03426716e-05]  gradient norm: 8.249549500780779e-05\n",
            "iter: 935882  x: [ 3.9999586  15.99966882]  f(x): 1.713766148030742e-09  grad at x: [-2.54357876e-06 -1.00314228e-05]  gradient norm: 1.0348876077999386e-05\n",
            "iter: 935883  x: [ 3.99995861 15.99966883]  f(x): 1.7137135379621758e-09  grad at x: [ 7.99965099e-05 -2.03484196e-05]  gradient norm: 8.254392633525966e-05\n",
            "iter: 935884  x: [ 3.9999586  15.99966883]  f(x): 1.7136615506594763e-09  grad at x: [-2.54431170e-06 -1.00310153e-05]  gradient norm: 1.0348661299716904e-05\n",
            "iter: 935885  x: [ 3.99995861 15.99966884]  f(x): 1.7136090081454772e-09  grad at x: [ 8.00459529e-05 -2.03542841e-05]  gradient norm: 8.259328939012101e-05\n",
            "iter: 935886  x: [ 3.99995861 15.99966884]  f(x): 1.7135569596789155e-09  grad at x: [-2.54504472e-06 -1.00306079e-05]  gradient norm: 1.0348446603716592e-05\n",
            "iter: 935887  x: [ 3.99995861 15.99966885]  f(x): 1.7135044847563336e-09  grad at x: [ 8.00953958e-05 -2.03601485e-05]  gradient norm: 8.264265288096006e-05\n",
            "iter: 935888  x: [ 3.99995861 15.99966885]  f(x): 1.7134523750887673e-09  grad at x: [-2.54577782e-06 -1.00302004e-05]  gradient norm: 1.0348231990456803e-05\n",
            "iter: 935889  x: [ 3.99995861 15.99966886]  f(x): 1.7133999677944517e-09  grad at x: [ 8.01448387e-05 -2.03660129e-05]  gradient norm: 8.269201680857748e-05\n",
            "iter: 935890  x: [ 3.99995861 15.99966886]  f(x): 1.713347796870922e-09  grad at x: [-2.54652554e-06 -1.00297912e-05]  gradient norm: 1.0348019277515886e-05\n",
            "iter: 935891  x: [ 3.99995861 15.99966887]  f(x): 1.7132954584353863e-09  grad at x: [ 8.01952273e-05 -2.03719956e-05]  gradient norm: 8.274232705681426e-05\n",
            "iter: 935892  x: [ 3.99995861 15.99966887]  f(x): 1.7132432250607204e-09  grad at x: [-2.54725879e-06 -1.00293837e-05]  gradient norm: 1.0347804830286839e-05\n",
            "iter: 935893  x: [ 3.99995861 15.99966887]  f(x): 1.7132040155153141e-09  grad at x: [ 3.88487129e-05 -1.52036228e-05]  gradient norm: 4.1717773624798094e-05\n",
            "iter: 935894  x: [ 3.99995861 15.99966887]  f(x): 1.713190128196888e-09  grad at x: [-1.90083341e-06 -1.01100250e-05]  gradient norm: 1.0287165417746151e-05\n",
            "iter: 935895  x: [ 3.99995862 15.99966891]  f(x): 1.712979724489465e-09  grad at x: [ 1.61199835e-04 -3.04959631e-05]  gradient norm: 0.00016405910660755336\n",
            "iter: 935896  x: [ 3.99995862 15.99966891]  f(x): 1.712826311865788e-09  grad at x: [ 7.86931619e-05 -2.01828298e-05]  gradient norm: 8.124014004041472e-05\n",
            "iter: 935897  x: [ 3.99995861 15.99966891]  f(x): 1.7127759286824039e-09  grad at x: [-2.52359867e-06 -1.00309298e-05]  gradient norm: 1.0343505390547805e-05\n",
            "iter: 935898  x: [ 3.99995862 15.99966892]  f(x): 1.712721834027611e-09  grad at x: [ 7.87417021e-05 -2.01885814e-05]  gradient norm: 8.128858752310395e-05\n",
            "iter: 935899  x: [ 3.99995862 15.99966892]  f(x): 1.7126713917655112e-09  grad at x: [-2.52431779e-06 -1.00305242e-05]  gradient norm: 1.0343287495046999e-05\n",
            "iter: 935900  x: [ 3.99995862 15.99966893]  f(x): 1.7126173626122834e-09  grad at x: [ 7.87902566e-05 -2.01943349e-05]  gradient norm: 8.133704999514147e-05\n",
            "iter: 935901  x: [ 3.99995862 15.99966893]  f(x): 1.7125668612187364e-09  grad at x: [-2.52505154e-06 -1.00301168e-05]  gradient norm: 1.034307146810338e-05\n",
            "iter: 935902  x: [ 3.99995862 15.99966894]  f(x): 1.7125128987416833e-09  grad at x: [ 7.88397279e-05 -2.02002029e-05]  gradient norm: 8.138642945506027e-05\n",
            "iter: 935903  x: [ 3.99995862 15.99966894]  f(x): 1.712462337058484e-09  grad at x: [-2.52575626e-06 -1.00297129e-05]  gradient norm: 1.0342851944173306e-05\n",
            "iter: 935904  x: [ 3.99995862 15.99966895]  f(x): 1.7124084390517162e-09  grad at x: [ 7.88873656e-05 -2.02058418e-05]  gradient norm: 8.14339762659279e-05\n",
            "iter: 935905  x: [ 3.99995862 15.99966895]  f(x): 1.7123578192677664e-09  grad at x: [-2.52647561e-06 -1.00293073e-05]  gradient norm: 1.0342634289059486e-05\n",
            "iter: 935906  x: [ 3.99995862 15.99966896]  f(x): 1.7123039869050435e-09  grad at x: [ 7.89359345e-05 -2.02115971e-05]  gradient norm: 8.148245461115635e-05\n",
            "iter: 935907  x: [ 3.99995862 15.99966896]  f(x): 1.712253307864108e-09  grad at x: [-2.52719504e-06 -1.00289017e-05]  gradient norm: 1.034241671397224e-05\n",
            "iter: 935908  x: [ 3.99995862 15.99966897]  f(x): 1.712199541180975e-09  grad at x: [ 7.89845033e-05 -2.02173524e-05]  gradient norm: 8.153093339472952e-05\n",
            "iter: 935909  x: [ 3.99995862 15.99966897]  f(x): 1.7121488028294016e-09  grad at x: [-2.52792910e-06 -1.00284942e-05]  gradient norm: 1.0342201012445348e-05\n",
            "iter: 935910  x: [ 3.99995862 15.99966898]  f(x): 1.7120951030023763e-09  grad at x: [ 7.90340034e-05 -2.02232241e-05]  gradient norm: 8.158034374666463e-05\n",
            "iter: 935911  x: [ 3.99995862 15.99966898]  f(x): 1.7120443041989838e-09  grad at x: [-2.52864868e-06 -1.00280886e-05]  gradient norm: 1.0341983599247386e-05\n",
            "iter: 935912  x: [ 3.99995863 15.99966899]  f(x): 1.7119906701233284e-09  grad at x: [ 7.90825721e-05 -2.02289793e-05]  gradient norm: 8.162882341523613e-05\n",
            "iter: 935913  x: [ 3.99995862 15.99966899]  f(x): 1.7119398119179987e-09  grad at x: [-2.52936834e-06 -1.00276829e-05]  gradient norm: 1.0341766265922286e-05\n",
            "iter: 935914  x: [ 3.99995863 15.999669  ]  f(x): 1.711886243664402e-09  grad at x: [ 7.91311698e-05 -2.02347383e-05]  gradient norm: 8.167733262065754e-05\n",
            "iter: 935915  x: [ 3.99995863 15.999669  ]  f(x): 1.711835326022904e-09  grad at x: [-2.53008808e-06 -1.00272773e-05]  gradient norm: 1.0341549013142727e-05\n",
            "iter: 935916  x: [ 3.99995863 15.99966901]  f(x): 1.7117818236269542e-09  grad at x: [ 7.91797674e-05 -2.02404972e-05]  gradient norm: 8.172584226131811e-05\n",
            "iter: 935917  x: [ 3.99995863 15.99966901]  f(x): 1.7117308464955957e-09  grad at x: [-2.53082245e-06 -1.00268699e-05]  gradient norm: 1.0341333638298861e-05\n",
            "iter: 935918  x: [ 3.99995863 15.99966902]  f(x): 1.7116774111014392e-09  grad at x: [ 7.92292672e-05 -2.02463689e-05]  gradient norm: 8.177525440629803e-05\n",
            "iter: 935919  x: [ 3.99995863 15.99966902]  f(x): 1.7116263733535939e-09  grad at x: [-2.53155689e-06 -1.00264624e-05]  gradient norm: 1.0341118345873049e-05\n",
            "iter: 935920  x: [ 3.99995863 15.99966903]  f(x): 1.711573005033375e-09  grad at x: [ 7.92787960e-05 -2.02522442e-05]  gradient norm: 8.1824696101562e-05\n",
            "iter: 935921  x: [ 3.99995863 15.99966903]  f(x): 1.7115219066144156e-09  grad at x: [-2.53227686e-06 -1.00260568e-05]  gradient norm: 1.034090133645026e-05\n",
            "iter: 935922  x: [ 3.99995863 15.99966904]  f(x): 1.711468604259208e-09  grad at x: [ 7.9327408e-05 -2.0258005e-05]  gradient norm: 8.187322161366102e-05\n",
            "iter: 935923  x: [ 3.99995863 15.99966904]  f(x): 1.7114174462232142e-09  grad at x: [-2.53299690e-06 -1.00256511e-05]  gradient norm: 1.0340684407223372e-05\n",
            "iter: 935924  x: [ 3.99995863 15.99966905]  f(x): 1.711364209905371e-09  grad at x: [ 7.93760198e-05 -2.02637657e-05]  gradient norm: 8.19217475593339e-05\n",
            "iter: 935925  x: [ 3.99995863 15.99966905]  f(x): 1.7113129922164423e-09  grad at x: [-2.53371702e-06 -1.00252455e-05]  gradient norm: 1.0340467558213383e-05\n",
            "iter: 935926  x: [ 3.99995864 15.99966906]  f(x): 1.711259821970837e-09  grad at x: [ 7.94246462e-05 -2.02695282e-05]  gradient norm: 8.197028848574707e-05\n",
            "iter: 935927  x: [ 3.99995863 15.99966906]  f(x): 1.7112085445759994e-09  grad at x: [-2.53445178e-06 -1.00248380e-05]  gradient norm: 1.0340252593115746e-05\n",
            "iter: 935928  x: [ 3.99995864 15.99966907]  f(x): 1.7111554415501889e-09  grad at x: [ 7.94741747e-05 -2.02754036e-05]  gradient norm: 8.201973195936085e-05\n",
            "iter: 935929  x: [ 3.99995864 15.99966907]  f(x): 1.7111041033194016e-09  grad at x: [-2.53518660e-06 -1.00244306e-05]  gradient norm: 1.0340037710543412e-05\n",
            "iter: 935930  x: [ 3.99995864 15.99966908]  f(x): 1.7110510675856823e-09  grad at x: [ 7.95237322e-05 -2.02812826e-05]  gradient norm: 8.206920498057318e-05\n",
            "iter: 935931  x: [ 3.99995864 15.99966908]  f(x): 1.7109996684463569e-09  grad at x: [-2.53592151e-06 -1.00240231e-05]  gradient norm: 1.0339822910953474e-05\n",
            "iter: 935932  x: [ 3.99995864 15.99966909]  f(x): 1.710946700005715e-09  grad at x: [ 7.95732751e-05 -2.02871597e-05]  gradient norm: 8.21186638986129e-05\n",
            "iter: 935933  x: [ 3.99995864 15.99966909]  f(x): 1.7108952399376406e-09  grad at x: [-2.53664194e-06 -1.00236175e-05]  gradient norm: 1.0339606387262579e-05\n",
            "iter: 935934  x: [ 3.99995864 15.9996691 ]  f(x): 1.7108423377491571e-09  grad at x: [ 7.96219302e-05 -2.02929259e-05]  gradient norm: 8.216723567567281e-05\n",
            "iter: 935935  x: [ 3.99995864 15.9996691 ]  f(x): 1.710790817794088e-09  grad at x: [-2.53737700e-06 -1.00232101e-05]  gradient norm: 1.0339391751687216e-05\n",
            "iter: 935936  x: [ 3.99995864 15.99966911]  f(x): 1.710737983044134e-09  grad at x: [ 7.96715021e-05 -2.02988067e-05]  gradient norm: 8.221672458000845e-05\n",
            "iter: 935937  x: [ 3.99995864 15.99966911]  f(x): 1.7106864020332123e-09  grad at x: [-2.53811214e-06 -1.00228026e-05]  gradient norm: 1.0339177199159082e-05\n",
            "iter: 935938  x: [ 3.99995864 15.99966912]  f(x): 1.7106336347581674e-09  grad at x: [ 7.97210884e-05 -2.03046893e-05]  gradient norm: 8.226622848126108e-05\n",
            "iter: 935939  x: [ 3.99995864 15.99966912]  f(x): 1.7105819926369179e-09  grad at x: [-2.53886190e-06 -1.00223933e-05]  gradient norm: 1.0338964539364818e-05\n",
            "iter: 935940  x: [ 3.99995864 15.99966913]  f(x): 1.710529293989866e-09  grad at x: [ 7.97715769e-05 -2.03106847e-05]  gradient norm: 8.231663499406918e-05\n",
            "iter: 935941  x: [ 3.99995864 15.99966913]  f(x): 1.7104775896405196e-09  grad at x: [-2.53959720e-06 -1.00219859e-05]  gradient norm: 1.0338750153704352e-05\n",
            "iter: 935942  x: [ 3.99995865 15.99966914]  f(x): 1.710424958507103e-09  grad at x: [ 7.98211485e-05 -2.03165655e-05]  gradient norm: 8.236612524188029e-05\n",
            "iter: 935943  x: [ 3.99995864 15.99966914]  f(x): 1.710373192989189e-09  grad at x: [-2.54033256e-06 -1.00215784e-05]  gradient norm: 1.0338535850501805e-05\n",
            "iter: 935944  x: [ 3.99995865 15.99966915]  f(x): 1.7103206294425554e-09  grad at x: [ 7.98707346e-05 -2.03224481e-05]  gradient norm: 8.24156304842068e-05\n",
            "iter: 935945  x: [ 3.99995865 15.99966915]  f(x): 1.7102688027015667e-09  grad at x: [-2.54108256e-06 -1.00211691e-05]  gradient norm: 1.0338323443987702e-05\n",
            "iter: 935946  x: [ 3.99995865 15.99966916]  f(x): 1.7102163080039536e-09  grad at x: [ 7.99212957e-05 -2.03284526e-05]  gradient norm: 8.246611112202271e-05\n",
            "iter: 935947  x: [ 3.99995865 15.99966916]  f(x): 1.7101644187951619e-09  grad at x: [-2.54183263e-06 -1.00207599e-05]  gradient norm: 1.033811112250241e-05\n",
            "iter: 935948  x: [ 3.99995865 15.99966917]  f(x): 1.7101119929134868e-09  grad at x: [ 7.99718129e-05 -2.03344516e-05]  gradient norm: 8.251654856352599e-05\n",
            "iter: 935949  x: [ 3.99995865 15.99966917]  f(x): 1.710060041269683e-09  grad at x: [-2.54258279e-06 -1.00203506e-05]  gradient norm: 1.0337898886504689e-05\n",
            "iter: 935950  x: [ 3.99995865 15.99966918]  f(x): 1.7100076842418386e-09  grad at x: [ 8.00223447e-05 -2.03404525e-05]  gradient norm: 8.2567001017757e-05\n",
            "iter: 935951  x: [ 3.99995865 15.99966918]  f(x): 1.7099556701059086e-09  grad at x: [-2.54331846e-06 -1.00199431e-05]  gradient norm: 1.0337684918311297e-05\n",
            "iter: 935952  x: [ 3.99995865 15.99966919]  f(x): 1.7099033808152699e-09  grad at x: [ 8.00719305e-05 -2.03463351e-05]  gradient norm: 8.261650805024522e-05\n",
            "iter: 935953  x: [ 3.99995865 15.99966919]  f(x): 1.709851305304677e-09  grad at x: [-2.54406877e-06 -1.00195339e-05]  gradient norm: 1.0337472851534115e-05\n",
            "iter: 935954  x: [ 3.99995865 15.9996692 ]  f(x): 1.7097990849803164e-09  grad at x: [ 8.01224766e-05 -2.03523377e-05]  gradient norm: 8.266697596166569e-05\n",
            "iter: 935955  x: [ 3.99995865 15.9996692 ]  f(x): 1.7097469468823657e-09  grad at x: [-2.54479004e-06 -1.00191282e-05]  gradient norm: 1.0337257230954117e-05\n",
            "iter: 935956  x: [ 3.99995865 15.99966921]  f(x): 1.7097078199041948e-09  grad at x: [ 3.88131995e-05 -1.51886197e-05]  gradient norm: 4.1679234967205285e-05\n",
            "iter: 935957  x: [ 3.99995865 15.99966921]  f(x): 1.709693958393285e-09  grad at x: [-1.89893350e-06 -1.00996986e-05]  gradient norm: 1.027666577099882e-05\n",
            "iter: 935958  x: [ 3.99995866 15.99966925]  f(x): 1.7094840102292153e-09  grad at x: [ 1.61045828e-04 -3.04661498e-05]  gradient norm: 0.0001639022426059766\n",
            "iter: 935959  x: [ 3.99995866 15.99966925]  f(x): 1.7093308908349701e-09  grad at x: [ 7.86180132e-05 -2.01628736e-05]  gradient norm: 8.116238948908524e-05\n",
            "iter: 935960  x: [ 3.99995866 15.99966925]  f(x): 1.7092806041610776e-09  grad at x: [-2.52109779e-06 -1.00206798e-05]  gradient norm: 1.0332954973771395e-05\n",
            "iter: 935961  x: [ 3.99995866 15.99966926]  f(x): 1.709226625764817e-09  grad at x: [ 7.86661432e-05 -2.01685743e-05]  gradient norm: 8.121042718229503e-05\n",
            "iter: 935962  x: [ 3.99995866 15.99966926]  f(x): 1.709176280560859e-09  grad at x: [-2.52181949e-06 -1.00202742e-05]  gradient norm: 1.033273771318525e-05\n",
            "iter: 935963  x: [ 3.99995866 15.99966927]  f(x): 1.7091223678071568e-09  grad at x: [ 7.87148553e-05 -2.01743478e-05]  gradient norm: 8.125904723722994e-05\n",
            "iter: 935964  x: [ 3.99995866 15.99966927]  f(x): 1.7090719633388017e-09  grad at x: [-2.52254127e-06 -1.00198686e-05]  gradient norm: 1.033252053344547e-05\n",
            "iter: 935965  x: [ 3.99995866 15.99966928]  f(x): 1.7090181162992633e-09  grad at x: [ 7.87635819e-05 -2.01801231e-05]  gradient norm: 8.130768228462748e-05\n",
            "iter: 935966  x: [ 3.99995866 15.99966928]  f(x): 1.708967652494613e-09  grad at x: [-2.52326312e-06 -1.00194629e-05]  gradient norm: 1.033230343435663e-05\n",
            "iter: 935967  x: [ 3.99995866 15.99966929]  f(x): 1.7089138711333027e-09  grad at x: [ 7.88122793e-05 -2.01858948e-05]  gradient norm: 8.13562886811151e-05\n",
            "iter: 935968  x: [ 3.99995866 15.99966929]  f(x): 1.7088633479912852e-09  grad at x: [-2.52398505e-06 -1.00190573e-05]  gradient norm: 1.0332086415723043e-05\n",
            "iter: 935969  x: [ 3.99995866 15.9996693 ]  f(x): 1.7088096324148324e-09  grad at x: [ 7.88610202e-05 -2.01916719e-05]  gradient norm: 8.140493916832931e-05\n",
            "iter: 935970  x: [ 3.99995866 15.9996693 ]  f(x): 1.7087590498652435e-09  grad at x: [-2.52470706e-06 -1.00186517e-05]  gradient norm: 1.0331869477565789e-05\n",
            "iter: 935971  x: [ 3.99995867 15.99966931]  f(x): 1.7087054001094492e-09  grad at x: [ 7.89097611e-05 -2.01974490e-05]  gradient norm: 8.145359009601729e-05\n",
            "iter: 935972  x: [ 3.99995866 15.99966931]  f(x): 1.7086547581161956e-09  grad at x: [-2.52542914e-06 -1.00182460e-05]  gradient norm: 1.0331652620340156e-05\n",
            "iter: 935973  x: [ 3.99995867 15.99966932]  f(x): 1.7086011741817954e-09  grad at x: [ 7.89584728e-05 -2.02032224e-05]  gradient norm: 8.150221236940606e-05\n",
            "iter: 935974  x: [ 3.99995867 15.99966932]  f(x): 1.7085504727249322e-09  grad at x: [-2.52613675e-06 -1.00178422e-05]  gradient norm: 1.0331434049314626e-05\n",
            "iter: 935975  x: [ 3.99995867 15.99966933]  f(x): 1.7084969535422005e-09  grad at x: [ 7.90062822e-05 -2.02088831e-05]  gradient norm: 8.154993304228536e-05\n",
            "iter: 935976  x: [ 3.99995867 15.99966933]  f(x): 1.7084461936922836e-09  grad at x: [-2.52685899e-06 -1.00174366e-05]  gradient norm: 1.0331217352238495e-05\n",
            "iter: 935977  x: [ 3.99995867 15.99966934]  f(x): 1.70839274047201e-09  grad at x: [ 7.90550519e-05 -2.02146639e-05]  gradient norm: 8.159861438433633e-05\n",
            "iter: 935978  x: [ 3.99995867 15.99966934]  f(x): 1.70834192101796e-09  grad at x: [-2.52759586e-06 -1.00170291e-05]  gradient norm: 1.0331002532512115e-05\n",
            "iter: 935979  x: [ 3.99995867 15.99966935]  f(x): 1.7082885349387343e-09  grad at x: [ 7.91047384e-05 -2.02205592e-05]  gradient norm: 8.164821277639706e-05\n",
            "iter: 935980  x: [ 3.99995867 15.99966935]  f(x): 1.7082376547372571e-09  grad at x: [-2.52831825e-06 -1.00166235e-05]  gradient norm: 1.0330785997923014e-05\n",
            "iter: 935981  x: [ 3.99995867 15.99966936]  f(x): 1.7081843346569287e-09  grad at x: [ 7.91534934e-05 -2.02263382e-05]  gradient norm: 8.169688045909871e-05\n",
            "iter: 935982  x: [ 3.99995867 15.99966936]  f(x): 1.7081333947953806e-09  grad at x: [-2.52904072e-06 -1.00162179e-05]  gradient norm: 1.0330569544154737e-05\n",
            "iter: 935983  x: [ 3.99995867 15.99966937]  f(x): 1.7080801407505406e-09  grad at x: [ 7.92022338e-05 -2.02321153e-05]  gradient norm: 8.174553402935466e-05\n",
            "iter: 935984  x: [ 3.99995867 15.99966937]  f(x): 1.7080291412109563e-09  grad at x: [-2.52977782e-06 -1.00158104e-05]  gradient norm: 1.0330354971200938e-05\n",
            "iter: 935985  x: [ 3.99995867 15.99966938]  f(x): 1.7079759544166462e-09  grad at x: [ 7.92519346e-05 -2.02380124e-05]  gradient norm: 8.179514832250364e-05\n",
            "iter: 935986  x: [ 3.99995867 15.99966938]  f(x): 1.7079248940192752e-09  grad at x: [-2.53050044e-06 -1.00154048e-05]  gradient norm: 1.0330138680265254e-05\n",
            "iter: 935987  x: [ 3.99995868 15.99966939]  f(x): 1.7078717733679848e-09  grad at x: [ 7.93007040e-05 -2.02437932e-05]  gradient norm: 8.184383187390245e-05\n",
            "iter: 935988  x: [ 3.99995867 15.99966939]  f(x): 1.7078206531655495e-09  grad at x: [-2.53122314e-06 -1.00149991e-05]  gradient norm: 1.0329922469779144e-05\n",
            "iter: 935989  x: [ 3.99995868 15.9996694 ]  f(x): 1.7077675987283625e-09  grad at x: [ 7.93495024e-05 -2.02495776e-05]  gradient norm: 8.189254496281119e-05\n",
            "iter: 935990  x: [ 3.99995868 15.9996694 ]  f(x): 1.7077164186684027e-09  grad at x: [-2.53196047e-06 -1.00145917e-05]  gradient norm: 1.0329708143791097e-05\n",
            "iter: 935991  x: [ 3.99995868 15.99966941]  f(x): 1.707663431592082e-09  grad at x: [ 7.93992029e-05 -2.02554747e-05]  gradient norm: 8.194216060033768e-05\n",
            "iter: 935992  x: [ 3.99995868 15.99966941]  f(x): 1.707612190563123e-09  grad at x: [-2.53268332e-06 -1.00141860e-05]  gradient norm: 1.0329492096483375e-05\n",
            "iter: 935993  x: [ 3.99995868 15.99966942]  f(x): 1.7075592697733489e-09  grad at x: [ 7.94480012e-05 -2.02612591e-05]  gradient norm: 8.199087456723426e-05\n",
            "iter: 935994  x: [ 3.99995868 15.99966942]  f(x): 1.7075079687960511e-09  grad at x: [-2.53343536e-06 -1.00137768e-05]  gradient norm: 1.0329279741227274e-05\n",
            "iter: 935995  x: [ 3.99995868 15.99966943]  f(x): 1.7074551165884898e-09  grad at x: [ 7.94986329e-05 -2.02672727e-05]  gradient norm: 8.20414223339025e-05\n",
            "iter: 935996  x: [ 3.99995868 15.99966943]  f(x): 1.7074037533835617e-09  grad at x: [-2.53417292e-06 -1.00133693e-05]  gradient norm: 1.0329065664694814e-05\n",
            "iter: 935997  x: [ 3.99995868 15.99966944]  f(x): 1.7073509686839394e-09  grad at x: [ 7.95483623e-05 -2.02731735e-05]  gradient norm: 8.209106842860772e-05\n",
            "iter: 935998  x: [ 3.99995868 15.99966944]  f(x): 1.7072995443620622e-09  grad at x: [-2.53489600e-06 -1.00129637e-05]  gradient norm: 1.0328849863462897e-05\n",
            "iter: 935999  x: [ 3.99995868 15.99966945]  f(x): 1.7072468260226799e-09  grad at x: [ 7.95971458e-05 -2.02789561e-05]  gradient norm: 8.213976916979004e-05\n",
            "iter: 936000  x: [ 3.99995868 15.99966945]  f(x): 1.7071953416767747e-09  grad at x: [-2.53561917e-06 -1.00125581e-05]  gradient norm: 1.0328634143025895e-05\n",
            "iter: 936001  x: [ 3.99995868 15.99966946]  f(x): 1.7071426898409358e-09  grad at x: [ 7.96459874e-05 -2.02847459e-05]  gradient norm: 8.218852854464832e-05\n",
            "iter: 936002  x: [ 3.99995868 15.99966946]  f(x): 1.7070911453463213e-09  grad at x: [-2.53635696e-06 -1.00121506e-05]  gradient norm: 1.0328420313628466e-05\n",
            "iter: 936003  x: [ 3.99995869 15.99966947]  f(x): 1.7070385611288862e-09  grad at x: [ 7.96957166e-05 -2.02906467e-05]  gradient norm: 8.223817596678221e-05\n",
            "iter: 936004  x: [ 3.99995868 15.99966947]  f(x): 1.7069869554059808e-09  grad at x: [-2.53708027e-06 -1.00117450e-05]  gradient norm: 1.0328204756409309e-05\n",
            "iter: 936005  x: [ 3.99995869 15.99966948]  f(x): 1.7069344376925418e-09  grad at x: [ 7.97445289e-05 -2.02964329e-05]  gradient norm: 8.228690710987294e-05\n",
            "iter: 936006  x: [ 3.99995869 15.99966948]  f(x): 1.7068827718009812e-09  grad at x: [-2.53780366e-06 -1.00113393e-05]  gradient norm: 1.03279892800488e-05\n",
            "iter: 936007  x: [ 3.99995869 15.99966949]  f(x): 1.7068303206641396e-09  grad at x: [ 7.97933412e-05 -2.03022191e-05]  gradient norm: 8.233563867831107e-05\n",
            "iter: 936008  x: [ 3.99995869 15.99966949]  f(x): 1.7067785945499433e-09  grad at x: [-2.53854169e-06 -1.00109319e-05]  gradient norm: 1.032777569841585e-05\n",
            "iter: 936009  x: [ 3.99995869 15.9996695 ]  f(x): 1.706726211177427e-09  grad at x: [ 7.98430992e-05 -2.03081236e-05]  gradient norm: 8.238531652548307e-05\n",
            "iter: 936010  x: [ 3.99995869 15.9996695 ]  f(x): 1.7066744236881416e-09  grad at x: [-2.53926523e-06 -1.00105262e-05]  gradient norm: 1.0327560385401558e-05\n",
            "iter: 936011  x: [ 3.99995869 15.99966951]  f(x): 1.7066221069280478e-09  grad at x: [ 7.98919113e-05 -2.03139098e-05]  gradient norm: 8.243404895977432e-05\n",
            "iter: 936012  x: [ 3.99995869 15.99966951]  f(x): 1.7065702591608097e-09  grad at x: [-2.53998886e-06 -1.00101206e-05]  gradient norm: 1.0327345153091215e-05\n",
            "iter: 936013  x: [ 3.99995869 15.99966952]  f(x): 1.7065180091567392e-09  grad at x: [ 7.99407816e-05 -2.03197033e-05]  gradient norm: 8.24828400246157e-05\n",
            "iter: 936014  x: [ 3.99995869 15.99966952]  f(x): 1.706466100986567e-09  grad at x: [-2.54072711e-06 -1.00097132e-05]  gradient norm: 1.0327131819197975e-05\n",
            "iter: 936015  x: [ 3.99995869 15.99966953]  f(x): 1.7064139188574152e-09  grad at x: [ 7.99905394e-05 -2.03256077e-05]  gradient norm: 8.253251918600678e-05\n",
            "iter: 936016  x: [ 3.99995869 15.99966953]  f(x): 1.7063619491829036e-09  grad at x: [-2.54146544e-06 -1.00093057e-05]  gradient norm: 1.032691856876695e-05\n",
            "iter: 936017  x: [ 3.99995869 15.99966954]  f(x): 1.7063098349654274e-09  grad at x: [ 8.00403117e-05 -2.03315140e-05]  gradient norm: 8.258221334381023e-05\n",
            "iter: 936018  x: [ 3.99995869 15.99966954]  f(x): 1.7062578037306195e-09  grad at x: [-2.54218930e-06 -1.00089001e-05]  gradient norm: 1.0326703582265022e-05\n",
            "iter: 936019  x: [ 3.99995869 15.99966955]  f(x): 1.7062187565412042e-09  grad at x: [ 3.87734962e-05 -1.51731037e-05]  gradient norm: 4.163660751163335e-05\n",
            "iter: 936020  x: [ 3.99995869 15.99966955]  f(x): 1.7062049233808255e-09  grad at x: [-1.89698890e-06 -1.00893885e-05]  gradient norm: 1.0266173955701343e-05\n",
            "iter: 936021  x: [ 3.9999587  15.99966959]  f(x): 1.7059953998045274e-09  grad at x: [ 1.60879861e-04 -3.04348523e-05]  gradient norm: 0.00016373335028221214\n",
            "iter: 936022  x: [ 3.9999587  15.99966959]  f(x): 1.7058425957861221e-09  grad at x: [ 7.85369718e-05 -2.01421917e-05]  gradient norm: 8.107875076487891e-05\n",
            "iter: 936023  x: [ 3.9999587  15.99966959]  f(x): 1.7057924126949186e-09  grad at x: [-2.51852311e-06 -1.00104498e-05]  gradient norm: 1.0322405954072594e-05\n",
            "iter: 936024  x: [ 3.9999587 15.9996696]  f(x): 1.7057385444077664e-09  grad at x: [ 7.85857832e-05 -2.01479779e-05]  gradient norm: 8.112746971197617e-05\n",
            "iter: 936025  x: [ 3.9999587 15.9996696]  f(x): 1.7056883020114133e-09  grad at x: [-2.51924738e-06 -1.00100442e-05]  gradient norm: 1.0322189322515017e-05\n",
            "iter: 936026  x: [ 3.9999587  15.99966961]  f(x): 1.7056344994671743e-09  grad at x: [ 7.86346528e-05 -2.01537714e-05]  gradient norm: 8.117624730199442e-05\n",
            "iter: 936027  x: [ 3.9999587  15.99966961]  f(x): 1.7055841976596295e-09  grad at x: [-2.51997174e-06 -1.00096386e-05]  gradient norm: 1.032197277160397e-05\n",
            "iter: 936028  x: [ 3.9999587  15.99966962]  f(x): 1.7055304609309785e-09  grad at x: [ 7.86835223e-05 -2.01595649e-05]  gradient norm: 8.122502534011526e-05\n",
            "iter: 936029  x: [ 3.9999587  15.99966962]  f(x): 1.7054800996759574e-09  grad at x: [-2.52069617e-06 -1.00092329e-05]  gradient norm: 1.0321756302011134e-05\n",
            "iter: 936030  x: [ 3.99995871 15.99966963]  f(x): 1.7054264287980305e-09  grad at x: [ 7.87324063e-05 -2.01653602e-05]  gradient norm: 8.127381837703387e-05\n",
            "iter: 936031  x: [ 3.9999587  15.99966963]  f(x): 1.705376008060105e-09  grad at x: [-2.52142067e-06 -1.00088273e-05]  gradient norm: 1.0321539913541108e-05\n",
            "iter: 936032  x: [ 3.99995871 15.99966964]  f(x): 1.7053224030680722e-09  grad at x: [ 7.87813048e-05 -2.01711573e-05]  gradient norm: 8.132262640880736e-05\n",
            "iter: 936033  x: [ 3.99995871 15.99966964]  f(x): 1.7052719227751036e-09  grad at x: [-2.52214526e-06 -1.00084217e-05]  gradient norm: 1.0321323605998233e-05\n",
            "iter: 936034  x: [ 3.99995871 15.99966965]  f(x): 1.7052183837416792e-09  grad at x: [ 7.88302031e-05 -2.01769544e-05]  gradient norm: 8.137143488643774e-05\n",
            "iter: 936035  x: [ 3.99995871 15.99966965]  f(x): 1.7051678438573396e-09  grad at x: [-2.52286992e-06 -1.00080160e-05]  gradient norm: 1.032110737962079e-05\n",
            "iter: 936036  x: [ 3.99995871 15.99966966]  f(x): 1.7051143707818852e-09  grad at x: [ 7.88791014e-05 -2.01827515e-05]  gradient norm: 8.142024381242418e-05\n",
            "iter: 936037  x: [ 3.99995871 15.99966966]  f(x): 1.7050637712698469e-09  grad at x: [-2.52359465e-06 -1.00076104e-05]  gradient norm: 1.032089123421298e-05\n",
            "iter: 936038  x: [ 3.99995871 15.99966967]  f(x): 1.7050103641892116e-09  grad at x: [ 7.89279851e-05 -2.01885468e-05]  gradient norm: 8.146903863359254e-05\n",
            "iter: 936039  x: [ 3.99995871 15.99966967]  f(x): 1.7049597050490095e-09  grad at x: [-2.52431947e-06 -1.00072048e-05]  gradient norm: 1.0320675170013225e-05\n",
            "iter: 936040  x: [ 3.99995871 15.99966968]  f(x): 1.7049063640701533e-09  grad at x: [ 7.89769124e-05 -2.01943476e-05]  gradient norm: 8.151787754604097e-05\n",
            "iter: 936041  x: [ 3.99995871 15.99966968]  f(x): 1.704855645194536e-09  grad at x: [-2.52504436e-06 -1.00067991e-05]  gradient norm: 1.0320459187042903e-05\n",
            "iter: 936042  x: [ 3.99995871 15.99966969]  f(x): 1.7048023702817716e-09  grad at x: [ 7.90258104e-05 -2.02001447e-05]  gradient norm: 8.156668780472597e-05\n",
            "iter: 936043  x: [ 3.99995871 15.99966969]  f(x): 1.7047515916694624e-09  grad at x: [-2.52576933e-06 -1.00063935e-05]  gradient norm: 1.0320243285106026e-05\n",
            "iter: 936044  x: [ 3.99995871 15.9996697 ]  f(x): 1.7046983829306146e-09  grad at x: [ 7.90747375e-05 -2.02059455e-05]  gradient norm: 8.161552760304179e-05\n",
            "iter: 936045  x: [ 3.99995871 15.9996697 ]  f(x): 1.7046475445101706e-09  grad at x: [-2.52649437e-06 -1.00059879e-05]  gradient norm: 1.0320027464223776e-05\n",
            "iter: 936046  x: [ 3.99995872 15.99966971]  f(x): 1.704594401944649e-09  grad at x: [ 7.91236645e-05 -2.02117462e-05]  gradient norm: 8.16643678456194e-05\n",
            "iter: 936047  x: [ 3.99995871 15.99966971]  f(x): 1.7045435036796992e-09  grad at x: [-2.52721949e-06 -1.00055822e-05]  gradient norm: 1.0319811724634846e-05\n",
            "iter: 936048  x: [ 3.99995872 15.99966972]  f(x): 1.7044904273243388e-09  grad at x: [ 7.91725769e-05 -2.02175452e-05]  gradient norm: 8.171319397856126e-05\n",
            "iter: 936049  x: [ 3.99995872 15.99966972]  f(x): 1.7044394692322003e-09  grad at x: [-2.52793014e-06 -1.00051784e-05]  gradient norm: 1.0319594265222223e-05\n",
            "iter: 936050  x: [ 3.99995872 15.99966973]  f(x): 1.7043864580146446e-09  grad at x: [ 7.92205870e-05 -2.02232313e-05]  gradient norm: 8.176111845347934e-05\n",
            "iter: 936051  x: [ 3.99995872 15.99966973]  f(x): 1.7043354411140633e-09  grad at x: [-2.52866996e-06 -1.00047710e-05]  gradient norm: 1.031938048942249e-05\n",
            "iter: 936052  x: [ 3.99995872 15.99966974]  f(x): 1.704282497357603e-09  grad at x: [ 7.92704597e-05 -2.02291503e-05]  gradient norm: 8.181090576395286e-05\n",
            "iter: 936053  x: [ 3.99995872 15.99966974]  f(x): 1.7042314193416492e-09  grad at x: [-2.52939532e-06 -1.00043653e-05]  gradient norm: 1.0319164993624136e-05\n",
            "iter: 936054  x: [ 3.99995872 15.99966975]  f(x): 1.7041785419747352e-09  grad at x: [ 7.93194155e-05 -2.02349547e-05]  gradient norm: 8.185977686403332e-05\n",
            "iter: 936055  x: [ 3.99995872 15.99966975]  f(x): 1.7041274039335608e-09  grad at x: [-2.53012075e-06 -1.00039597e-05]  gradient norm: 1.0318949579204527e-05\n",
            "iter: 936056  x: [ 3.99995872 15.99966976]  f(x): 1.704074592920404e-09  grad at x: [ 7.93683421e-05 -2.02407555e-05]  gradient norm: 8.190861930239012e-05\n",
            "iter: 936057  x: [ 3.99995872 15.99966976]  f(x): 1.7040233948528425e-09  grad at x: [-2.53084625e-06 -1.00035541e-05]  gradient norm: 1.0318734245967214e-05\n",
            "iter: 936058  x: [ 3.99995872 15.99966977]  f(x): 1.7039706503367234e-09  grad at x: [ 7.94173269e-05 -2.02465635e-05]  gradient norm: 8.195752037873918e-05\n",
            "iter: 936059  x: [ 3.99995872 15.99966977]  f(x): 1.7039193921369924e-09  grad at x: [-2.53160094e-06 -1.00031448e-05]  gradient norm: 1.0318522607811281e-05\n",
            "iter: 936060  x: [ 3.99995872 15.99966978]  f(x): 1.703866716341009e-09  grad at x: [ 7.94681161e-05 -2.02525971e-05]  gradient norm: 8.200822617783025e-05\n",
            "iter: 936061  x: [ 3.99995872 15.99966978]  f(x): 1.703815395765702e-09  grad at x: [-2.53234115e-06 -1.00027373e-05]  gradient norm: 1.0318309247696698e-05\n",
            "iter: 936062  x: [ 3.99995873 15.99966979]  f(x): 1.7037627876522496e-09  grad at x: [ 7.95180175e-05 -2.02585197e-05]  gradient norm: 8.205804484723769e-05\n",
            "iter: 936063  x: [ 3.99995872 15.99966979]  f(x): 1.7037114057564482e-09  grad at x: [-2.53305234e-06 -1.00023335e-05]  gradient norm: 1.0318092352841818e-05\n",
            "iter: 936064  x: [ 3.99995873 15.9996698 ]  f(x): 1.7036588630660624e-09  grad at x: [ 7.95660561e-05 -2.02642095e-05]  gradient norm: 8.21060014456507e-05\n",
            "iter: 936065  x: [ 3.99995873 15.9996698 ]  f(x): 1.703607422074529e-09  grad at x: [-2.53379270e-06 -1.00019261e-05]  gradient norm: 1.0317879157725008e-05\n",
            "iter: 936066  x: [ 3.99995873 15.99966981]  f(x): 1.7035549471403513e-09  grad at x: [ 7.96159574e-05 -2.02701322e-05]  gradient norm: 8.215582100098278e-05\n",
            "iter: 936067  x: [ 3.99995873 15.99966981]  f(x): 1.7035034447540644e-09  grad at x: [-2.53450404e-06 -1.00015222e-05]  gradient norm: 1.0317662423379241e-05\n",
            "iter: 936068  x: [ 3.99995873 15.99966982]  f(x): 1.7034510353138494e-09  grad at x: [ 7.96639959e-05 -2.02758220e-05]  gradient norm: 8.220377844838496e-05\n",
            "iter: 936069  x: [ 3.99995873 15.99966982]  f(x): 1.7033994737603555e-09  grad at x: [-2.53524456e-06 -1.00011148e-05]  gradient norm: 1.0317449393345973e-05\n",
            "iter: 936070  x: [ 3.99995873 15.99966983]  f(x): 1.7033471321854262e-09  grad at x: [ 7.97139261e-05 -2.02817482e-05]  gradient norm: 8.225362798989565e-05\n",
            "iter: 936071  x: [ 3.99995873 15.99966983]  f(x): 1.7032955091286446e-09  grad at x: [-2.53598516e-06 -1.00007073e-05]  gradient norm: 1.0317236447149633e-05\n",
            "iter: 936072  x: [ 3.99995873 15.99966984]  f(x): 1.7032432354211675e-09  grad at x: [ 7.97638271e-05 -2.02876708e-05]  gradient norm: 8.230344887934979e-05\n",
            "iter: 936073  x: [ 3.99995873 15.99966984]  f(x): 1.7031915508219847e-09  grad at x: [-2.53672583e-06 -1.00002999e-05]  gradient norm: 1.0317023584593676e-05\n",
            "iter: 936074  x: [ 3.99995873 15.99966985]  f(x): 1.703139345054953e-09  grad at x: [ 7.98137571e-05 -2.02935971e-05]  gradient norm: 8.235329931884861e-05\n",
            "iter: 936075  x: [ 3.99995873 15.99966985]  f(x): 1.7030875988767415e-09  grad at x: [-2.53746658e-06 -9.99989243e-06]  gradient norm: 1.0316810805699726e-05\n",
            "iter: 936076  x: [ 3.99995873 15.99966986]  f(x): 1.7030354610516847e-09  grad at x: [ 7.98636725e-05 -2.02995216e-05]  gradient norm: 8.240313565707855e-05\n",
            "iter: 936077  x: [ 3.99995873 15.99966986]  f(x): 1.7029836532559698e-09  grad at x: [-2.53820741e-06 -9.99948497e-06]  gradient norm: 1.0316598110707935e-05\n",
            "iter: 936078  x: [ 3.99995874 15.99966987]  f(x): 1.7029315834825983e-09  grad at x: [ 7.99136170e-05 -2.03054497e-05]  gradient norm: 8.245300154431809e-05\n",
            "iter: 936079  x: [ 3.99995873 15.99966987]  f(x): 1.7028797140137948e-09  grad at x: [-2.53893376e-06 -9.99907934e-06]  gradient norm: 1.0316383681344507e-05\n",
            "iter: 936080  x: [ 3.99995874 15.99966988]  f(x): 1.7028277111034287e-09  grad at x: [ 7.99626009e-05 -2.03112577e-05]  gradient norm: 8.250190743945149e-05\n",
            "iter: 936081  x: [ 3.99995874 15.99966988]  f(x): 1.702775781095511e-09  grad at x: [-2.53966019e-06 -9.99867370e-06]  gradient norm: 1.0316169333419732e-05\n",
            "iter: 936082  x: [ 3.99995874 15.99966988]  f(x): 1.7027368148305494e-09  grad at x: [ 3.87359768e-05 -1.51578715e-05]  gradient norm: 4.15961172384922e-05\n",
            "iter: 936083  x: [ 3.99995874 15.99966988]  f(x): 1.7027230086446088e-09  grad at x: [-1.89508684e-06 -1.00790839e-05]  gradient norm: 1.0255695363569277e-05\n",
            "iter: 936084  x: [ 3.99995874 15.99966992]  f(x): 1.7025139347967508e-09  grad at x: [ 1.60724577e-04 -3.04049008e-05]  gradient norm: 0.00016357520443432852\n",
            "iter: 936085  x: [ 3.99995874 15.99966992]  f(x): 1.7023614258630595e-09  grad at x: [ 7.8461214e-05 -2.0122181e-05]  gradient norm: 8.100039672771851e-05\n",
            "iter: 936086  x: [ 3.99995874 15.99966992]  f(x): 1.7023113398118409e-09  grad at x: [-2.51602006e-06 -1.00002217e-05]  gradient norm: 1.031187617572509e-05\n",
            "iter: 936087  x: [ 3.99995874 15.99966993]  f(x): 1.7022575867290513e-09  grad at x: [ 7.85099065e-05 -2.01279527e-05]  gradient norm: 8.104899684491822e-05\n",
            "iter: 936088  x: [ 3.99995874 15.99966993]  f(x): 1.7022074415724683e-09  grad at x: [-2.51674691e-06 -9.99981603e-06]  gradient norm: 1.03116601774934e-05\n",
            "iter: 936089  x: [ 3.99995875 15.99966994]  f(x): 1.7021537544083794e-09  grad at x: [ 7.85589481e-05 -2.01337680e-05]  gradient norm: 8.109794656484941e-05\n",
            "iter: 936090  x: [ 3.99995874 15.99966994]  f(x): 1.702103549691757e-09  grad at x: [-2.51747383e-06 -9.99941039e-06]  gradient norm: 1.0311444260794656e-05\n",
            "iter: 936091  x: [ 3.99995875 15.99966995]  f(x): 1.7020499284459777e-09  grad at x: [ 7.86079896e-05 -2.01395833e-05]  gradient norm: 8.114689673852762e-05\n",
            "iter: 936092  x: [ 3.99995875 15.99966995]  f(x): 1.7019996641327733e-09  grad at x: [-2.51820084e-06 -9.99900476e-06]  gradient norm: 1.0311228425433413e-05\n",
            "iter: 936093  x: [ 3.99995875 15.99966996]  f(x): 1.7019461088781972e-09  grad at x: [ 7.86570311e-05 -2.01453986e-05]  gradient norm: 8.119584736327298e-05\n",
            "iter: 936094  x: [ 3.99995875 15.99966996]  f(x): 1.7018957849318695e-09  grad at x: [-2.51892792e-06 -9.99859913e-06]  gradient norm: 1.0311012671647914e-05\n",
            "iter: 936095  x: [ 3.99995875 15.99966997]  f(x): 1.7018422956681076e-09  grad at x: [ 7.87060725e-05 -2.01512139e-05]  gradient norm: 8.124479844157036e-05\n",
            "iter: 936096  x: [ 3.99995875 15.99966997]  f(x): 1.7017919120521143e-09  grad at x: [-2.51965507e-06 -9.99819349e-06]  gradient norm: 1.0310796999242583e-05\n",
            "iter: 936097  x: [ 3.99995875 15.99966998]  f(x): 1.701738488887032e-09  grad at x: [ 7.87551430e-05 -2.01570328e-05]  gradient norm: 8.129377906604934e-05\n",
            "iter: 936098  x: [ 3.99995875 15.99966998]  f(x): 1.7016880455298576e-09  grad at x: [-2.52038230e-06 -9.99778786e-06]  gradient norm: 1.0310581408455796e-05\n",
            "iter: 936099  x: [ 3.99995875 15.99966999]  f(x): 1.7016346884281147e-09  grad at x: [ 7.88041842e-05 -2.01628482e-05]  gradient norm: 8.134273104372329e-05\n",
            "iter: 936100  x: [ 3.99995875 15.99966999]  f(x): 1.70158418532817e-09  grad at x: [-2.52110961e-06 -9.99738222e-06]  gradient norm: 1.0310365899091848e-05\n",
            "iter: 936101  x: [ 3.99995875 15.99967   ]  f(x): 1.701530894432692e-09  grad at x: [ 7.88532836e-05 -2.01686707e-05]  gradient norm: 8.139174166560666e-05\n",
            "iter: 936102  x: [ 3.99995875 15.99967   ]  f(x): 1.7014803314833994e-09  grad at x: [-2.52183700e-06 -9.99697659e-06]  gradient norm: 1.0310150471389254e-05\n",
            "iter: 936103  x: [ 3.99995875 15.99967001]  f(x): 1.7014271067238076e-09  grad at x: [ 7.89023247e-05 -2.01744861e-05]  gradient norm: 8.144069454087134e-05\n",
            "iter: 936104  x: [ 3.99995875 15.99967001]  f(x): 1.701376483958619e-09  grad at x: [-2.52256446e-06 -9.99657095e-06]  gradient norm: 1.0309935125152176e-05\n",
            "iter: 936105  x: [ 3.99995876 15.99967002]  f(x): 1.7013233254779231e-09  grad at x: [ 7.89514239e-05 -2.01803086e-05]  gradient norm: 8.148970605963116e-05\n",
            "iter: 936106  x: [ 3.99995875 15.99967002]  f(x): 1.7012726427901741e-09  grad at x: [-2.52329201e-06 -9.99616532e-06]  gradient norm: 1.0309719860619267e-05\n",
            "iter: 936107  x: [ 3.99995876 15.99967003]  f(x): 1.7012195505529945e-09  grad at x: [ 7.90004940e-05 -2.01861276e-05]  gradient norm: 8.153868892548158e-05\n",
            "iter: 936108  x: [ 3.99995876 15.99967003]  f(x): 1.7011688079411405e-09  grad at x: [-2.52401962e-06 -9.99575968e-06]  gradient norm: 1.030950467759456e-05\n",
            "iter: 936109  x: [ 3.99995876 15.99967004]  f(x): 1.701115782055509e-09  grad at x: [ 7.90495930e-05 -2.01919502e-05]  gradient norm: 8.158770133590956e-05\n",
            "iter: 936110  x: [ 3.99995876 15.99967004]  f(x): 1.7010649794478608e-09  grad at x: [-2.52474732e-06 -9.99535405e-06]  gradient norm: 1.0309289576316841e-05\n",
            "iter: 936111  x: [ 3.99995876 15.99967005]  f(x): 1.7010120199142344e-09  grad at x: [ 7.90986775e-05 -2.01977709e-05]  gradient norm: 8.163669964222134e-05\n",
            "iter: 936112  x: [ 3.99995876 15.99967005]  f(x): 1.700961157292289e-09  grad at x: [-2.52548964e-06 -9.99494659e-06]  gradient norm: 1.030907635812351e-05\n",
            "iter: 936113  x: [ 3.99995876 15.99967006]  f(x): 1.7009082652536354e-09  grad at x: [ 7.91486786e-05 -2.02037063e-05]  gradient norm: 8.16866150405321e-05\n",
            "iter: 936114  x: [ 3.99995876 15.99967007]  f(x): 1.70085734145526e-09  grad at x: [-2.52623204e-06 -9.99453914e-06]  gradient norm: 1.0308863223578488e-05\n",
            "iter: 936115  x: [ 3.99995876 15.99967007]  f(x): 1.7008045170562522e-09  grad at x: [ 7.91987379e-05 -2.02096489e-05]  gradient norm: 8.173658910003319e-05\n",
            "iter: 936116  x: [ 3.99995876 15.99967008]  f(x): 1.7007535319731138e-09  grad at x: [-2.52697452e-06 -9.99413169e-06]  gradient norm: 1.030865017335644e-05\n",
            "iter: 936117  x: [ 3.99995876 15.99967008]  f(x): 1.7007007751797178e-09  grad at x: [ 7.92487680e-05 -2.02155879e-05]  gradient norm: 8.178653452157765e-05\n",
            "iter: 936118  x: [ 3.99995876 15.99967009]  f(x): 1.700649728808931e-09  grad at x: [-2.52771707e-06 -9.99372423e-06]  gradient norm: 1.0308437207043901e-05\n",
            "iter: 936119  x: [ 3.99995876 15.99967009]  f(x): 1.7005970397307347e-09  grad at x: [ 7.92988272e-05 -2.02215306e-05]  gradient norm: 8.183650950384434e-05\n",
            "iter: 936120  x: [ 3.99995876 15.9996701 ]  f(x): 1.7005459319990498e-09  grad at x: [-2.52845970e-06 -9.99331678e-06]  gradient norm: 1.0308224324880439e-05\n",
            "iter: 936121  x: [ 3.99995877 15.99967011]  f(x): 1.7004933106019764e-09  grad at x: [ 7.93488571e-05 -2.02274696e-05]  gradient norm: 8.188645584387069e-05\n",
            "iter: 936122  x: [ 3.99995876 15.99967011]  f(x): 1.7004421415065531e-09  grad at x: [-2.52920241e-06 -9.99290933e-06]  gradient norm: 1.030801152667004e-05\n",
            "iter: 936123  x: [ 3.99995877 15.99967012]  f(x): 1.7003895879002324e-09  grad at x: [ 7.93989161e-05 -2.02334122e-05]  gradient norm: 8.193643174496837e-05\n",
            "iter: 936124  x: [ 3.99995877 15.99967012]  f(x): 1.7003383573677767e-09  grad at x: [-2.52994519e-06 -9.99250187e-06]  gradient norm: 1.0307798812652411e-05\n",
            "iter: 936125  x: [ 3.99995877 15.99967013]  f(x): 1.7002858715180896e-09  grad at x: [ 7.94489459e-05 -2.02393512e-05]  gradient norm: 8.1986379001275e-05\n",
            "iter: 936126  x: [ 3.99995877 15.99967013]  f(x): 1.7002345795635557e-09  grad at x: [-2.53067350e-06 -9.99209624e-06]  gradient norm: 1.0307584373212795e-05\n",
            "iter: 936127  x: [ 3.99995877 15.99967014]  f(x): 1.7001821604320002e-09  grad at x: [ 7.94980879e-05 -2.02451793e-05]  gradient norm: 8.203543910080748e-05\n",
            "iter: 936128  x: [ 3.99995877 15.99967014]  f(x): 1.7001308080769743e-09  grad at x: [-2.53143099e-06 -9.99168697e-06]  gradient norm: 1.0307373636628737e-05\n",
            "iter: 936129  x: [ 3.99995877 15.99967015]  f(x): 1.7000784579963907e-09  grad at x: [ 7.95490926e-05 -2.02512401e-05]  gradient norm: 8.208636218775188e-05\n",
            "iter: 936130  x: [ 3.99995877 15.99967015]  f(x): 1.7000270429421175e-09  grad at x: [-2.53215945e-06 -9.99128133e-06]  gradient norm: 1.030715936314938e-05\n",
            "iter: 936131  x: [ 3.99995877 15.99967016]  f(x): 1.6999747596538634e-09  grad at x: [ 7.95982345e-05 -2.02570682e-05]  gradient norm: 8.213542318039719e-05\n",
            "iter: 936132  x: [ 3.99995877 15.99967016]  f(x): 1.6999232841243221e-09  grad at x: [-2.53291710e-06 -9.99087206e-06]  gradient norm: 1.0306948797420075e-05\n",
            "iter: 936133  x: [ 3.99995877 15.99967017]  f(x): 1.6998710699640808e-09  grad at x: [ 7.9649239e-05 -2.0263129e-05]  gradient norm: 8.218634719436094e-05\n",
            "iter: 936134  x: [ 3.99995877 15.99967017]  f(x): 1.6998195316576697e-09  grad at x: [-2.53364571e-06 -9.99046642e-06]  gradient norm: 1.0306734689987755e-05\n",
            "iter: 936135  x: [ 3.99995877 15.99967018]  f(x): 1.6997673843639548e-09  grad at x: [ 7.96983807e-05 -2.02689571e-05]  gradient norm: 8.223540907630571e-05\n",
            "iter: 936136  x: [ 3.99995877 15.99967018]  f(x): 1.6997157855075005e-09  grad at x: [-2.53440351e-06 -9.99005715e-06]  gradient norm: 1.0306524294982989e-05\n",
            "iter: 936137  x: [ 3.99995878 15.99967019]  f(x): 1.6996637074548543e-09  grad at x: [ 7.97493996e-05 -2.02750198e-05]  gradient norm: 8.228634856480573e-05\n",
            "iter: 936138  x: [ 3.99995877 15.99967019]  f(x): 1.6996120457090179e-09  grad at x: [-2.53516139e-06 -9.98964788e-06]  gradient norm: 1.0306313986662043e-05\n",
            "iter: 936139  x: [ 3.99995878 15.9996702 ]  f(x): 1.6995600369000909e-09  grad at x: [ 7.98004184e-05 -2.02810825e-05]  gradient norm: 8.233728852400766e-05\n",
            "iter: 936140  x: [ 3.99995878 15.9996702 ]  f(x): 1.6995083122419336e-09  grad at x: [-2.53587568e-06 -9.98924406e-06]  gradient norm: 1.0306098311963824e-05\n",
            "iter: 936141  x: [ 3.99995878 15.99967021]  f(x): 1.6994563692945169e-09  grad at x: [ 7.98486577e-05 -2.02867977e-05]  gradient norm: 8.238544951476759e-05\n",
            "iter: 936142  x: [ 3.99995878 15.99967021]  f(x): 1.6994045850904654e-09  grad at x: [-2.53661916e-06 -9.98883661e-06]  gradient norm: 1.0305886354413995e-05\n",
            "iter: 936143  x: [ 3.99995878 15.99967022]  f(x): 1.6993527103459865e-09  grad at x: [ 7.98987595e-05 -2.02927458e-05]  gradient norm: 8.243547359752556e-05\n",
            "iter: 936144  x: [ 3.99995878 15.99967022]  f(x): 1.6993138256582544e-09  grad at x: [ 3.86807130e-05 -1.51405893e-05]  gradient norm: 4.15383557616306e-05\n",
            "iter: 936145  x: [ 3.99995878 15.99967022]  f(x): 1.699300057143183e-09  grad at x: [-1.89294272e-06 -1.00689776e-05]  gradient norm: 1.0245366901710534e-05\n",
            "iter: 936146  x: [ 3.99995879 15.99967026]  f(x): 1.6990912512298908e-09  grad at x: [ 1.60501226e-04 -3.03666093e-05]  gradient norm: 0.00016334862874047026\n",
            "iter: 936147  x: [ 3.99995878 15.99967026]  f(x): 1.6989391643291646e-09  grad at x: [ 7.83519227e-05 -2.00981467e-05]  gradient norm: 8.088856097897245e-05\n",
            "iter: 936148  x: [ 3.99995878 15.99967026]  f(x): 1.6988892158579888e-09  grad at x: [-2.51304195e-06 -9.99022086e-06]  gradient norm: 1.0301450999593394e-05\n",
            "iter: 936149  x: [ 3.99995879 15.99967027]  f(x): 1.6988355360189928e-09  grad at x: [ 7.84023007e-05 -2.01041294e-05]  gradient norm: 8.09388458956372e-05\n",
            "iter: 936150  x: [ 3.99995878 15.99967027]  f(x): 1.698785526508017e-09  grad at x: [-2.51377134e-06 -9.98981523e-06]  gradient norm: 1.0301235584574642e-05\n",
            "iter: 936151  x: [ 3.99995879 15.99967028]  f(x): 1.698731912667129e-09  grad at x: [ 7.84514999e-05 -2.01099647e-05]  gradient norm: 8.098795289704324e-05\n",
            "iter: 936152  x: [ 3.99995879 15.99967028]  f(x): 1.698681843470519e-09  grad at x: [-2.51450079e-06 -9.98940959e-06]  gradient norm: 1.0301020251314757e-05\n",
            "iter: 936153  x: [ 3.99995879 15.99967029]  f(x): 1.698628295664228e-09  grad at x: [ 7.8500699e-05 -2.0115800e-05]  gradient norm: 8.10370603581824e-05\n",
            "iter: 936154  x: [ 3.99995879 15.99967029]  f(x): 1.698578166780695e-09  grad at x: [-2.51520122e-06 -9.98900759e-06]  gradient norm: 1.03008014212188e-05\n",
            "iter: 936155  x: [ 3.99995879 15.9996703 ]  f(x): 1.6985246827774595e-09  grad at x: [ 7.85480353e-05 -2.01214025e-05]  gradient norm: 8.108430607760899e-05\n",
            "iter: 936156  x: [ 3.99995879 15.9996703 ]  f(x): 1.6984744964038826e-09  grad at x: [-2.51593084e-06 -9.98860196e-06]  gradient norm: 1.0300586249478155e-05\n",
            "iter: 936157  x: [ 3.99995879 15.99967031]  f(x): 1.6984210785068239e-09  grad at x: [ 7.85972343e-05 -2.01272378e-05]  gradient norm: 8.113341442930116e-05\n",
            "iter: 936158  x: [ 3.99995879 15.99967031]  f(x): 1.6983708323386774e-09  grad at x: [-2.51666052e-06 -9.98819633e-06]  gradient norm: 1.0300371159560297e-05\n",
            "iter: 936159  x: [ 3.99995879 15.99967032]  f(x): 1.698317480619211e-09  grad at x: [ 7.86464622e-05 -2.01330768e-05]  gradient norm: 8.118255233643178e-05\n",
            "iter: 936160  x: [ 3.99995879 15.99967032]  f(x): 1.6982671746213923e-09  grad at x: [-2.51739029e-06 -9.98779069e-06]  gradient norm: 1.0300156151703662e-05\n",
            "iter: 936161  x: [ 3.99995879 15.99967033]  f(x): 1.6982138891160488e-09  grad at x: [ 7.86956901e-05 -2.01389157e-05]  gradient norm: 8.123169069489301e-05\n",
            "iter: 936162  x: [ 3.99995879 15.99967033]  f(x): 1.698163523232877e-09  grad at x: [-2.51810558e-06 -9.98738687e-06]  gradient norm: 1.0299939432092663e-05\n",
            "iter: 936163  x: [ 3.99995879 15.99967034]  f(x): 1.6981103028413978e-09  grad at x: [ 7.87439866e-05 -2.01446383e-05]  gradient norm: 8.127989837161578e-05\n",
            "iter: 936164  x: [ 3.99995879 15.99967034]  f(x): 1.6980598781562187e-09  grad at x: [-2.51885005e-06 -9.98697942e-06]  gradient norm: 1.0299726381825895e-05\n",
            "iter: 936165  x: [ 3.9999588  15.99967035]  f(x): 1.6980067251887159e-09  grad at x: [ 7.87941457e-05 -2.01505936e-05]  gradient norm: 8.132996877400121e-05\n",
            "iter: 936166  x: [ 3.99995879 15.99967035]  f(x): 1.6979562394254912e-09  grad at x: [-2.51956550e-06 -9.98657561e-06]  gradient norm: 1.0299509823946974e-05\n",
            "iter: 936167  x: [ 3.9999588  15.99967036]  f(x): 1.6979031516435172e-09  grad at x: [ 7.88424420e-05 -2.01563162e-05]  gradient norm: 8.137817733648768e-05\n",
            "iter: 936168  x: [ 3.9999588  15.99967036]  f(x): 1.6978526070237822e-09  grad at x: [-2.52029557e-06 -9.98616997e-06]  gradient norm: 1.0299295142975383e-05\n",
            "iter: 936169  x: [ 3.9999588  15.99967037]  f(x): 1.6977995856005767e-09  grad at x: [ 7.88916842e-05 -2.01621569e-05]  gradient norm: 8.14273320441324e-05\n",
            "iter: 936170  x: [ 3.9999588  15.99967037]  f(x): 1.6977489809142059e-09  grad at x: [-2.52104027e-06 -9.98576252e-06]  gradient norm: 1.0299082342354295e-05\n",
            "iter: 936171  x: [ 3.9999588  15.99967038]  f(x): 1.6976960270625044e-09  grad at x: [ 7.89418576e-05 -2.01681141e-05]  gradient norm: 8.147741837549423e-05\n",
            "iter: 936172  x: [ 3.9999588  15.99967038]  f(x): 1.6976453611508093e-09  grad at x: [-2.52178505e-06 -9.98535506e-06]  gradient norm: 1.0298869626225625e-05\n",
            "iter: 936173  x: [ 3.9999588  15.99967039]  f(x): 1.6975924749078164e-09  grad at x: [ 7.89920455e-05 -2.01740731e-05]  gradient norm: 8.152751972468566e-05\n",
            "iter: 936174  x: [ 3.9999588  15.99967039]  f(x): 1.6975417477144434e-09  grad at x: [-2.52251535e-06 -9.98494943e-06]  gradient norm: 1.0298655193671504e-05\n",
            "iter: 936175  x: [ 3.9999588 15.9996704]  f(x): 1.6974889279412884e-09  grad at x: [ 7.90412874e-05 -2.01799139e-05]  gradient norm: 8.157667579931154e-05\n",
            "iter: 936176  x: [ 3.9999588 15.9996704]  f(x): 1.6974381405870826e-09  grad at x: [-2.52324573e-06 -9.98454379e-06]  gradient norm: 1.0298440843133142e-05\n",
            "iter: 936177  x: [ 3.9999588  15.99967041]  f(x): 1.6973853873920335e-09  grad at x: [ 7.90905583e-05 -2.01857583e-05]  gradient norm: 8.162586141914156e-05\n",
            "iter: 936178  x: [ 3.9999588  15.99967041]  f(x): 1.6973345398050295e-09  grad at x: [-2.52397619e-06 -9.98413816e-06]  gradient norm: 1.0298226574849598e-05\n",
            "iter: 936179  x: [ 3.9999588  15.99967042]  f(x): 1.6972818531888126e-09  grad at x: [ 7.91398146e-05 -2.01916009e-05]  gradient norm: 8.167503293610734e-05\n",
            "iter: 936180  x: [ 3.9999588  15.99967042]  f(x): 1.697230945331403e-09  grad at x: [-2.52470672e-06 -9.98373253e-06]  gradient norm: 1.0298012388624696e-05\n",
            "iter: 936181  x: [ 3.99995881 15.99967043]  f(x): 1.6971783253298823e-09  grad at x: [ 7.91890854e-05 -2.01974453e-05]  gradient norm: 8.172421945065373e-05\n",
            "iter: 936182  x: [ 3.9999588  15.99967043]  f(x): 1.6971273571659143e-09  grad at x: [-2.52543733e-06 -9.98332689e-06]  gradient norm: 1.0297798284479813e-05\n",
            "iter: 936183  x: [ 3.99995881 15.99967044]  f(x): 1.6970748038522747e-09  grad at x: [ 7.92383561e-05 -2.02032898e-05]  gradient norm: 8.177340640863414e-05\n",
            "iter: 936184  x: [ 3.99995881 15.99967044]  f(x): 1.697023775344864e-09  grad at x: [-2.52616802e-06 -9.98292126e-06]  gradient norm: 1.0297584262654213e-05\n",
            "iter: 936185  x: [ 3.99995881 15.99967045]  f(x): 1.696971288755011e-09  grad at x: [ 7.92876413e-05 -2.02091360e-05]  gradient norm: 8.182260836117473e-05\n",
            "iter: 936186  x: [ 3.99995881 15.99967045]  f(x): 1.6969201998502278e-09  grad at x: [-2.52691333e-06 -9.98251380e-06]  gradient norm: 1.0297372130740927e-05\n",
            "iter: 936187  x: [ 3.99995881 15.99967046]  f(x): 1.6968677811300762e-09  grad at x: [ 7.93378432e-05 -2.02150968e-05]  gradient norm: 8.18727274555257e-05\n",
            "iter: 936188  x: [ 3.99995881 15.99967046]  f(x): 1.6968166306628622e-09  grad at x: [-2.52765872e-06 -9.98210635e-06]  gradient norm: 1.0297160083276672e-05\n",
            "iter: 936189  x: [ 3.99995881 15.99967047]  f(x): 1.696764279922261e-09  grad at x: [ 7.93880741e-05 -2.02210613e-05]  gradient norm: 8.192287611225599e-05\n",
            "iter: 936190  x: [ 3.99995881 15.99967047]  f(x): 1.6967130678002108e-09  grad at x: [-2.52838964e-06 -9.98170071e-06]  gradient norm: 1.0296946310386491e-05\n",
            "iter: 936191  x: [ 3.99995881 15.99967048]  f(x): 1.696660783929925e-09  grad at x: [ 7.94373882e-05 -2.02269111e-05]  gradient norm: 8.197210851282201e-05\n",
            "iter: 936192  x: [ 3.99995881 15.99967048]  f(x): 1.696609511263106e-09  grad at x: [-2.52913519e-06 -9.98129326e-06]  gradient norm: 1.0296734430941006e-05\n",
            "iter: 936193  x: [ 3.99995881 15.99967049]  f(x): 1.6965572953758874e-09  grad at x: [ 7.94875898e-05 -2.02328720e-05]  gradient norm: 8.202222897881464e-05\n",
            "iter: 936194  x: [ 3.99995881 15.99967049]  f(x): 1.6965059610501351e-09  grad at x: [-2.52986626e-06 -9.98088763e-06]  gradient norm: 1.0296520823807899e-05\n",
            "iter: 936195  x: [ 3.99995881 15.9996705 ]  f(x): 1.6964538121072197e-09  grad at x: [ 7.95369037e-05 -2.02387218e-05]  gradient norm: 8.207146226815935e-05\n",
            "iter: 936196  x: [ 3.99995881 15.9996705 ]  f(x): 1.6964024171432795e-09  grad at x: [-2.53059740e-06 -9.98048199e-06]  gradient norm: 1.0296307298905314e-05\n",
            "iter: 936197  x: [ 3.99995882 15.99967051]  f(x): 1.6963503352172896e-09  grad at x: [ 7.95862321e-05 -2.02445735e-05]  gradient norm: 8.212071054815668e-05\n",
            "iter: 936198  x: [ 3.99995881 15.99967051]  f(x): 1.6962988795611027e-09  grad at x: [-2.53134318e-06 -9.98007454e-06]  gradient norm: 1.0296095670960384e-05\n",
            "iter: 936199  x: [ 3.99995882 15.99967052]  f(x): 1.6962468657662211e-09  grad at x: [ 7.96364627e-05 -2.02505380e-05]  gradient norm: 8.217086147071313e-05\n",
            "iter: 936200  x: [ 3.99995882 15.99967052]  f(x): 1.696195348302192e-09  grad at x: [-2.53207448e-06 -9.97966890e-06]  gradient norm: 1.0295882312162807e-05\n",
            "iter: 936201  x: [ 3.99995882 15.99967053]  f(x): 1.6961434015622933e-09  grad at x: [ 7.96857763e-05 -2.02563879e-05]  gradient norm: 8.222009608476674e-05\n",
            "iter: 936202  x: [ 3.99995882 15.99967053]  f(x): 1.6960918233485296e-09  grad at x: [-2.53280586e-06 -9.97926327e-06]  gradient norm: 1.0295669035441838e-05\n",
            "iter: 936203  x: [ 3.99995882 15.99967054]  f(x): 1.6960399437362673e-09  grad at x: [ 7.97351045e-05 -2.02622396e-05]  gradient norm: 8.226934568711437e-05\n",
            "iter: 936204  x: [ 3.99995882 15.99967054]  f(x): 1.6959883047364049e-09  grad at x: [-2.53353731e-06 -9.97885763e-06]  gradient norm: 1.02954558412558e-05\n",
            "iter: 936205  x: [ 3.99995882 15.99967055]  f(x): 1.6959364922164513e-09  grad at x: [ 7.97844035e-05 -2.02680876e-05]  gradient norm: 8.23185666201434e-05\n",
            "iter: 936206  x: [ 3.99995882 15.99967055]  f(x): 1.6958847924289507e-09  grad at x: [-2.53426884e-06 -9.97845200e-06]  gradient norm: 1.0295242729407653e-05\n",
            "iter: 936207  x: [ 3.99995882 15.99967055]  f(x): 1.6958459791527116e-09  grad at x: [ 3.86497458e-05 -1.51261975e-05]  gradient norm: 4.150427332013749e-05\n",
            "iter: 936208  x: [ 3.99995882 15.99967055]  f(x): 1.6958322335549687e-09  grad at x: [-1.89113874e-06 -1.00586822e-05]  gradient norm: 1.0234915368815184e-05\n",
            "iter: 936209  x: [ 3.99995883 15.99967059]  f(x): 1.6956239358293315e-09  grad at x: [ 1.60370655e-04 -3.03397683e-05]  gradient norm: 0.00016321534377970368\n",
            "iter: 936210  x: [ 3.99995883 15.99967059]  f(x): 1.6954720971256615e-09  grad at x: [ 7.82883198e-05 -2.00796767e-05]  gradient norm: 8.0822363473729e-05\n",
            "iter: 936211  x: [ 3.99995883 15.99967059]  f(x): 1.695422230710649e-09  grad at x: [-2.51070972e-06 -9.97999268e-06]  gradient norm: 1.029096289226913e-05\n",
            "iter: 936212  x: [ 3.99995883 15.9996706 ]  f(x): 1.6953686785688688e-09  grad at x: [ 7.83371964e-05 -2.00854720e-05]  gradient norm: 8.087114763048125e-05\n",
            "iter: 936213  x: [ 3.99995883 15.9996706 ]  f(x): 1.6953187529590696e-09  grad at x: [-2.51145622e-06 -9.97958523e-06]  gradient norm: 1.029074990982997e-05\n",
            "iter: 936214  x: [ 3.99995883 15.99967061]  f(x): 1.6952652680935037e-09  grad at x: [ 7.83874989e-05 -2.00914455e-05]  gradient norm: 8.092135795954083e-05\n",
            "iter: 936215  x: [ 3.99995883 15.99967061]  f(x): 1.6952152815280199e-09  grad at x: [-2.51218825e-06 -9.97917959e-06]  gradient norm: 1.0290535223356862e-05\n",
            "iter: 936216  x: [ 3.99995883 15.99967062]  f(x): 1.6951618627738869e-09  grad at x: [ 7.84368264e-05 -2.00972972e-05]  gradient norm: 8.097059403261627e-05\n",
            "iter: 936217  x: [ 3.99995883 15.99967062]  f(x): 1.6951118164172099e-09  grad at x: [-2.51290580e-06 -9.97877578e-06]  gradient norm: 1.029031882943879e-05\n",
            "iter: 936218  x: [ 3.99995883 15.99967063]  f(x): 1.6950584627486611e-09  grad at x: [ 7.84852662e-05 -2.01030380e-05]  gradient norm: 8.101894310930662e-05\n",
            "iter: 936219  x: [ 3.99995883 15.99967063]  f(x): 1.6950083576086242e-09  grad at x: [-2.51362343e-06 -9.97837196e-06]  gradient norm: 1.0290102515512113e-05\n",
            "iter: 936220  x: [ 3.99995883 15.99967064]  f(x): 1.694955069061019e-09  grad at x: [ 7.85337058e-05 -2.01087787e-05]  gradient norm: 8.106729262677214e-05\n",
            "iter: 936221  x: [ 3.99995883 15.99967064]  f(x): 1.6949049051030914e-09  grad at x: [-2.51437024e-06 -9.97796451e-06]  gradient norm: 1.0289889865697553e-05\n",
            "iter: 936222  x: [ 3.99995883 15.99967065]  f(x): 1.6948516840156478e-09  grad at x: [ 7.85840372e-05 -2.01147559e-05]  gradient norm: 8.111753392220018e-05\n",
            "iter: 936223  x: [ 3.99995883 15.99967065]  f(x): 1.6948014589346551e-09  grad at x: [-2.51508802e-06 -9.97756069e-06]  gradient norm: 1.028967371449927e-05\n",
            "iter: 936224  x: [ 3.99995884 15.99967066]  f(x): 1.694748303040269e-09  grad at x: [ 7.86324767e-05 -2.01204966e-05]  gradient norm: 8.116588433579132e-05\n",
            "iter: 936225  x: [ 3.99995883 15.99967066]  f(x): 1.6946980190675778e-09  grad at x: [-2.51580588e-06 -9.97715688e-06]  gradient norm: 1.0289457643138848e-05\n",
            "iter: 936226  x: [ 3.99995884 15.99967067]  f(x): 1.6946449284365504e-09  grad at x: [ 7.86809453e-05 -2.01262410e-05]  gradient norm: 8.12142642866205e-05\n",
            "iter: 936227  x: [ 3.99995884 15.99967067]  f(x): 1.6945945855204102e-09  grad at x: [-2.51653836e-06 -9.97675124e-06]  gradient norm: 1.0289243447416624e-05\n",
            "iter: 936228  x: [ 3.99995884 15.99967068]  f(x): 1.6945415612897424e-09  grad at x: [ 7.87303160e-05 -2.01320981e-05]  gradient norm: 8.126354672362558e-05\n",
            "iter: 936229  x: [ 3.99995884 15.99967068]  f(x): 1.6944911582740248e-09  grad at x: [-2.51727093e-06 -9.97634561e-06]  gradient norm: 1.0289029334061196e-05\n",
            "iter: 936230  x: [ 3.99995884 15.99967069]  f(x): 1.69443820051545e-09  grad at x: [ 7.87797157e-05 -2.01379589e-05]  gradient norm: 8.131285871547191e-05\n",
            "iter: 936231  x: [ 3.99995884 15.99967069]  f(x): 1.6943877373458541e-09  grad at x: [-2.51798902e-06 -9.97594179e-06]  gradient norm: 1.0288813505675904e-05\n",
            "iter: 936232  x: [ 3.99995884 15.9996707 ]  f(x): 1.6943348449581966e-09  grad at x: [ 7.88281840e-05 -2.01437033e-05]  gradient norm: 8.13612399948225e-05\n",
            "iter: 936233  x: [ 3.99995884 15.9996707 ]  f(x): 1.6942843227367265e-09  grad at x: [-2.51872173e-06 -9.97553616e-06]  gradient norm: 1.028859955619051e-05\n",
            "iter: 936234  x: [ 3.99995884 15.99967071]  f(x): 1.6942314969290704e-09  grad at x: [ 7.88776127e-05 -2.01495677e-05]  gradient norm: 8.141058198244838e-05\n",
            "iter: 936235  x: [ 3.99995884 15.99967071]  f(x): 1.6941809144452347e-09  grad at x: [-2.51943997e-06 -9.97513234e-06]  gradient norm: 1.0288383889230387e-05\n",
            "iter: 936236  x: [ 3.99995884 15.99967072]  f(x): 1.6941281540800064e-09  grad at x: [ 7.89260808e-05 -2.01553121e-05]  gradient norm: 8.14589641384635e-05\n",
            "iter: 936237  x: [ 3.99995884 15.99967072]  f(x): 1.6940775124533696e-09  grad at x: [-2.52015829e-06 -9.97472853e-06]  gradient norm: 1.028816830266962e-05\n",
            "iter: 936238  x: [ 3.99995884 15.99967073]  f(x): 1.69402481756523e-09  grad at x: [ 7.89745634e-05 -2.01610583e-05]  gradient norm: 8.150736127715312e-05\n",
            "iter: 936239  x: [ 3.99995884 15.99967073]  f(x): 1.6939741167608435e-09  grad at x: [-2.52087669e-06 -9.97432471e-06]  gradient norm: 1.0287952796094187e-05\n",
            "iter: 936240  x: [ 3.99995885 15.99967074]  f(x): 1.6939214874217691e-09  grad at x: [ 7.90230460e-05 -2.01668045e-05]  gradient norm: 8.155575884824572e-05\n",
            "iter: 936241  x: [ 3.99995884 15.99967074]  f(x): 1.6938707273862056e-09  grad at x: [-2.52160971e-06 -9.97391908e-06]  gradient norm: 1.028773917324202e-05\n",
            "iter: 936242  x: [ 3.99995885 15.99967075]  f(x): 1.6938181647723192e-09  grad at x: [ 7.90724744e-05 -2.01726689e-05]  gradient norm: 8.160510261615504e-05\n",
            "iter: 936243  x: [ 3.99995885 15.99967075]  f(x): 1.6937673443291665e-09  grad at x: [-2.52235736e-06 -9.97351162e-06]  gradient norm: 1.0287527437572782e-05\n",
            "iter: 936244  x: [ 3.99995885 15.99967076]  f(x): 1.6937148496545752e-09  grad at x: [ 7.91228631e-05 -2.01786534e-05]  gradient norm: 8.165540715526075e-05\n",
            "iter: 936245  x: [ 3.99995885 15.99967076]  f(x): 1.6936639675883171e-09  grad at x: [-2.52309054e-06 -9.97310599e-06]  gradient norm: 1.028731398135758e-05\n",
            "iter: 936246  x: [ 3.99995885 15.99967077]  f(x): 1.6936115397133035e-09  grad at x: [ 7.91722913e-05 -2.01845178e-05]  gradient norm: 8.17047518291818e-05\n",
            "iter: 936247  x: [ 3.99995885 15.99967077]  f(x): 1.693560597145653e-09  grad at x: [-2.52382380e-06 -9.97270035e-06]  gradient norm: 1.0287100607484559e-05\n",
            "iter: 936248  x: [ 3.99995885 15.99967078]  f(x): 1.6935082360711852e-09  grad at x: [ 7.92217049e-05 -2.01903804e-05]  gradient norm: 8.175408240030011e-05\n",
            "iter: 936249  x: [ 3.99995885 15.99967078]  f(x): 1.6934572330008852e-09  grad at x: [-2.52455713e-06 -9.97229472e-06]  gradient norm: 1.0286887316192962e-05\n",
            "iter: 936250  x: [ 3.99995885 15.99967079]  f(x): 1.6934049388707325e-09  grad at x: [ 7.92711766e-05 -2.01962503e-05]  gradient norm: 8.180347161989967e-05\n",
            "iter: 936251  x: [ 3.99995885 15.99967079]  f(x): 1.6933538751902757e-09  grad at x: [-2.52529053e-06 -9.97188909e-06]  gradient norm: 1.0286674107722303e-05\n",
            "iter: 936252  x: [ 3.99995885 15.9996708 ]  f(x): 1.6933016480054471e-09  grad at x: [ 7.93206337e-05 -2.02021183e-05]  gradient norm: 8.1852846735385e-05\n",
            "iter: 936253  x: [ 3.99995885 15.9996708 ]  f(x): 1.6932505236769849e-09  grad at x: [-2.52602402e-06 -9.97148345e-06]  gradient norm: 1.028646098187615e-05\n",
            "iter: 936254  x: [ 3.99995885 15.99967081]  f(x): 1.6931983634743582e-09  grad at x: [ 7.93700907e-05 -2.02079864e-05]  gradient norm: 8.190222229619868e-05\n",
            "iter: 936255  x: [ 3.99995885 15.99967081]  f(x): 1.6931471784795597e-09  grad at x: [-2.52677213e-06 -9.97107600e-06]  gradient norm: 1.0286249750242974e-05\n",
            "iter: 936256  x: [ 3.99995886 15.99967082]  f(x): 1.6930950864064643e-09  grad at x: [ 7.94204645e-05 -2.02139690e-05]  gradient norm: 8.195251502985214e-05\n",
            "iter: 936257  x: [ 3.99995885 15.99967082]  f(x): 1.6930438395777554e-09  grad at x: [-2.52749121e-06 -9.97067218e-06]  gradient norm: 1.0286034978579755e-05\n",
            "iter: 936258  x: [ 3.99995886 15.99967083]  f(x): 1.6929918134142432e-09  grad at x: [ 7.94689900e-05 -2.02197207e-05]  gradient norm: 8.200096019720319e-05\n",
            "iter: 936259  x: [ 3.99995886 15.99967083]  f(x): 1.692940506973528e-09  grad at x: [-2.52823948e-06 -9.97026473e-06]  gradient norm: 1.0285823914597649e-05\n",
            "iter: 936260  x: [ 3.99995886 15.99967084]  f(x): 1.6928885490865299e-09  grad at x: [ 7.95193927e-05 -2.02257070e-05]  gradient norm: 8.205128293743966e-05\n",
            "iter: 936261  x: [ 3.99995886 15.99967084]  f(x): 1.6928371807020112e-09  grad at x: [-2.52898782e-06 -9.96985727e-06]  gradient norm: 1.0285612935859891e-05\n",
            "iter: 936262  x: [ 3.99995886 15.99967085]  f(x): 1.6927852911292378e-09  grad at x: [ 7.95698098e-05 -2.02316951e-05]  gradient norm: 8.210162068788727e-05\n",
            "iter: 936263  x: [ 3.99995886 15.99967085]  f(x): 1.6927338607263715e-09  grad at x: [-2.52973624e-06 -9.96944982e-06]  gradient norm: 1.0285402042170144e-05\n",
            "iter: 936264  x: [ 3.99995886 15.99967086]  f(x): 1.692682039506162e-09  grad at x: [ 7.96202269e-05 -2.02376832e-05]  gradient norm: 8.215195889988568e-05\n",
            "iter: 936265  x: [ 3.99995886 15.99967086]  f(x): 1.6926305470640303e-09  grad at x: [-2.53047018e-06 -9.96904419e-06]  gradient norm: 1.0285189416402663e-05\n",
            "iter: 936266  x: [ 3.99995886 15.99967087]  f(x): 1.6925787930848094e-09  grad at x: [ 7.96697125e-05 -2.02435549e-05]  gradient norm: 8.220136624283419e-05\n",
            "iter: 936267  x: [ 3.99995886 15.99967087]  f(x): 1.69252723969699e-09  grad at x: [-2.53120420e-06 -9.96863855e-06]  gradient norm: 1.0284976873410748e-05\n",
            "iter: 936268  x: [ 3.99995886 15.99967088]  f(x): 1.6924755529597072e-09  grad at x: [ 7.97191836e-05 -2.02494248e-05]  gradient norm: 8.225075947323401e-05\n",
            "iter: 936269  x: [ 3.99995886 15.99967088]  f(x): 1.6924239386426696e-09  grad at x: [-2.53192375e-06 -9.96823474e-06]  gradient norm: 1.0284762594011663e-05\n",
            "iter: 936270  x: [ 3.99995886 15.99967089]  f(x): 1.69238520917676e-09  grad at x: [ 3.86179070e-05 -1.51117074e-05]  gradient norm: 4.146934337959699e-05\n",
            "iter: 936271  x: [ 3.99995886 15.99967089]  f(x): 1.6923714870061596e-09  grad at x: [-1.88931882e-06 -1.00483994e-05]  gradient norm: 1.0224473407025267e-05\n",
            "iter: 936272  x: [ 3.99995887 15.99967093]  f(x): 1.6921636850835484e-09  grad at x: [ 1.60235632e-04 -3.03123816e-05]  gradient norm: 0.0001630775834034476\n",
            "iter: 936273  x: [ 3.99995887 15.99967093]  f(x): 1.692012102653051e-09  grad at x: [ 7.82225209e-05 -2.00609429e-05]  gradient norm: 8.07539733433928e-05\n",
            "iter: 936274  x: [ 3.99995887 15.99967093]  f(x): 1.691962320880376e-09  grad at x: [-2.50836154e-06 -9.96977724e-06]  gradient norm: 1.0280483248190011e-05\n",
            "iter: 936275  x: [ 3.99995887 15.99967094]  f(x): 1.6919088946678991e-09  grad at x: [ 7.82709583e-05 -2.00666836e-05]  gradient norm: 8.080231872108032e-05\n",
            "iter: 936276  x: [ 3.99995887 15.99967094]  f(x): 1.6918590543102118e-09  grad at x: [-2.50908151e-06 -9.96937342e-06]  gradient norm: 1.0280267333676797e-05\n",
            "iter: 936277  x: [ 3.99995887 15.99967095]  f(x): 1.6918056932567602e-09  grad at x: [ 7.83195703e-05 -2.00724462e-05]  gradient norm: 8.085083911927785e-05\n",
            "iter: 936278  x: [ 3.99995887 15.99967095]  f(x): 1.6917557940331945e-09  grad at x: [-2.50980155e-06 -9.96896961e-06]  gradient norm: 1.0280051499779117e-05\n",
            "iter: 936279  x: [ 3.99995887 15.99967096]  f(x): 1.6917024981395803e-09  grad at x: [ 7.83681531e-05 -2.00782051e-05]  gradient norm: 8.089933086775138e-05\n",
            "iter: 936280  x: [ 3.99995887 15.99967096]  f(x): 1.6916525400490363e-09  grad at x: [-2.51052166e-06 -9.96856579e-06]  gradient norm: 1.0279835746084465e-05\n",
            "iter: 936281  x: [ 3.99995887 15.99967097]  f(x): 1.6915993094213324e-09  grad at x: [ 7.84167794e-05 -2.00839695e-05]  gradient norm: 8.094786670574009e-05\n",
            "iter: 936282  x: [ 3.99995887 15.99967097]  f(x): 1.6915492923762717e-09  grad at x: [-2.51125641e-06 -9.96816016e-06]  gradient norm: 1.0279621864116199e-05\n",
            "iter: 936283  x: [ 3.99995887 15.99967098]  f(x): 1.6914961281123754e-09  grad at x: [ 7.84662934e-05 -2.00898448e-05]  gradient norm: 8.099729045588749e-05\n",
            "iter: 936284  x: [ 3.99995887 15.99967098]  f(x): 1.6914460510134964e-09  grad at x: [-2.51197668e-06 -9.96775634e-06]  gradient norm: 1.0279406272887327e-05\n",
            "iter: 936285  x: [ 3.99995888 15.99967099]  f(x): 1.6913929520517404e-09  grad at x: [ 7.85149050e-05 -2.00956074e-05]  gradient norm: 8.104581264135865e-05\n",
            "iter: 936286  x: [ 3.99995887 15.99967099]  f(x): 1.6913428159438308e-09  grad at x: [-2.51272613e-06 -9.96734889e-06]  gradient norm: 1.0279194348855764e-05\n",
            "iter: 936287  x: [ 3.99995888 15.999671  ]  f(x): 1.6912897845525141e-09  grad at x: [ 7.85653647e-05 -2.01016010e-05]  gradient norm: 8.109618298733545e-05\n",
            "iter: 936288  x: [ 3.99995888 15.999671  ]  f(x): 1.6912395871824614e-09  grad at x: [-2.51343200e-06 -9.96694689e-06]  gradient norm: 1.0278977126159742e-05\n",
            "iter: 936289  x: [ 3.99995888 15.99967101]  f(x): 1.6911866200309906e-09  grad at x: [ 7.86130449e-05 -2.01072471e-05]  gradient norm: 8.114377493479474e-05\n",
            "iter: 936290  x: [ 3.99995888 15.99967101]  f(x): 1.6911363647136256e-09  grad at x: [-2.51416706e-06 -9.96654126e-06]  gradient norm: 1.0278763573416417e-05\n",
            "iter: 936291  x: [ 3.99995888 15.99967102]  f(x): 1.691083464142334e-09  grad at x: [ 7.86626167e-05 -2.01131297e-05]  gradient norm: 8.11932587047044e-05\n",
            "iter: 936292  x: [ 3.99995888 15.99967102]  f(x): 1.6910331485536237e-09  grad at x: [-2.51488763e-06 -9.96613744e-06]  gradient norm: 1.027854830650701e-05\n",
            "iter: 936293  x: [ 3.99995888 15.99967103]  f(x): 1.6909803134283196e-09  grad at x: [ 7.87112281e-05 -2.01188923e-05]  gradient norm: 8.124178267405857e-05\n",
            "iter: 936294  x: [ 3.99995888 15.99967103]  f(x): 1.6909299386844635e-09  grad at x: [-2.51560829e-06 -9.96573362e-06]  gradient norm: 1.0278333120383328e-05\n",
            "iter: 936295  x: [ 3.99995888 15.99967104]  f(x): 1.6908771690757378e-09  grad at x: [ 7.87598684e-05 -2.01246585e-05]  gradient norm: 8.129033618080973e-05\n",
            "iter: 936296  x: [ 3.99995888 15.99967104]  f(x): 1.6908267351058573e-09  grad at x: [-2.51632902e-06 -9.96532981e-06]  gradient norm: 1.0278118014631803e-05\n",
            "iter: 936297  x: [ 3.99995888 15.99967105]  f(x): 1.690774031049367e-09  grad at x: [ 7.88085087e-05 -2.01304247e-05]  gradient norm: 8.133889012783926e-05\n",
            "iter: 936298  x: [ 3.99995888 15.99967105]  f(x): 1.690723537818635e-09  grad at x: [-2.51707893e-06 -9.96492236e-06]  gradient norm: 1.0277906590056185e-05\n",
            "iter: 936299  x: [ 3.99995888 15.99967106]  f(x): 1.6906709016625354e-09  grad at x: [ 7.88590262e-05 -2.01364255e-05]  gradient norm: 8.138932143822572e-05\n",
            "iter: 936300  x: [ 3.99995888 15.99967106]  f(x): 1.6906203468402106e-09  grad at x: [-2.51784347e-06 -9.96451308e-06]  gradient norm: 1.0277697052307473e-05\n",
            "iter: 936301  x: [ 3.99995889 15.99967107]  f(x): 1.6905677797263146e-09  grad at x: [ 7.89104604e-05 -2.01425410e-05]  gradient norm: 8.144066987183969e-05\n",
            "iter: 936302  x: [ 3.99995888 15.99967107]  f(x): 1.6905171621691772e-09  grad at x: [-2.51859353e-06 -9.96410563e-06]  gradient norm: 1.0277485799609702e-05\n",
            "iter: 936303  x: [ 3.99995889 15.99967108]  f(x): 1.6904646629968465e-09  grad at x: [ 7.89609776e-05 -2.01485418e-05]  gradient norm: 8.1491102142272e-05\n",
            "iter: 936304  x: [ 3.99995889 15.99967108]  f(x): 1.690413983787546e-09  grad at x: [-2.51934367e-06 -9.96369818e-06]  gradient norm: 1.027727463218966e-05\n",
            "iter: 936305  x: [ 3.99995889 15.99967109]  f(x): 1.690361552595988e-09  grad at x: [ 7.90114803e-05 -2.01545408e-05]  gradient norm: 8.154152033213037e-05\n",
            "iter: 936306  x: [ 3.99995889 15.99967109]  f(x): 1.690310811712728e-09  grad at x: [-2.52007934e-06 -9.96329254e-06]  gradient norm: 1.0277061745397398e-05\n",
            "iter: 936307  x: [ 3.99995889 15.9996711 ]  f(x): 1.6902584474342713e-09  grad at x: [ 7.90610807e-05 -2.01604271e-05]  gradient norm: 8.159103686872897e-05\n",
            "iter: 936308  x: [ 3.99995889 15.9996711 ]  f(x): 1.6902076459267358e-09  grad at x: [-2.52081508e-06 -9.96288691e-06]  gradient norm: 1.0276848941386555e-05\n",
            "iter: 936309  x: [ 3.99995889 15.99967111]  f(x): 1.6901553485984746e-09  grad at x: [ 7.91106810e-05 -2.01663133e-05]  gradient norm: 8.164055385574796e-05\n",
            "iter: 936310  x: [ 3.99995889 15.99967111]  f(x): 1.6901044864469786e-09  grad at x: [-2.52153634e-06 -9.96248309e-06]  gradient norm: 1.0276634413225207e-05\n",
            "iter: 936311  x: [ 3.99995889 15.99967112]  f(x): 1.6900522549633582e-09  grad at x: [ 7.91593498e-05 -2.01720832e-05]  gradient norm: 8.168914004847204e-05\n",
            "iter: 936312  x: [ 3.99995889 15.99967112]  f(x): 1.6900013332565907e-09  grad at x: [-2.52228679e-06 -9.96207564e-06]  gradient norm: 1.027642358288454e-05\n",
            "iter: 936313  x: [ 3.99995889 15.99967113]  f(x): 1.6899491699400006e-09  grad at x: [ 7.92098813e-05 -2.01780858e-05]  gradient norm: 8.173958918408914e-05\n",
            "iter: 936314  x: [ 3.99995889 15.99967113]  f(x): 1.6898981863718606e-09  grad at x: [-2.52302276e-06 -9.96167000e-06]  gradient norm: 1.0276211028218704e-05\n",
            "iter: 936315  x: [ 3.99995889 15.99967114]  f(x): 1.689846090151945e-09  grad at x: [ 7.92595104e-05 -2.01839757e-05]  gradient norm: 8.178913662496713e-05\n",
            "iter: 936316  x: [ 3.99995889 15.99967114]  f(x): 1.6897950457748044e-09  grad at x: [-2.52375881e-06 -9.96126437e-06]  gradient norm: 1.0275998556638403e-05\n",
            "iter: 936317  x: [ 3.9999589  15.99967115]  f(x): 1.6897430166534797e-09  grad at x: [ 7.93091104e-05 -2.01898620e-05]  gradient norm: 8.183865541125443e-05\n",
            "iter: 936318  x: [ 3.99995889 15.99967115]  f(x): 1.6896919114651344e-09  grad at x: [-2.52449493e-06 -9.96085873e-06]  gradient norm: 1.0275786168383408e-05\n",
            "iter: 936319  x: [ 3.9999589  15.99967116]  f(x): 1.6896399495147371e-09  grad at x: [ 7.93587394e-05 -2.01957519e-05]  gradient norm: 8.188820374695424e-05\n",
            "iter: 936320  x: [ 3.9999589  15.99967116]  f(x): 1.689588783461377e-09  grad at x: [-2.52524569e-06 -9.96045128e-06]  gradient norm: 1.027557567620674e-05\n",
            "iter: 936321  x: [ 3.9999589  15.99967117]  f(x): 1.6895368898652272e-09  grad at x: [ 7.94092997e-05 -2.02017582e-05]  gradient norm: 8.193868382373905e-05\n",
            "iter: 936322  x: [ 3.9999589  15.99967117]  f(x): 1.6894856617444307e-09  grad at x: [-2.52599652e-06 -9.96004383e-06]  gradient norm: 1.0275365269504985e-05\n",
            "iter: 936323  x: [ 3.9999589  15.99967118]  f(x): 1.689433836505191e-09  grad at x: [ 7.94598453e-05 -2.02077626e-05]  gradient norm: 8.198914981227857e-05\n",
            "iter: 936324  x: [ 3.9999589  15.99967118]  f(x): 1.6893825463305772e-09  grad at x: [-2.52670377e-06 -9.95964183e-06]  gradient norm: 1.0275149502259152e-05\n",
            "iter: 936325  x: [ 3.9999589  15.99967119]  f(x): 1.6893307860798757e-09  grad at x: [ 7.95076114e-05 -2.02134197e-05]  gradient norm: 8.203683688245579e-05\n",
            "iter: 936326  x: [ 3.9999589  15.99967119]  f(x): 1.6892794372040792e-09  grad at x: [-2.52744020e-06 -9.95923619e-06]  gradient norm: 1.0274937446867229e-05\n",
            "iter: 936327  x: [ 3.9999589 15.9996712]  f(x): 1.6892277443081726e-09  grad at x: [ 7.95572692e-05 -2.02193132e-05]  gradient norm: 8.208641610350002e-05\n",
            "iter: 936328  x: [ 3.9999589 15.9996712]  f(x): 1.6891763343458377e-09  grad at x: [-2.52819126e-06 -9.95882874e-06]  gradient norm: 1.0274727292030215e-05\n",
            "iter: 936329  x: [ 3.9999589  15.99967121]  f(x): 1.6891247099914833e-09  grad at x: [ 7.96078437e-05 -2.02253214e-05]  gradient norm: 8.21369125477606e-05\n",
            "iter: 936330  x: [ 3.9999589  15.99967121]  f(x): 1.689073237809759e-09  grad at x: [-2.52894239e-06 -9.95842129e-06]  gradient norm: 1.0274517222974155e-05\n",
            "iter: 936331  x: [ 3.9999589  15.99967122]  f(x): 1.689021682034973e-09  grad at x: [ 7.96584327e-05 -2.02313313e-05]  gradient norm: 8.218742400338281e-05\n",
            "iter: 936332  x: [ 3.9999589  15.99967122]  f(x): 1.6889830310070733e-09  grad at x: [ 3.85643841e-05 -1.50946744e-05]  gradient norm: 4.1413293937614305e-05\n",
            "iter: 936333  x: [ 3.9999589  15.99967122]  f(x): 1.6889693453608781e-09  grad at x: [-1.8871800e-06 -1.0038324e-05]  gradient norm: 1.0214176313949423e-05\n",
            "iter: 936334  x: [ 3.99995891 15.99967126]  f(x): 1.6887618089335242e-09  grad at x: [ 1.60012640e-04 -3.02741664e-05]  gradient norm: 0.00016285137418406905\n",
            "iter: 936335  x: [ 3.99995891 15.99967126]  f(x): 1.6886106465877071e-09  grad at x: [ 7.81134136e-05 -2.00369632e-05]  gradient norm: 8.064232929162529e-05\n",
            "iter: 936336  x: [ 3.99995891 15.99967126]  f(x): 1.688561001764701e-09  grad at x: [-2.5053596e-06 -9.9598110e-06]  gradient norm: 1.0270085772832183e-05\n",
            "iter: 936337  x: [ 3.99995891 15.99967127]  f(x): 1.6885076458136109e-09  grad at x: [ 7.81615865e-05 -2.00426712e-05]  gradient norm: 8.06904100484818e-05\n",
            "iter: 936338  x: [ 3.99995891 15.99967127]  f(x): 1.6884579427846916e-09  grad at x: [-2.50609664e-06 -9.95940536e-06]  gradient norm: 1.026987222433658e-05\n",
            "iter: 936339  x: [ 3.99995891 15.99967128]  f(x): 1.6884046532010412e-09  grad at x: [ 7.82112728e-05 -2.00485683e-05]  gradient norm: 8.074000424824075e-05\n",
            "iter: 936340  x: [ 3.99995891 15.99967128]  f(x): 1.6883548900883352e-09  grad at x: [-2.50683376e-06 -9.95899973e-06]  gradient norm: 1.026965875918087e-05\n",
            "iter: 936341  x: [ 3.99995891 15.99967129]  f(x): 1.6883016669093501e-09  grad at x: [ 7.82609590e-05 -2.00544655e-05]  gradient norm: 8.078959891763577e-05\n",
            "iter: 936342  x: [ 3.99995891 15.99967129]  f(x): 1.688251843675344e-09  grad at x: [-2.50757095e-06 -9.95859409e-06]  gradient norm: 1.0269445376953145e-05\n",
            "iter: 936343  x: [ 3.99995891 15.9996713 ]  f(x): 1.6881986869382499e-09  grad at x: [ 7.83106452e-05 -2.00603627e-05]  gradient norm: 8.083919405566165e-05\n",
            "iter: 936344  x: [ 3.99995891 15.9996713 ]  f(x): 1.6881488035631204e-09  grad at x: [-2.50829367e-06 -9.95819028e-06]  gradient norm: 1.0269230287639552e-05\n",
            "iter: 936345  x: [ 3.99995892 15.99967131]  f(x): 1.6880957121738692e-09  grad at x: [ 7.83593999e-05 -2.00661434e-05]  gradient norm: 8.088785855391745e-05\n",
            "iter: 936346  x: [ 3.99995891 15.99967131]  f(x): 1.688045769733686e-09  grad at x: [-2.50901646e-06 -9.95778646e-06]  gradient norm: 1.0269015279009906e-05\n",
            "iter: 936347  x: [ 3.99995892 15.99967132]  f(x): 1.6879927437629264e-09  grad at x: [ 7.84081836e-05 -2.00719278e-05]  gradient norm: 8.093655259651697e-05\n",
            "iter: 936348  x: [ 3.99995892 15.99967132]  f(x): 1.6879427421878682e-09  grad at x: [-2.50976844e-06 -9.95737901e-06]  gradient norm: 1.0268803937011684e-05\n",
            "iter: 936349  x: [ 3.99995892 15.99967133]  f(x): 1.6878897839019552e-09  grad at x: [ 7.84588009e-05 -2.00779414e-05]  gradient norm: 8.098708024197909e-05\n",
            "iter: 936350  x: [ 3.99995892 15.99967133]  f(x): 1.6878397209419526e-09  grad at x: [-2.51050594e-06 -9.95697337e-06]  gradient norm: 1.0268590886859433e-05\n",
            "iter: 936351  x: [ 3.99995892 15.99967134]  f(x): 1.6877868292810109e-09  grad at x: [ 7.85085158e-05 -2.00838422e-05]  gradient norm: 8.103670633267258e-05\n",
            "iter: 936352  x: [ 3.99995892 15.99967134]  f(x): 1.6877367059779638e-09  grad at x: [-2.51124352e-06 -9.95656774e-06]  gradient norm: 1.0268377919743e-05\n",
            "iter: 936353  x: [ 3.99995892 15.99967135]  f(x): 1.6876838809792621e-09  grad at x: [ 7.85582307e-05 -2.00897430e-05]  gradient norm: 8.108633288762553e-05\n",
            "iter: 936354  x: [ 3.99995892 15.99967135]  f(x): 1.6876336972956143e-09  grad at x: [-2.51198117e-06 -9.95616210e-06]  gradient norm: 1.02681650359011e-05\n",
            "iter: 936355  x: [ 3.99995892 15.99967136]  f(x): 1.6875809389964212e-09  grad at x: [ 7.86079455e-05 -2.00956438e-05]  gradient norm: 8.113595990584563e-05\n",
            "iter: 936356  x: [ 3.99995892 15.99967136]  f(x): 1.6875306949123016e-09  grad at x: [-2.51270435e-06 -9.95575829e-06]  gradient norm: 1.0267950438198674e-05\n",
            "iter: 936357  x: [ 3.99995892 15.99967137]  f(x): 1.6874780022143915e-09  grad at x: [ 7.86567288e-05 -2.01014282e-05]  gradient norm: 8.118465621968117e-05\n",
            "iter: 936358  x: [ 3.99995892 15.99967137]  f(x): 1.6874276988111683e-09  grad at x: [-2.51345670e-06 -9.95535083e-06]  gradient norm: 1.0267739518562315e-05\n",
            "iter: 936359  x: [ 3.99995892 15.99967138]  f(x): 1.6873750740577498e-09  grad at x: [ 7.87074039e-05 -2.01074490e-05]  gradient norm: 8.123524442679821e-05\n",
            "iter: 936360  x: [ 3.99995892 15.99967138]  f(x): 1.6873247089908117e-09  grad at x: [-2.51420914e-06 -9.95494338e-06]  gradient norm: 1.026752868459583e-05\n",
            "iter: 936361  x: [ 3.99995893 15.99967139]  f(x): 1.6872721521856465e-09  grad at x: [ 7.87580498e-05 -2.01134662e-05]  gradient norm: 8.128580401340164e-05\n",
            "iter: 936362  x: [ 3.99995892 15.99967139]  f(x): 1.6872217254686276e-09  grad at x: [-2.51494710e-06 -9.95453775e-06]  gradient norm: 1.0267316135658857e-05\n",
            "iter: 936363  x: [ 3.99995893 15.9996714 ]  f(x): 1.6871692355477678e-09  grad at x: [ 7.88077934e-05 -2.01193707e-05]  gradient norm: 8.133546198390376e-05\n",
            "iter: 936364  x: [ 3.99995893 15.9996714 ]  f(x): 1.6871187482266442e-09  grad at x: [-2.51568513e-06 -9.95413211e-06]  gradient norm: 1.026710366988743e-05\n",
            "iter: 936365  x: [ 3.99995893 15.99967141]  f(x): 1.687066325227402e-09  grad at x: [ 7.88575369e-05 -2.01252751e-05]  gradient norm: 8.138512041160234e-05\n",
            "iter: 936366  x: [ 3.99995893 15.99967141]  f(x): 1.6870157772645744e-09  grad at x: [-2.51642325e-06 -9.95372648e-06]  gradient norm: 1.026689128752069e-05\n",
            "iter: 936367  x: [ 3.99995893 15.99967142]  f(x): 1.686963421224262e-09  grad at x: [ 7.89072803e-05 -2.01311796e-05]  gradient norm: 8.14347792989602e-05\n",
            "iter: 936368  x: [ 3.99995893 15.99967142]  f(x): 1.6869128125832483e-09  grad at x: [-2.51719054e-06 -9.95331720e-06]  gradient norm: 1.026668259772833e-05\n",
            "iter: 936369  x: [ 3.99995893 15.99967143]  f(x): 1.6868605258537685e-09  grad at x: [ 7.89589155e-05 -2.01373205e-05]  gradient norm: 8.148633019010516e-05\n",
            "iter: 936370  x: [ 3.99995893 15.99967143]  f(x): 1.686809854198942e-09  grad at x: [-2.51794336e-06 -9.95290975e-06]  gradient norm: 1.0266472190307887e-05\n",
            "iter: 936371  x: [ 3.99995893 15.99967144]  f(x): 1.6867576356449378e-09  grad at x: [ 7.90095901e-05 -2.01433413e-05]  gradient norm: 8.153692124179833e-05\n",
            "iter: 936372  x: [ 3.99995893 15.99967144]  f(x): 1.6867069020936869e-09  grad at x: [-2.51869625e-06 -9.95250230e-06]  gradient norm: 1.0266261868689622e-05\n",
            "iter: 936373  x: [ 3.99995893 15.99967145]  f(x): 1.6866547517890056e-09  grad at x: [ 7.90602937e-05 -2.01493658e-05]  gradient norm: 8.158754187000495e-05\n",
            "iter: 936374  x: [ 3.99995893 15.99967145]  f(x): 1.6866039562671955e-09  grad at x: [-2.51944922e-06 -9.95209484e-06]  gradient norm: 1.0266051632895611e-05\n",
            "iter: 936375  x: [ 3.99995893 15.99967146]  f(x): 1.686551874215486e-09  grad at x: [ 7.91109682e-05 -2.01553867e-05]  gradient norm: 8.16381338690172e-05\n",
            "iter: 936376  x: [ 3.99995893 15.99967146]  f(x): 1.6865010167368586e-09  grad at x: [-2.52018772e-06 -9.95168921e-06]  gradient norm: 1.0265839674093627e-05\n",
            "iter: 936377  x: [ 3.99995894 15.99967147]  f(x): 1.6864490018693632e-09  grad at x: [ 7.91607404e-05 -2.01612947e-05]  gradient norm: 8.168782418042031e-05\n",
            "iter: 936378  x: [ 3.99995893 15.99967147]  f(x): 1.686398083502387e-09  grad at x: [-2.52091174e-06 -9.95128539e-06]  gradient norm: 1.0265625988401242e-05\n",
            "iter: 936379  x: [ 3.99995894 15.99967148]  f(x): 1.6863461347124707e-09  grad at x: [ 7.92095956e-05 -2.01670882e-05]  gradient norm: 8.173659822336049e-05\n",
            "iter: 936380  x: [ 3.99995894 15.99967148]  f(x): 1.6862951565281385e-09  grad at x: [-2.52165038e-06 -9.95087976e-06]  gradient norm: 1.0265414195535725e-05\n",
            "iter: 936381  x: [ 3.99995894 15.99967149]  f(x): 1.6862432749964514e-09  grad at x: [ 7.92593676e-05 -2.01729963e-05]  gradient norm: 8.17862894297917e-05\n",
            "iter: 936382  x: [ 3.99995894 15.99967149]  f(x): 1.6861922358315037e-09  grad at x: [-2.52238911e-06 -9.95047412e-06]  gradient norm: 1.0265202486030732e-05\n",
            "iter: 936383  x: [ 3.99995894 15.9996715 ]  f(x): 1.6861404215954003e-09  grad at x: [ 7.93091396e-05 -2.01789044e-05]  gradient norm: 8.183598108692266e-05\n",
            "iter: 936384  x: [ 3.99995894 15.9996715 ]  f(x): 1.6860893214298706e-09  grad at x: [-2.52311336e-06 -9.95007031e-06]  gradient norm: 1.0264989046687752e-05\n",
            "iter: 936385  x: [ 3.99995894 15.99967151]  f(x): 1.6860375734164983e-09  grad at x: [ 7.93580092e-05 -2.01846997e-05]  gradient norm: 8.188477099651902e-05\n",
            "iter: 936386  x: [ 3.99995894 15.99967151]  f(x): 1.6859864133052752e-09  grad at x: [-2.52383768e-06 -9.94966649e-06]  gradient norm: 1.0264775688455656e-05\n",
            "iter: 936387  x: [ 3.99995894 15.99967152]  f(x): 1.6859347315506321e-09  grad at x: [ 7.94068787e-05 -2.01904950e-05]  gradient norm: 8.19335613387169e-05\n",
            "iter: 936388  x: [ 3.99995894 15.99967152]  f(x): 1.6858835114585517e-09  grad at x: [-2.52459119e-06 -9.94925904e-06]  gradient norm: 1.0264566043670885e-05\n",
            "iter: 936389  x: [ 3.99995894 15.99967153]  f(x): 1.6858318982923216e-09  grad at x: [ 7.94576108e-05 -2.01965231e-05]  gradient norm: 8.198421474382468e-05\n",
            "iter: 936390  x: [ 3.99995894 15.99967153]  f(x): 1.6857806158882924e-09  grad at x: [-2.52534477e-06 -9.94885158e-06]  gradient norm: 1.0264356485104438e-05\n",
            "iter: 936391  x: [ 3.99995894 15.99967154]  f(x): 1.6857290713493009e-09  grad at x: [ 7.95083429e-05 -2.02025512e-05]  gradient norm: 8.203486861689093e-05\n",
            "iter: 936392  x: [ 3.99995894 15.99967154]  f(x): 1.6856777265942105e-09  grad at x: [-2.52609843e-06 -9.94844413e-06]  gradient norm: 1.0264147012341437e-05\n",
            "iter: 936393  x: [ 3.99995895 15.99967155]  f(x): 1.685626250721283e-09  grad at x: [ 7.95590749e-05 -2.02085794e-05]  gradient norm: 8.208552295346762e-05\n",
            "iter: 936394  x: [ 3.99995894 15.99967155]  f(x): 1.68557484359369e-09  grad at x: [-2.52683761e-06 -9.94803850e-06]  gradient norm: 1.0263935806139493e-05\n",
            "iter: 936395  x: [ 3.99995895 15.99967156]  f(x): 1.6855362716959892e-09  grad at x: [ 3.85410189e-05 -1.50812648e-05]  gradient norm: 4.138664865127884e-05\n",
            "iter: 936396  x: [ 3.99995895 15.99967156]  f(x): 1.685522604242092e-09  grad at x: [-1.88551584e-06 -1.00280431e-05]  gradient norm: 1.0203764920543901e-05\n",
            "iter: 936397  x: [ 3.99995895 15.99967159]  f(x): 1.6853156585858055e-09  grad at x: [ 1.59917291e-04 -3.02517601e-05]  gradient norm: 0.000162753521744956\n",
            "iter: 936398  x: [ 3.99995895 15.9996716 ]  f(x): 1.6851646780050362e-09  grad at x: [ 7.80671335e-05 -2.00206905e-05]  gradient norm: 8.059345743527685e-05\n",
            "iter: 936399  x: [ 3.99995895 15.9996716 ]  f(x): 1.6851150940107146e-09  grad at x: [-2.50332724e-06 -9.94957736e-06]  gradient norm: 1.025966553735278e-05\n",
            "iter: 936400  x: [ 3.99995895 15.99967161]  f(x): 1.6850618876542979e-09  grad at x: [ 7.81154203e-05 -2.00264130e-05]  gradient norm: 8.064165243710452e-05\n",
            "iter: 936401  x: [ 3.99995895 15.99967161]  f(x): 1.685012245334399e-09  grad at x: [-2.50405229e-06 -9.94917355e-06]  gradient norm: 1.0259450867792785e-05\n",
            "iter: 936402  x: [ 3.99995895 15.99967162]  f(x): 1.6849591043419757e-09  grad at x: [ 7.81643182e-05 -2.00322120e-05]  gradient norm: 8.069045890549022e-05\n",
            "iter: 936403  x: [ 3.99995895 15.99967162]  f(x): 1.684909402950899e-09  grad at x: [-2.50479197e-06 -9.94876791e-06]  gradient norm: 1.0259238068421877e-05\n",
            "iter: 936404  x: [ 3.99995896 15.99967163]  f(x): 1.6848563285224225e-09  grad at x: [ 7.82141765e-05 -2.00381310e-05]  gradient norm: 8.074022601911175e-05\n",
            "iter: 936405  x: [ 3.99995895 15.99967163]  f(x): 1.6848065668588136e-09  grad at x: [-2.50551717e-06 -9.94836410e-06]  gradient norm: 1.0259023562823723e-05\n",
            "iter: 936406  x: [ 3.99995896 15.99967164]  f(x): 1.6847535579018836e-09  grad at x: [ 7.82631034e-05 -2.00439335e-05]  gradient norm: 8.078906249916611e-05\n",
            "iter: 936407  x: [ 3.99995896 15.99967164]  f(x): 1.6847037370225116e-09  grad at x: [-2.50625700e-06 -9.94795846e-06]  gradient norm: 1.0258810929536675e-05\n",
            "iter: 936408  x: [ 3.99995896 15.99967165]  f(x): 1.684650794669016e-09  grad at x: [ 7.83129324e-05 -2.00498489e-05]  gradient norm: 8.083880144774152e-05\n",
            "iter: 936409  x: [ 3.99995896 15.99967165]  f(x): 1.6846009134593786e-09  grad at x: [-2.50699691e-06 -9.94755283e-06]  gradient norm: 1.0258598380120252e-05\n",
            "iter: 936410  x: [ 3.99995896 15.99967166]  f(x): 1.6845480378163618e-09  grad at x: [ 7.83628195e-05 -2.00557715e-05]  gradient norm: 8.088859906335158e-05\n",
            "iter: 936411  x: [ 3.99995896 15.99967166]  f(x): 1.6844980961691274e-09  grad at x: [-2.50773689e-06 -9.94714719e-06]  gradient norm: 1.0258385914162144e-05\n",
            "iter: 936412  x: [ 3.99995896 15.99967167]  f(x): 1.6844452872392973e-09  grad at x: [ 7.84126775e-05 -2.00616905e-05]  gradient norm: 8.093836804782325e-05\n",
            "iter: 936413  x: [ 3.99995896 15.99967167]  f(x): 1.6843952851514711e-09  grad at x: [-2.50847695e-06 -9.94674156e-06]  gradient norm: 1.0258173532118255e-05\n",
            "iter: 936414  x: [ 3.99995896 15.99967168]  f(x): 1.6843425429723142e-09  grad at x: [ 7.84625354e-05 -2.00676095e-05]  gradient norm: 8.098813750207376e-05\n",
            "iter: 936415  x: [ 3.99995896 15.99967168]  f(x): 1.684292480423791e-09  grad at x: [-2.50920254e-06 -9.94633774e-06]  gradient norm: 1.0257959437748513e-05\n",
            "iter: 936416  x: [ 3.99995896 15.99967169]  f(x): 1.684239803934247e-09  grad at x: [ 7.85114910e-05 -2.00734157e-05]  gradient norm: 8.10370053692353e-05\n",
            "iter: 936417  x: [ 3.99995896 15.99967169]  f(x): 1.68418968196813e-09  grad at x: [-2.50992820e-06 -9.94593393e-06]  gradient norm: 1.0257745425038903e-05\n",
            "iter: 936418  x: [ 3.99995896 15.9996717 ]  f(x): 1.6841370711694383e-09  grad at x: [ 7.85604174e-05 -2.00792183e-05]  gradient norm: 8.108584458399949e-05\n",
            "iter: 936419  x: [ 3.99995896 15.9996717 ]  f(x): 1.6840868897842017e-09  grad at x: [-2.51065394e-06 -9.94553011e-06]  gradient norm: 1.0257531493793543e-05\n",
            "iter: 936420  x: [ 3.99995897 15.99967171]  f(x): 1.6840343447473557e-09  grad at x: [ 7.86093728e-05 -2.00850245e-05]  gradient norm: 8.113471334508305e-05\n",
            "iter: 936421  x: [ 3.99995896 15.99967171]  f(x): 1.683984103889385e-09  grad at x: [-2.51136520e-06 -9.94512811e-06]  gradient norm: 1.0257315844593469e-05\n",
            "iter: 936422  x: [ 3.99995897 15.99967172]  f(x): 1.6839316234793386e-09  grad at x: [ 7.86573823e-05 -2.00907125e-05]  gradient norm: 8.118263682047889e-05\n",
            "iter: 936423  x: [ 3.99995897 15.99967172]  f(x): 1.6838813242480597e-09  grad at x: [-2.51209109e-06 -9.94472430e-06]  gradient norm: 1.0257102075201532e-05\n",
            "iter: 936424  x: [ 3.99995897 15.99967173]  f(x): 1.683828909706361e-09  grad at x: [ 7.87063667e-05 -2.00965223e-05]  gradient norm: 8.123153556159093e-05\n",
            "iter: 936425  x: [ 3.99995897 15.99967173]  f(x): 1.683778550877606e-09  grad at x: [-2.51281705e-06 -9.94432048e-06]  gradient norm: 1.0256888387337642e-05\n",
            "iter: 936426  x: [ 3.99995897 15.99967174]  f(x): 1.6837262022411592e-09  grad at x: [ 7.87553365e-05 -2.01023304e-05]  gradient norm: 8.128042019567939e-05\n",
            "iter: 936427  x: [ 3.99995897 15.99967174]  f(x): 1.683675783778853e-09  grad at x: [-2.51357220e-06 -9.94391303e-06]  gradient norm: 1.02566783863239e-05\n",
            "iter: 936428  x: [ 3.99995897 15.99967175]  f(x): 1.683623503358235e-09  grad at x: [ 7.88061834e-05 -2.01083731e-05]  gradient norm: 8.13311822432059e-05\n",
            "iter: 936429  x: [ 3.99995897 15.99967175]  f(x): 1.6835730229503982e-09  grad at x: [-2.51432742e-06 -9.94350557e-06]  gradient norm: 1.025646847152091e-05\n",
            "iter: 936430  x: [ 3.99995897 15.99967176]  f(x): 1.683520810749593e-09  grad at x: [ 7.88570011e-05 -2.01144121e-05]  gradient norm: 8.138191566959928e-05\n",
            "iter: 936431  x: [ 3.99995897 15.99967176]  f(x): 1.6834702684096172e-09  grad at x: [-2.51506817e-06 -9.94309994e-06]  gradient norm: 1.0256256838146435e-05\n",
            "iter: 936432  x: [ 3.99995897 15.99967177]  f(x): 1.6834181233635995e-09  grad at x: [ 7.89069165e-05 -2.01203384e-05]  gradient norm: 8.143174744738579e-05\n",
            "iter: 936433  x: [ 3.99995897 15.99967177]  f(x): 1.683367520138559e-09  grad at x: [-2.51580900e-06 -9.94269431e-06]  gradient norm: 1.0256045288468057e-05\n",
            "iter: 936434  x: [ 3.99995897 15.99967178]  f(x): 1.6833154422849025e-09  grad at x: [ 7.89568319e-05 -2.01262646e-05]  gradient norm: 8.148157968457489e-05\n",
            "iter: 936435  x: [ 3.99995897 15.99967178]  f(x): 1.6832647781545981e-09  grad at x: [-2.51653535e-06 -9.94229049e-06]  gradient norm: 1.0255832015620897e-05\n",
            "iter: 936436  x: [ 3.99995898 15.99967179]  f(x): 1.6832127663897691e-09  grad at x: [ 7.90058304e-05 -2.01320763e-05]  gradient norm: 8.153049568393738e-05\n",
            "iter: 936437  x: [ 3.99995897 15.99967179]  f(x): 1.6831620424221246e-09  grad at x: [-2.51727632e-06 -9.94188485e-06]  gradient norm: 1.0255620632674902e-05\n",
            "iter: 936438  x: [ 3.99995898 15.9996718 ]  f(x): 1.683110097924106e-09  grad at x: [ 7.90557455e-05 -2.01380026e-05]  gradient norm: 8.158032882940457e-05\n",
            "iter: 936439  x: [ 3.99995898 15.9996718 ]  f(x): 1.6830593129585132e-09  grad at x: [-2.51801738e-06 -9.94147922e-06]  gradient norm: 1.0255409333925912e-05\n",
            "iter: 936440  x: [ 3.99995898 15.99967181]  f(x): 1.683007435800009e-09  grad at x: [ 7.91056898e-05 -2.01439325e-05]  gradient norm: 8.163019153113881e-05\n",
            "iter: 936441  x: [ 3.99995898 15.99967181]  f(x): 1.6829565897634773e-09  grad at x: [-2.51875851e-06 -9.94107359e-06]  gradient norm: 1.0255198118959597e-05\n",
            "iter: 936442  x: [ 3.99995898 15.99967182]  f(x): 1.6829047800178978e-09  grad at x: [ 7.91556485e-05 -2.01498642e-05]  gradient norm: 8.168006924158862e-05\n",
            "iter: 936443  x: [ 3.99995898 15.99967182]  f(x): 1.6828538728367298e-09  grad at x: [-2.51949972e-06 -9.94066795e-06]  gradient norm: 1.0254986988233922e-05\n",
            "iter: 936444  x: [ 3.99995898 15.99967183]  f(x): 1.682802130470734e-09  grad at x: [ 7.92055634e-05 -2.01557905e-05]  gradient norm: 8.172990375258186e-05\n",
            "iter: 936445  x: [ 3.99995898 15.99967183]  f(x): 1.6827511621956413e-09  grad at x: [-2.52022645e-06 -9.94026414e-06]  gradient norm: 1.025477412844658e-05\n",
            "iter: 936446  x: [ 3.99995898 15.99967184]  f(x): 1.682699486137419e-09  grad at x: [ 7.92545906e-05 -2.01616058e-05]  gradient norm: 8.177885107707962e-05\n",
            "iter: 936447  x: [ 3.99995898 15.99967184]  f(x): 1.6826484578046094e-09  grad at x: [-2.52096781e-06 -9.93985850e-06]  gradient norm: 1.0254563164451657e-05\n",
            "iter: 936448  x: [ 3.99995898 15.99967185]  f(x): 1.68259684923566e-09  grad at x: [ 7.93045345e-05 -2.01675357e-05]  gradient norm: 8.182871558969652e-05\n",
            "iter: 936449  x: [ 3.99995898 15.99967185]  f(x): 1.6825457596810055e-09  grad at x: [-2.52170924e-06 -9.93945287e-06]  gradient norm: 1.0254352284762702e-05\n",
            "iter: 936450  x: [ 3.99995898 15.99967186]  f(x): 1.6824942186389455e-09  grad at x: [ 7.93544784e-05 -2.01734656e-05]  gradient norm: 8.187858055281648e-05\n",
            "iter: 936451  x: [ 3.99995898 15.99967186]  f(x): 1.6824430678245426e-09  grad at x: [-2.52245075e-06 -9.93904723e-06]  gradient norm: 1.0254141488964707e-05\n",
            "iter: 936452  x: [ 3.99995899 15.99967187]  f(x): 1.6823915943822518e-09  grad at x: [ 7.94044512e-05 -2.01793991e-05]  gradient norm: 8.192847507217961e-05\n",
            "iter: 936453  x: [ 3.99995898 15.99967187]  f(x): 1.6823403822349337e-09  grad at x: [-2.52319234e-06 -9.93864160e-06]  gradient norm: 1.0253930777516332e-05\n",
            "iter: 936454  x: [ 3.99995899 15.99967188]  f(x): 1.682288976465929e-09  grad at x: [ 7.94544386e-05 -2.01853345e-05]  gradient norm: 8.197838459419821e-05\n",
            "iter: 936455  x: [ 3.99995899 15.99967188]  f(x): 1.6822377029130128e-09  grad at x: [-2.52396311e-06 -9.93823232e-06]  gradient norm: 1.0253723788069292e-05\n",
            "iter: 936456  x: [ 3.99995899 15.99967188]  f(x): 1.6821992003018754e-09  grad at x: [ 3.84911554e-05 -1.50648666e-05]  gradient norm: 4.133423824877171e-05\n",
            "iter: 936457  x: [ 3.99995899 15.99967188]  f(x): 1.6821855670029293e-09  grad at x: [-1.88347207e-06 -1.00181333e-05]  gradient norm: 1.0193648067517023e-05\n",
            "iter: 936458  x: [ 3.99995899 15.99967192]  f(x): 1.6819789188615918e-09  grad at x: [ 1.59713238e-04 -3.02160897e-05]  gradient norm: 0.00016254639481882971\n",
            "iter: 936459  x: [ 3.99995899 15.99967192]  f(x): 1.681828322189048e-09  grad at x: [ 7.79673174e-05 -1.99980495e-05]  gradient norm: 8.049114591684798e-05\n",
            "iter: 936460  x: [ 3.99995899 15.99967192]  f(x): 1.6817788635536838e-09  grad at x: [-2.50052204e-06 -9.93976391e-06]  gradient norm: 1.0249464236418919e-05\n",
            "iter: 936461  x: [ 3.99995899 15.99967193]  f(x): 1.681725737294014e-09  grad at x: [ 7.80171879e-05 -2.00039703e-05]  gradient norm: 8.054092401747407e-05\n",
            "iter: 936462  x: [ 3.99995899 15.99967193]  f(x): 1.6816762185038656e-09  grad at x: [-2.50124957e-06 -9.93936010e-06]  gradient norm: 1.0249250147002021e-05\n",
            "iter: 936463  x: [ 3.99995899 15.99967194]  f(x): 1.6816231577654138e-09  grad at x: [ 7.80662725e-05 -2.00097929e-05]  gradient norm: 8.058991699471647e-05\n",
            "iter: 936464  x: [ 3.99995899 15.99967194]  f(x): 1.6815735797375245e-09  grad at x: [-2.50199173e-06 -9.93895446e-06]  gradient norm: 1.0249037927756403e-05\n",
            "iter: 936465  x: [ 3.999959   15.99967195]  f(x): 1.6815205856132695e-09  grad at x: [ 7.81162593e-05 -2.00157283e-05]  gradient norm: 8.063981242246852e-05\n",
            "iter: 936466  x: [ 3.99995899 15.99967195]  f(x): 1.6814709472168415e-09  grad at x: [-2.50271942e-06 -9.93855065e-06]  gradient norm: 1.0248824002961095e-05\n",
            "iter: 936467  x: [ 3.999959   15.99967196]  f(x): 1.6814180186515552e-09  grad at x: [ 7.81653292e-05 -2.00215491e-05]  gradient norm: 8.068879177562932e-05\n",
            "iter: 936468  x: [ 3.999959   15.99967196]  f(x): 1.6813683209602964e-09  grad at x: [-2.50344718e-06 -9.93814683e-06]  gradient norm: 1.0248610159937702e-05\n",
            "iter: 936469  x: [ 3.999959   15.99967197]  f(x): 1.6813154580250124e-09  grad at x: [ 7.82144282e-05 -2.00273735e-05]  gradient norm: 8.07378006810495e-05\n",
            "iter: 936470  x: [ 3.999959   15.99967197]  f(x): 1.6812657009676024e-09  grad at x: [-2.50417501e-06 -9.93774302e-06]  gradient norm: 1.0248396398490591e-05\n",
            "iter: 936471  x: [ 3.999959   15.99967198]  f(x): 1.6812129036639065e-09  grad at x: [ 7.82634979e-05 -2.00331942e-05]  gradient norm: 8.078678094306172e-05\n",
            "iter: 936472  x: [ 3.999959   15.99967198]  f(x): 1.681163087256125e-09  grad at x: [-2.50488837e-06 -9.93734102e-06]  gradient norm: 1.0248180926063159e-05\n",
            "iter: 936473  x: [ 3.999959   15.99967199]  f(x): 1.6811103545245362e-09  grad at x: [ 7.83116653e-05 -2.00389022e-05]  gradient norm: 8.083485962732906e-05\n",
            "iter: 936474  x: [ 3.999959   15.99967199]  f(x): 1.6810604797902721e-09  grad at x: [-2.50561636e-06 -9.93693720e-06]  gradient norm: 1.024796732734102e-05\n",
            "iter: 936475  x: [ 3.999959 15.999672]  f(x): 1.681007812796993e-09  grad at x: [ 7.83607640e-05 -2.00447266e-05]  gradient norm: 8.08838698857738e-05\n",
            "iter: 936476  x: [ 3.999959 15.999672]  f(x): 1.68095787858741e-09  grad at x: [-2.50634443e-06 -9.93653339e-06]  gradient norm: 1.0247753810476227e-05\n",
            "iter: 936477  x: [ 3.999959   15.99967201]  f(x): 1.680905277368783e-09  grad at x: [ 7.84098627e-05 -2.00505510e-05]  gradient norm: 8.09328805965925e-05\n",
            "iter: 936478  x: [ 3.999959   15.99967201]  f(x): 1.680855283647252e-09  grad at x: [-2.50707257e-06 -9.93612957e-06]  gradient norm: 1.0247540375490179e-05\n",
            "iter: 936479  x: [ 3.999959   15.99967202]  f(x): 1.6808027482396187e-09  grad at x: [ 7.84589612e-05 -2.00563754e-05]  gradient norm: 8.098189175882492e-05\n",
            "iter: 936480  x: [ 3.999959   15.99967202]  f(x): 1.680752694987161e-09  grad at x: [-2.50778623e-06 -9.93572758e-06]  gradient norm: 1.0247325224623643e-05\n",
            "iter: 936481  x: [ 3.99995901 15.99967203]  f(x): 1.6807002242578925e-09  grad at x: [ 7.85071138e-05 -2.00620816e-05]  gradient norm: 8.10299576540769e-05\n",
            "iter: 936482  x: [ 3.999959   15.99967203]  f(x): 1.6806501125715505e-09  grad at x: [-2.50851453e-06 -9.93532376e-06]  gradient norm: 1.024711195231587e-05\n",
            "iter: 936483  x: [ 3.99995901 15.99967204]  f(x): 1.6805977077957857e-09  grad at x: [ 7.85562559e-05 -2.00679115e-05]  gradient norm: 8.107901335644158e-05\n",
            "iter: 936484  x: [ 3.99995901 15.99967204]  f(x): 1.6805475364177839e-09  grad at x: [-2.50924290e-06 -9.93491994e-06]  gradient norm: 1.02468987619509e-05\n",
            "iter: 936485  x: [ 3.99995901 15.99967205]  f(x): 1.6804951975613618e-09  grad at x: [ 7.86053542e-05 -2.00737359e-05]  gradient norm: 8.112802585802946e-05\n",
            "iter: 936486  x: [ 3.99995901 15.99967205]  f(x): 1.680444966525575e-09  grad at x: [-2.50997135e-06 -9.93451613e-06]  gradient norm: 1.0246685653550138e-05\n",
            "iter: 936487  x: [ 3.99995901 15.99967206]  f(x): 1.6803926936597667e-09  grad at x: [ 7.86544815e-05 -2.00795639e-05]  gradient norm: 8.117706790652827e-05\n",
            "iter: 936488  x: [ 3.99995901 15.99967206]  f(x): 1.680342402912283e-09  grad at x: [-2.51068532e-06 -9.93411413e-06]  gradient norm: 1.0246470825018162e-05\n",
            "iter: 936489  x: [ 3.99995901 15.99967207]  f(x): 1.6802901949016858e-09  grad at x: [ 7.87026629e-05 -2.00852737e-05]  gradient norm: 8.122516464839664e-05\n",
            "iter: 936490  x: [ 3.99995901 15.99967207]  f(x): 1.680239845542328e-09  grad at x: [-2.51141392e-06 -9.93371032e-06]  gradient norm: 1.0246257879248422e-05\n",
            "iter: 936491  x: [ 3.99995901 15.99967208]  f(x): 1.6801877036650682e-09  grad at x: [ 7.87518338e-05 -2.00911072e-05]  gradient norm: 8.127425123072995e-05\n",
            "iter: 936492  x: [ 3.99995901 15.99967208]  f(x): 1.6801372944330703e-09  grad at x: [-2.5121426e-06 -9.9333065e-06]  gradient norm: 1.0246045015724597e-05\n",
            "iter: 936493  x: [ 3.99995901 15.99967209]  f(x): 1.6800852186549017e-09  grad at x: [ 7.88009609e-05 -2.00969353e-05]  gradient norm: 8.132329461077827e-05\n",
            "iter: 936494  x: [ 3.99995901 15.99967209]  f(x): 1.6800347495842234e-09  grad at x: [-2.51287135e-06 -9.93290269e-06]  gradient norm: 1.0245832234250469e-05\n",
            "iter: 936495  x: [ 3.99995901 15.9996721 ]  f(x): 1.6799827399765476e-09  grad at x: [ 7.88501171e-05 -2.01027669e-05]  gradient norm: 8.137236753400308e-05\n",
            "iter: 936496  x: [ 3.99995901 15.9996721 ]  f(x): 1.679932211013144e-09  grad at x: [-2.51358563e-06 -9.93250069e-06]  gradient norm: 1.0245617728174793e-05\n",
            "iter: 936497  x: [ 3.99995902 15.99967211]  f(x): 1.6798802664027433e-09  grad at x: [ 7.88982981e-05 -2.01084767e-05]  gradient norm: 8.142046600875648e-05\n",
            "iter: 936498  x: [ 3.99995901 15.99967211]  f(x): 1.679829678666615e-09  grad at x: [-2.51432908e-06 -9.93209505e-06]  gradient norm: 1.0245406917318974e-05\n",
            "iter: 936499  x: [ 3.99995902 15.99967212]  f(x): 1.6797778014741457e-09  grad at x: [ 7.89484000e-05 -2.01144267e-05]  gradient norm: 8.147048561412564e-05\n",
            "iter: 936500  x: [ 3.99995902 15.99967212]  f(x): 1.6797271525796383e-09  grad at x: [-2.51507262e-06 -9.93168942e-06]  gradient norm: 1.0245196191104757e-05\n",
            "iter: 936501  x: [ 3.99995902 15.99967213]  f(x): 1.679675342807217e-09  grad at x: [ 7.89984873e-05 -2.01203748e-05]  gradient norm: 8.152049112840745e-05\n",
            "iter: 936502  x: [ 3.99995902 15.99967213]  f(x): 1.6796246327519271e-09  grad at x: [-2.51581623e-06 -9.93128378e-06]  gradient norm: 1.0244985549117977e-05\n",
            "iter: 936503  x: [ 3.99995902 15.99967214]  f(x): 1.6795728904373896e-09  grad at x: [ 7.90485745e-05 -2.01263229e-05]  gradient norm: 8.157049710271136e-05\n",
            "iter: 936504  x: [ 3.99995902 15.99967214]  f(x): 1.6795221192008361e-09  grad at x: [-2.51654536e-06 -9.93087997e-06]  gradient norm: 1.024477318050319e-05\n",
            "iter: 936505  x: [ 3.99995902 15.99967215]  f(x): 1.679470443239666e-09  grad at x: [ 7.90977448e-05 -2.01321564e-05]  gradient norm: 8.16195868096008e-05\n",
            "iter: 936506  x: [ 3.99995902 15.99967215]  f(x): 1.679419611890796e-09  grad at x: [-2.51728913e-06 -9.93047433e-06]  gradient norm: 1.0244562706525343e-05\n",
            "iter: 936507  x: [ 3.99995902 15.99967216]  f(x): 1.679368003498254e-09  grad at x: [ 7.91478464e-05 -2.01381063e-05]  gradient norm: 8.166960824282394e-05\n",
            "iter: 936508  x: [ 3.99995902 15.99967216]  f(x): 1.6793171108391616e-09  grad at x: [-2.51803296e-06 -9.93006870e-06]  gradient norm: 1.0244352316840116e-05\n",
            "iter: 936509  x: [ 3.99995902 15.99967217]  f(x): 1.6792655700524933e-09  grad at x: [ 7.91979624e-05 -2.01440580e-05]  gradient norm: 8.171964468641187e-05\n",
            "iter: 936510  x: [ 3.99995902 15.99967217]  f(x): 1.6792146160632853e-09  grad at x: [-2.51876233e-06 -9.92966488e-06]  gradient norm: 1.0244140197115577e-05\n",
            "iter: 936511  x: [ 3.99995902 15.99967218]  f(x): 1.6791631417407383e-09  grad at x: [ 7.92471325e-05 -2.01498915e-05]  gradient norm: 8.176873572634487e-05\n",
            "iter: 936512  x: [ 3.99995902 15.99967218]  f(x): 1.6791121275276024e-09  grad at x: [-2.51950632e-06 -9.92925925e-06]  gradient norm: 1.0243929975569853e-05\n",
            "iter: 936513  x: [ 3.99995903 15.99967219]  f(x): 1.679060720885966e-09  grad at x: [ 7.92972484e-05 -2.01558432e-05]  gradient norm: 8.181877307281797e-05\n",
            "iter: 936514  x: [ 3.99995902 15.99967219]  f(x): 1.6790096452494658e-09  grad at x: [-2.52025039e-06 -9.92885361e-06]  gradient norm: 1.024371983838194e-05\n",
            "iter: 936515  x: [ 3.99995903 15.9996722 ]  f(x): 1.6789583063624343e-09  grad at x: [ 7.93473788e-05 -2.01617968e-05]  gradient norm: 8.186882542574919e-05\n",
            "iter: 936516  x: [ 3.99995903 15.9996722 ]  f(x): 1.678907169228589e-09  grad at x: [-2.52099453e-06 -9.92844798e-06]  gradient norm: 1.0243509786010658e-05\n",
            "iter: 936517  x: [ 3.99995903 15.99967221]  f(x): 1.6788558980976724e-09  grad at x: [ 7.93975091e-05 -2.01677503e-05]  gradient norm: 8.191887823275916e-05\n",
            "iter: 936518  x: [ 3.99995903 15.99967221]  f(x): 1.6788046994470495e-09  grad at x: [-2.52175331e-06 -9.92804053e-06]  gradient norm: 1.0243301637715148e-05\n",
            "iter: 936519  x: [ 3.99995903 15.99967222]  f(x): 1.6787662823870885e-09  grad at x: [ 3.84634014e-05 -1.50509295e-05]  gradient norm: 4.130331375629205e-05\n",
            "iter: 936520  x: [ 3.99995903 15.99967222]  f(x): 1.678752669905367e-09  grad at x: [-1.88172923e-06 -1.00078832e-05]  gradient norm: 1.0183252524962772e-05\n",
            "iter: 936521  x: [ 3.99995904 15.99967226]  f(x): 1.6785465578623462e-09  grad at x: [ 1.59596794e-04 -3.01910677e-05]  gradient norm: 0.00016242732907485342\n",
            "iter: 936522  x: [ 3.99995903 15.99967226]  f(x): 1.678396181855063e-09  grad at x: [ 7.79106676e-05 -1.99805017e-05]  gradient norm: 8.04319126463828e-05\n",
            "iter: 936523  x: [ 3.99995903 15.99967226]  f(x): 1.678346796449448e-09  grad at x: [-2.49830911e-06 -9.92957393e-06]  gradient norm: 1.0239042284995554e-05\n",
            "iter: 936524  x: [ 3.99995904 15.99967227]  f(x): 1.6782938049292023e-09  grad at x: [ 7.79593131e-05 -1.99862698e-05]  gradient norm: 8.048046647672712e-05\n",
            "iter: 936525  x: [ 3.99995903 15.99967227]  f(x): 1.6782443608710207e-09  grad at x: [-2.49906830e-06 -9.92916648e-06]  gradient norm: 1.0238832421584991e-05\n",
            "iter: 936526  x: [ 3.99995904 15.99967228]  f(x): 1.6781914372053601e-09  grad at x: [ 7.80103888e-05 -1.99923415e-05]  gradient norm: 8.053145030992636e-05\n",
            "iter: 936527  x: [ 3.99995904 15.99967228]  f(x): 1.6781419315653527e-09  grad at x: [-2.49981301e-06 -9.92876085e-06]  gradient norm: 1.0238620856250723e-05\n",
            "iter: 936528  x: [ 3.99995904 15.99967229]  f(x): 1.678089074665807e-09  grad at x: [ 7.80605477e-05 -1.99982987e-05]  gradient norm: 8.058151809432233e-05\n",
            "iter: 936529  x: [ 3.99995904 15.99967229]  f(x): 1.6780395084957723e-09  grad at x: [-2.50054325e-06 -9.92835703e-06]  gradient norm: 1.0238407585078656e-05\n",
            "iter: 936530  x: [ 3.99995904 15.9996723 ]  f(x): 1.6779867173436877e-09  grad at x: [ 7.81098042e-05 -2.00041432e-05]  gradient norm: 8.063068434984652e-05\n",
            "iter: 936531  x: [ 3.99995904 15.9996723 ]  f(x): 1.6779370916983759e-09  grad at x: [-2.50125901e-06 -9.92795503e-06]  gradient norm: 1.0238192604866354e-05\n",
            "iter: 936532  x: [ 3.99995904 15.99967231]  f(x): 1.6778843651308816e-09  grad at x: [ 7.81581002e-05 -2.00098675e-05]  gradient norm: 8.067889085397651e-05\n",
            "iter: 936533  x: [ 3.99995904 15.99967231]  f(x): 1.6778346811376045e-09  grad at x: [-2.50198941e-06 -9.92755122e-06]  gradient norm: 1.0237979497028657e-05\n",
            "iter: 936534  x: [ 3.99995904 15.99967232]  f(x): 1.6777820203544523e-09  grad at x: [ 7.82073421e-05 -2.00157101e-05]  gradient norm: 8.072804346908246e-05\n",
            "iter: 936535  x: [ 3.99995904 15.99967232]  f(x): 1.6777322768131746e-09  grad at x: [-2.50273443e-06 -9.92714558e-06]  gradient norm: 1.0237768264811484e-05\n",
            "iter: 936536  x: [ 3.99995904 15.99967233]  f(x): 1.6776796830162444e-09  grad at x: [ 7.82575297e-05 -2.00216709e-05]  gradient norm: 8.077814222513551e-05\n",
            "iter: 936537  x: [ 3.99995904 15.99967233]  f(x): 1.6776298787600685e-09  grad at x: [-2.50346497e-06 -9.92674177e-06]  gradient norm: 1.02375553226884e-05\n",
            "iter: 936538  x: [ 3.99995904 15.99967234]  f(x): 1.6775773508205035e-09  grad at x: [ 7.83067859e-05 -2.00275153e-05]  gradient norm: 8.082731031233205e-05\n",
            "iter: 936539  x: [ 3.99995904 15.99967234]  f(x): 1.6775274869427323e-09  grad at x: [-2.50421014e-06 -9.92633613e-06]  gradient norm: 1.0237344258761852e-05\n",
            "iter: 936540  x: [ 3.99995905 15.99967235]  f(x): 1.67747502602907e-09  grad at x: [ 7.83569589e-05 -2.00334744e-05]  gradient norm: 8.087739546040508e-05\n",
            "iter: 936541  x: [ 3.99995904 15.99967235]  f(x): 1.6774251013785132e-09  grad at x: [-2.50495539e-06 -9.92593050e-06]  gradient norm: 1.0237133279271639e-05\n",
            "iter: 936542  x: [ 3.99995905 15.99967236]  f(x): 1.6773727075991391e-09  grad at x: [ 7.84071754e-05 -2.00394388e-05]  gradient norm: 8.0927524731167e-05\n",
            "iter: 936543  x: [ 3.99995905 15.99967236]  f(x): 1.6773227220847568e-09  grad at x: [-2.50568616e-06 -9.92552668e-06]  gradient norm: 1.0236920586456678e-05\n",
            "iter: 936544  x: [ 3.99995905 15.99967237]  f(x): 1.6772703942738944e-09  grad at x: [ 7.84564314e-05 -2.00452832e-05]  gradient norm: 8.09766942013994e-05\n",
            "iter: 936545  x: [ 3.99995905 15.99967237]  f(x): 1.6772203490071699e-09  grad at x: [-2.50641701e-06 -9.92512287e-06]  gradient norm: 1.0236707975804983e-05\n",
            "iter: 936546  x: [ 3.99995905 15.99967238]  f(x): 1.6771680872370187e-09  grad at x: [ 7.85057018e-05 -2.00511295e-05]  gradient norm: 8.102587867716959e-05\n",
            "iter: 936547  x: [ 3.99995905 15.99967238]  f(x): 1.6771179821818419e-09  grad at x: [-2.50714794e-06 -9.92471905e-06]  gradient norm: 1.0236495447555378e-05\n",
            "iter: 936548  x: [ 3.99995905 15.99967239]  f(x): 1.6770657865595165e-09  grad at x: [ 7.85550159e-05 -2.00569812e-05]  gradient norm: 8.107510725197053e-05\n",
            "iter: 936549  x: [ 3.99995905 15.99967239]  f(x): 1.677015621627229e-09  grad at x: [-2.50789349e-06 -9.92431342e-06]  gradient norm: 1.023628480360909e-05\n",
            "iter: 936550  x: [ 3.99995905 15.9996724 ]  f(x): 1.6769634932178988e-09  grad at x: [ 7.8605203e-05 -2.0062942e-05]  gradient norm: 8.112520928009547e-05\n",
            "iter: 936551  x: [ 3.99995905 15.9996724 ]  f(x): 1.6769132673055597e-09  grad at x: [-2.50862457e-06 -9.92390960e-06]  gradient norm: 1.023607244115901e-05\n",
            "iter: 936552  x: [ 3.99995905 15.99967241]  f(x): 1.6768612050823916e-09  grad at x: [ 7.86545024e-05 -2.00687919e-05]  gradient norm: 8.117442421845597e-05\n",
            "iter: 936553  x: [ 3.99995905 15.99967241]  f(x): 1.6768109192352904e-09  grad at x: [-2.50935573e-06 -9.92350579e-06]  gradient norm: 1.0235860161393257e-05\n",
            "iter: 936554  x: [ 3.99995905 15.99967242]  f(x): 1.6767589232349272e-09  grad at x: [ 7.87038016e-05 -2.00746417e-05]  gradient norm: 8.122363960650001e-05\n",
            "iter: 936555  x: [ 3.99995905 15.99967242]  f(x): 1.6767085773985078e-09  grad at x: [-2.51010151e-06 -9.92310015e-06]  gradient norm: 1.0235649769244355e-05\n",
            "iter: 936556  x: [ 3.99995906 15.99967243]  f(x): 1.6766566487943984e-09  grad at x: [ 7.87540322e-05 -2.00806080e-05]  gradient norm: 8.127378667206769e-05\n",
            "iter: 936557  x: [ 3.99995905 15.99967243]  f(x): 1.6766062418125538e-09  grad at x: [-2.51084737e-06 -9.92269452e-06]  gradient norm: 1.0235439461923641e-05\n",
            "iter: 936558  x: [ 3.99995906 15.99967244]  f(x): 1.6765543806427541e-09  grad at x: [ 7.88042626e-05 -2.00865743e-05]  gradient norm: 8.132393420435906e-05\n",
            "iter: 936559  x: [ 3.99995906 15.99967244]  f(x): 1.6765039124947676e-09  grad at x: [-2.51157875e-06 -9.92229070e-06]  gradient norm: 1.0235227431767168e-05\n",
            "iter: 936560  x: [ 3.99995906 15.99967245]  f(x): 1.6764521176591013e-09  grad at x: [ 7.88535617e-05 -2.00924242e-05]  gradient norm: 8.137315095447305e-05\n",
            "iter: 936561  x: [ 3.99995906 15.99967245]  f(x): 1.6764015893919862e-09  grad at x: [-2.51233932e-06 -9.92188325e-06]  gradient norm: 1.0235019101636476e-05\n",
            "iter: 936562  x: [ 3.99995906 15.99967246]  f(x): 1.6763498632400142e-09  grad at x: [ 7.89047524e-05 -2.00985105e-05]  gradient norm: 8.142425976807857e-05\n",
            "iter: 936563  x: [ 3.99995906 15.99967246]  f(x): 1.6762992725568005e-09  grad at x: [-2.51308540e-06 -9.92147761e-06]  gradient norm: 1.023480904893183e-05\n",
            "iter: 936564  x: [ 3.99995906 15.99967247]  f(x): 1.676247613917614e-09  grad at x: [ 7.89549681e-05 -2.01044750e-05]  gradient norm: 8.147439414404389e-05\n",
            "iter: 936565  x: [ 3.99995906 15.99967247]  f(x): 1.6761969619525584e-09  grad at x: [-2.51381702e-06 -9.92107380e-06]  gradient norm: 1.0234597269946997e-05\n",
            "iter: 936566  x: [ 3.99995906 15.99967248]  f(x): 1.6761453698303543e-09  grad at x: [ 7.90043106e-05 -2.01103303e-05]  gradient norm: 8.152365591143653e-05\n",
            "iter: 936567  x: [ 3.99995906 15.99967248]  f(x): 1.6760946575977143e-09  grad at x: [-2.51454870e-06 -9.92066998e-06]  gradient norm: 1.0234385573361763e-05\n",
            "iter: 936568  x: [ 3.99995906 15.99967249]  f(x): 1.6760431319934654e-09  grad at x: [ 7.90536384e-05 -2.01161838e-05]  gradient norm: 8.157290356986502e-05\n",
            "iter: 936569  x: [ 3.99995906 15.99967249]  f(x): 1.675992359491982e-09  grad at x: [-2.51528047e-06 -9.92026617e-06]  gradient norm: 1.0234173959634013e-05\n",
            "iter: 936570  x: [ 3.99995906 15.9996725 ]  f(x): 1.6759409004423737e-09  grad at x: [ 7.91029662e-05 -2.01220373e-05]  gradient norm: 8.162215167260908e-05\n",
            "iter: 936571  x: [ 3.99995906 15.9996725 ]  f(x): 1.6758900676174535e-09  grad at x: [-2.51602686e-06 -9.91986053e-06]  gradient norm: 1.0233964242994254e-05\n",
            "iter: 936572  x: [ 3.99995907 15.99967251]  f(x): 1.6758386763367963e-09  grad at x: [ 7.91532543e-05 -2.01280109e-05]  gradient norm: 8.167236062402757e-05\n",
            "iter: 936573  x: [ 3.99995906 15.99967251]  f(x): 1.675787782009086e-09  grad at x: [-2.51675878e-06 -9.91945672e-06]  gradient norm: 1.0233752795759724e-05\n",
            "iter: 936574  x: [ 3.99995907 15.99967252]  f(x): 1.6757364573213977e-09  grad at x: [ 7.92025674e-05 -2.01338626e-05]  gradient norm: 8.172159506718395e-05\n",
            "iter: 936575  x: [ 3.99995907 15.99967252]  f(x): 1.6756855026126138e-09  grad at x: [-2.51749077e-06 -9.91905290e-06]  gradient norm: 1.0233541431010711e-05\n",
            "iter: 936576  x: [ 3.99995907 15.99967253]  f(x): 1.6756342446613073e-09  grad at x: [ 7.92519386e-05 -2.01397215e-05]  gradient norm: 8.177088815642175e-05\n",
            "iter: 936577  x: [ 3.99995907 15.99967253]  f(x): 1.6755832294652286e-09  grad at x: [-2.51825195e-06 -9.91864545e-06]  gradient norm: 1.023333378480441e-05\n",
            "iter: 936578  x: [ 3.99995907 15.99967254]  f(x): 1.675532040540455e-09  grad at x: [ 7.93031578e-05 -2.01458115e-05]  gradient norm: 8.182202979984044e-05\n",
            "iter: 936579  x: [ 3.99995907 15.99967254]  f(x): 1.6754809625831445e-09  grad at x: [-2.51899864e-06 -9.91823981e-06]  gradient norm: 1.0233124407137356e-05\n",
            "iter: 936580  x: [ 3.99995907 15.99967254]  f(x): 1.6754426166781966e-09  grad at x: [ 3.84172017e-05 -1.50350097e-05]  gradient norm: 4.12544894570074e-05\n",
            "iter: 936581  x: [ 3.99995907 15.99967254]  f(x): 1.6754290360593812e-09  grad at x: [-1.87974709e-06 -9.99798613e-06]  gradient norm: 1.0173159572217697e-05\n",
            "iter: 936582  x: [ 3.99995908 15.99967258]  f(x): 1.6752232569016e-09  grad at x: [ 1.59408061e-04 -3.01573327e-05]  gradient norm: 0.00016223561496271443\n",
            "iter: 936583  x: [ 3.99995907 15.99967258]  f(x): 1.675073235583949e-09  grad at x: [ 7.78184007e-05 -1.99588249e-05]  gradient norm: 8.033715313806264e-05\n",
            "iter: 936584  x: [ 3.99995907 15.99967258]  f(x): 1.6750239661746282e-09  grad at x: [-2.49560917e-06 -9.91976776e-06]  gradient norm: 1.0228873720822838e-05\n",
            "iter: 936585  x: [ 3.99995908 15.99967259]  f(x): 1.674971062106758e-09  grad at x: [ 7.78676550e-05 -1.99646693e-05]  gradient norm: 8.038631543160874e-05\n",
            "iter: 936586  x: [ 3.99995907 15.99967259]  f(x): 1.6749217334074015e-09  grad at x: [-2.49632718e-06 -9.91936577e-06]  gradient norm: 1.022865908093893e-05\n",
            "iter: 936587  x: [ 3.99995908 15.9996726 ]  f(x): 1.6748688939779916e-09  grad at x: [ 7.79161234e-05 -1.99704155e-05]  gradient norm: 8.04346925869373e-05\n",
            "iter: 936588  x: [ 3.99995908 15.9996726 ]  f(x): 1.674819506887116e-09  grad at x: [-2.49707437e-06 -9.91896013e-06]  gradient norm: 1.0228448098800484e-05\n",
            "iter: 936589  x: [ 3.99995908 15.99967261]  f(x): 1.6747667343117978e-09  grad at x: [ 7.79664252e-05 -1.99763908e-05]  gradient norm: 8.04849032789639e-05\n",
            "iter: 936590  x: [ 3.99995908 15.99967261]  f(x): 1.674717286593649e-09  grad at x: [-2.49780709e-06 -9.91855632e-06]  gradient norm: 1.0228235411642675e-05\n",
            "iter: 936591  x: [ 3.99995908 15.99967262]  f(x): 1.6746645798552639e-09  grad at x: [ 7.80158248e-05 -1.99822534e-05]  gradient norm: 8.053421244725836e-05\n",
            "iter: 936592  x: [ 3.99995908 15.99967262]  f(x): 1.6746150725454437e-09  grad at x: [-2.49853988e-06 -9.91815250e-06]  gradient norm: 1.0228022807154771e-05\n",
            "iter: 936593  x: [ 3.99995908 15.99967263]  f(x): 1.674562431645279e-09  grad at x: [ 7.80652098e-05 -1.99881142e-05]  gradient norm: 8.05835075304718e-05\n",
            "iter: 936594  x: [ 3.99995908 15.99967263]  f(x): 1.6745128647422134e-09  grad at x: [-2.49927275e-06 -9.91774868e-06]  gradient norm: 1.0227810285358345e-05\n",
            "iter: 936595  x: [ 3.99995908 15.99967264]  f(x): 1.6744602897162165e-09  grad at x: [ 7.81146092e-05 -1.99939768e-05]  gradient norm: 8.06328176241488e-05\n",
            "iter: 936596  x: [ 3.99995908 15.99967264]  f(x): 1.6744106631660554e-09  grad at x: [-2.50002024e-06 -9.91734305e-06]  gradient norm: 1.0227599639287508e-05\n",
            "iter: 936597  x: [ 3.99995908 15.99967265]  f(x): 1.6743581552505002e-09  grad at x: [ 7.81649690e-05 -1.99999595e-05]  gradient norm: 8.068308840860457e-05\n",
            "iter: 936598  x: [ 3.99995908 15.99967265]  f(x): 1.674308467851918e-09  grad at x: [-2.50075326e-06 -9.91693923e-06]  gradient norm: 1.0227387284090721e-05\n",
            "iter: 936599  x: [ 3.99995908 15.99967266]  f(x): 1.6742560258848437e-09  grad at x: [ 7.82143683e-05 -2.00058221e-05]  gradient norm: 8.073239943548484e-05\n",
            "iter: 936600  x: [ 3.99995908 15.99967266]  f(x): 1.6742062787455561e-09  grad at x: [-2.50148636e-06 -9.91653542e-06]  gradient norm: 1.0227175011433043e-05\n",
            "iter: 936601  x: [ 3.99995909 15.99967267]  f(x): 1.6741539028348564e-09  grad at x: [ 7.82637966e-05 -2.00116883e-05]  gradient norm: 8.078174001955411e-05\n",
            "iter: 936602  x: [ 3.99995908 15.99967267]  f(x): 1.6741040959017524e-09  grad at x: [-2.50223408e-06 -9.91612978e-06]  gradient norm: 1.0226964618477316e-05\n",
            "iter: 936603  x: [ 3.99995909 15.99967268]  f(x): 1.6740517871436874e-09  grad at x: [ 7.83141270e-05 -2.00176673e-05]  gradient norm: 8.083198312375718e-05\n",
            "iter: 936604  x: [ 3.99995909 15.99967268]  f(x): 1.6740019192827696e-09  grad at x: [-2.50296733e-06 -9.91572597e-06]  gradient norm: 1.022675251254932e-05\n",
            "iter: 936605  x: [ 3.99995909 15.99967269]  f(x): 1.6739496766554338e-09  grad at x: [ 7.83635552e-05 -2.00235336e-05]  gradient norm: 8.088132463392798e-05\n",
            "iter: 936606  x: [ 3.99995909 15.99967269]  f(x): 1.6738997489070472e-09  grad at x: [-2.50370066e-06 -9.91532215e-06]  gradient norm: 1.022654048944242e-05\n",
            "iter: 936607  x: [ 3.99995909 15.9996727 ]  f(x): 1.6738475724109417e-09  grad at x: [ 7.84129832e-05 -2.00293998e-05]  gradient norm: 8.093066660275935e-05\n",
            "iter: 936608  x: [ 3.99995909 15.9996727 ]  f(x): 1.6737975847566871e-09  grad at x: [-2.50444861e-06 -9.91491652e-06]  gradient norm: 1.022633034914602e-05\n",
            "iter: 936609  x: [ 3.99995909 15.99967271]  f(x): 1.6737454756324906e-09  grad at x: [ 7.84633717e-05 -2.00353861e-05]  gradient norm: 8.098096931311273e-05\n",
            "iter: 936610  x: [ 3.99995909 15.99967271]  f(x): 1.6736954268490166e-09  grad at x: [-2.50519664e-06 -9.91451088e-06]  gradient norm: 1.0226120294257796e-05\n",
            "iter: 936611  x: [ 3.99995909 15.99967272]  f(x): 1.6736433850638258e-09  grad at x: [ 7.85137309e-05 -2.00413688e-05]  gradient norm: 8.103124340227315e-05\n",
            "iter: 936612  x: [ 3.99995909 15.99967272]  f(x): 1.6735932751650265e-09  grad at x: [-2.50593020e-06 -9.91410707e-06]  gradient norm: 1.0225908521832006e-05\n",
            "iter: 936613  x: [ 3.99995909 15.99967273]  f(x): 1.6735412996942298e-09  grad at x: [ 7.85631879e-05 -2.00472386e-05]  gradient norm: 8.108061585331155e-05\n",
            "iter: 936614  x: [ 3.99995909 15.99967273]  f(x): 1.6734911297418777e-09  grad at x: [-2.50667838e-06 -9.91370143e-06]  gradient norm: 1.0225698636217335e-05\n",
            "iter: 936615  x: [ 3.99995909 15.99967274]  f(x): 1.6734392216859029e-09  grad at x: [ 7.86135470e-05 -2.00532213e-05]  gradient norm: 8.113089087838604e-05\n",
            "iter: 936616  x: [ 3.99995909 15.99967274]  f(x): 1.6733889905242284e-09  grad at x: [-2.50742664e-06 -9.91329580e-06]  gradient norm: 1.0225488835641499e-05\n",
            "iter: 936617  x: [ 3.9999591  15.99967275]  f(x): 1.6733371499569641e-09  grad at x: [ 7.86639206e-05 -2.00592058e-05]  gradient norm: 8.118118092299717e-05\n",
            "iter: 936618  x: [ 3.99995909 15.99967275]  f(x): 1.6732868575657355e-09  grad at x: [-2.50816042e-06 -9.91289198e-06]  gradient norm: 1.0225277314310192e-05\n",
            "iter: 936619  x: [ 3.9999591  15.99967276]  f(x): 1.6732350834241916e-09  grad at x: [ 7.87133918e-05 -2.00650775e-05]  gradient norm: 8.123056930240182e-05\n",
            "iter: 936620  x: [ 3.9999591  15.99967276]  f(x): 1.6731847308132867e-09  grad at x: [-2.50892338e-06 -9.91248453e-06]  gradient norm: 1.0225069490129426e-05\n",
            "iter: 936621  x: [ 3.9999591  15.99967277]  f(x): 1.6731330254082299e-09  grad at x: [ 7.87647257e-05 -2.00711820e-05]  gradient norm: 8.128182062761666e-05\n",
            "iter: 936622  x: [ 3.9999591  15.99967277]  f(x): 1.6730826103183082e-09  grad at x: [-2.50964276e-06 -9.91208253e-06]  gradient norm: 1.022485632849239e-05\n",
            "iter: 936623  x: [ 3.9999591  15.99967278]  f(x): 1.6730309702765417e-09  grad at x: [ 7.88132655e-05 -2.00769373e-05]  gradient norm: 8.133027867162735e-05\n",
            "iter: 936624  x: [ 3.9999591  15.99967278]  f(x): 1.672980496028805e-09  grad at x: [-2.51039133e-06 -9.91167690e-06]  gradient norm: 1.022464686659532e-05\n",
            "iter: 936625  x: [ 3.9999591  15.99967279]  f(x): 1.6729289236625137e-09  grad at x: [ 7.88636679e-05 -2.00829254e-05]  gradient norm: 8.13805996784609e-05\n",
            "iter: 936626  x: [ 3.9999591  15.99967279]  f(x): 1.6728783879973136e-09  grad at x: [-2.51112542e-06 -9.91127308e-06]  gradient norm: 1.0224435679373833e-05\n",
            "iter: 936627  x: [ 3.9999591 15.9996728]  f(x): 1.6728268822057582e-09  grad at x: [ 7.89131388e-05 -2.00887971e-05]  gradient norm: 8.142998987645666e-05\n",
            "iter: 936628  x: [ 3.9999591 15.9996728]  f(x): 1.6727762861883353e-09  grad at x: [-2.51187413e-06 -9.91086745e-06]  gradient norm: 1.022422638705625e-05\n",
            "iter: 936629  x: [ 3.9999591  15.99967281]  f(x): 1.6727248481832464e-09  grad at x: [ 7.89635702e-05 -2.00947889e-05]  gradient norm: 8.148034090879636e-05\n",
            "iter: 936630  x: [ 3.9999591  15.99967281]  f(x): 1.6726741906191908e-09  grad at x: [-2.51262292e-06 -9.91046181e-06]  gradient norm: 1.0224017180148735e-05\n",
            "iter: 936631  x: [ 3.9999591  15.99967282]  f(x): 1.6726228204038427e-09  grad at x: [ 7.90139723e-05 -2.01007770e-05]  gradient norm: 8.153066330262311e-05\n",
            "iter: 936632  x: [ 3.9999591  15.99967282]  f(x): 1.6725721012708743e-09  grad at x: [-2.51335724e-06 -9.91005800e-06]  gradient norm: 1.0223806244260094e-05\n",
            "iter: 936633  x: [ 3.99995911 15.99967283]  f(x): 1.6725207977775077e-09  grad at x: [ 7.90634722e-05 -2.01066523e-05]  gradient norm: 8.158008396239197e-05\n",
            "iter: 936634  x: [ 3.9999591  15.99967283]  f(x): 1.6724700181618202e-09  grad at x: [-2.51409163e-06 -9.90965418e-06]  gradient norm: 1.022359539149558e-05\n",
            "iter: 936635  x: [ 3.99995911 15.99967284]  f(x): 1.6724187814273804e-09  grad at x: [ 7.91129719e-05 -2.01125276e-05]  gradient norm: 8.162950506696872e-05\n",
            "iter: 936636  x: [ 3.99995911 15.99967284]  f(x): 1.6723679412741402e-09  grad at x: [-2.51484065e-06 -9.90924855e-06]  gradient norm: 1.0223386438162472e-05\n",
            "iter: 936637  x: [ 3.99995911 15.99967285]  f(x): 1.6723167724781712e-09  grad at x: [ 7.91634030e-05 -2.01185194e-05]  gradient norm: 8.167985793641488e-05\n",
            "iter: 936638  x: [ 3.99995911 15.99967285]  f(x): 1.6722658706251524e-09  grad at x: [-2.51558975e-06 -9.90884291e-06]  gradient norm: 1.0223177570545538e-05\n",
            "iter: 936639  x: [ 3.99995911 15.99967286]  f(x): 1.6722147698060174e-09  grad at x: [ 7.92138339e-05 -2.01245111e-05]  gradient norm: 8.17302112674748e-05\n",
            "iter: 936640  x: [ 3.99995911 15.99967286]  f(x): 1.6721638062145704e-09  grad at x: [-2.51633892e-06 -9.90843728e-06]  gradient norm: 1.0222968788448392e-05\n",
            "iter: 936641  x: [ 3.99995911 15.99967287]  f(x): 1.6721127734100753e-09  grad at x: [ 7.92642794e-05 -2.01305047e-05]  gradient norm: 8.178057961279372e-05\n",
            "iter: 936642  x: [ 3.99995911 15.99967287]  f(x): 1.6720745041220616e-09  grad at x: [ 3.83735956e-05 -1.50192682e-05]  gradient norm: 4.120814549219489e-05\n",
            "iter: 936643  x: [ 3.99995911 15.99967287]  f(x): 1.6720609538079198e-09  grad at x: [-1.87779066e-06 -9.98793985e-06]  gradient norm: 1.01629247838492e-05\n",
            "iter: 936644  x: [ 3.99995912 15.99967291]  f(x): 1.6718555464576622e-09  grad at x: [ 1.59230654e-04 -3.01248674e-05]  gradient norm: 0.00016205526437605052\n",
            "iter: 936645  x: [ 3.99995912 15.99967291]  f(x): 1.671705858452429e-09  grad at x: [ 7.77317251e-05 -1.99377009e-05]  gradient norm: 8.024794703945725e-05\n",
            "iter: 936646  x: [ 3.99995911 15.99967291]  f(x): 1.671656698227618e-09  grad at x: [-2.49297875e-06 -9.90980698e-06]  gradient norm: 1.0218572178753863e-05\n",
            "iter: 936647  x: [ 3.99995912 15.99967292]  f(x): 1.6716038912054127e-09  grad at x: [ 7.77816172e-05 -1.99436254e-05]  gradient norm: 8.029774692392567e-05\n",
            "iter: 936648  x: [ 3.99995912 15.99967292]  f(x): 1.67155467099954e-09  grad at x: [-2.49369927e-06 -9.90940498e-06]  gradient norm: 1.0218358142706685e-05\n",
            "iter: 936649  x: [ 3.99995912 15.99967293]  f(x): 1.6715019287109259e-09  grad at x: [ 7.78302431e-05 -1.99493916e-05]  gradient norm: 8.034628159714189e-05\n",
            "iter: 936650  x: [ 3.99995912 15.99967293]  f(x): 1.6714526499726733e-09  grad at x: [-2.49444898e-06 -9.90899935e-06]  gradient norm: 1.0218147764303107e-05\n",
            "iter: 936651  x: [ 3.99995912 15.99967294]  f(x): 1.671399974667431e-09  grad at x: [ 7.78807026e-05 -1.99553870e-05]  gradient norm: 8.039664980820836e-05\n",
            "iter: 936652  x: [ 3.99995912 15.99967294]  f(x): 1.6713506351995406e-09  grad at x: [-2.49518421e-06 -9.90859553e-06]  gradient norm: 1.0217935681714046e-05\n",
            "iter: 936653  x: [ 3.99995912 15.99967295]  f(x): 1.6712980258256013e-09  grad at x: [ 7.79302597e-05 -1.99612696e-05]  gradient norm: 8.044611649910799e-05\n",
            "iter: 936654  x: [ 3.99995912 15.99967295]  f(x): 1.671248626625944e-09  grad at x: [-2.49591951e-06 -9.90819171e-06]  gradient norm: 1.021772368202779e-05\n",
            "iter: 936655  x: [ 3.99995912 15.99967296]  f(x): 1.6711960832203433e-09  grad at x: [ 7.79798168e-05 -1.99671522e-05]  gradient norm: 8.049558366061887e-05\n",
            "iter: 936656  x: [ 3.99995912 15.99967296]  f(x): 1.6711466242879089e-09  grad at x: [-2.49665489e-06 -9.90778790e-06]  gradient norm: 1.0217511765482824e-05\n",
            "iter: 936657  x: [ 3.99995912 15.99967297]  f(x): 1.6710941468876797e-09  grad at x: [ 7.80293737e-05 -1.99730348e-05]  gradient norm: 8.054505128657686e-05\n",
            "iter: 936658  x: [ 3.99995912 15.99967297]  f(x): 1.6710446281851494e-09  grad at x: [-2.49739035e-06 -9.90738408e-06]  gradient norm: 1.0217299932100815e-05\n",
            "iter: 936659  x: [ 3.99995912 15.99967298]  f(x): 1.6709922167918354e-09  grad at x: [ 7.80789161e-05 -1.99789156e-05]  gradient norm: 8.059450482907872e-05\n",
            "iter: 936660  x: [ 3.99995912 15.99967298]  f(x): 1.6709426382810738e-09  grad at x: [-2.49812588e-06 -9.90698027e-06]  gradient norm: 1.0217088181686265e-05\n",
            "iter: 936661  x: [ 3.99995913 15.99967299]  f(x): 1.670890293037386e-09  grad at x: [ 7.81285166e-05 -1.99848037e-05]  gradient norm: 8.064401703399459e-05\n",
            "iter: 936662  x: [ 3.99995912 15.99967299]  f(x): 1.6708406546293022e-09  grad at x: [-2.49884693e-06 -9.90657827e-06]  gradient norm: 1.021687471909971e-05\n",
            "iter: 936663  x: [ 3.99995913 15.999673  ]  f(x): 1.670788374372725e-09  grad at x: [ 7.81771566e-05 -1.99905717e-05]  gradient norm: 8.069256945331818e-05\n",
            "iter: 936664  x: [ 3.99995913 15.999673  ]  f(x): 1.6707386771767555e-09  grad at x: [-2.49959717e-06 -9.90617264e-06]  gradient norm: 1.0216664930497307e-05\n",
            "iter: 936665  x: [ 3.99995913 15.99967301]  f(x): 1.6706864642378292e-09  grad at x: [ 7.82276591e-05 -1.99965725e-05]  gradient norm: 8.074298463532643e-05\n",
            "iter: 936666  x: [ 3.99995913 15.99967301]  f(x): 1.6706367059759408e-09  grad at x: [-2.50033293e-06 -9.90576882e-06]  gradient norm: 1.021645342976624e-05\n",
            "iter: 936667  x: [ 3.99995913 15.99967302]  f(x): 1.6705845592623585e-09  grad at x: [ 7.82772449e-05 -2.00024588e-05]  gradient norm: 8.079248367795544e-05\n",
            "iter: 936668  x: [ 3.99995913 15.99967302]  f(x): 1.670534740973784e-09  grad at x: [-2.50109787e-06 -9.90536137e-06]  gradient norm: 1.0216245609849902e-05\n",
            "iter: 936669  x: [ 3.99995913 15.99967303]  f(x): 1.670482662784068e-09  grad at x: [ 7.83286932e-05 -2.00085778e-05]  gradient norm: 8.084384553793288e-05\n",
            "iter: 936670  x: [ 3.99995913 15.99967303]  f(x): 1.6704327822216766e-09  grad at x: [-2.50181923e-06 -9.90495937e-06]  gradient norm: 1.0216032477949282e-05\n",
            "iter: 936671  x: [ 3.99995913 15.99967304]  f(x): 1.6703807692362402e-09  grad at x: [ 7.83773765e-05 -2.00143513e-05]  gradient norm: 8.089244343402332e-05\n",
            "iter: 936672  x: [ 3.99995913 15.99967304]  f(x): 1.6703308296852534e-09  grad at x: [-2.50255522e-06 -9.90455555e-06]  gradient norm: 1.0215821228036618e-05\n",
            "iter: 936673  x: [ 3.99995913 15.99967305]  f(x): 1.6702788830015538e-09  grad at x: [ 7.84269474e-05 -2.00202358e-05]  gradient norm: 8.094192931799445e-05\n",
            "iter: 936674  x: [ 3.99995913 15.99967305]  f(x): 1.670228883345525e-09  grad at x: [-2.50329129e-06 -9.90415174e-06]  gradient norm: 1.0215610061242517e-05\n",
            "iter: 936675  x: [ 3.99995913 15.99967306]  f(x): 1.6701770031066178e-09  grad at x: [ 7.84765765e-05 -2.00261275e-05]  gradient norm: 8.099147385880493e-05\n",
            "iter: 936676  x: [ 3.99995913 15.99967306]  f(x): 1.6701269432572111e-09  grad at x: [-2.50404198e-06 -9.90374610e-06]  gradient norm: 1.0215400781327323e-05\n",
            "iter: 936677  x: [ 3.99995914 15.99967307]  f(x): 1.670075130562613e-09  grad at x: [ 7.85271077e-05 -2.00321319e-05]  gradient norm: 8.10419209747636e-05\n",
            "iter: 936678  x: [ 3.99995913 15.99967307]  f(x): 1.6700250093826164e-09  grad at x: [-2.50477820e-06 -9.90334229e-06]  gradient norm: 1.0215189782428326e-05\n",
            "iter: 936679  x: [ 3.99995914 15.99967308]  f(x): 1.6699732631721804e-09  grad at x: [ 7.85767221e-05 -2.00380218e-05]  gradient norm: 8.109145189088333e-05\n",
            "iter: 936680  x: [ 3.99995914 15.99967308]  f(x): 1.669923081722569e-09  grad at x: [-2.50552904e-06 -9.90293665e-06]  gradient norm: 1.0214980672788478e-05\n",
            "iter: 936681  x: [ 3.99995914 15.99967309]  f(x): 1.669871403203988e-09  grad at x: [ 7.86272822e-05 -2.00440300e-05]  gradient norm: 8.114192904751622e-05\n",
            "iter: 936682  x: [ 3.99995914 15.99967309]  f(x): 1.669821160294375e-09  grad at x: [-2.50627996e-06 -9.90253102e-06]  gradient norm: 1.0214771648908724e-05\n",
            "iter: 936683  x: [ 3.99995914 15.9996731 ]  f(x): 1.6697695494349798e-09  grad at x: [ 7.86778132e-05 -2.00500344e-05]  gradient norm: 8.119237757890266e-05\n",
            "iter: 936684  x: [ 3.99995914 15.9996731 ]  f(x): 1.6697192450790468e-09  grad at x: [-2.50701641e-06 -9.90212720e-06]  gradient norm: 1.0214560902377258e-05\n",
            "iter: 936685  x: [ 3.99995914 15.99967311]  f(x): 1.669667700852208e-09  grad at x: [ 7.87274419e-05 -2.00559261e-05]  gradient norm: 8.124192442798666e-05\n",
            "iter: 936686  x: [ 3.99995914 15.99967311]  f(x): 1.669617336095002e-09  grad at x: [-2.50775293e-06 -9.90172339e-06]  gradient norm: 1.0214350239312247e-05\n",
            "iter: 936687  x: [ 3.99995914 15.99967312]  f(x): 1.6695658585015702e-09  grad at x: [ 7.87770705e-05 -2.00618178e-05]  gradient norm: 8.129147172989475e-05\n",
            "iter: 936688  x: [ 3.99995914 15.99967312]  f(x): 1.6695154333243658e-09  grad at x: [-2.50850408e-06 -9.90131775e-06]  gradient norm: 1.0214141470268435e-05\n",
            "iter: 936689  x: [ 3.99995914 15.99967313]  f(x): 1.6694640235749436e-09  grad at x: [ 7.88276449e-05 -2.00678278e-05]  gradient norm: 8.134196530906703e-05\n",
            "iter: 936690  x: [ 3.99995914 15.99967313]  f(x): 1.6694135367657416e-09  grad at x: [-2.50924075e-06 -9.90091394e-06]  gradient norm: 1.0213930975141982e-05\n",
            "iter: 936691  x: [ 3.99995914 15.99967314]  f(x): 1.6693621937960432e-09  grad at x: [ 7.88773025e-05 -2.00737231e-05]  gradient norm: 8.139154262873338e-05\n",
            "iter: 936692  x: [ 3.99995914 15.99967314]  f(x): 1.6693116464375455e-09  grad at x: [-2.50997750e-06 -9.90051012e-06]  gradient norm: 1.0213720563547057e-05\n",
            "iter: 936693  x: [ 3.99995915 15.99967315]  f(x): 1.669260370213417e-09  grad at x: [ 7.89269309e-05 -2.00796148e-05]  gradient norm: 8.144109129484895e-05\n",
            "iter: 936694  x: [ 3.99995914 15.99967315]  f(x): 1.6692097623219055e-09  grad at x: [-2.51072888e-06 -9.90010449e-06]  gradient norm: 1.0213512049535897e-05\n",
            "iter: 936695  x: [ 3.99995915 15.99967316]  f(x): 1.669158554056108e-09  grad at x: [ 7.89775051e-05 -2.00856248e-05]  gradient norm: 8.149158626232499e-05\n",
            "iter: 936696  x: [ 3.99995915 15.99967316]  f(x): 1.6691078844174238e-09  grad at x: [-2.51146579e-06 -9.89970067e-06]  gradient norm: 1.0213301806009905e-05\n",
            "iter: 936697  x: [ 3.99995915 15.99967317]  f(x): 1.6690567430429811e-09  grad at x: [ 7.90271770e-05 -2.00915219e-05]  gradient norm: 8.154117949095923e-05\n",
            "iter: 936698  x: [ 3.99995915 15.99967317]  f(x): 1.6690060127425149e-09  grad at x: [-2.51220276e-06 -9.89929686e-06]  gradient norm: 1.0213091646080527e-05\n",
            "iter: 936699  x: [ 3.99995915 15.99967318]  f(x): 1.6689549382615155e-09  grad at x: [ 7.90768197e-05 -2.00974155e-05]  gradient norm: 8.159074406427978e-05\n",
            "iter: 936700  x: [ 3.99995915 15.99967318]  f(x): 1.6689041472968937e-09  grad at x: [-2.51293982e-06 -9.89889304e-06]  gradient norm: 1.0212881569769461e-05\n",
            "iter: 936701  x: [ 3.99995915 15.99967319]  f(x): 1.668853139781639e-09  grad at x: [ 7.91264914e-05 -2.01033126e-05]  gradient norm: 8.16403381874546e-05\n",
            "iter: 936702  x: [ 3.99995915 15.99967319]  f(x): 1.6688022880451079e-09  grad at x: [-2.51370605e-06 -9.89848559e-06]  gradient norm: 1.0212675214497e-05\n",
            "iter: 936703  x: [ 3.99995915 15.9996732 ]  f(x): 1.6687513498183649e-09  grad at x: [ 7.91780257e-05 -2.01094426e-05]  gradient norm: 8.169179543554961e-05\n",
            "iter: 936704  x: [ 3.99995915 15.9996732 ]  f(x): 1.668713163565788e-09  grad at x: [ 3.83317985e-05 -1.50037631e-05]  gradient norm: 4.116357229518289e-05\n",
            "iter: 936705  x: [ 3.99995915 15.9996732 ]  f(x): 1.6686996424441414e-09  grad at x: [-1.87584427e-06 -9.97790266e-06]  gradient norm: 1.0152700788631867e-05\n",
            "iter: 936706  x: [ 3.99995916 15.99967324]  f(x): 1.6684946113099345e-09  grad at x: [ 1.59055521e-04 -3.00926968e-05]  gradient norm: 0.00016187720359415507\n",
            "iter: 936707  x: [ 3.99995916 15.99967324]  f(x): 1.668345252073663e-09  grad at x: [ 7.76461891e-05 -1.99167298e-05]  gradient norm: 8.015988277804431e-05\n",
            "iter: 936708  x: [ 3.99995916 15.99967324]  f(x): 1.6682961995411343e-09  grad at x: [-2.49035836e-06 -9.89985529e-06]  gradient norm: 1.0208281904100154e-05\n",
            "iter: 936709  x: [ 3.99995916 15.99967325]  f(x): 1.6682434899461994e-09  grad at x: [ 7.76961514e-05 -1.99226633e-05]  gradient norm: 8.020975289554122e-05\n",
            "iter: 936710  x: [ 3.99995916 15.99967325]  f(x): 1.6681943774146727e-09  grad at x: [-2.49106684e-06 -9.89945511e-06]  gradient norm: 1.020806668442884e-05\n",
            "iter: 936711  x: [ 3.99995916 15.99967326]  f(x): 1.6681417315269817e-09  grad at x: [ 7.77439890e-05 -1.99283313e-05]  gradient norm: 8.025749946582317e-05\n",
            "iter: 936712  x: [ 3.99995916 15.99967326]  f(x): 1.6680925614976428e-09  grad at x: [-2.49178995e-06 -9.89905311e-06]  gradient norm: 1.0207853332167586e-05\n",
            "iter: 936713  x: [ 3.99995916 15.99967327]  f(x): 1.668039980474779e-09  grad at x: [ 7.77927579e-05 -1.99341157e-05]  gradient norm: 8.030617755909153e-05\n",
            "iter: 936714  x: [ 3.99995916 15.99967327]  f(x): 1.6679907517721767e-09  grad at x: [-2.49254224e-06 -9.89864748e-06]  gradient norm: 1.0207643639513119e-05\n",
            "iter: 936715  x: [ 3.99995916 15.99967328]  f(x): 1.6679382378976222e-09  grad at x: [ 7.78433894e-05 -1.99401329e-05]  gradient norm: 8.035671830509847e-05\n",
            "iter: 936716  x: [ 3.99995916 15.99967328]  f(x): 1.6678889482896357e-09  grad at x: [-2.49325095e-06 -9.89824730e-06]  gradient norm: 1.0207428661286973e-05\n",
            "iter: 936717  x: [ 3.99995916 15.99967329]  f(x): 1.6678364982630781e-09  grad at x: [ 7.78912559e-05 -1.99458045e-05]  gradient norm: 8.040449531179501e-05\n",
            "iter: 936718  x: [ 3.99995916 15.99967329]  f(x): 1.6677871510156736e-09  grad at x: [-2.49397428e-06 -9.89784530e-06]  gradient norm: 1.0207215553541408e-05\n",
            "iter: 936719  x: [ 3.99995916 15.9996733 ]  f(x): 1.6677347659622166e-09  grad at x: [ 7.79400246e-05 -1.99515889e-05]  gradient norm: 8.04531747712537e-05\n",
            "iter: 936720  x: [ 3.99995916 15.9996733 ]  f(x): 1.6676853599324254e-09  grad at x: [-2.49472680e-06 -9.89743967e-06]  gradient norm: 1.0207006112783239e-05\n",
            "iter: 936721  x: [ 3.99995917 15.99967331]  f(x): 1.6676330421743671e-09  grad at x: [ 7.79906849e-05 -1.99576098e-05]  gradient norm: 8.050374603536682e-05\n",
            "iter: 936722  x: [ 3.99995916 15.99967331]  f(x): 1.6675835750747714e-09  grad at x: [-2.49547939e-06 -9.89703403e-06]  gradient norm: 1.0206796758003968e-05\n",
            "iter: 936723  x: [ 3.99995917 15.99967332]  f(x): 1.667531324650831e-09  grad at x: [ 7.80413452e-05 -1.99636306e-05]  gradient norm: 8.055431778575248e-05\n",
            "iter: 936724  x: [ 3.99995917 15.99967332]  f(x): 1.6674817964413181e-09  grad at x: [-2.49620296e-06 -9.89663204e-06]  gradient norm: 1.0206583898605141e-05\n",
            "iter: 936725  x: [ 3.99995917 15.99967333]  f(x): 1.6674296111355285e-09  grad at x: [ 7.80901428e-05 -1.99694186e-05]  gradient norm: 8.060302772924948e-05\n",
            "iter: 936726  x: [ 3.99995917 15.99967333]  f(x): 1.6673800240153078e-09  grad at x: [-2.49694115e-06 -9.89622822e-06]  gradient norm: 1.0206372916915318e-05\n",
            "iter: 936727  x: [ 3.99995917 15.99967334]  f(x): 1.6673279049908124e-09  grad at x: [ 7.81398861e-05 -1.99753249e-05]  gradient norm: 8.065268382709269e-05\n",
            "iter: 936728  x: [ 3.99995917 15.99967334]  f(x): 1.66727825777777e-09  grad at x: [-2.49767942e-06 -9.89582441e-06]  gradient norm: 1.0206162018709001e-05\n",
            "iter: 936729  x: [ 3.99995917 15.99967335]  f(x): 1.6672262051081516e-09  grad at x: [ 7.81896294e-05 -1.99812312e-05]  gradient norm: 8.070234039065444e-05\n",
            "iter: 936730  x: [ 3.99995917 15.99967335]  f(x): 1.6671764977822646e-09  grad at x: [-2.49840322e-06 -9.89542241e-06]  gradient norm: 1.0205949405786886e-05\n",
            "iter: 936731  x: [ 3.99995917 15.99967336]  f(x): 1.6671245103746367e-09  grad at x: [ 7.82384558e-05 -1.99870228e-05]  gradient norm: 8.075108079272932e-05\n",
            "iter: 936732  x: [ 3.99995917 15.99967336]  f(x): 1.6670747439933504e-09  grad at x: [-2.49914164e-06 -9.89501859e-06]  gradient norm: 1.0205738673885388e-05\n",
            "iter: 936733  x: [ 3.99995917 15.99967337]  f(x): 1.667022823013786e-09  grad at x: [ 7.82882135e-05 -1.99929309e-05]  gradient norm: 8.080075282650067e-05\n",
            "iter: 936734  x: [ 3.99995917 15.99967337]  f(x): 1.6669729963931675e-09  grad at x: [-2.49990924e-06 -9.89461114e-06]  gradient norm: 1.020553162773022e-05\n",
            "iter: 936735  x: [ 3.99995917 15.99967338]  f(x): 1.6669211441407286e-09  grad at x: [ 7.83398338e-05 -1.99990718e-05]  gradient norm: 8.085228771296235e-05\n",
            "iter: 936736  x: [ 3.99995917 15.99967338]  f(x): 1.6668712550154755e-09  grad at x: [-2.50064781e-06 -9.89420732e-06]  gradient norm: 1.020532106548918e-05\n",
            "iter: 936737  x: [ 3.99995918 15.99967339]  f(x): 1.6668194692671895e-09  grad at x: [ 7.83895913e-05 -2.00049799e-05]  gradient norm: 8.090196069095293e-05\n",
            "iter: 936738  x: [ 3.99995917 15.99967339]  f(x): 1.6667695198610985e-09  grad at x: [-2.50138646e-06 -9.89380351e-06]  gradient norm: 1.020511058705771e-05\n",
            "iter: 936739  x: [ 3.99995918 15.9996734 ]  f(x): 1.6667178006543023e-09  grad at x: [ 7.84393487e-05 -2.00108880e-05]  gradient norm: 8.095163412996453e-05\n",
            "iter: 936740  x: [ 3.99995918 15.9996734 ]  f(x): 1.666667790912177e-09  grad at x: [-2.50213974e-06 -9.89339787e-06]  gradient norm: 1.0204901996966199e-05\n",
            "iter: 936741  x: [ 3.99995918 15.99967341]  f(x): 1.6666161393816512e-09  grad at x: [ 7.84900229e-05 -2.00169106e-05]  gradient norm: 8.100222470434509e-05\n",
            "iter: 936742  x: [ 3.99995918 15.99967341]  f(x): 1.666566068149743e-09  grad at x: [-2.50289310e-06 -9.89299224e-06]  gradient norm: 1.0204693492856124e-05\n",
            "iter: 936743  x: [ 3.99995918 15.99967342]  f(x): 1.6665144844402464e-09  grad at x: [ 7.85407552e-05 -2.00229406e-05]  gradient norm: 8.105287395939732e-05\n",
            "iter: 936744  x: [ 3.99995918 15.99967342]  f(x): 1.6664643516097708e-09  grad at x: [-2.50364653e-06 -9.89258660e-06]  gradient norm: 1.0204485074967387e-05\n",
            "iter: 936745  x: [ 3.99995918 15.99967343]  f(x): 1.666412835724554e-09  grad at x: [ 7.85914729e-05 -2.00289687e-05]  gradient norm: 8.110350914042679e-05\n",
            "iter: 936746  x: [ 3.99995918 15.99967343]  f(x): 1.666362641273292e-09  grad at x: [-2.50438548e-06 -9.89218279e-06]  gradient norm: 1.020427493504479e-05\n",
            "iter: 936747  x: [ 3.99995918 15.99967344]  f(x): 1.6663111920804134e-09  grad at x: [ 7.86412446e-05 -2.00348786e-05]  gradient norm: 8.115319899666913e-05\n",
            "iter: 936748  x: [ 3.99995918 15.99967344]  f(x): 1.6662609371587052e-09  grad at x: [-2.50512451e-06 -9.89177897e-06]  gradient norm: 1.0204064879040788e-05\n",
            "iter: 936749  x: [ 3.99995918 15.99967345]  f(x): 1.6662095547311235e-09  grad at x: [ 7.86910307e-05 -2.00407903e-05]  gradient norm: 8.12029038582333e-05\n",
            "iter: 936750  x: [ 3.99995918 15.99967345]  f(x): 1.6661592392294712e-09  grad at x: [-2.50586362e-06 -9.89137516e-06]  gradient norm: 1.0203854906759041e-05\n",
            "iter: 936751  x: [ 3.99995918 15.99967346]  f(x): 1.666107923640179e-09  grad at x: [ 7.87408314e-05 -2.00467039e-05]  gradient norm: 8.125262372802714e-05\n",
            "iter: 936752  x: [ 3.99995918 15.99967346]  f(x): 1.6660575475215605e-09  grad at x: [-2.50660280e-06 -9.89097134e-06]  gradient norm: 1.0203645018439307e-05\n",
            "iter: 936753  x: [ 3.99995919 15.99967347]  f(x): 1.6660062988073288e-09  grad at x: [ 7.87906465e-05 -2.00526192e-05]  gradient norm: 8.13023586037952e-05\n",
            "iter: 936754  x: [ 3.99995918 15.99967347]  f(x): 1.6659558620171189e-09  grad at x: [-2.50735661e-06 -9.89056571e-06]  gradient norm: 1.0203437026816154e-05\n",
            "iter: 936755  x: [ 3.99995919 15.99967348]  f(x): 1.6659046812827162e-09  grad at x: [ 7.88413492e-05 -2.00586455e-05]  gradient norm: 8.135298157261387e-05\n",
            "iter: 936756  x: [ 3.99995919 15.99967348]  f(x): 1.6658541827323178e-09  grad at x: [-2.50808139e-06 -9.89016371e-06]  gradient norm: 1.0203225493773021e-05\n",
            "iter: 936757  x: [ 3.99995919 15.99967349]  f(x): 1.6658030678098036e-09  grad at x: [ 7.88902329e-05 -2.00644445e-05]  gradient norm: 8.14017860651029e-05\n",
            "iter: 936758  x: [ 3.99995919 15.99967349]  f(x): 1.6657525096328486e-09  grad at x: [-2.50883535e-06 -9.88975808e-06]  gradient norm: 1.0203017672291951e-05\n",
            "iter: 936759  x: [ 3.99995919 15.9996735 ]  f(x): 1.6657014628726916e-09  grad at x: [ 7.89409937e-05 -2.00704781e-05]  gradient norm: 8.145246816452609e-05\n",
            "iter: 936760  x: [ 3.99995919 15.9996735 ]  f(x): 1.665650842753565e-09  grad at x: [-2.50958939e-06 -9.88935244e-06]  gradient norm: 1.0202809937208603e-05\n",
            "iter: 936761  x: [ 3.99995919 15.99967351]  f(x): 1.6655998641589743e-09  grad at x: [ 7.89917398e-05 -2.00765098e-05]  gradient norm: 8.150313618121334e-05\n",
            "iter: 936762  x: [ 3.99995919 15.99967351]  f(x): 1.6655491820766154e-09  grad at x: [-2.51035806e-06 -9.88894499e-06]  gradient norm: 1.0202604105757327e-05\n",
            "iter: 936763  x: [ 3.99995919 15.99967352]  f(x): 1.665498272826728e-09  grad at x: [ 7.90434318e-05 -2.00826598e-05]  gradient norm: 8.155475055078222e-05\n",
            "iter: 936764  x: [ 3.99995919 15.99967352]  f(x): 1.6654475276006012e-09  grad at x: [-2.51111225e-06 -9.88853935e-06]  gradient norm: 1.020239654450241e-05\n",
            "iter: 936765  x: [ 3.99995919 15.99967353]  f(x): 1.6653966865947162e-09  grad at x: [ 7.90941778e-05 -2.00886916e-05]  gradient norm: 8.160541951632743e-05\n",
            "iter: 936766  x: [ 3.99995919 15.99967353]  f(x): 1.6653585810205713e-09  grad at x: [ 3.82911556e-05 -1.49884127e-05]  gradient norm: 4.112013028364773e-05\n",
            "iter: 936767  x: [ 3.99995919 15.99967353]  f(x): 1.6653450883472144e-09  grad at x: [-1.87390783e-06 -9.96787458e-06]  gradient norm: 1.0142487570836368e-05\n",
            "iter: 936768  x: [ 3.9999592  15.99967357]  f(x): 1.6651404377346096e-09  grad at x: [ 1.58882619e-04 -3.00608153e-05]  gradient norm: 0.00016170138878229736\n",
            "iter: 936769  x: [ 3.9999592  15.99967357]  f(x): 1.6649914027210111e-09  grad at x: [ 7.75617200e-05 -1.98959024e-05]  gradient norm: 8.007288769238196e-05\n",
            "iter: 936770  x: [ 3.9999592  15.99967357]  f(x): 1.6649424564785245e-09  grad at x: [-2.48773336e-06 -9.88991451e-06]  gradient norm: 1.019800109043414e-05\n",
            "iter: 936771  x: [ 3.9999592  15.99967358]  f(x): 1.6648898436067949e-09  grad at x: [ 7.76103265e-05 -1.99016667e-05]  gradient norm: 8.012140235350812e-05\n",
            "iter: 936772  x: [ 3.9999592  15.99967358]  f(x): 1.6648408390378302e-09  grad at x: [-2.48848800e-06 -9.88950887e-06]  gradient norm: 1.0197791834440853e-05\n",
            "iter: 936773  x: [ 3.9999592  15.99967359]  f(x): 1.6647882933336334e-09  grad at x: [ 7.76611011e-05 -1.99077022e-05]  gradient norm: 8.017208513515055e-05\n",
            "iter: 936774  x: [ 3.9999592  15.99967359]  f(x): 1.6647392277960973e-09  grad at x: [-2.48922817e-06 -9.88910506e-06]  gradient norm: 1.0197580876396756e-05\n",
            "iter: 936775  x: [ 3.9999592 15.9996736]  f(x): 1.6646867481755348e-09  grad at x: [ 7.77109589e-05 -1.99136230e-05]  gradient norm: 8.022185187298324e-05\n",
            "iter: 936776  x: [ 3.9999592 15.9996736]  f(x): 1.6646376227530418e-09  grad at x: [-2.48995386e-06 -9.88870306e-06]  gradient norm: 1.0197368212827839e-05\n",
            "iter: 936777  x: [ 3.9999592  15.99967361]  f(x): 1.6645852081318278e-09  grad at x: [ 7.77598708e-05 -1.99194255e-05]  gradient norm: 8.027067343901804e-05\n",
            "iter: 936778  x: [ 3.9999592  15.99967361]  f(x): 1.6645360239094853e-09  grad at x: [-2.49069418e-06 -9.88829925e-06]  gradient norm: 1.0197157421644995e-05\n",
            "iter: 936779  x: [ 3.9999592  15.99967362]  f(x): 1.664483675481565e-09  grad at x: [ 7.78097430e-05 -1.99253482e-05]  gradient norm: 8.03204556673707e-05\n",
            "iter: 936780  x: [ 3.9999592  15.99967362]  f(x): 1.6644344312640384e-09  grad at x: [-2.49142002e-06 -9.88789725e-06]  gradient norm: 1.0196944922453373e-05\n",
            "iter: 936781  x: [ 3.99995921 15.99967363]  f(x): 1.6643821480128754e-09  grad at x: [ 7.78587274e-05 -1.99311598e-05]  gradient norm: 8.036935089627005e-05\n",
            "iter: 936782  x: [ 3.9999592  15.99967363]  f(x): 1.6643328448361936e-09  grad at x: [-2.49217505e-06 -9.88749161e-06]  gradient norm: 1.019673609078804e-05\n",
            "iter: 936783  x: [ 3.99995921 15.99967364]  f(x): 1.6642806289419989e-09  grad at x: [ 7.79095162e-05 -1.99371971e-05]  gradient norm: 8.042005064053386e-05\n",
            "iter: 936784  x: [ 3.99995921 15.99967364]  f(x): 1.6642312646058903e-09  grad at x: [-2.4929156e-06 -9.8870878e-06]  gradient norm: 1.019652555137436e-05\n",
            "iter: 936785  x: [ 3.99995921 15.99967365]  f(x): 1.6641791150175489e-09  grad at x: [ 7.79593882e-05 -1.99431197e-05]  gradient norm: 8.046983428814983e-05\n",
            "iter: 936786  x: [ 3.99995921 15.99967365]  f(x): 1.664129690572844e-09  grad at x: [-2.49364167e-06 -9.88668580e-06]  gradient norm: 1.0196313300736207e-05\n",
            "iter: 936787  x: [ 3.99995921 15.99967366]  f(x): 1.6640776062363563e-09  grad at x: [ 7.80083578e-05 -1.99489295e-05]  gradient norm: 8.051871635827771e-05\n",
            "iter: 936788  x: [ 3.99995921 15.99967366]  f(x): 1.6640281227378785e-09  grad at x: [-2.49438237e-06 -9.88628199e-06]  gradient norm: 1.0196102928400734e-05\n",
            "iter: 936789  x: [ 3.99995921 15.99967367]  f(x): 1.6639761048162489e-09  grad at x: [ 7.80582588e-05 -1.99548558e-05]  gradient norm: 8.056853003719391e-05\n",
            "iter: 936790  x: [ 3.99995921 15.99967367]  f(x): 1.6639265610996023e-09  grad at x: [-2.49510859e-06 -9.88587999e-06]  gradient norm: 1.0195890842355078e-05\n",
            "iter: 936791  x: [ 3.99995921 15.99967368]  f(x): 1.663874608502828e-09  grad at x: [ 7.81072283e-05 -1.99606657e-05]  gradient norm: 8.061741302024046e-05\n",
            "iter: 936792  x: [ 3.99995921 15.99967368]  f(x): 1.6638250056412798e-09  grad at x: [-2.49586400e-06 -9.88547436e-06]  gradient norm: 1.0195682435346595e-05\n",
            "iter: 936793  x: [ 3.99995921 15.99967369]  f(x): 1.6637731206620377e-09  grad at x: [ 7.81580604e-05 -1.99667084e-05]  gradient norm: 8.06681588043643e-05\n",
            "iter: 936794  x: [ 3.99995921 15.99967369]  f(x): 1.6637234563977484e-09  grad at x: [-2.49661948e-06 -9.88506872e-06]  gradient norm: 1.0195474114890332e-05\n",
            "iter: 936795  x: [ 3.99995921 15.9996737 ]  f(x): 1.663671639075024e-09  grad at x: [ 7.82088924e-05 -1.99727510e-05]  gradient norm: 8.071890507547405e-05\n",
            "iter: 936796  x: [ 3.99995921 15.9996737 ]  f(x): 1.663621913350056e-09  grad at x: [-2.49736048e-06 -9.88466491e-06]  gradient norm: 1.0195264079819206e-05\n",
            "iter: 936797  x: [ 3.99995922 15.99967371]  f(x): 1.6635701626278783e-09  grad at x: [ 7.82588221e-05 -1.99786809e-05]  gradient norm: 8.076874973713453e-05\n",
            "iter: 936798  x: [ 3.99995921 15.99967371]  f(x): 1.6635203764990272e-09  grad at x: [-2.49811611e-06 -9.88425927e-06]  gradient norm: 1.0195055931128848e-05\n",
            "iter: 936799  x: [ 3.99995922 15.99967372]  f(x): 1.6634686935106401e-09  grad at x: [ 7.83096540e-05 -1.99847236e-05]  gradient norm: 8.081949697128796e-05\n",
            "iter: 936800  x: [ 3.99995922 15.99967372]  f(x): 1.663418845860827e-09  grad at x: [-2.49884272e-06 -9.88385727e-06]  gradient norm: 1.0194844262424942e-05\n",
            "iter: 936801  x: [ 3.99995922 15.99967373]  f(x): 1.6633672284177432e-09  grad at x: [ 7.83586522e-05 -1.99905371e-05]  gradient norm: 8.086841135956113e-05\n",
            "iter: 936802  x: [ 3.99995922 15.99967373]  f(x): 1.6633173214187221e-09  grad at x: [-2.49958395e-06 -9.88345346e-06]  gradient norm: 1.0194634479927762e-05\n",
            "iter: 936803  x: [ 3.99995922 15.99967374]  f(x): 1.663265770653441e-09  grad at x: [ 7.84085672e-05 -1.99964652e-05]  gradient norm: 8.09182428678209e-05\n",
            "iter: 936804  x: [ 3.99995922 15.99967374]  f(x): 1.6632158031537639e-09  grad at x: [-2.50032526e-06 -9.88304964e-06]  gradient norm: 1.0194424781520238e-05\n",
            "iter: 936805  x: [ 3.99995922 15.99967375]  f(x): 1.6631643191749284e-09  grad at x: [ 7.84585112e-05 -2.00023969e-05]  gradient norm: 8.096810393936365e-05\n",
            "iter: 936806  x: [ 3.99995922 15.99967375]  f(x): 1.663114291101891e-09  grad at x: [-2.50106664e-06 -9.88264583e-06]  gradient norm: 1.0194215167441935e-05\n",
            "iter: 936807  x: [ 3.99995922 15.99967376]  f(x): 1.6630628739464438e-09  grad at x: [ 7.85084696e-05 -2.00083305e-05]  gradient norm: 8.101798002369413e-05\n",
            "iter: 936808  x: [ 3.99995922 15.99967376]  f(x): 1.6630127852441528e-09  grad at x: [-2.50179355e-06 -9.88224383e-06]  gradient norm: 1.0194003829760064e-05\n",
            "iter: 936809  x: [ 3.99995922 15.99967377]  f(x): 1.6629614337808984e-09  grad at x: [ 7.85574675e-05 -2.00141440e-05]  gradient norm: 8.106689621849288e-05\n",
            "iter: 936810  x: [ 3.99995922 15.99967377]  f(x): 1.662911285581377e-09  grad at x: [-2.50253508e-06 -9.88184001e-06]  gradient norm: 1.019379438302e-05\n",
            "iter: 936811  x: [ 3.99995922 15.99967378]  f(x): 1.662860001016067e-09  grad at x: [ 7.86074258e-05 -2.00200775e-05]  gradient norm: 8.111677321714544e-05\n",
            "iter: 936812  x: [ 3.99995922 15.99967378]  f(x): 1.6628097921132799e-09  grad at x: [-2.50329125e-06 -9.88143438e-06]  gradient norm: 1.0193586830964819e-05\n",
            "iter: 936813  x: [ 3.99995923 15.99967379]  f(x): 1.662758575618928e-09  grad at x: [ 7.86583154e-05 -2.00261275e-05]  gradient norm: 8.11675819481046e-05\n",
            "iter: 936814  x: [ 3.99995922 15.99967379]  f(x): 1.662708304838467e-09  grad at x: [-2.50403294e-06 -9.88103056e-06]  gradient norm: 1.0193377553985592e-05\n",
            "iter: 936815  x: [ 3.99995923 15.9996738 ]  f(x): 1.6626571552824718e-09  grad at x: [ 7.87082590e-05 -2.00320592e-05]  gradient norm: 8.121744532371384e-05\n",
            "iter: 936816  x: [ 3.99995923 15.9996738 ]  f(x): 1.6626068237566548e-09  grad at x: [-2.50476015e-06 -9.88062857e-06]  gradient norm: 1.0193166548818088e-05\n",
            "iter: 936817  x: [ 3.99995923 15.99967381]  f(x): 1.6625557400754438e-09  grad at x: [ 7.87572857e-05 -2.00378763e-05]  gradient norm: 8.126639241985726e-05\n",
            "iter: 936818  x: [ 3.99995923 15.99967381]  f(x): 1.6625053488511202e-09  grad at x: [-2.50551654e-06 -9.88022293e-06]  gradient norm: 1.0192959253145585e-05\n",
            "iter: 936819  x: [ 3.99995923 15.99967382]  f(x): 1.6624543333915202e-09  grad at x: [ 7.88081896e-05 -2.00439281e-05]  gradient norm: 8.131721710529855e-05\n",
            "iter: 936820  x: [ 3.99995923 15.99967382]  f(x): 1.662403880156683e-09  grad at x: [-2.50627301e-06 -9.87981730e-06]  gradient norm: 1.0192752044312573e-05\n",
            "iter: 936821  x: [ 3.99995923 15.99967383]  f(x): 1.6623529329571938e-09  grad at x: [ 7.88591079e-05 -2.00499817e-05]  gradient norm: 8.136805681726298e-05\n",
            "iter: 936822  x: [ 3.99995923 15.99967383]  f(x): 1.6623024176543953e-09  grad at x: [-2.50701500e-06 -9.87941348e-06]  gradient norm: 1.0192543105949346e-05\n",
            "iter: 936823  x: [ 3.99995923 15.99967384]  f(x): 1.6622515375801497e-09  grad at x: [ 7.89090658e-05 -2.00559152e-05]  gradient norm: 8.141793658206788e-05\n",
            "iter: 936824  x: [ 3.99995923 15.99967384]  f(x): 1.6622009613450867e-09  grad at x: [-2.50777162e-06 -9.87900785e-06]  gradient norm: 1.0192336069454095e-05\n",
            "iter: 936825  x: [ 3.99995923 15.99967385]  f(x): 1.6621501496084455e-09  grad at x: [ 7.89599840e-05 -2.00619688e-05]  gradient norm: 8.146877723186605e-05\n",
            "iter: 936826  x: [ 3.99995923 15.99967385]  f(x): 1.6620995112273606e-09  grad at x: [-2.50851376e-06 -9.87860403e-06]  gradient norm: 1.0192127301114386e-05\n",
            "iter: 936827  x: [ 3.99995923 15.99967386]  f(x): 1.6620487667270671e-09  grad at x: [ 7.90099708e-05 -2.00679060e-05]  gradient norm: 8.151868701843177e-05\n",
            "iter: 936828  x: [ 3.99995923 15.99967386]  f(x): 1.6620107420601141e-09  grad at x: [ 3.82503428e-05 -1.49730513e-05]  gradient norm: 4.10765260489346e-05\n",
            "iter: 936829  x: [ 3.99995923 15.99967386]  f(x): 1.6619972778849169e-09  grad at x: [-1.87201037e-06 -9.95785194e-06]  gradient norm: 1.0132286916826447e-05\n",
            "iter: 936830  x: [ 3.99995924 15.99967389]  f(x): 1.661793030467189e-09  grad at x: [ 1.58719471e-04 -3.00301635e-05]  gradient norm: 0.00016153538718796954\n",
            "iter: 936831  x: [ 3.99995924 15.9996739 ]  f(x): 1.6616443012722799e-09  grad at x: [ 7.74820579e-05 -1.98756861e-05]  gradient norm: 7.99907006420013e-05\n",
            "iter: 936832  x: [ 3.99995924 15.9996739 ]  f(x): 1.6615954554140554e-09  grad at x: [-2.48522008e-06 -9.87997009e-06]  gradient norm: 1.0187744003502811e-05\n",
            "iter: 936833  x: [ 3.99995924 15.9996739 ]  f(x): 1.661542947413068e-09  grad at x: [ 7.75315349e-05 -1.98815596e-05]  gradient norm: 8.004008573733352e-05\n",
            "iter: 936834  x: [ 3.99995924 15.99967391]  f(x): 1.6614940422571532e-09  grad at x: [-2.48594812e-06 -9.87956810e-06]  gradient norm: 1.018753178388329e-05\n",
            "iter: 936835  x: [ 3.99995924 15.99967391]  f(x): 1.6614415993160965e-09  grad at x: [ 7.7580619e-05 -1.9887384e-05]  gradient norm: 8.008907850492284e-05\n",
            "iter: 936836  x: [ 3.99995924 15.99967392]  f(x): 1.6613926352909658e-09  grad at x: [-2.48669079e-06 -9.87916428e-06]  gradient norm: 1.0187321434260591e-05\n",
            "iter: 936837  x: [ 3.99995924 15.99967392]  f(x): 1.661340258566927e-09  grad at x: [ 7.76306344e-05 -1.98933249e-05]  gradient norm: 8.013900282281236e-05\n",
            "iter: 936838  x: [ 3.99995924 15.99967393]  f(x): 1.6612912345141066e-09  grad at x: [-2.48741899e-06 -9.87876228e-06]  gradient norm: 1.018710937961246e-05\n",
            "iter: 936839  x: [ 3.99995924 15.99967393]  f(x): 1.6612389229233453e-09  grad at x: [ 7.76797184e-05 -1.98991493e-05]  gradient norm: 8.018799652127561e-05\n",
            "iter: 936840  x: [ 3.99995924 15.99967394]  f(x): 1.6611898399273961e-09  grad at x: [-2.48816182e-06 -9.87835847e-06]  gradient norm: 1.0186899197757119e-05\n",
            "iter: 936841  x: [ 3.99995925 15.99967394]  f(x): 1.661137594627567e-09  grad at x: [ 7.77297481e-05 -1.99050919e-05]  gradient norm: 8.023793633752551e-05\n",
            "iter: 936842  x: [ 3.99995924 15.99967395]  f(x): 1.6610884515294462e-09  grad at x: [-2.48889016e-06 -9.87795647e-06]  gradient norm: 1.0186687308383308e-05\n",
            "iter: 936843  x: [ 3.99995925 15.99967395]  f(x): 1.6610362714362523e-09  grad at x: [ 7.77788319e-05 -1.99109163e-05]  gradient norm: 8.028693096472947e-05\n",
            "iter: 936844  x: [ 3.99995925 15.99967396]  f(x): 1.6609870693199734e-09  grad at x: [-2.48960404e-06 -9.87755629e-06]  gradient norm: 1.0186473708497816e-05\n",
            "iter: 936845  x: [ 3.99995925 15.99967396]  f(x): 1.6609349533807394e-09  grad at x: [ 7.78270134e-05 -1.99166279e-05]  gradient norm: 8.033502402176226e-05\n",
            "iter: 936846  x: [ 3.99995925 15.99967396]  f(x): 1.660885693282254e-09  grad at x: [-2.49034709e-06 -9.87715248e-06]  gradient norm: 1.0186263776049538e-05\n",
            "iter: 936847  x: [ 3.99995925 15.99967397]  f(x): 1.6608336437804747e-09  grad at x: [ 7.78770575e-05 -1.99225724e-05]  gradient norm: 8.038497978792992e-05\n",
            "iter: 936848  x: [ 3.99995925 15.99967397]  f(x): 1.660784323432446e-09  grad at x: [-2.49107566e-06 -9.87675048e-06]  gradient norm: 1.0186052132915262e-05\n",
            "iter: 936849  x: [ 3.99995925 15.99967398]  f(x): 1.6607323392809263e-09  grad at x: [ 7.79261702e-05 -1.99284004e-05]  gradient norm: 8.043400488541673e-05\n",
            "iter: 936850  x: [ 3.99995925 15.99967398]  f(x): 1.6606829597713719e-09  grad at x: [-2.49181887e-06 -9.87634667e-06]  gradient norm: 1.0185842368451077e-05\n",
            "iter: 936851  x: [ 3.99995925 15.99967399]  f(x): 1.6606310421667762e-09  grad at x: [ 7.79762432e-05 -1.99343485e-05]  gradient norm: 8.048399069085945e-05\n",
            "iter: 936852  x: [ 3.99995925 15.99967399]  f(x): 1.6605816022976424e-09  grad at x: [-2.49254760e-06 -9.87594467e-06]  gradient norm: 1.0185630890806109e-05\n",
            "iter: 936853  x: [ 3.99995925 15.999674  ]  f(x): 1.66052975011676e-09  grad at x: [ 7.80253557e-05 -1.99401766e-05]  gradient norm: 8.053301670683745e-05\n",
            "iter: 936854  x: [ 3.99995925 15.999674  ]  f(x): 1.6604802509945378e-09  grad at x: [-2.49330550e-06 -9.87553904e-06]  gradient norm: 1.0185423092505829e-05\n",
            "iter: 936855  x: [ 3.99995925 15.99967401]  f(x): 1.6604284665980078e-09  grad at x: [ 7.80763745e-05 -1.99462429e-05]  gradient norm: 8.058394917592292e-05\n",
            "iter: 936856  x: [ 3.99995925 15.99967401]  f(x): 1.660378905896861e-09  grad at x: [-2.49406349e-06 -9.87513340e-06]  gradient norm: 1.0185215381222661e-05\n",
            "iter: 936857  x: [ 3.99995926 15.99967402]  f(x): 1.6603271892885156e-09  grad at x: [ 7.81273787e-05 -1.99523074e-05]  gradient norm: 8.063486758702994e-05\n",
            "iter: 936858  x: [ 3.99995925 15.99967402]  f(x): 1.6602775669856787e-09  grad at x: [-2.49480700e-06 -9.87472959e-06]  gradient norm: 1.0185005956067192e-05\n",
            "iter: 936859  x: [ 3.99995926 15.99967403]  f(x): 1.6602259170762335e-09  grad at x: [ 7.81774514e-05 -1.99582555e-05]  gradient norm: 8.068485529236187e-05\n",
            "iter: 936860  x: [ 3.99995926 15.99967403]  f(x): 1.6601762342618147e-09  grad at x: [-2.49556513e-06 -9.87432395e-06]  gradient norm: 1.0184798417475396e-05\n",
            "iter: 936861  x: [ 3.99995926 15.99967404]  f(x): 1.660124652218338e-09  grad at x: [ 7.82284554e-05 -1.99643200e-05]  gradient norm: 8.073577467455803e-05\n",
            "iter: 936862  x: [ 3.99995926 15.99967404]  f(x): 1.6600749077238783e-09  grad at x: [-2.49630879e-06 -9.87392013e-06]  gradient norm: 1.0184589162474013e-05\n",
            "iter: 936863  x: [ 3.99995926 15.99967405]  f(x): 1.6600233924201762e-09  grad at x: [ 7.82785135e-05 -1.99702663e-05]  gradient norm: 8.078574877947784e-05\n",
            "iter: 936864  x: [ 3.99995926 15.99967405]  f(x): 1.6599735873715857e-09  grad at x: [-2.49703797e-06 -9.87351814e-06]  gradient norm: 1.018437818778745e-05\n",
            "iter: 936865  x: [ 3.99995926 15.99967406]  f(x): 1.659922137785055e-09  grad at x: [ 7.83276837e-05 -1.99761016e-05]  gradient norm: 8.083483577887758e-05\n",
            "iter: 936866  x: [ 3.99995926 15.99967406]  f(x): 1.659872273205762e-09  grad at x: [-2.49778179e-06 -9.87311432e-06]  gradient norm: 1.0184169100901641e-05\n",
            "iter: 936867  x: [ 3.99995926 15.99967407]  f(x): 1.6598208904694178e-09  grad at x: [ 7.83777562e-05 -1.99820497e-05]  gradient norm: 8.088482536012777e-05\n",
            "iter: 936868  x: [ 3.99995926 15.99967407]  f(x): 1.659770965225015e-09  grad at x: [-2.49851112e-06 -9.87271233e-06]  gradient norm: 1.0183958291833067e-05\n",
            "iter: 936869  x: [ 3.99995926 15.99967408]  f(x): 1.6597196482794255e-09  grad at x: [ 7.84269263e-05 -1.99878850e-05]  gradient norm: 8.093391326566968e-05\n",
            "iter: 936870  x: [ 3.99995926 15.99967408]  f(x): 1.659669663412634e-09  grad at x: [-2.49926964e-06 -9.87230669e-06]  gradient norm: 1.0183751181290067e-05\n",
            "iter: 936871  x: [ 3.99995926 15.99967409]  f(x): 1.659618414559822e-09  grad at x: [ 7.84779590e-05 -1.99939532e-05]  gradient norm: 8.0984864122178e-05\n",
            "iter: 936872  x: [ 3.99995926 15.99967409]  f(x): 1.6595683677847645e-09  grad at x: [-2.50001368e-06 -9.87190288e-06]  gradient norm: 1.018354234839004e-05\n",
            "iter: 936873  x: [ 3.99995927 15.9996741 ]  f(x): 1.659517185930513e-09  grad at x: [ 7.85280603e-05 -1.99999049e-05]  gradient norm: 8.103488420078974e-05\n",
            "iter: 936874  x: [ 3.99995926 15.9996741 ]  f(x): 1.6594670783422331e-09  grad at x: [-2.50077234e-06 -9.87149724e-06]  gradient norm: 1.0183335410629208e-05\n",
            "iter: 936875  x: [ 3.99995927 15.99967411]  f(x): 1.6594159646935275e-09  grad at x: [ 7.85791220e-05 -2.00059767e-05]  gradient norm: 8.108586511678175e-05\n",
            "iter: 936876  x: [ 3.99995927 15.99967411]  f(x): 1.6593657950836462e-09  grad at x: [-2.50151653e-06 -9.87109343e-06]  gradient norm: 1.0183126748407563e-05\n",
            "iter: 936877  x: [ 3.99995927 15.99967412]  f(x): 1.6593147485099588e-09  grad at x: [ 7.86292232e-05 -2.00119284e-05]  gradient norm: 8.113588613049314e-05\n",
            "iter: 936878  x: [ 3.99995927 15.99967412]  f(x): 1.6592645180098311e-09  grad at x: [-2.50227535e-06 -9.87068779e-06]  gradient norm: 1.0182919983953627e-05\n",
            "iter: 936879  x: [ 3.99995927 15.99967413]  f(x): 1.6592135397196285e-09  grad at x: [ 7.86802847e-05 -2.00180002e-05]  gradient norm: 8.118686800105359e-05\n",
            "iter: 936880  x: [ 3.99995927 15.99967413]  f(x): 1.659163247119394e-09  grad at x: [-2.50301969e-06 -9.87028398e-06]  gradient norm: 1.0182711492498444e-05\n",
            "iter: 936881  x: [ 3.99995927 15.99967414]  f(x): 1.6591123360156306e-09  grad at x: [ 7.87304148e-05 -2.00239556e-05]  gradient norm: 8.123691905010255e-05\n",
            "iter: 936882  x: [ 3.99995927 15.99967414]  f(x): 1.6590619824120514e-09  grad at x: [-2.50374956e-06 -9.86988198e-06]  gradient norm: 1.0182501270763032e-05\n",
            "iter: 936883  x: [ 3.99995927 15.99967415]  f(x): 1.6590111373955463e-09  grad at x: [ 7.87796135e-05 -2.00297945e-05]  gradient norm: 8.128603925167524e-05\n",
            "iter: 936884  x: [ 3.99995927 15.99967415]  f(x): 1.6589607238710995e-09  grad at x: [-2.50450861e-06 -9.86947634e-06]  gradient norm: 1.0182294764208052e-05\n",
            "iter: 936885  x: [ 3.99995927 15.99967416]  f(x): 1.6589099472539335e-09  grad at x: [ 7.88306748e-05 -2.00358663e-05]  gradient norm: 8.133702252982995e-05\n",
            "iter: 936886  x: [ 3.99995927 15.99967416]  f(x): 1.6588594715126767e-09  grad at x: [-2.50525318e-06 -9.86907253e-06]  gradient norm: 1.0182086527198111e-05\n",
            "iter: 936887  x: [ 3.99995927 15.99967417]  f(x): 1.6588087621956683e-09  grad at x: [ 7.88808047e-05 -2.00418217e-05]  gradient norm: 8.138707495853113e-05\n",
            "iter: 936888  x: [ 3.99995927 15.99967417]  f(x): 1.6587582253376115e-09  grad at x: [-2.50601238e-06 -9.86866689e-06]  gradient norm: 1.0181880193734279e-05\n",
            "iter: 936889  x: [ 3.99995928 15.99967418]  f(x): 1.6587075844979016e-09  grad at x: [ 7.89318659e-05 -2.00478935e-05]  gradient norm: 8.143805918134068e-05\n",
            "iter: 936890  x: [ 3.99995927 15.99967418]  f(x): 1.6586696350243687e-09  grad at x: [ 3.82125471e-05 -1.49580774e-05]  gradient norm: 4.103587253787619e-05\n",
            "iter: 936891  x: [ 3.99995927 15.99967418]  f(x): 1.6586561975198058e-09  grad at x: [-1.87012269e-06 -9.94783841e-06]  gradient norm: 1.012209700921903e-05\n",
            "iter: 936892  x: [ 3.99995928 15.99967422]  f(x): 1.6584523575351165e-09  grad at x: [ 1.58558555e-04 -2.99998010e-05]  gradient norm: 0.00016137163172573764\n",
            "iter: 936893  x: [ 3.99995928 15.99967422]  f(x): 1.658303929773219e-09  grad at x: [ 7.74035210e-05 -1.98556208e-05]  gradient norm: 7.99096411065409e-05\n",
            "iter: 936894  x: [ 3.99995928 15.99967422]  f(x): 1.6582551828643919e-09  grad at x: [-2.48271657e-06 -9.87003477e-06]  gradient norm: 1.0177498121804471e-05\n",
            "iter: 936895  x: [ 3.99995928 15.99967423]  f(x): 1.6582027800641068e-09  grad at x: [ 7.74532721e-05 -1.98615289e-05]  gradient norm: 7.995930018379518e-05\n",
            "iter: 936896  x: [ 3.99995928 15.99967423]  f(x): 1.6581539735757738e-09  grad at x: [-2.48344712e-06 -9.86963278e-06]  gradient norm: 1.0177286512416756e-05\n",
            "iter: 936897  x: [ 3.99995928 15.99967424]  f(x): 1.658101635970234e-09  grad at x: [ 7.75025283e-05 -1.98673752e-05]  gradient norm: 8.000846510311844e-05\n",
            "iter: 936898  x: [ 3.99995928 15.99967424]  f(x): 1.658052770468536e-09  grad at x: [-2.48419230e-06 -9.86922896e-06]  gradient norm: 1.0177076773476988e-05\n",
            "iter: 936899  x: [ 3.99995928 15.99967425]  f(x): 1.6580004992139621e-09  grad at x: [ 7.75527158e-05 -1.98733378e-05]  gradient norm: 8.00585615751297e-05\n",
            "iter: 936900  x: [ 3.99995928 15.99967425]  f(x): 1.6579515735237621e-09  grad at x: [-2.48493755e-06 -9.86882515e-06]  gradient norm: 1.0176867119452319e-05\n",
            "iter: 936901  x: [ 3.99995929 15.99967426]  f(x): 1.6578993686236876e-09  grad at x: [ 7.76028741e-05 -1.98792968e-05]  gradient norm: 8.010862943636173e-05\n",
            "iter: 936902  x: [ 3.99995928 15.99967426]  f(x): 1.6578503827587005e-09  grad at x: [-2.48566832e-06 -9.86842315e-06]  gradient norm: 1.0176655759481859e-05\n",
            "iter: 936903  x: [ 3.99995929 15.99967427]  f(x): 1.6577982431644996e-09  grad at x: [ 7.76521301e-05 -1.98851430e-05]  gradient norm: 8.015779576901848e-05\n",
            "iter: 936904  x: [ 3.99995929 15.99967427]  f(x): 1.6577491981741716e-09  grad at x: [-2.48641372e-06 -9.86801933e-06]  gradient norm: 1.0176446273744383e-05\n",
            "iter: 936905  x: [ 3.99995929 15.99967428]  f(x): 1.657697125078696e-09  grad at x: [ 7.77023465e-05 -1.98911093e-05]  gradient norm: 8.020792277759944e-05\n",
            "iter: 936906  x: [ 3.99995929 15.99967428]  f(x): 1.6576480197687886e-09  grad at x: [-2.48714465e-06 -9.86761734e-06]  gradient norm: 1.017623508020945e-05\n",
            "iter: 936907  x: [ 3.99995929 15.99967429]  f(x): 1.6575960120530742e-09  grad at x: [ 7.77516023e-05 -1.98969556e-05]  gradient norm: 8.025709004525344e-05\n",
            "iter: 936908  x: [ 3.99995929 15.99967429]  f(x): 1.6575468475258446e-09  grad at x: [-2.48790476e-06 -9.86721170e-06]  gradient norm: 1.0176027557016617e-05\n",
            "iter: 936909  x: [ 3.99995929 15.9996743 ]  f(x): 1.6574949074728346e-09  grad at x: [ 7.78027208e-05 -1.99030346e-05]  gradient norm: 8.030812004593912e-05\n",
            "iter: 936910  x: [ 3.99995929 15.9996743 ]  f(x): 1.6574456814614816e-09  grad at x: [-2.48865039e-06 -9.86680789e-06]  gradient norm: 1.0175818326070259e-05\n",
            "iter: 936911  x: [ 3.99995929 15.99967431]  f(x): 1.657393808021271e-09  grad at x: [ 7.78529369e-05 -1.99090009e-05]  gradient norm: 8.035824849796275e-05\n",
            "iter: 936912  x: [ 3.99995929 15.99967431]  f(x): 1.6573445215765211e-09  grad at x: [-2.48941064e-06 -9.86640225e-06]  gradient norm: 1.0175610976278463e-05\n",
            "iter: 936913  x: [ 3.99995929 15.99967432]  f(x): 1.657292715911774e-09  grad at x: [ 7.79040843e-05 -1.99150836e-05]  gradient norm: 8.040930858607956e-05\n",
            "iter: 936914  x: [ 3.99995929 15.99967432]  f(x): 1.6572433678695751e-09  grad at x: [-2.49015642e-06 -9.86599844e-06]  gradient norm: 1.0175401916188466e-05\n",
            "iter: 936915  x: [ 3.99995929 15.99967433]  f(x): 1.657191628894418e-09  grad at x: [ 7.79543003e-05 -1.99210499e-05]  gradient norm: 8.04594380030628e-05\n",
            "iter: 936916  x: [ 3.99995929 15.99967433]  f(x): 1.657142220322835e-09  grad at x: [-2.49090228e-06 -9.86559462e-06]  gradient norm: 1.0175192941189143e-05\n",
            "iter: 936917  x: [ 3.9999593  15.99967434]  f(x): 1.6570905480753078e-09  grad at x: [ 7.80045162e-05 -1.99270162e-05]  gradient norm: 8.05095678978012e-05\n",
            "iter: 936918  x: [ 3.99995929 15.99967434]  f(x): 1.6570410789546498e-09  grad at x: [-2.49166277e-06 -9.86518899e-06]  gradient norm: 1.0174985850958324e-05\n",
            "iter: 936919  x: [ 3.9999593  15.99967435]  f(x): 1.656989474599568e-09  grad at x: [ 7.80556634e-05 -1.99330989e-05]  gradient norm: 8.05606294548766e-05\n",
            "iter: 936920  x: [ 3.9999593  15.99967435]  f(x): 1.6569399437811543e-09  grad at x: [-2.49239422e-06 -9.86478699e-06]  gradient norm: 1.0174775245897982e-05\n",
            "iter: 936921  x: [ 3.9999593  15.99967436]  f(x): 1.6568884051022684e-09  grad at x: [ 7.81049624e-05 -1.99389506e-05]  gradient norm: 8.060984366263463e-05\n",
            "iter: 936922  x: [ 3.9999593  15.99967436]  f(x): 1.6568388147670172e-09  grad at x: [-2.49312576e-06 -9.86438499e-06]  gradient norm: 1.0174564723662704e-05\n",
            "iter: 936923  x: [ 3.9999593  15.99967437]  f(x): 1.6567873418364054e-09  grad at x: [ 7.81542758e-05 -1.99448041e-05]  gradient norm: 8.06590728759655e-05\n",
            "iter: 936924  x: [ 3.9999593  15.99967437]  f(x): 1.6567376919119571e-09  grad at x: [-2.49385736e-06 -9.86398300e-06]  gradient norm: 1.01743542838387e-05\n",
            "iter: 936925  x: [ 3.9999593  15.99967438]  f(x): 1.6566862847315597e-09  grad at x: [ 7.82035601e-05 -1.99506540e-05]  gradient norm: 8.070827344276253e-05\n",
            "iter: 936926  x: [ 3.9999593  15.99967438]  f(x): 1.6566365752343214e-09  grad at x: [-2.49460360e-06 -9.86357918e-06]  gradient norm: 1.017414573161644e-05\n",
            "iter: 936927  x: [ 3.9999593  15.99967439]  f(x): 1.656585235005106e-09  grad at x: [ 7.82538047e-05 -1.99566239e-05]  gradient norm: 8.075843478707435e-05\n",
            "iter: 936928  x: [ 3.9999593  15.99967439]  f(x): 1.6565354647327199e-09  grad at x: [-2.49533536e-06 -9.86317718e-06]  gradient norm: 1.017393545848815e-05\n",
            "iter: 936929  x: [ 3.9999593 15.9996744]  f(x): 1.656484190362465e-09  grad at x: [ 7.83031179e-05 -1.99624774e-05]  gradient norm: 8.080766536677952e-05\n",
            "iter: 936930  x: [ 3.9999593 15.9996744]  f(x): 1.656434360407977e-09  grad at x: [-2.49608175e-06 -9.86277337e-06]  gradient norm: 1.0173727075337578e-05\n",
            "iter: 936931  x: [ 3.9999593  15.99967441]  f(x): 1.6563831530991517e-09  grad at x: [ 7.83533915e-05 -1.99684509e-05]  gradient norm: 8.085785674403112e-05\n",
            "iter: 936932  x: [ 3.9999593  15.99967441]  f(x): 1.656333262241183e-09  grad at x: [-2.49682821e-06 -9.86236955e-06]  gradient norm: 1.0173518777017096e-05\n",
            "iter: 936933  x: [ 3.9999593  15.99967442]  f(x): 1.6562821219970958e-09  grad at x: [ 7.84036359e-05 -1.99744209e-05]  gradient norm: 8.090801948928394e-05\n",
            "iter: 936934  x: [ 3.9999593  15.99967442]  f(x): 1.6562321702495752e-09  grad at x: [-2.49756020e-06 -9.86196756e-06]  gradient norm: 1.0173308754781926e-05\n",
            "iter: 936935  x: [ 3.99995931 15.99967443]  f(x): 1.656181096010718e-09  grad at x: [ 7.8452978e-05 -1.9980278e-05]  gradient norm: 8.09572805414131e-05\n",
            "iter: 936936  x: [ 3.9999593  15.99967443]  f(x): 1.6561310844339786e-09  grad at x: [-2.49830682e-06 -9.86156374e-06]  gradient norm: 1.0173100625663825e-05\n",
            "iter: 936937  x: [ 3.99995931 15.99967444]  f(x): 1.6560800773701948e-09  grad at x: [ 7.85032514e-05 -1.99862516e-05]  gradient norm: 8.100747331480038e-05\n",
            "iter: 936938  x: [ 3.99995931 15.99967444]  f(x): 1.656030004775485e-09  grad at x: [-2.49905351e-06 -9.86115992e-06]  gradient norm: 1.0172892581877369e-05\n",
            "iter: 936939  x: [ 3.99995931 15.99967445]  f(x): 1.6559790649249017e-09  grad at x: [ 7.85535247e-05 -1.99922251e-05]  gradient norm: 8.105766655427425e-05\n",
            "iter: 936940  x: [ 3.99995931 15.99967445]  f(x): 1.6559289312924388e-09  grad at x: [-2.49981483e-06 -9.86075429e-06]  gradient norm: 1.0172686435960892e-05\n",
            "iter: 936941  x: [ 3.99995931 15.99967446]  f(x): 1.6558780598632781e-09  grad at x: [ 7.86047438e-05 -1.99983169e-05]  gradient norm: 8.110880610233995e-05\n",
            "iter: 936942  x: [ 3.99995931 15.99967446]  f(x): 1.6558278639834475e-09  grad at x: [-2.50056167e-06 -9.86035047e-06]  gradient norm: 1.01724785636448e-05\n",
            "iter: 936943  x: [ 3.99995931 15.99967447]  f(x): 1.6557770598444631e-09  grad at x: [ 7.86550169e-05 -2.00042905e-05]  gradient norm: 8.115900028234309e-05\n",
            "iter: 936944  x: [ 3.99995931 15.99967447]  f(x): 1.6557268028493384e-09  grad at x: [-2.50132314e-06 -9.85994484e-06]  gradient norm: 1.0172272592055528e-05\n",
            "iter: 936945  x: [ 3.99995931 15.99967448]  f(x): 1.6556760671740763e-09  grad at x: [ 7.87062359e-05 -2.00103823e-05]  gradient norm: 8.12101407883753e-05\n",
            "iter: 936946  x: [ 3.99995931 15.99967448]  f(x): 1.6556257478712036e-09  grad at x: [-2.50208469e-06 -9.85953920e-06]  gradient norm: 1.0172066707825831e-05\n",
            "iter: 936947  x: [ 3.99995931 15.99967449]  f(x): 1.6555750806998357e-09  grad at x: [ 7.87574402e-05 -2.00164723e-05]  gradient norm: 8.126126722427001e-05\n",
            "iter: 936948  x: [ 3.99995931 15.99967449]  f(x): 1.655524699066276e-09  grad at x: [-2.50283176e-06 -9.85913539e-06]  gradient norm: 1.0171859093687983e-05\n",
            "iter: 936949  x: [ 3.99995931 15.9996745 ]  f(x): 1.655474099335899e-09  grad at x: [ 7.88077422e-05 -2.00224495e-05]  gradient norm: 8.131149191470237e-05\n",
            "iter: 936950  x: [ 3.99995931 15.9996745 ]  f(x): 1.6554236564167593e-09  grad at x: [-2.50357890e-06 -9.85873157e-06]  gradient norm: 1.0171651565014002e-05\n",
            "iter: 936951  x: [ 3.99995932 15.99967451]  f(x): 1.655373124165544e-09  grad at x: [ 7.88580442e-05 -2.00284267e-05]  gradient norm: 8.136171706747199e-05\n",
            "iter: 936952  x: [ 3.99995932 15.99967451]  f(x): 1.6553352458696144e-09  grad at x: [ 3.81768663e-05 -1.49433781e-05]  gradient norm: 4.099728856115242e-05\n",
            "iter: 936953  x: [ 3.99995931 15.99967451]  f(x): 1.655321833704566e-09  grad at x: [-1.86830293e-06 -9.93782669e-06]  gradient norm: 1.0111921436305888e-05\n",
            "iter: 936954  x: [ 3.99995932 15.99967455]  f(x): 1.6551184419645437e-09  grad at x: [ 1.58414889e-04 -2.99716048e-05]  gradient norm: 0.0001612252275364834\n",
            "iter: 936955  x: [ 3.99995932 15.99967455]  f(x): 1.6549702834009756e-09  grad at x: [ 7.73334293e-05 -1.98366215e-05]  gradient norm: 7.983702671502914e-05\n",
            "iter: 936956  x: [ 3.99995932 15.99967455]  f(x): 1.654921625196815e-09  grad at x: [-2.48032463e-06 -9.86009582e-06]  gradient norm: 1.016727592597746e-05\n",
            "iter: 936957  x: [ 3.99995932 15.99967456]  f(x): 1.6548693358149012e-09  grad at x: [ 7.73821155e-05 -1.98423968e-05]  gradient norm: 7.988562145331471e-05\n",
            "iter: 936958  x: [ 3.99995932 15.99967456]  f(x): 1.6548206193606135e-09  grad at x: [-2.48105767e-06 -9.85969382e-06]  gradient norm: 1.0167064934631617e-05\n",
            "iter: 936959  x: [ 3.99995932 15.99967457]  f(x): 1.6547683953140936e-09  grad at x: [ 7.74315293e-05 -1.98482630e-05]  gradient norm: 7.993494405029494e-05\n",
            "iter: 936960  x: [ 3.99995932 15.99967457]  f(x): 1.654719619713987e-09  grad at x: [-2.48179080e-06 -9.85929182e-06]  gradient norm: 1.016685402651817e-05\n",
            "iter: 936961  x: [ 3.99995932 15.99967458]  f(x): 1.654667460969144e-09  grad at x: [ 7.74809140e-05 -1.98541256e-05]  gradient norm: 7.998423802184595e-05\n",
            "iter: 936962  x: [ 3.99995932 15.99967458]  f(x): 1.6546186262030105e-09  grad at x: [-2.48253855e-06 -9.85888801e-06]  gradient norm: 1.0166644990425809e-05\n",
            "iter: 936963  x: [ 3.99995933 15.99967459]  f(x): 1.6545665339512166e-09  grad at x: [ 7.75312444e-05 -1.98601065e-05]  gradient norm: 8.003447810906414e-05\n",
            "iter: 936964  x: [ 3.99995932 15.99967459]  f(x): 1.6545176388624294e-09  grad at x: [-2.48327182e-06 -9.85848601e-06]  gradient norm: 1.0166434249133453e-05\n",
            "iter: 936965  x: [ 3.99995933 15.9996746 ]  f(x): 1.6544656120218714e-09  grad at x: [ 7.75806434e-05 -1.98659709e-05]  gradient norm: 8.008378757393512e-05\n",
            "iter: 936966  x: [ 3.99995933 15.9996746 ]  f(x): 1.6544166576930627e-09  grad at x: [-2.48401972e-06 -9.85808219e-06]  gradient norm: 1.0166225382460364e-05\n",
            "iter: 936967  x: [ 3.99995933 15.99967461]  f(x): 1.6543646974557448e-09  grad at x: [ 7.76310028e-05 -1.98719554e-05]  gradient norm: 8.013405771938085e-05\n",
            "iter: 936968  x: [ 3.99995933 15.99967461]  f(x): 1.6543156826760146e-09  grad at x: [-2.48476770e-06 -9.85767838e-06]  gradient norm: 1.0166016601228117e-05\n",
            "iter: 936969  x: [ 3.99995933 15.99967462]  f(x): 1.6542637890801972e-09  grad at x: [ 7.76813621e-05 -1.98779398e-05]  gradient norm: 8.018432835291389e-05\n",
            "iter: 936970  x: [ 3.99995933 15.99967462]  f(x): 1.654214713828514e-09  grad at x: [-2.48550120e-06 -9.85727638e-06]  gradient norm: 1.0165806111126464e-05\n",
            "iter: 936971  x: [ 3.99995933 15.99967463]  f(x): 1.6541628857902968e-09  grad at x: [ 7.77307900e-05 -1.98838079e-05]  gradient norm: 8.023366833044568e-05\n",
            "iter: 936972  x: [ 3.99995933 15.99967463]  f(x): 1.6541137511513812e-09  grad at x: [-2.48624933e-06 -9.85687257e-06]  gradient norm: 1.016559749922774e-05\n",
            "iter: 936973  x: [ 3.99995933 15.99967464]  f(x): 1.6540619897951363e-09  grad at x: [ 7.77811346e-05 -1.98897906e-05]  gradient norm: 8.028392537137549e-05\n",
            "iter: 936974  x: [ 3.99995933 15.99967464]  f(x): 1.6540127946246177e-09  grad at x: [-2.48696843e-06 -9.85647239e-06]  gradient norm: 1.0165385379730276e-05\n",
            "iter: 936975  x: [ 3.99995933 15.99967465]  f(x): 1.6539610978121283e-09  grad at x: [ 7.78296456e-05 -1.98955440e-05]  gradient norm: 8.033234967544973e-05\n",
            "iter: 936976  x: [ 3.99995933 15.99967465]  f(x): 1.6539118442676575e-09  grad at x: [-2.48770216e-06 -9.85607039e-06]  gradient norm: 1.0165175138478732e-05\n",
            "iter: 936977  x: [ 3.99995933 15.99967466]  f(x): 1.6538602131578815e-09  grad at x: [ 7.78791024e-05 -1.99014157e-05]  gradient norm: 8.038172013935675e-05\n",
            "iter: 936978  x: [ 3.99995933 15.99967466]  f(x): 1.6538109000627114e-09  grad at x: [-2.48846507e-06 -9.85566476e-06]  gradient norm: 1.0164968578181418e-05\n",
            "iter: 936979  x: [ 3.99995934 15.99967467]  f(x): 1.6537593369424832e-09  grad at x: [ 7.79304217e-05 -1.99075203e-05]  gradient norm: 8.043295342029733e-05\n",
            "iter: 936980  x: [ 3.99995933 15.99967467]  f(x): 1.6537099620259007e-09  grad at x: [-2.48921350e-06 -9.85526094e-06]  gradient norm: 1.0164760305428707e-05\n",
            "iter: 936981  x: [ 3.99995934 15.99967468]  f(x): 1.6536584657746273e-09  grad at x: [ 7.79807806e-05 -1.99135047e-05]  gradient norm: 8.048322691445921e-05\n",
            "iter: 936982  x: [ 3.99995934 15.99967468]  f(x): 1.6536090301394367e-09  grad at x: [-2.48996201e-06 -9.85485713e-06]  gradient norm: 1.0164552118270612e-05\n",
            "iter: 936983  x: [ 3.99995934 15.99967469]  f(x): 1.6535576008300305e-09  grad at x: [ 7.80311685e-05 -1.99194928e-05]  gradient norm: 8.053352998533314e-05\n",
            "iter: 936984  x: [ 3.99995934 15.99967469]  f(x): 1.6535081044391535e-09  grad at x: [-2.49071059e-06 -9.85445331e-06]  gradient norm: 1.0164344016511624e-05\n",
            "iter: 936985  x: [ 3.99995934 15.9996747 ]  f(x): 1.6534567421091974e-09  grad at x: [ 7.80815709e-05 -1.99254828e-05]  gradient norm: 8.058384808469235e-05\n",
            "iter: 936986  x: [ 3.99995934 15.9996747 ]  f(x): 1.6534071848700422e-09  grad at x: [-2.49144470e-06 -9.85405131e-06]  gradient norm: 1.0164134196676918e-05\n",
            "iter: 936987  x: [ 3.99995934 15.99967471]  f(x): 1.65335588843073e-09  grad at x: [ 7.81310273e-05 -1.99313545e-05]  gradient norm: 8.063322089313856e-05\n",
            "iter: 936988  x: [ 3.99995934 15.99967471]  f(x): 1.6533062714690429e-09  grad at x: [-2.49219343e-06 -9.85364750e-06]  gradient norm: 1.0163926264600779e-05\n",
            "iter: 936989  x: [ 3.99995934 15.99967472]  f(x): 1.6532550421212188e-09  grad at x: [ 7.81814295e-05 -1.99373444e-05]  gradient norm: 8.068353993405081e-05\n",
            "iter: 936990  x: [ 3.99995934 15.99967472]  f(x): 1.6532053642347664e-09  grad at x: [-2.49292769e-06 -9.85324550e-06]  gradient norm: 1.0163716612368898e-05\n",
            "iter: 936991  x: [ 3.99995934 15.99967473]  f(x): 1.6531542008868105e-09  grad at x: [ 7.82309148e-05 -1.99432197e-05]  gradient norm: 8.073294276651716e-05\n",
            "iter: 936992  x: [ 3.99995934 15.99967473]  f(x): 1.6531044631505345e-09  grad at x: [-2.49369113e-06 -9.85283987e-06]  gradient norm: 1.0163510657300517e-05\n",
            "iter: 936993  x: [ 3.99995934 15.99967474]  f(x): 1.653053368099314e-09  grad at x: [ 7.82822628e-05 -1.99493279e-05]  gradient norm: 8.078420854162402e-05\n",
            "iter: 936994  x: [ 3.99995934 15.99967474]  f(x): 1.6530035682499627e-09  grad at x: [-2.49442554e-06 -9.85243787e-06]  gradient norm: 1.0163301173919196e-05\n",
            "iter: 936995  x: [ 3.99995935 15.99967475]  f(x): 1.6529525392384246e-09  grad at x: [ 7.83317334e-05 -1.99552014e-05]  gradient norm: 8.083359775008641e-05\n",
            "iter: 936996  x: [ 3.99995934 15.99967475]  f(x): 1.6529026794802635e-09  grad at x: [-2.49517458e-06 -9.85203405e-06]  gradient norm: 1.0163093583088325e-05\n",
            "iter: 936997  x: [ 3.99995935 15.99967476]  f(x): 1.6528517177121693e-09  grad at x: [ 7.83821499e-05 -1.99611932e-05]  gradient norm: 8.088393322806367e-05\n",
            "iter: 936998  x: [ 3.99995935 15.99967476]  f(x): 1.6528017968761583e-09  grad at x: [-2.49590914e-06 -9.85163206e-06]  gradient norm: 1.0162884267047874e-05\n",
            "iter: 936999  x: [ 3.99995935 15.99967477]  f(x): 1.6527509012577444e-09  grad at x: [ 7.84316349e-05 -1.99670685e-05]  gradient norm: 8.093333790179065e-05\n",
            "iter: 937000  x: [ 3.99995935 15.99967477]  f(x): 1.6527009204198643e-09  grad at x: [-2.49664378e-06 -9.85123006e-06]  gradient norm: 1.0162675034456885e-05\n",
            "iter: 937001  x: [ 3.99995935 15.99967478]  f(x): 1.6526500910583923e-09  grad at x: [ 7.84811636e-05 -1.99729493e-05]  gradient norm: 8.09827866789456e-05\n",
            "iter: 937002  x: [ 3.99995935 15.99967478]  f(x): 1.652600050129708e-09  grad at x: [-2.49739304e-06 -9.85082625e-06]  gradient norm: 1.0162467697985324e-05\n",
            "iter: 937003  x: [ 3.99995935 15.99967479]  f(x): 1.6525492881253204e-09  grad at x: [ 7.85315798e-05 -1.99789411e-05]  gradient norm: 8.103312354806152e-05\n",
            "iter: 937004  x: [ 3.99995935 15.99967479]  f(x): 1.652499186005407e-09  grad at x: [-2.49815693e-06 -9.85042061e-06]  gradient norm: 1.0162262261638207e-05\n",
            "iter: 937005  x: [ 3.99995935 15.9996748 ]  f(x): 1.6524484925300919e-09  grad at x: [ 7.85829419e-05 -1.99850510e-05]  gradient norm: 8.108440673727297e-05\n",
            "iter: 937006  x: [ 3.99995935 15.9996748 ]  f(x): 1.6523983280269637e-09  grad at x: [-2.49889180e-06 -9.85001861e-06]  gradient norm: 1.0162053282355379e-05\n",
            "iter: 937007  x: [ 3.99995935 15.99967481]  f(x): 1.6523477008861136e-09  grad at x: [ 7.86324557e-05 -1.99909300e-05]  gradient norm: 8.113384234175972e-05\n",
            "iter: 937008  x: [ 3.99995935 15.99967481]  f(x): 1.6522974761963153e-09  grad at x: [-2.49965584e-06 -9.84961298e-06]  gradient norm: 1.016184801967576e-05\n",
            "iter: 937009  x: [ 3.99995935 15.99967482]  f(x): 1.6522469176982422e-09  grad at x: [ 7.86838322e-05 -1.99970418e-05]  gradient norm: 8.11851410357714e-05\n",
            "iter: 937010  x: [ 3.99995935 15.99967482]  f(x): 1.6521966305295677e-09  grad at x: [-2.50040541e-06 -9.84920916e-06]  gradient norm: 1.0161641027209932e-05\n",
            "iter: 937011  x: [ 3.99995936 15.99967483]  f(x): 1.6521461396481996e-09  grad at x: [ 7.87343209e-05 -2.00030427e-05]  gradient norm: 8.123555253903567e-05\n",
            "iter: 937012  x: [ 3.99995935 15.99967483]  f(x): 1.652095791027548e-09  grad at x: [-2.50116961e-06 -9.84880353e-06]  gradient norm: 1.0161435939708516e-05\n",
            "iter: 937013  x: [ 3.99995936 15.99967484]  f(x): 1.6520453688323886e-09  grad at x: [ 7.87856826e-05 -2.00091526e-05]  gradient norm: 8.12868376407511e-05\n",
            "iter: 937014  x: [ 3.99995936 15.99967484]  f(x): 1.6520075602105887e-09  grad at x: [ 3.81418598e-05 -1.49287735e-05]  gradient norm: 4.095936701636311e-05\n",
            "iter: 937015  x: [ 3.99995936 15.99967484]  f(x): 1.65199417300145e-09  grad at x: [-1.86644912e-06 -9.92782952e-06]  gradient norm: 1.0101753876436207e-05\n",
            "iter: 937016  x: [ 3.99995936 15.99967488]  f(x): 1.6517912059333563e-09  grad at x: [ 1.58262073e-04 -2.99422754e-05]  gradient norm: 0.00016106962375209193\n",
            "iter: 937017  x: [ 3.99995936 15.99967488]  f(x): 1.6516433332624688e-09  grad at x: [ 7.72588604e-05 -1.98170728e-05]  gradient norm: 7.975993910005391e-05\n",
            "iter: 937018  x: [ 3.99995936 15.99967488]  f(x): 1.6515947690455984e-09  grad at x: [-2.47788409e-06 -9.85017323e-06]  gradient norm: 1.0157057751452337e-05\n",
            "iter: 937019  x: [ 3.99995936 15.99967489]  f(x): 1.6515425888957511e-09  grad at x: [ 7.73077333e-05 -1.98228718e-05]  gradient norm: 7.980872057605837e-05\n",
            "iter: 937020  x: [ 3.99995936 15.99967489]  f(x): 1.6514939662641756e-09  grad at x: [-2.47860508e-06 -9.84977305e-06]  gradient norm: 1.0156845586753818e-05\n",
            "iter: 937021  x: [ 3.99995936 15.9996749 ]  f(x): 1.6514418504003031e-09  grad at x: [ 7.73563443e-05 -1.98286380e-05]  gradient norm: 7.985724064458148e-05\n",
            "iter: 937022  x: [ 3.99995936 15.9996749 ]  f(x): 1.6513931696280145e-09  grad at x: [-2.47935525e-06 -9.84936923e-06]  gradient norm: 1.015663707984581e-05\n",
            "iter: 937023  x: [ 3.99995937 15.99967491]  f(x): 1.6513411203551591e-09  grad at x: [ 7.74068469e-05 -1.98346406e-05]  gradient norm: 7.990765244372659e-05\n",
            "iter: 937024  x: [ 3.99995936 15.99967491]  f(x): 1.651292379153229e-09  grad at x: [-2.48009094e-06 -9.84896724e-06]  gradient norm: 1.015642686883162e-05\n",
            "iter: 937025  x: [ 3.99995937 15.99967492]  f(x): 1.6512403953916253e-09  grad at x: [ 7.74564181e-05 -1.98405269e-05]  gradient norm: 7.99571336348197e-05\n",
            "iter: 937026  x: [ 3.99995937 15.99967492]  f(x): 1.651191594839536e-09  grad at x: [-2.48081216e-06 -9.84856706e-06]  gradient norm: 1.0156214950677231e-05\n",
            "iter: 937027  x: [ 3.99995937 15.99967493]  f(x): 1.6511396755073076e-09  grad at x: [ 7.75050580e-05 -1.98462967e-05]  gradient norm: 8.000568418752082e-05\n",
            "iter: 937028  x: [ 3.99995937 15.99967493]  f(x): 1.6510908166702604e-09  grad at x: [-2.48156256e-06 -9.84816324e-06]  gradient norm: 1.0156006697357017e-05\n",
            "iter: 937029  x: [ 3.99995937 15.99967494]  f(x): 1.6510389640423397e-09  grad at x: [ 7.75555604e-05 -1.98522994e-05]  gradient norm: 8.005609742932278e-05\n",
            "iter: 937030  x: [ 3.99995937 15.99967494]  f(x): 1.6509900446440205e-09  grad at x: [-2.48231303e-06 -9.84775943e-06]  gradient norm: 1.0155798529504624e-05\n",
            "iter: 937031  x: [ 3.99995937 15.99967495]  f(x): 1.6509382587588885e-09  grad at x: [ 7.76060627e-05 -1.98583020e-05]  gradient norm: 8.010651116098697e-05\n",
            "iter: 937032  x: [ 3.99995937 15.99967495]  f(x): 1.6508892787605354e-09  grad at x: [-2.48306358e-06 -9.84735561e-06]  gradient norm: 1.0155590447576171e-05\n",
            "iter: 937033  x: [ 3.99995937 15.99967496]  f(x): 1.6508375596911594e-09  grad at x: [ 7.76565941e-05 -1.98643083e-05]  gradient norm: 8.01569544772682e-05\n",
            "iter: 937034  x: [ 3.99995937 15.99967496]  f(x): 1.6507885190545074e-09  grad at x: [-2.48378510e-06 -9.84695544e-06]  gradient norm: 1.0155378860661852e-05\n",
            "iter: 937035  x: [ 3.99995937 15.99967497]  f(x): 1.6507368645613325e-09  grad at x: [ 7.77052336e-05 -1.98700782e-05]  gradient norm: 8.0205506885914e-05\n",
            "iter: 937036  x: [ 3.99995937 15.99967497]  f(x): 1.6506877654731788e-09  grad at x: [-2.48452125e-06 -9.84655344e-06]  gradient norm: 1.0155169151332723e-05\n",
            "iter: 937037  x: [ 3.99995937 15.99967498]  f(x): 1.6506361767488704e-09  grad at x: [ 7.77548335e-05 -1.98759681e-05]  gradient norm: 8.025501999833145e-05\n",
            "iter: 937038  x: [ 3.99995937 15.99967498]  f(x): 1.6505870180523548e-09  grad at x: [-2.48527203e-06 -9.84614962e-06]  gradient norm: 1.0154961323102219e-05\n",
            "iter: 937039  x: [ 3.99995938 15.99967499]  f(x): 1.6505354962572017e-09  grad at x: [ 7.78053646e-05 -1.98819744e-05]  gradient norm: 8.03054647432621e-05\n",
            "iter: 937040  x: [ 3.99995937 15.99967499]  f(x): 1.6504862767906492e-09  grad at x: [-2.48600833e-06 -9.84574763e-06]  gradient norm: 1.0154751782023584e-05\n",
            "iter: 937041  x: [ 3.99995938 15.999675  ]  f(x): 1.6504348208039437e-09  grad at x: [ 7.78549498e-05 -1.98878624e-05]  gradient norm: 8.035496424680245e-05\n",
            "iter: 937042  x: [ 3.99995938 15.999675  ]  f(x): 1.6503855416702912e-09  grad at x: [-2.48674471e-06 -9.84534563e-06]  gradient norm: 1.015454232441202e-05\n",
            "iter: 937043  x: [ 3.99995938 15.99967501]  f(x): 1.6503341515997918e-09  grad at x: [ 7.79045640e-05 -1.98937541e-05]  gradient norm: 8.040449331042435e-05\n",
            "iter: 937044  x: [ 3.99995938 15.99967501]  f(x): 1.650284812690999e-09  grad at x: [-2.48748116e-06 -9.84494363e-06]  gradient norm: 1.0154332950071545e-05\n",
            "iter: 937045  x: [ 3.99995938 15.99967502]  f(x): 1.6502334885731007e-09  grad at x: [ 7.79541927e-05 -1.98996477e-05]  gradient norm: 8.045403738952123e-05\n",
            "iter: 937046  x: [ 3.99995938 15.99967502]  f(x): 1.650184089853597e-09  grad at x: [-2.48824679e-06 -9.84453800e-06]  gradient norm: 1.0154127264404628e-05\n",
            "iter: 937047  x: [ 3.99995938 15.99967503]  f(x): 1.6501328339774938e-09  grad at x: [ 7.8005684e-05 -1.9905774e-05]  gradient norm: 8.050544434426478e-05\n",
            "iter: 937048  x: [ 3.99995938 15.99967503]  f(x): 1.650083373191674e-09  grad at x: [-2.48898339e-06 -9.84413600e-06]  gradient norm: 1.0153918059871139e-05\n",
            "iter: 937049  x: [ 3.99995938 15.99967504]  f(x): 1.6500321833092077e-09  grad at x: [ 7.80552834e-05 -1.99116639e-05]  gradient norm: 8.055496026486787e-05\n",
            "iter: 937050  x: [ 3.99995938 15.99967504]  f(x): 1.6499826626524863e-09  grad at x: [-2.48973462e-06 -9.84373219e-06]  gradient norm: 1.0153710743398835e-05\n",
            "iter: 937051  x: [ 3.99995938 15.99967505]  f(x): 1.6499315399628999e-09  grad at x: [ 7.81058432e-05 -1.99176739e-05]  gradient norm: 8.060543697371147e-05\n",
            "iter: 937052  x: [ 3.99995938 15.99967505]  f(x): 1.6498819582532414e-09  grad at x: [-2.49048593e-06 -9.84332837e-06]  gradient norm: 1.0153503513070728e-05\n",
            "iter: 937053  x: [ 3.99995938 15.99967506]  f(x): 1.6498309027951028e-09  grad at x: [ 7.81564029e-05 -1.99236838e-05]  gradient norm: 8.065591416043986e-05\n",
            "iter: 937054  x: [ 3.99995938 15.99967506]  f(x): 1.649781260029733e-09  grad at x: [-2.49123731e-06 -9.84292456e-06]  gradient norm: 1.0153296368691122e-05\n",
            "iter: 937055  x: [ 3.99995939 15.99967507]  f(x): 1.6497302718409384e-09  grad at x: [ 7.82069771e-05 -1.99296956e-05]  gradient norm: 8.070640637444639e-05\n",
            "iter: 937056  x: [ 3.99995938 15.99967507]  f(x): 1.6496805679270133e-09  grad at x: [-2.49197422e-06 -9.84252256e-06]  gradient norm: 1.0153087501998673e-05\n",
            "iter: 937057  x: [ 3.99995939 15.99967508]  f(x): 1.6496296459526215e-09  grad at x: [ 7.82566199e-05 -1.99355909e-05]  gradient norm: 8.075596781001888e-05\n",
            "iter: 937058  x: [ 3.99995939 15.99967508]  f(x): 1.6495798819819821e-09  grad at x: [-2.49272575e-06 -9.84211874e-06]  gradient norm: 1.0152880528613834e-05\n",
            "iter: 937059  x: [ 3.99995939 15.99967509]  f(x): 1.6495290273888222e-09  grad at x: [ 7.83072085e-05 -1.99416045e-05]  gradient norm: 8.080647551973615e-05\n",
            "iter: 937060  x: [ 3.99995939 15.99967509]  f(x): 1.6494792021932505e-09  grad at x: [-2.49346281e-06 -9.84171675e-06]  gradient norm: 1.0152671830390048e-05\n",
            "iter: 937061  x: [ 3.99995939 15.9996751 ]  f(x): 1.6494284138534719e-09  grad at x: [ 7.83568511e-05 -1.99474998e-05]  gradient norm: 8.085603787755645e-05\n",
            "iter: 937062  x: [ 3.99995939 15.9996751 ]  f(x): 1.6493785285255725e-09  grad at x: [-2.49421449e-06 -9.84131293e-06]  gradient norm: 1.0152465027869653e-05\n",
            "iter: 937063  x: [ 3.99995939 15.99967511]  f(x): 1.649327807678967e-09  grad at x: [ 7.84074541e-05 -1.99535152e-05]  gradient norm: 8.09065610762279e-05\n",
            "iter: 937064  x: [ 3.99995939 15.99967511]  f(x): 1.6492778610147387e-09  grad at x: [-2.49498081e-06 -9.84090730e-06]  gradient norm: 1.0152260124634838e-05\n",
            "iter: 937065  x: [ 3.99995939 15.99967512]  f(x): 1.64922720879695e-09  grad at x: [ 7.84589738e-05 -1.99596452e-05]  gradient norm: 8.095800149091871e-05\n",
            "iter: 937066  x: [ 3.99995939 15.99967512]  f(x): 1.6491771996593598e-09  grad at x: [-2.49573264e-06 -9.84050348e-06]  gradient norm: 1.0152053495440437e-05\n",
            "iter: 937067  x: [ 3.99995939 15.99967513]  f(x): 1.649126614941786e-09  grad at x: [ 7.85095475e-05 -1.99656570e-05]  gradient norm: 8.100849654228145e-05\n",
            "iter: 937068  x: [ 3.99995939 15.99967513]  f(x): 1.6490765444241932e-09  grad at x: [-2.49649911e-06 -9.84009785e-06]  gradient norm: 1.0151848767970829e-05\n",
            "iter: 937069  x: [ 3.99995939 15.99967514]  f(x): 1.6490260284497067e-09  grad at x: [ 7.85610962e-05 -1.99717906e-05]  gradient norm: 8.105996703365003e-05\n",
            "iter: 937070  x: [ 3.99995939 15.99967514]  f(x): 1.6489758953439188e-09  grad at x: [-2.49725109e-06 -9.83969403e-06]  gradient norm: 1.0151642312191104e-05\n",
            "iter: 937071  x: [ 3.9999594  15.99967515]  f(x): 1.6489254470185555e-09  grad at x: [ 7.86116989e-05 -1.99778060e-05]  gradient norm: 8.111049213886444e-05\n",
            "iter: 937072  x: [ 3.99995939 15.99967515]  f(x): 1.6488752524182534e-09  grad at x: [-2.49798861e-06 -9.83929203e-06]  gradient norm: 1.0151434124998551e-05\n",
            "iter: 937073  x: [ 3.9999594  15.99967516]  f(x): 1.6488248706092308e-09  grad at x: [ 7.86613702e-05 -1.99837050e-05]  gradient norm: 8.116008638133259e-05\n",
            "iter: 937074  x: [ 3.9999594  15.99967516]  f(x): 1.6487746156119592e-09  grad at x: [-2.49874074e-06 -9.83888822e-06]  gradient norm: 1.0151227840565826e-05\n",
            "iter: 937075  x: [ 3.9999594  15.99967516]  f(x): 1.6487368790343576e-09  grad at x: [ 3.81066378e-05 -1.49143070e-05]  gradient norm: 4.0921295171812716e-05\n",
            "iter: 937076  x: [ 3.9999594  15.99967516]  f(x): 1.6487235167930657e-09  grad at x: [-1.86465076e-06 -9.91799061e-06]  gradient norm: 1.009175208817599e-05\n",
            "iter: 937077  x: [ 3.9999594 15.9996752]  f(x): 1.6485209832472795e-09  grad at x: [ 1.58118356e-04 -2.99142484e-05]  gradient norm: 0.0001609232015203002\n",
            "iter: 937078  x: [ 3.9999594 15.9996752]  f(x): 1.6483733792918403e-09  grad at x: [ 7.71887329e-05 -1.97982445e-05]  gradient norm: 7.968733252339288e-05\n",
            "iter: 937079  x: [ 3.9999594 15.9996752]  f(x): 1.6483249035686613e-09  grad at x: [-2.47555703e-06 -9.84040162e-06]  gradient norm: 1.0147013679423132e-05\n",
            "iter: 937080  x: [ 3.9999594  15.99967521]  f(x): 1.6482728364328574e-09  grad at x: [ 7.72392769e-05 -1.98042526e-05]  gradient norm: 7.973778470700008e-05\n",
            "iter: 937081  x: [ 3.9999594  15.99967521]  f(x): 1.6482243003605836e-09  grad at x: [-2.47628048e-06 -9.84000144e-06]  gradient norm: 1.014680212428393e-05\n",
            "iter: 937082  x: [ 3.9999594  15.99967522]  f(x): 1.6481722976883e-09  grad at x: [ 7.72880745e-05 -1.98100424e-05]  gradient norm: 7.978649160745709e-05\n",
            "iter: 937083  x: [ 3.9999594  15.99967522]  f(x): 1.6481237033061158e-09  grad at x: [-2.47701856e-06 -9.83959944e-06]  gradient norm: 1.0146592439240199e-05\n",
            "iter: 937084  x: [ 3.99995941 15.99967523]  f(x): 1.648071766179381e-09  grad at x: [ 7.73377743e-05 -1.98159451e-05]  gradient norm: 7.983610095943806e-05\n",
            "iter: 937085  x: [ 3.9999594  15.99967523]  f(x): 1.64802311236892e-09  grad at x: [-2.47777126e-06 -9.83919563e-06]  gradient norm: 1.0146384627599497e-05\n",
            "iter: 937086  x: [ 3.99995941 15.99967524]  f(x): 1.64797124201182e-09  grad at x: [ 7.73884491e-05 -1.98219695e-05]  gradient norm: 7.988668553481843e-05\n",
            "iter: 937087  x: [ 3.99995941 15.99967524]  f(x): 1.6479225275836728e-09  grad at x: [-2.47850949e-06 -9.83879363e-06]  gradient norm: 1.0146175110967008e-05\n",
            "iter: 937088  x: [ 3.99995941 15.99967525]  f(x): 1.6478707229178162e-09  grad at x: [ 7.74381778e-05 -1.98278758e-05]  gradient norm: 7.993632494360913e-05\n",
            "iter: 937089  x: [ 3.99995941 15.99967525]  f(x): 1.647821948951192e-09  grad at x: [-2.47926234e-06 -9.83838981e-06]  gradient norm: 1.0145967470571595e-05\n",
            "iter: 937090  x: [ 3.99995941 15.99967526]  f(x): 1.6477702110964985e-09  grad at x: [ 7.74888379e-05 -1.98338985e-05]  gradient norm: 7.998689594954016e-05\n",
            "iter: 937091  x: [ 3.99995941 15.99967526]  f(x): 1.6477213764340419e-09  grad at x: [-2.48000072e-06 -9.83798782e-06]  gradient norm: 1.0145758122871513e-05\n",
            "iter: 937092  x: [ 3.99995941 15.99967527]  f(x): 1.647669704310653e-09  grad at x: [ 7.75385519e-05 -1.98398029e-05]  gradient norm: 8.003652176642155e-05\n",
            "iter: 937093  x: [ 3.99995941 15.99967527]  f(x): 1.6476208100505199e-09  grad at x: [-2.48073917e-06 -9.83758582e-06]  gradient norm: 1.0145548858977748e-05\n",
            "iter: 937094  x: [ 3.99995941 15.99967528]  f(x): 1.6475692037654222e-09  grad at x: [ 7.75883096e-05 -1.98457128e-05]  gradient norm: 8.008619170218633e-05\n",
            "iter: 937095  x: [ 3.99995941 15.99967528]  f(x): 1.6475202498363957e-09  grad at x: [-2.48147771e-06 -9.83718382e-06]  gradient norm: 1.0145339679129215e-05\n",
            "iter: 937096  x: [ 3.99995941 15.99967529]  f(x): 1.6474687093564021e-09  grad at x: [ 7.76380381e-05 -1.98516191e-05]  gradient norm: 8.013583301072566e-05\n",
            "iter: 937097  x: [ 3.99995941 15.99967529]  f(x): 1.6474196957378623e-09  grad at x: [-2.48223086e-06 -9.83678001e-06]  gradient norm: 1.0145132379647595e-05\n",
            "iter: 937098  x: [ 3.99995941 15.9996753 ]  f(x): 1.64736822225706e-09  grad at x: [ 7.76887123e-05 -1.98576436e-05]  gradient norm: 8.018642050049522e-05\n",
            "iter: 937099  x: [ 3.99995941 15.9996753 ]  f(x): 1.6473191477895877e-09  grad at x: [-2.48296954e-06 -9.83637801e-06]  gradient norm: 1.0144923368688934e-05\n",
            "iter: 937100  x: [ 3.99995942 15.99967531]  f(x): 1.6472677402590135e-09  grad at x: [ 7.77384843e-05 -1.98635553e-05]  gradient norm: 8.023610640542727e-05\n",
            "iter: 937101  x: [ 3.99995941 15.99967531]  f(x): 1.6472186059563444e-09  grad at x: [-2.48372285e-06 -9.83597420e-06]  gradient norm: 1.0144716240716333e-05\n",
            "iter: 937102  x: [ 3.99995942 15.99967532]  f(x): 1.647167265501757e-09  grad at x: [ 7.77891584e-05 -1.98695798e-05]  gradient norm: 8.028669486207255e-05\n",
            "iter: 937103  x: [ 3.99995942 15.99967532]  f(x): 1.6471180702727968e-09  grad at x: [-2.48446168e-06 -9.83557220e-06]  gradient norm: 1.0144507398734878e-05\n",
            "iter: 937104  x: [ 3.99995942 15.99967533]  f(x): 1.6470667958791578e-09  grad at x: [ 7.78389448e-05 -1.98754933e-05]  gradient norm: 8.033639626244629e-05\n",
            "iter: 937105  x: [ 3.99995942 15.99967533]  f(x): 1.6470175407397662e-09  grad at x: [-2.48521514e-06 -9.83516838e-06]  gradient norm: 1.0144300442141895e-05\n",
            "iter: 937106  x: [ 3.99995942 15.99967534]  f(x): 1.646966333498191e-09  grad at x: [ 7.78896334e-05 -1.98815196e-05]  gradient norm: 8.038700023164774e-05\n",
            "iter: 937107  x: [ 3.99995942 15.99967534]  f(x): 1.6469170173198228e-09  grad at x: [-2.48595413e-06 -9.83476639e-06]  gradient norm: 1.0144091769224925e-05\n",
            "iter: 937108  x: [ 3.99995942 15.99967535]  f(x): 1.6468658761793255e-09  grad at x: [ 7.79394050e-05 -1.98874313e-05]  gradient norm: 8.043668802454684e-05\n",
            "iter: 937109  x: [ 3.99995942 15.99967535]  f(x): 1.6468165000498346e-09  grad at x: [-2.48670774e-06 -9.83436257e-06]  gradient norm: 1.0143884984317141e-05\n",
            "iter: 937110  x: [ 3.99995942 15.99967536]  f(x): 1.6467654261735688e-09  grad at x: [ 7.79901080e-05 -1.98934595e-05]  gradient norm: 8.04873075027461e-05\n",
            "iter: 937111  x: [ 3.99995942 15.99967536]  f(x): 1.646715988893478e-09  grad at x: [-2.48747598e-06 -9.83395694e-06]  gradient norm: 1.014368009057601e-05\n",
            "iter: 937112  x: [ 3.99995942 15.99967537]  f(x): 1.6466649834814167e-09  grad at x: [ 7.80417713e-05 -1.98996077e-05]  gradient norm: 8.053888779310934e-05\n",
            "iter: 937113  x: [ 3.99995942 15.99967537]  f(x): 1.6466154839028784e-09  grad at x: [-2.48821519e-06 -9.83355494e-06]  gradient norm: 1.0143471673391862e-05\n",
            "iter: 937114  x: [ 3.99995942 15.99967538]  f(x): 1.6465645447061263e-09  grad at x: [ 7.80915427e-05 -1.99055194e-05]  gradient norm: 8.058857700526106e-05\n",
            "iter: 937115  x: [ 3.99995942 15.99967538]  f(x): 1.6465149850253495e-09  grad at x: [-2.48896902e-06 -9.83315113e-06]  gradient norm: 1.0143265147636387e-05\n",
            "iter: 937116  x: [ 3.99995943 15.99967539]  f(x): 1.6464641132439249e-09  grad at x: [ 7.81422745e-05 -1.99115511e-05]  gradient norm: 8.063922702980229e-05\n",
            "iter: 937117  x: [ 3.99995942 15.99967539]  f(x): 1.6464144922780799e-09  grad at x: [-2.48972294e-06 -9.83274731e-06]  gradient norm: 1.0143058708091244e-05\n",
            "iter: 937118  x: [ 3.99995943 15.9996754 ]  f(x): 1.6463636879508172e-09  grad at x: [ 7.81930063e-05 -1.99175829e-05]  gradient norm: 8.068987753569756e-05\n",
            "iter: 937119  x: [ 3.99995943 15.9996754 ]  f(x): 1.646314005678254e-09  grad at x: [-2.49046237e-06 -9.83234531e-06]  gradient norm: 1.0142850545449957e-05\n",
            "iter: 937120  x: [ 3.99995943 15.99967541]  f(x): 1.646263267714596e-09  grad at x: [ 7.82428066e-05 -1.99234983e-05]  gradient norm: 8.073959725359092e-05\n",
            "iter: 937121  x: [ 3.99995943 15.99967541]  f(x): 1.6462135251906599e-09  grad at x: [-2.49121644e-06 -9.83194150e-06]  gradient norm: 1.0142644277854686e-05\n",
            "iter: 937122  x: [ 3.99995943 15.99967542]  f(x): 1.646162854758113e-09  grad at x: [ 7.82935382e-05 -1.99295300e-05]  gradient norm: 8.079024870767436e-05\n",
            "iter: 937123  x: [ 3.99995943 15.99967542]  f(x): 1.6461130508674122e-09  grad at x: [-2.49194147e-06 -9.83154132e-06]  gradient norm: 1.0142434472522826e-05\n",
            "iter: 937124  x: [ 3.99995943 15.99967543]  f(x): 1.6460624457431846e-09  grad at x: [ 7.8342407e-05 -1.9935329e-05]  gradient norm: 8.0839038063556e-05\n",
            "iter: 937125  x: [ 3.99995943 15.99967543]  f(x): 1.6460125826569415e-09  grad at x: [-2.49271024e-06 -9.83113569e-06]  gradient norm: 1.0142230189070793e-05\n",
            "iter: 937126  x: [ 3.99995943 15.99967544]  f(x): 1.6459620463063927e-09  grad at x: [ 7.83940989e-05 -1.99414808e-05]  gradient norm: 8.089065085145073e-05\n",
            "iter: 937127  x: [ 3.99995943 15.99967544]  f(x): 1.6459121205927898e-09  grad at x: [-2.49346453e-06 -9.83073187e-06]  gradient norm: 1.0142024179834047e-05\n",
            "iter: 937128  x: [ 3.99995943 15.99967545]  f(x): 1.645861651853721e-09  grad at x: [ 7.84448157e-05 -1.99475107e-05]  gradient norm: 8.094128917302337e-05\n",
            "iter: 937129  x: [ 3.99995943 15.99967545]  f(x): 1.6458116646386424e-09  grad at x: [-2.49420435e-06 -9.83032987e-06]  gradient norm: 1.0141816441478353e-05\n",
            "iter: 937130  x: [ 3.99995943 15.99967546]  f(x): 1.6457612625226496e-09  grad at x: [ 7.84946593e-05 -1.99534315e-05]  gradient norm: 8.099105485941723e-05\n",
            "iter: 937131  x: [ 3.99995943 15.99967546]  f(x): 1.6457112148138974e-09  grad at x: [-2.49497334e-06 -9.82992424e-06]  gradient norm: 1.0141612421283438e-05\n",
            "iter: 937132  x: [ 3.99995944 15.99967547]  f(x): 1.6456608815903592e-09  grad at x: [ 7.85463509e-05 -1.99595834e-05]  gradient norm: 8.104266909965089e-05\n",
            "iter: 937133  x: [ 3.99995943 15.99967547]  f(x): 1.6456107711346281e-09  grad at x: [-2.49572786e-06 -9.82952042e-06]  gradient norm: 1.0141406671795384e-05\n",
            "iter: 937134  x: [ 3.99995944 15.99967548]  f(x): 1.6455605057443597e-09  grad at x: [ 7.85971403e-05 -1.99656224e-05]  gradient norm: 8.10933816011014e-05\n",
            "iter: 937135  x: [ 3.99995944 15.99967548]  f(x): 1.6455103335830915e-09  grad at x: [-2.49648245e-06 -9.82911661e-06]  gradient norm: 1.014120100915309e-05\n",
            "iter: 937136  x: [ 3.99995944 15.99967548]  f(x): 1.645472675812959e-09  grad at x: [ 3.80757017e-05 -1.49003863e-05]  gradient norm: 4.0887413377600166e-05\n",
            "iter: 937137  x: [ 3.99995944 15.99967548]  f(x): 1.6454593359357512e-09  grad at x: [-1.86291759e-06 -9.90815352e-06]  gradient norm: 1.008176413310482e-05\n",
            "iter: 937138  x: [ 3.99995944 15.99967552]  f(x): 1.6452572748280251e-09  grad at x: [ 1.57991163e-04 -2.98882969e-05]  gradient norm: 0.00016079340142886896\n",
            "iter: 937139  x: [ 3.99995944 15.99967552]  f(x): 1.645109908980408e-09  grad at x: [ 7.71267621e-05 -1.97804457e-05]  gradient norm: 7.962288281915357e-05\n",
            "iter: 937140  x: [ 3.99995944 15.99967552]  f(x): 1.6450615119271712e-09  grad at x: [-2.47330971e-06 -9.83063001e-06]  gradient norm: 1.013698906255528e-05\n",
            "iter: 937141  x: [ 3.99995944 15.99967553]  f(x): 1.6450095635584741e-09  grad at x: [ 7.71758921e-05 -1.97862773e-05]  gradient norm: 7.967192162209592e-05\n",
            "iter: 937142  x: [ 3.99995944 15.99967553]  f(x): 1.6449611078879294e-09  grad at x: [-2.47403562e-06 -9.83022983e-06]  gradient norm: 1.0136778122520252e-05\n",
            "iter: 937143  x: [ 3.99995944 15.99967554]  f(x): 1.6449092240942265e-09  grad at x: [ 7.72248328e-05 -1.97920854e-05]  gradient norm: 7.972077176360623e-05\n",
            "iter: 937144  x: [ 3.99995944 15.99967554]  f(x): 1.6448607099931661e-09  grad at x: [-2.47477615e-06 -9.82982783e-06]  gradient norm: 1.0136569053323855e-05\n",
            "iter: 937145  x: [ 3.99995945 15.99967555]  f(x): 1.6448088918558492e-09  grad at x: [ 7.72746757e-05 -1.97980062e-05]  gradient norm: 7.977052436402211e-05\n",
            "iter: 937146  x: [ 3.99995944 15.99967555]  f(x): 1.6447603182065792e-09  grad at x: [-2.47553130e-06 -9.82942402e-06]  gradient norm: 1.0136361858287449e-05\n",
            "iter: 937147  x: [ 3.99995945 15.99967556]  f(x): 1.6447085669841587e-09  grad at x: [ 7.73255081e-05 -1.98040507e-05]  gradient norm: 7.982126674028339e-05\n",
            "iter: 937148  x: [ 3.99995945 15.99967556]  f(x): 1.6446599325802705e-09  grad at x: [-2.47625743e-06 -9.82902384e-06]  gradient norm: 1.0136151167459456e-05\n",
            "iter: 937149  x: [ 3.99995945 15.99967557]  f(x): 1.6446082460072515e-09  grad at x: [ 7.73744486e-05 -1.98098587e-05]  gradient norm: 7.987011828931396e-05\n",
            "iter: 937150  x: [ 3.99995945 15.99967557]  f(x): 1.6445595530615779e-09  grad at x: [-2.47699819e-06 -9.82862184e-06]  gradient norm: 1.0135942350617912e-05\n",
            "iter: 937151  x: [ 3.99995945 15.99967558]  f(x): 1.6445079323622167e-09  grad at x: [ 7.74243494e-05 -1.98157868e-05]  gradient norm: 7.991993051862594e-05\n",
            "iter: 937152  x: [ 3.99995945 15.99967558]  f(x): 1.64445917968514e-09  grad at x: [-2.47772447e-06 -9.82822166e-06]  gradient norm: 1.013573182495682e-05\n",
            "iter: 937153  x: [ 3.99995945 15.99967559]  f(x): 1.6444076237081267e-09  grad at x: [ 7.74732898e-05 -1.98215948e-05]  gradient norm: 7.996878299217997e-05\n",
            "iter: 937154  x: [ 3.99995945 15.99967559]  f(x): 1.6443588124157588e-09  grad at x: [-2.47846538e-06 -9.82781967e-06]  gradient norm: 1.013552317543238e-05\n",
            "iter: 937155  x: [ 3.99995945 15.9996756 ]  f(x): 1.6443073223867946e-09  grad at x: [ 7.75231905e-05 -1.98275229e-05]  gradient norm: 8.001859616403436e-05\n",
            "iter: 937156  x: [ 3.99995945 15.9996756 ]  f(x): 1.6442584512891713e-09  grad at x: [-2.47922091e-06 -9.82741585e-06]  gradient norm: 1.0135316406453396e-05\n",
            "iter: 937157  x: [ 3.99995945 15.99967561]  f(x): 1.6442070282952172e-09  grad at x: [ 7.75739934e-05 -1.98335638e-05]  gradient norm: 8.00693118640117e-05\n",
            "iter: 937158  x: [ 3.99995945 15.99967561]  f(x): 1.6441580962679812e-09  grad at x: [-2.47996197e-06 -9.82701386e-06]  gradient norm: 1.0135107926896045e-05\n",
            "iter: 937159  x: [ 3.99995945 15.99967562]  f(x): 1.6441067393323558e-09  grad at x: [ 7.76239231e-05 -1.98394955e-05]  gradient norm: 8.011915509211376e-05\n",
            "iter: 937160  x: [ 3.99995945 15.99967562]  f(x): 1.6440577473890231e-09  grad at x: [-2.48071766e-06 -9.82661004e-06]  gradient norm: 1.0134901330078075e-05\n",
            "iter: 937161  x: [ 3.99995946 15.99967563]  f(x): 1.6440064576001196e-09  grad at x: [ 7.76747549e-05 -1.98455400e-05]  gradient norm: 8.016990086761614e-05\n",
            "iter: 937162  x: [ 3.99995945 15.99967563]  f(x): 1.643957404614903e-09  grad at x: [-2.48145887e-06 -9.82620804e-06]  gradient norm: 1.0134693020358315e-05\n",
            "iter: 937163  x: [ 3.99995946 15.99967564]  f(x): 1.6439061809602236e-09  grad at x: [ 7.77246844e-05 -1.98514717e-05]  gradient norm: 8.021974505074171e-05\n",
            "iter: 937164  x: [ 3.99995946 15.99967564]  f(x): 1.6438570679824535e-09  grad at x: [-2.48221471e-06 -9.82580423e-06]  gradient norm: 1.013448659578955e-05\n",
            "iter: 937165  x: [ 3.99995946 15.99967565]  f(x): 1.6438059115517794e-09  grad at x: [ 7.77755161e-05 -1.98575162e-05]  gradient norm: 8.027049179642954e-05\n",
            "iter: 937166  x: [ 3.99995946 15.99967565]  f(x): 1.643756737454282e-09  grad at x: [-2.48295607e-06 -9.82540223e-06]  gradient norm: 1.0134278455777401e-05\n",
            "iter: 937167  x: [ 3.99995946 15.99967566]  f(x): 1.643705647233727e-09  grad at x: [ 7.78254455e-05 -1.98634480e-05]  gradient norm: 8.032033693042417e-05\n",
            "iter: 937168  x: [ 3.99995946 15.99967566]  f(x): 1.6436564130672203e-09  grad at x: [-2.48371206e-06 -9.82499841e-06]  gradient norm: 1.013407220354597e-05\n",
            "iter: 937169  x: [ 3.99995946 15.99967567]  f(x): 1.6436053901825373e-09  grad at x: [ 7.78763061e-05 -1.98694961e-05]  gradient norm: 8.037111374532659e-05\n",
            "iter: 937170  x: [ 3.99995946 15.99967567]  f(x): 1.64355609478498e-09  grad at x: [-2.48448267e-06 -9.82459278e-06]  gradient norm: 1.013386784226649e-05\n",
            "iter: 937171  x: [ 3.99995946 15.99967568]  f(x): 1.6435051404361034e-09  grad at x: [ 7.79280980e-05 -1.98756607e-05]  gradient norm: 8.042282226952693e-05\n",
            "iter: 937172  x: [ 3.99995946 15.99967568]  f(x): 1.6434557826421853e-09  grad at x: [-2.48523881e-06 -9.82418896e-06]  gradient norm: 1.0133661764850725e-05\n",
            "iter: 937173  x: [ 3.99995946 15.99967569]  f(x): 1.6434048957079743e-09  grad at x: [ 7.79789585e-05 -1.98817088e-05]  gradient norm: 8.047360006840016e-05\n",
            "iter: 937174  x: [ 3.99995946 15.99967569]  f(x): 1.6433554766036528e-09  grad at x: [-2.48600958e-06 -9.82378333e-06]  gradient norm: 1.0133457580624573e-05\n",
            "iter: 937175  x: [ 3.99995946 15.9996757 ]  f(x): 1.6433046583201496e-09  grad at x: [ 7.80307793e-05 -1.98878770e-05]  gradient norm: 8.052533869659087e-05\n",
            "iter: 937176  x: [ 3.99995946 15.9996757 ]  f(x): 1.6432551767040043e-09  grad at x: [-2.48676587e-06 -9.82337951e-06]  gradient norm: 1.0133251678113753e-05\n",
            "iter: 937177  x: [ 3.99995947 15.99967571]  f(x): 1.643204425913982e-09  grad at x: [ 7.80816396e-05 -1.98939251e-05]  gradient norm: 8.05761174754098e-05\n",
            "iter: 937178  x: [ 3.99995946 15.99967571]  f(x): 1.6431548829080596e-09  grad at x: [-2.48753679e-06 -9.82297388e-06]  gradient norm: 1.0133047671466571e-05\n",
            "iter: 937179  x: [ 3.99995947 15.99967572]  f(x): 1.643104200849061e-09  grad at x: [ 7.81334604e-05 -1.99000933e-05]  gradient norm: 8.062785709994486e-05\n",
            "iter: 937180  x: [ 3.99995947 15.99967572]  f(x): 1.6430545952504367e-09  grad at x: [-2.48829323e-06 -9.82257006e-06]  gradient norm: 1.0132841943732027e-05\n",
            "iter: 937181  x: [ 3.99995947 15.99967573]  f(x): 1.6430039807984549e-09  grad at x: [ 7.81843496e-05 -1.99061451e-05]  gradient norm: 8.067866595776936e-05\n",
            "iter: 937182  x: [ 3.99995947 15.99967573]  f(x): 1.642954313730854e-09  grad at x: [-2.48903519e-06 -9.82216807e-06]  gradient norm: 1.0132634491781803e-05\n",
            "iter: 937183  x: [ 3.99995947 15.99967574]  f(x): 1.6429037657963426e-09  grad at x: [ 7.82342930e-05 -1.99120786e-05]  gradient norm: 8.07285294642784e-05\n",
            "iter: 937184  x: [ 3.99995947 15.99967574]  f(x): 1.6428540383141345e-09  grad at x: [-2.48979179e-06 -9.82176425e-06]  gradient norm: 1.0132428936957373e-05\n",
            "iter: 937185  x: [ 3.99995947 15.99967575]  f(x): 1.6428035580994482e-09  grad at x: [ 7.82851966e-05 -1.99181322e-05]  gradient norm: 8.077935382426639e-05\n",
            "iter: 937186  x: [ 3.99995947 15.99967575]  f(x): 1.6427537690348934e-09  grad at x: [-2.49053390e-06 -9.82136226e-06]  gradient norm: 1.0132221655372578e-05\n",
            "iter: 937187  x: [ 3.99995947 15.99967576]  f(x): 1.6427033554484478e-09  grad at x: [ 7.83351689e-05 -1.99240694e-05]  gradient norm: 8.082924736468911e-05\n",
            "iter: 937188  x: [ 3.99995947 15.99967576]  f(x): 1.642653505857957e-09  grad at x: [-2.49129065e-06 -9.82095844e-06]  gradient norm: 1.0132016273328478e-05\n",
            "iter: 937189  x: [ 3.99995947 15.99967577]  f(x): 1.6426031600688166e-09  grad at x: [ 7.83860724e-05 -1.99301230e-05]  gradient norm: 8.088007267578806e-05\n",
            "iter: 937190  x: [ 3.99995947 15.99967577]  f(x): 1.642553248817937e-09  grad at x: [-2.49203292e-06 -9.82055644e-06]  gradient norm: 1.01318091621968e-05\n",
            "iter: 937191  x: [ 3.99995947 15.99967578]  f(x): 1.6425029697330852e-09  grad at x: [ 7.84360446e-05 -1.99360602e-05]  gradient norm: 8.092996714443257e-05\n",
            "iter: 937192  x: [ 3.99995947 15.99967578]  f(x): 1.6424529978796629e-09  grad at x: [-2.49278981e-06 -9.82015263e-06]  gradient norm: 1.0131603953021294e-05\n",
            "iter: 937193  x: [ 3.99995948 15.99967579]  f(x): 1.642402786704452e-09  grad at x: [ 7.84869770e-05 -1.99421174e-05]  gradient norm: 8.098082250425696e-05\n",
            "iter: 937194  x: [ 3.99995947 15.99967579]  f(x): 1.6423527530777437e-09  grad at x: [-2.49353223e-06 -9.81975063e-06]  gradient norm: 1.0131397012430438e-05\n",
            "iter: 937195  x: [ 3.99995948 15.9996758 ]  f(x): 1.6423026086828907e-09  grad at x: [ 7.85369490e-05 -1.99480546e-05]  gradient norm: 8.103071789911594e-05\n",
            "iter: 937196  x: [ 3.99995948 15.9996758 ]  f(x): 1.6422650378810242e-09  grad at x: [ 3.80213153e-05 -1.48836989e-05]  gradient norm: 4.083068589610089e-05\n",
            "iter: 937197  x: [ 3.99995948 15.9996758 ]  f(x): 1.642251734360324e-09  grad at x: [-1.86081276e-06 -9.89852742e-06]  gradient norm: 1.0071914876912022e-05\n",
            "iter: 937198  x: [ 3.99995948 15.99967584]  f(x): 1.6420498860116253e-09  grad at x: [ 1.57762462e-04 -2.98498217e-05]  gradient norm: 0.0001605615343427349\n",
            "iter: 937199  x: [ 3.99995948 15.99967584]  f(x): 1.641902944712494e-09  grad at x: [ 7.70148417e-05 -1.97565678e-05]  gradient norm: 7.95085392382435e-05\n",
            "iter: 937200  x: [ 3.99995948 15.99967584]  f(x): 1.6418546858417179e-09  grad at x: [-2.47034132e-06 -9.82111305e-06]  gradient norm: 1.0127035492155491e-05\n",
            "iter: 937201  x: [ 3.99995948 15.99967585]  f(x): 1.6418027961605627e-09  grad at x: [ 7.70650025e-05 -1.97625286e-05]  gradient norm: 7.955860822191303e-05\n",
            "iter: 937202  x: [ 3.99995948 15.99967585]  f(x): 1.641754477527001e-09  grad at x: [-2.47106964e-06 -9.82071288e-06]  gradient norm: 1.0126825097151524e-05\n",
            "iter: 937203  x: [ 3.99995948 15.99967586]  f(x): 1.6417026525309566e-09  grad at x: [ 7.71141154e-05 -1.97683585e-05]  gradient norm: 7.960763023055951e-05\n",
            "iter: 937204  x: [ 3.99995948 15.99967586]  f(x): 1.6416542753477853e-09  grad at x: [-2.47181258e-06 -9.82031088e-06]  gradient norm: 1.0126616572622698e-05\n",
            "iter: 937205  x: [ 3.99995949 15.99967587]  f(x): 1.6416025161178562e-09  grad at x: [ 7.71641159e-05 -1.97742993e-05]  gradient norm: 7.965754014847276e-05\n",
            "iter: 937206  x: [ 3.99995948 15.99967587]  f(x): 1.641554079267805e-09  grad at x: [-2.47257015e-06 -9.81990706e-06]  gradient norm: 1.012640992190403e-05\n",
            "iter: 937207  x: [ 3.99995949 15.99967588]  f(x): 1.6415023869907474e-09  grad at x: [ 7.72150769e-05 -1.97803602e-05]  gradient norm: 7.970841074352714e-05\n",
            "iter: 937208  x: [ 3.99995949 15.99967588]  f(x): 1.6414538893216676e-09  grad at x: [-2.47331325e-06 -9.81950507e-06]  gradient norm: 1.012620156778521e-05\n",
            "iter: 937209  x: [ 3.99995949 15.99967589]  f(x): 1.641402262921198e-09  grad at x: [ 7.72651064e-05 -1.97863046e-05]  gradient norm: 7.975835073361938e-05\n",
            "iter: 937210  x: [ 3.99995949 15.99967589]  f(x): 1.6413537054742067e-09  grad at x: [-2.47407097e-06 -9.81910125e-06]  gradient norm: 1.0125995089895233e-05\n",
            "iter: 937211  x: [ 3.99995949 15.9996759 ]  f(x): 1.6413021461386049e-09  grad at x: [ 7.73160962e-05 -1.97923691e-05]  gradient norm: 7.980925141988581e-05\n",
            "iter: 937212  x: [ 3.99995949 15.9996759 ]  f(x): 1.6412535277600275e-09  grad at x: [-2.47481422e-06 -9.81869925e-06]  gradient norm: 1.0125786906274363e-05\n",
            "iter: 937213  x: [ 3.99995949 15.99967591]  f(x): 1.6412020343772618e-09  grad at x: [ 7.73661256e-05 -1.97983136e-05]  gradient norm: 7.985919238257974e-05\n",
            "iter: 937214  x: [ 3.99995949 15.99967591]  f(x): 1.6411533561614069e-09  grad at x: [-2.47555754e-06 -9.81829726e-06]  gradient norm: 1.012557880734679e-05\n",
            "iter: 937215  x: [ 3.99995949 15.99967592]  f(x): 1.641101928768436e-09  grad at x: [ 7.74161694e-05 -1.98042599e-05]  gradient norm: 7.990914837451593e-05\n",
            "iter: 937216  x: [ 3.99995949 15.99967592]  f(x): 1.6410531906595253e-09  grad at x: [-2.47628639e-06 -9.81789708e-06]  gradient norm: 1.0125368997805805e-05\n",
            "iter: 937217  x: [ 3.99995949 15.99967593]  f(x): 1.6410018282117924e-09  grad at x: [ 7.74652818e-05 -1.98100897e-05]  gradient norm: 7.995817369833754e-05\n",
            "iter: 937218  x: [ 3.99995949 15.99967593]  f(x): 1.6409530312911825e-09  grad at x: [-2.47702986e-06 -9.81749508e-06]  gradient norm: 1.0125161067152702e-05\n",
            "iter: 937219  x: [ 3.99995949 15.99967594]  f(x): 1.6409017349432943e-09  grad at x: [ 7.75153400e-05 -1.98160378e-05]  gradient norm: 8.000814518459157e-05\n",
            "iter: 937220  x: [ 3.99995949 15.99967594]  f(x): 1.6408528780375582e-09  grad at x: [-2.47777341e-06 -9.81709309e-06]  gradient norm: 1.0124953221258304e-05\n",
            "iter: 937221  x: [ 3.9999595  15.99967595]  f(x): 1.640801647792106e-09  grad at x: [ 7.75653836e-05 -1.98219841e-05]  gradient norm: 8.005810260139152e-05\n",
            "iter: 937222  x: [ 3.99995949 15.99967595]  f(x): 1.6407527308623963e-09  grad at x: [-2.47851703e-06 -9.81669109e-06]  gradient norm: 1.012474545992704e-05\n",
            "iter: 937223  x: [ 3.9999595  15.99967596]  f(x): 1.640701566862074e-09  grad at x: [ 7.76154854e-05 -1.98279376e-05]  gradient norm: 8.010811869053577e-05\n",
            "iter: 937224  x: [ 3.9999595  15.99967596]  f(x): 1.6406525898199334e-09  grad at x: [-2.47927528e-06 -9.81628727e-06]  gradient norm: 1.0124539583438155e-05\n",
            "iter: 937225  x: [ 3.9999595  15.99967597]  f(x): 1.6406014931188108e-09  grad at x: [ 7.76664602e-05 -1.98340003e-05]  gradient norm: 8.015900824546944e-05\n",
            "iter: 937226  x: [ 3.9999595  15.99967597]  f(x): 1.640552454872813e-09  grad at x: [-2.48001906e-06 -9.81588528e-06]  gradient norm: 1.0124331992911535e-05\n",
            "iter: 937227  x: [ 3.9999595  15.99967598]  f(x): 1.640501424493222e-09  grad at x: [ 7.77165617e-05 -1.98399539e-05]  gradient norm: 8.02090252947034e-05\n",
            "iter: 937228  x: [ 3.9999595  15.99967598]  f(x): 1.6404523260578308e-09  grad at x: [-2.48077746e-06 -9.81548146e-06]  gradient norm: 1.0124126289648693e-05\n",
            "iter: 937229  x: [ 3.9999595  15.99967599]  f(x): 1.6404013630904416e-09  grad at x: [ 7.77675509e-05 -1.98460184e-05]  gradient norm: 8.025993037409176e-05\n",
            "iter: 937230  x: [ 3.9999595  15.99967599]  f(x): 1.640352203356169e-09  grad at x: [-2.48153593e-06 -9.81507765e-06]  gradient norm: 1.0123920673414103e-05\n",
            "iter: 937231  x: [ 3.9999595 15.999676 ]  f(x): 1.6403013078395114e-09  grad at x: [ 7.78185546e-05 -1.98520847e-05]  gradient norm: 8.031085049581361e-05\n",
            "iter: 937232  x: [ 3.9999595 15.999676 ]  f(x): 1.640252086749011e-09  grad at x: [-2.48227993e-06 -9.81467565e-06]  gradient norm: 1.0123713339848702e-05\n",
            "iter: 937233  x: [ 3.9999595  15.99967601]  f(x): 1.640201257668853e-09  grad at x: [ 7.78686559e-05 -1.98580383e-05]  gradient norm: 8.036086898318104e-05\n",
            "iter: 937234  x: [ 3.9999595  15.99967601]  f(x): 1.64015197627315e-09  grad at x: [-2.48303856e-06 -9.81427183e-06]  gradient norm: 1.0123507897190784e-05\n",
            "iter: 937235  x: [ 3.9999595  15.99967602]  f(x): 1.6401012147561433e-09  grad at x: [ 7.79196886e-05 -1.98641083e-05]  gradient norm: 8.041181917805758e-05\n",
            "iter: 937236  x: [ 3.9999595  15.99967602]  f(x): 1.6400518719086671e-09  grad at x: [-2.48376816e-06 -9.81387166e-06]  gradient norm: 1.0123298927911558e-05\n",
            "iter: 937237  x: [ 3.99995951 15.99967603]  f(x): 1.6400011757438414e-09  grad at x: [ 7.79688439e-05 -1.98699436e-05]  gradient norm: 8.046089281979895e-05\n",
            "iter: 937238  x: [ 3.9999595  15.99967603]  f(x): 1.6399517736215197e-09  grad at x: [-2.48452694e-06 -9.81346784e-06]  gradient norm: 1.0123093657065413e-05\n",
            "iter: 937239  x: [ 3.99995951 15.99967604]  f(x): 1.6399011451676074e-09  grad at x: [ 7.80199055e-05 -1.98760172e-05]  gradient norm: 8.051187307347074e-05\n",
            "iter: 937240  x: [ 3.99995951 15.99967604]  f(x): 1.6398516814648299e-09  grad at x: [-2.48530035e-06 -9.81306221e-06]  gradient norm: 1.0122890283368627e-05\n",
            "iter: 937241  x: [ 3.99995951 15.99967605]  f(x): 1.6398011217827848e-09  grad at x: [ 7.80718401e-05 -1.98821999e-05]  gradient norm: 8.056372687612943e-05\n",
            "iter: 937242  x: [ 3.99995951 15.99967605]  f(x): 1.6397515954186787e-09  grad at x: [-2.48604473e-06 -9.81266021e-06]  gradient norm: 1.0122683378119854e-05\n",
            "iter: 937243  x: [ 3.99995951 15.99967606]  f(x): 1.6397011023639525e-09  grad at x: [ 7.81219556e-05 -1.98881553e-05]  gradient norm: 8.061376228771828e-05\n",
            "iter: 937244  x: [ 3.99995951 15.99967606]  f(x): 1.6396515154664592e-09  grad at x: [-2.48680373e-06 -9.81225639e-06]  gradient norm: 1.0122478369629047e-05\n",
            "iter: 937245  x: [ 3.99995951 15.99967607]  f(x): 1.639601090240631e-09  grad at x: [ 7.81730170e-05 -1.98942289e-05]  gradient norm: 8.066474399975244e-05\n",
            "iter: 937246  x: [ 3.99995951 15.99967607]  f(x): 1.6395514416427524e-09  grad at x: [-2.48754826e-06 -9.81185440e-06]  gradient norm: 1.0122271635625205e-05\n",
            "iter: 937247  x: [ 3.99995951 15.99967608]  f(x): 1.6395010830853922e-09  grad at x: [ 7.82231178e-05 -1.99001825e-05]  gradient norm: 8.071476580083364e-05\n",
            "iter: 937248  x: [ 3.99995951 15.99967608]  f(x): 1.6394513739298473e-09  grad at x: [-2.48829287e-06 -9.81145240e-06]  gradient norm: 1.0122064986686978e-05\n",
            "iter: 937249  x: [ 3.99995951 15.99967609]  f(x): 1.6394010821489439e-09  grad at x: [ 7.82732622e-05 -1.99061415e-05]  gradient norm: 8.076483172040101e-05\n",
            "iter: 937250  x: [ 3.99995951 15.99967609]  f(x): 1.6393513123100365e-09  grad at x: [-2.48905210e-06 -9.81104859e-06]  gradient norm: 1.0121860238132577e-05\n",
            "iter: 937251  x: [ 3.99995951 15.9996761 ]  f(x): 1.6393010884392386e-09  grad at x: [ 7.83243088e-05 -1.99122132e-05]  gradient norm: 8.081580031274663e-05\n",
            "iter: 937252  x: [ 3.99995951 15.9996761 ]  f(x): 1.6392512568004692e-09  grad at x: [-2.48981140e-06 -9.81064477e-06]  gradient norm: 1.0121655577068482e-05\n",
            "iter: 937253  x: [ 3.99995952 15.9996761 ]  f(x): 1.6392011009139074e-09  grad at x: [ 7.83753844e-05 -1.99182887e-05]  gradient norm: 8.086679849029127e-05\n",
            "iter: 937254  x: [ 3.99995951 15.99967611]  f(x): 1.6391512074008658e-09  grad at x: [-2.49057079e-06 -9.81024095e-06]  gradient norm: 1.012145100351699e-05\n",
            "iter: 937255  x: [ 3.99995952 15.99967611]  f(x): 1.6391011195379095e-09  grad at x: [ 7.84264599e-05 -1.99243641e-05]  gradient norm: 8.091779714761906e-05\n",
            "iter: 937256  x: [ 3.99995952 15.99967612]  f(x): 1.6390511640935208e-09  grad at x: [-2.49134480e-06 -9.80983532e-06]  gradient norm: 1.012124833620226e-05\n",
            "iter: 937257  x: [ 3.99995952 15.99967612]  f(x): 1.6390136497633947e-09  grad at x: [ 3.79935828e-05 -1.48701984e-05]  gradient norm: 4.0799940316347275e-05\n",
            "iter: 937258  x: [ 3.99995952 15.99967612]  f(x): 1.6390003666265581e-09  grad at x: [-1.85916485e-06 -9.88869942e-06]  gradient norm: 1.0061951611792694e-05\n",
            "iter: 937259  x: [ 3.99995952 15.99967616]  f(x): 1.6387990404233502e-09  grad at x: [ 1.5765675e-04 -2.9826575e-05]  gradient norm: 0.00016045334372757436\n",
            "iter: 937260  x: [ 3.99995952 15.99967616]  f(x): 1.6386522972129715e-09  grad at x: [ 7.69634379e-05 -1.97401096e-05]  gradient norm: 7.945465817427691e-05\n",
            "iter: 937261  x: [ 3.99995952 15.99967616]  f(x): 1.6386041042307378e-09  grad at x: [-2.46828111e-06 -9.81133780e-06]  gradient norm: 1.0117052987254026e-05\n",
            "iter: 937262  x: [ 3.99995952 15.99967617]  f(x): 1.6385523468503063e-09  grad at x: [ 7.70134362e-05 -1.97460504e-05]  gradient norm: 7.950456502174443e-05\n",
            "iter: 937263  x: [ 3.99995952 15.99967617]  f(x): 1.6385040943195488e-09  grad at x: [-2.46904098e-06 -9.81093399e-06]  gradient norm: 1.0116846795883084e-05\n",
            "iter: 937264  x: [ 3.99995952 15.99967618]  f(x): 1.6384524039340178e-09  grad at x: [ 7.70645403e-05 -1.97521294e-05]  gradient norm: 7.955557801702634e-05\n",
            "iter: 937265  x: [ 3.99995952 15.99967618]  f(x): 1.638404090532566e-09  grad at x: [-2.46975727e-06 -9.81053563e-06]  gradient norm: 1.0116635326091687e-05\n",
            "iter: 937266  x: [ 3.99995953 15.99967619]  f(x): 1.6383524638414262e-09  grad at x: [ 7.71128504e-05 -1.97578593e-05]  gradient norm: 7.960379824222208e-05\n",
            "iter: 937267  x: [ 3.99995952 15.99967619]  f(x): 1.638304092835751e-09  grad at x: [-2.47048819e-06 -9.81013545e-06]  gradient norm: 1.0116425726234718e-05\n",
            "iter: 937268  x: [ 3.99995953 15.9996762 ]  f(x): 1.6382525309881647e-09  grad at x: [ 7.71620917e-05 -1.97637055e-05]  gradient norm: 7.965295001739832e-05\n",
            "iter: 937269  x: [ 3.99995953 15.9996762 ]  f(x): 1.6382041012288257e-09  grad at x: [-2.47123373e-06 -9.80973346e-06]  gradient norm: 1.0116218000031629e-05\n",
            "iter: 937270  x: [ 3.99995953 15.99967621]  f(x): 1.6381526053760534e-09  grad at x: [ 7.72122642e-05 -1.97696681e-05]  gradient norm: 7.970303337078468e-05\n",
            "iter: 937271  x: [ 3.99995953 15.99967621]  f(x): 1.6381041157463628e-09  grad at x: [-2.47196480e-06 -9.80933328e-06]  gradient norm: 1.0116008566836569e-05\n",
            "iter: 937272  x: [ 3.99995953 15.99967622]  f(x): 1.6380526848452864e-09  grad at x: [ 7.72615345e-05 -1.97755180e-05]  gradient norm: 7.975221518581568e-05\n",
            "iter: 937273  x: [ 3.99995953 15.99967622]  f(x): 1.638004136370656e-09  grad at x: [-2.47269594e-06 -9.80893310e-06]  gradient norm: 1.0115799216641635e-05\n",
            "iter: 937274  x: [ 3.99995953 15.99967623]  f(x): 1.6379527704578853e-09  grad at x: [ 7.73108047e-05 -1.97813679e-05]  gradient norm: 7.980139746479075e-05\n",
            "iter: 937275  x: [ 3.99995953 15.99967623]  f(x): 1.637904163084002e-09  grad at x: [-2.47344171e-06 -9.80853110e-06]  gradient norm: 1.0115591743451616e-05\n",
            "iter: 937276  x: [ 3.99995953 15.99967624]  f(x): 1.6378528633129514e-09  grad at x: [ 7.73610061e-05 -1.97873342e-05]  gradient norm: 7.985151134882365e-05\n",
            "iter: 937277  x: [ 3.99995953 15.99967624]  f(x): 1.6378041958861235e-09  grad at x: [-2.47420211e-06 -9.80812729e-06]  gradient norm: 1.0115386151051199e-05\n",
            "iter: 937278  x: [ 3.99995953 15.99967625]  f(x): 1.6377529634123459e-09  grad at x: [ 7.74121389e-05 -1.97934169e-05]  gradient norm: 7.990255686641569e-05\n",
            "iter: 937279  x: [ 3.99995953 15.99967625]  f(x): 1.6377042348115866e-09  grad at x: [-2.47494803e-06 -9.80772529e-06]  gradient norm: 1.0115178849403692e-05\n",
            "iter: 937280  x: [ 3.99995953 15.99967626]  f(x): 1.637653068556284e-09  grad at x: [ 7.74623402e-05 -1.97993832e-05]  gradient norm: 7.995267172553516e-05\n",
            "iter: 937281  x: [ 3.99995953 15.99967626]  f(x): 1.6376042798426883e-09  grad at x: [-2.47569403e-06 -9.80732329e-06]  gradient norm: 1.0114971632969396e-05\n",
            "iter: 937282  x: [ 3.99995954 15.99967627]  f(x): 1.637553179878305e-09  grad at x: [ 7.75125705e-05 -1.98053531e-05]  gradient norm: 8.000281616250809e-05\n",
            "iter: 937283  x: [ 3.99995953 15.99967627]  f(x): 1.6375043309617286e-09  grad at x: [-2.47645465e-06 -9.80691948e-06]  gradient norm: 1.0114766300958601e-05\n",
            "iter: 937284  x: [ 3.99995954 15.99967628]  f(x): 1.6374532983763751e-09  grad at x: [ 7.75636884e-05 -1.98114340e-05]  gradient norm: 8.005384861180267e-05\n",
            "iter: 937285  x: [ 3.99995954 15.99967628]  f(x): 1.63740438816733e-09  grad at x: [-2.47720080e-06 -9.80651748e-06]  gradient norm: 1.0114559255981642e-05\n",
            "iter: 937286  x: [ 3.99995954 15.99967629]  f(x): 1.6373534219849111e-09  grad at x: [ 7.76139332e-05 -1.98174057e-05]  gradient norm: 8.010400856611616e-05\n",
            "iter: 937287  x: [ 3.99995954 15.99967629]  f(x): 1.637304451495152e-09  grad at x: [-2.47793247e-06 -9.80611730e-06]  gradient norm: 1.0114350494730009e-05\n",
            "iter: 937288  x: [ 3.99995954 15.9996763 ]  f(x): 1.6372535505974312e-09  grad at x: [ 7.76632319e-05 -1.98232592e-05]  gradient norm: 8.015322325005709e-05\n",
            "iter: 937289  x: [ 3.99995954 15.9996763 ]  f(x): 1.6372045209274948e-09  grad at x: [-2.47866422e-06 -9.80571713e-06]  gradient norm: 1.0114141816434513e-05\n",
            "iter: 937290  x: [ 3.99995954 15.99967631]  f(x): 1.6371536853511237e-09  grad at x: [ 7.77125306e-05 -1.98291127e-05]  gradient norm: 8.02024383904738e-05\n",
            "iter: 937291  x: [ 3.99995954 15.99967631]  f(x): 1.637104596446661e-09  grad at x: [-2.47941059e-06 -9.80531513e-06]  gradient norm: 1.0113935024994439e-05\n",
            "iter: 937292  x: [ 3.99995954 15.99967632]  f(x): 1.6370538273501002e-09  grad at x: [ 7.77627751e-05 -1.98350845e-05]  gradient norm: 8.02525997566833e-05\n",
            "iter: 937293  x: [ 3.99995954 15.99967632]  f(x): 1.637004678052373e-09  grad at x: [-2.48017159e-06 -9.80491131e-06]  gradient norm: 1.0113730123980851e-05\n",
            "iter: 937294  x: [ 3.99995954 15.99967633]  f(x): 1.6369539766328796e-09  grad at x: [ 7.78139509e-05 -1.98411726e-05]  gradient norm: 8.030369282705916e-05\n",
            "iter: 937295  x: [ 3.99995954 15.99967633]  f(x): 1.6369047657791856e-09  grad at x: [-2.48091812e-06 -9.80450932e-06]  gradient norm: 1.011352350465312e-05\n",
            "iter: 937296  x: [ 3.99995954 15.99967634]  f(x): 1.636854130951646e-09  grad at x: [ 7.78642098e-05 -1.98471462e-05]  gradient norm: 8.035386970373182e-05\n",
            "iter: 937297  x: [ 3.99995954 15.99967634]  f(x): 1.6368048595919862e-09  grad at x: [-2.48167927e-06 -9.80410550e-06]  gradient norm: 1.0113318777747895e-05\n",
            "iter: 937298  x: [ 3.99995955 15.99967635]  f(x): 1.636754292449317e-09  grad at x: [ 7.79153563e-05 -1.98532307e-05]  gradient norm: 8.04049346491328e-05\n",
            "iter: 937299  x: [ 3.99995954 15.99967635]  f(x): 1.63670495950681e-09  grad at x: [-2.48241139e-06 -9.80370532e-06]  gradient norm: 1.01131105215319e-05\n",
            "iter: 937300  x: [ 3.99995955 15.99967636]  f(x): 1.6366544579076056e-09  grad at x: [ 7.79646837e-05 -1.98590878e-05]  gradient norm: 8.04541812226337e-05\n",
            "iter: 937301  x: [ 3.99995955 15.99967636]  f(x): 1.6366050655070646e-09  grad at x: [-2.48315814e-06 -9.80330333e-06]  gradient norm: 1.011290415799998e-05\n",
            "iter: 937302  x: [ 3.99995955 15.99967637]  f(x): 1.6365546306840426e-09  grad at x: [ 7.80149860e-05 -1.98650669e-05]  gradient norm: 8.050440316830758e-05\n",
            "iter: 937303  x: [ 3.99995955 15.99967637]  f(x): 1.6365051776109889e-09  grad at x: [-2.48393407e-06 -9.80289769e-06]  gradient norm: 1.0112701502203237e-05\n",
            "iter: 937304  x: [ 3.99995955 15.99967638]  f(x): 1.6364548117860014e-09  grad at x: [ 7.80671073e-05 -1.98712733e-05]  gradient norm: 8.05564444867248e-05\n",
            "iter: 937305  x: [ 3.99995955 15.99967638]  f(x): 1.6364052958160976e-09  grad at x: [-2.48468097e-06 -9.80249570e-06]  gradient norm: 1.011249531197012e-05\n",
            "iter: 937306  x: [ 3.99995955 15.99967639]  f(x): 1.6363549967397265e-09  grad at x: [ 7.81173513e-05 -1.98772450e-05]  gradient norm: 8.060660918592854e-05\n",
            "iter: 937307  x: [ 3.99995955 15.99967639]  f(x): 1.6363054201232143e-09  grad at x: [-2.48542795e-06 -9.80209370e-06]  gradient norm: 1.0112289207235557e-05\n",
            "iter: 937308  x: [ 3.99995955 15.9996764 ]  f(x): 1.6362551879035796e-09  grad at x: [ 7.81676389e-05 -1.98832222e-05]  gradient norm: 8.065681800908318e-05\n",
            "iter: 937309  x: [ 3.99995955 15.9996764 ]  f(x): 1.6362055504972362e-09  grad at x: [-2.48620411e-06 -9.80168807e-06]  gradient norm: 1.0112086817272966e-05\n",
            "iter: 937310  x: [ 3.99995955 15.99967641]  f(x): 1.636155387465803e-09  grad at x: [ 7.82198036e-05 -1.98894340e-05]  gradient norm: 8.070890446384739e-05\n",
            "iter: 937311  x: [ 3.99995955 15.99967641]  f(x): 1.63610568699012e-09  grad at x: [-2.48696579e-06 -9.80128425e-06]  gradient norm: 1.0111882701811894e-05\n",
            "iter: 937312  x: [ 3.99995955 15.99967642]  f(x): 1.6360555920228913e-09  grad at x: [ 7.82710223e-05 -1.98955277e-05]  gradient norm: 8.076004555599637e-05\n",
            "iter: 937313  x: [ 3.99995955 15.99967642]  f(x): 1.636005829584174e-09  grad at x: [-2.48772754e-06 -9.80088043e-06]  gradient norm: 1.0111678674305672e-05\n",
            "iter: 937314  x: [ 3.99995956 15.99967643]  f(x): 1.6359558026853905e-09  grad at x: [ 7.83222265e-05 -1.99016195e-05]  gradient norm: 8.081117258200103e-05\n",
            "iter: 937315  x: [ 3.99995955 15.99967643]  f(x): 1.6359059782606049e-09  grad at x: [-2.48847482e-06 -9.80047844e-06]  gradient norm: 1.0111472916305287e-05\n",
            "iter: 937316  x: [ 3.99995956 15.99967644]  f(x): 1.6358560183740241e-09  grad at x: [ 7.83725137e-05 -1.99075967e-05]  gradient norm: 8.086138330727047e-05\n",
            "iter: 937317  x: [ 3.99995956 15.99967644]  f(x): 1.6358061330376478e-09  grad at x: [-2.48922217e-06 -9.80007644e-06]  gradient norm: 1.0111267243913688e-05\n",
            "iter: 937318  x: [ 3.99995956 15.99967644]  f(x): 1.6357686994536648e-09  grad at x: [ 3.79668039e-05 -1.48568270e-05]  gradient norm: 4.077013007066656e-05\n",
            "iter: 937319  x: [ 3.99995956 15.99967644]  f(x): 1.6357554361462285e-09  grad at x: [-1.85745093e-06 -9.87888961e-06]  gradient norm: 1.0051994028432141e-05\n",
            "iter: 937320  x: [ 3.99995956 15.99967648]  f(x): 1.6355545884461176e-09  grad at x: [ 1.57533598e-04 -2.98011582e-05]  gradient norm: 0.00016032761345950372\n",
            "iter: 937321  x: [ 3.99995956 15.99967648]  f(x): 1.6354080751740622e-09  grad at x: [ 7.69034271e-05 -1.97225854e-05]  gradient norm: 7.939217514901485e-05\n",
            "iter: 937322  x: [ 3.99995956 15.99967648]  f(x): 1.6353599582542281e-09  grad at x: [-2.46611121e-06 -9.80158620e-06]  gradient norm: 1.0107066666618235e-05\n",
            "iter: 937323  x: [ 3.99995956 15.99967649]  f(x): 1.6353083243348247e-09  grad at x: [ 7.69547471e-05 -1.97286918e-05]  gradient norm: 7.944340367430342e-05\n",
            "iter: 937324  x: [ 3.99995956 15.99967649]  f(x): 1.635260146360425e-09  grad at x: [-2.46685898e-06 -9.80118421e-06]  gradient norm: 1.0106859307407363e-05\n",
            "iter: 937325  x: [ 3.99995956 15.9996765 ]  f(x): 1.6352085784366364e-09  grad at x: [ 7.70050630e-05 -1.97346726e-05]  gradient norm: 7.94936288877573e-05\n",
            "iter: 937326  x: [ 3.99995956 15.9996765 ]  f(x): 1.635160340548018e-09  grad at x: [-2.46762137e-06 -9.80078039e-06]  gradient norm: 1.0106653822708555e-05\n",
            "iter: 937327  x: [ 3.99995957 15.99967651]  f(x): 1.6351088397696566e-09  grad at x: [ 7.70563247e-05 -1.97407717e-05]  gradient norm: 7.954480023655692e-05\n",
            "iter: 937328  x: [ 3.99995956 15.99967651]  f(x): 1.6350605408330423e-09  grad at x: [-2.46835474e-06 -9.80038021e-06]  gradient norm: 1.0106444845269995e-05\n",
            "iter: 937329  x: [ 3.99995957 15.99967652]  f(x): 1.6350091050142417e-09  grad at x: [ 7.71057091e-05 -1.97466361e-05]  gradient norm: 7.959409533616081e-05\n",
            "iter: 937330  x: [ 3.99995957 15.99967652]  f(x): 1.634960747216314e-09  grad at x: [-2.46908818e-06 -9.79998003e-06]  gradient norm: 1.0106235951234392e-05\n",
            "iter: 937331  x: [ 3.99995957 15.99967653]  f(x): 1.6349093764281204e-09  grad at x: [ 7.71551225e-05 -1.97525042e-05]  gradient norm: 7.964342000101066e-05\n",
            "iter: 937332  x: [ 3.99995957 15.99967653]  f(x): 1.634860959680146e-09  grad at x: [-2.46983624e-06 -9.79957804e-06]  gradient norm: 1.0106028932724673e-05\n",
            "iter: 937333  x: [ 3.99995957 15.99967654]  f(x): 1.6348096550739639e-09  grad at x: [ 7.72054672e-05 -1.97584886e-05]  gradient norm: 7.969367626203595e-05\n",
            "iter: 937334  x: [ 3.99995957 15.99967654]  f(x): 1.6347611782242611e-09  grad at x: [-2.47059894e-06 -9.79917422e-06]  gradient norm: 1.0105823793538416e-05\n",
            "iter: 937335  x: [ 3.99995957 15.99967655]  f(x): 1.6347099410230574e-09  grad at x: [ 7.72567868e-05 -1.97645950e-05]  gradient norm: 7.974490779234097e-05\n",
            "iter: 937336  x: [ 3.99995957 15.99967655]  f(x): 1.6346614028657878e-09  grad at x: [-2.47136171e-06 -9.79877041e-06]  gradient norm: 1.0105618742349033e-05\n",
            "iter: 937337  x: [ 3.99995957 15.99967656]  f(x): 1.6346102330047416e-09  grad at x: [ 7.73080481e-05 -1.97706941e-05]  gradient norm: 7.979608163362983e-05\n",
            "iter: 937338  x: [ 3.99995957 15.99967656]  f(x): 1.6345616336033493e-09  grad at x: [-2.47209545e-06 -9.79837023e-06]  gradient norm: 1.0105410186667417e-05\n",
            "iter: 937339  x: [ 3.99995957 15.99967657]  f(x): 1.6345105289237417e-09  grad at x: [ 7.73574612e-05 -1.97765621e-05]  gradient norm: 7.984540821849219e-05\n",
            "iter: 937340  x: [ 3.99995957 15.99967657]  f(x): 1.6344618704377632e-09  grad at x: [-2.47282926e-06 -9.79797005e-06]  gradient norm: 1.010520171428033e-05\n",
            "iter: 937341  x: [ 3.99995957 15.99967658]  f(x): 1.6344108310107948e-09  grad at x: [ 7.74069033e-05 -1.97824338e-05]  gradient norm: 7.989476436734405e-05\n",
            "iter: 937342  x: [ 3.99995957 15.99967658]  f(x): 1.6343621133513458e-09  grad at x: [-2.47357771e-06 -9.79756805e-06]  gradient norm: 1.0104995123895216e-05\n",
            "iter: 937343  x: [ 3.99995958 15.99967659]  f(x): 1.6343111403320392e-09  grad at x: [ 7.74572768e-05 -1.97884219e-05]  gradient norm: 7.994505215545417e-05\n",
            "iter: 937344  x: [ 3.99995957 15.99967659]  f(x): 1.6342623623612231e-09  grad at x: [-2.47432622e-06 -9.79716606e-06]  gradient norm: 1.0104788618983649e-05\n",
            "iter: 937345  x: [ 3.99995958 15.9996766 ]  f(x): 1.6342114557878635e-09  grad at x: [ 7.75076501e-05 -1.97944100e-05]  gradient norm: 7.999534042553616e-05\n",
            "iter: 937346  x: [ 3.99995958 15.9996766 ]  f(x): 1.6341626174323108e-09  grad at x: [-2.47510392e-06 -9.79676042e-06]  gradient norm: 1.010458580153328e-05\n",
            "iter: 937347  x: [ 3.99995958 15.99967661]  f(x): 1.634111779582392e-09  grad at x: [ 7.7559886e-05 -1.9800631e-05]  gradient norm: 8.00474915677202e-05\n",
            "iter: 937348  x: [ 3.99995958 15.99967661]  f(x): 1.63406287861544e-09  grad at x: [-2.47583804e-06 -9.79636025e-06]  gradient norm: 1.0104377668154693e-05\n",
            "iter: 937349  x: [ 3.99995958 15.99967662]  f(x): 1.6340121061691445e-09  grad at x: [ 7.76093279e-05 -1.98065027e-05]  gradient norm: 8.009684961784805e-05\n",
            "iter: 937350  x: [ 3.99995958 15.99967662]  f(x): 1.6339631458766252e-09  grad at x: [-2.47658678e-06 -9.79595825e-06]  gradient norm: 1.0104171421417715e-05\n",
            "iter: 937351  x: [ 3.99995958 15.99967663]  f(x): 1.6339124400263373e-09  grad at x: [ 7.76597301e-05 -1.98124944e-05]  gradient norm: 8.014716844233791e-05\n",
            "iter: 937352  x: [ 3.99995958 15.99967663]  f(x): 1.6338634192329899e-09  grad at x: [-2.47733560e-06 -9.79555625e-06]  gradient norm: 1.0103965260459764e-05\n",
            "iter: 937353  x: [ 3.99995958 15.99967664]  f(x): 1.633812780017039e-09  grad at x: [ 7.77101322e-05 -1.98184862e-05]  gradient norm: 8.019748774519508e-05\n",
            "iter: 937354  x: [ 3.99995958 15.99967664]  f(x): 1.6337636986842546e-09  grad at x: [-2.47808450e-06 -9.79515426e-06]  gradient norm: 1.0103759185520713e-05\n",
            "iter: 937355  x: [ 3.99995958 15.99967665]  f(x): 1.6337131261064363e-09  grad at x: [ 7.77605051e-05 -1.98244743e-05]  gradient norm: 8.024777842488693e-05\n",
            "iter: 937356  x: [ 3.99995958 15.99967665]  f(x): 1.633663984212741e-09  grad at x: [-2.47884802e-06 -9.79475044e-06]  gradient norm: 1.0103555003009753e-05\n",
            "iter: 937357  x: [ 3.99995958 15.99967666]  f(x): 1.6336134794690831e-09  grad at x: [ 7.78118385e-05 -1.98305825e-05]  gradient norm: 8.029902992885219e-05\n",
            "iter: 937358  x: [ 3.99995958 15.99967666]  f(x): 1.6335642758344691e-09  grad at x: [-2.47958252e-06 -9.79435026e-06]  gradient norm: 1.0103347292480438e-05\n",
            "iter: 937359  x: [ 3.99995959 15.99967667]  f(x): 1.6335138367162686e-09  grad at x: [ 7.78613236e-05 -1.98364596e-05]  gradient norm: 8.034843397160512e-05\n",
            "iter: 937360  x: [ 3.99995958 15.99967667]  f(x): 1.6334645735154648e-09  grad at x: [-2.48034619e-06 -9.79394645e-06]  gradient norm: 1.0103143283839923e-05\n",
            "iter: 937361  x: [ 3.99995959 15.99967668]  f(x): 1.6334142023447751e-09  grad at x: [ 7.79126713e-05 -1.98425696e-05]  gradient norm: 8.039970099522617e-05\n",
            "iter: 937362  x: [ 3.99995959 15.99967668]  f(x): 1.6333648773076436e-09  grad at x: [-2.48109538e-06 -9.79354445e-06]  gradient norm: 1.010293755307782e-05\n",
            "iter: 937363  x: [ 3.99995959 15.99967669]  f(x): 1.6333145729636524e-09  grad at x: [ 7.79630731e-05 -1.98485614e-05]  gradient norm: 8.045002269084739e-05\n",
            "iter: 937364  x: [ 3.99995959 15.99967669]  f(x): 1.6332651871759317e-09  grad at x: [-2.48185921e-06 -9.79314063e-06]  gradient norm: 1.0102733719823763e-05\n",
            "iter: 937365  x: [ 3.99995959 15.9996767 ]  f(x): 1.6332149508576772e-09  grad at x: [ 7.80144352e-05 -1.98546732e-05]  gradient norm: 8.050130524376395e-05\n",
            "iter: 937366  x: [ 3.99995959 15.9996767 ]  f(x): 1.6331655031374471e-09  grad at x: [-2.48262311e-06 -9.79273682e-06]  gradient norm: 1.0102529974901215e-05\n",
            "iter: 937367  x: [ 3.99995959 15.99967671]  f(x): 1.6331153348847475e-09  grad at x: [ 7.80657973e-05 -1.98607850e-05]  gradient norm: 8.055258828777686e-05\n",
            "iter: 937368  x: [ 3.99995959 15.99967671]  f(x): 1.6330658251734138e-09  grad at x: [-2.48337253e-06 -9.79233482e-06]  gradient norm: 1.0102324504316563e-05\n",
            "iter: 937369  x: [ 3.99995959 15.99967672]  f(x): 1.6330157238985665e-09  grad at x: [ 7.81162279e-05 -1.98667803e-05]  gradient norm: 8.060294052253141e-05\n",
            "iter: 937370  x: [ 3.99995959 15.99967672]  f(x): 1.6329661533020498e-09  grad at x: [-2.48412203e-06 -9.79193283e-06]  gradient norm: 1.010211911949119e-05\n",
            "iter: 937371  x: [ 3.99995959 15.99967673]  f(x): 1.6329161190081266e-09  grad at x: [ 7.81666439e-05 -1.98727739e-05]  gradient norm: 8.065327867543782e-05\n",
            "iter: 937372  x: [ 3.99995959 15.99967673]  f(x): 1.63286648750458e-09  grad at x: [-2.48485705e-06 -9.79153265e-06]  gradient norm: 1.0101912004073871e-05\n",
            "iter: 937373  x: [ 3.99995959 15.99967674]  f(x): 1.6328165191363045e-09  grad at x: [ 7.82161430e-05 -1.98786529e-05]  gradient norm: 8.07027005300027e-05\n",
            "iter: 937374  x: [ 3.99995959 15.99967674]  f(x): 1.6327668277992218e-09  grad at x: [-2.48559214e-06 -9.79113247e-06]  gradient norm: 1.010170497253919e-05\n",
            "iter: 937375  x: [ 3.9999596  15.99967675]  f(x): 1.6327169254283058e-09  grad at x: [ 7.82656712e-05 -1.98845355e-05]  gradient norm: 8.075215193844378e-05\n",
            "iter: 937376  x: [ 3.99995959 15.99967675]  f(x): 1.6326671741683043e-09  grad at x: [-2.48634187e-06 -9.79073047e-06]  gradient norm: 1.0101499843181407e-05\n",
            "iter: 937377  x: [ 3.9999596  15.99967676]  f(x): 1.6326173389620923e-09  grad at x: [ 7.83161307e-05 -1.98905345e-05]  gradient norm: 8.080253513385694e-05\n",
            "iter: 937378  x: [ 3.9999596  15.99967676]  f(x): 1.6325799795246469e-09  grad at x: [ 3.79145122e-05 -1.48404306e-05]  gradient norm: 4.071545918209293e-05\n",
            "iter: 937379  x: [ 3.9999596  15.99967676]  f(x): 1.6325667511990695e-09  grad at x: [-1.85541966e-06 -9.86928353e-06]  gradient norm: 1.0042178027498925e-05\n",
            "iter: 937380  x: [ 3.9999596  15.99967679]  f(x): 1.6323661572213236e-09  grad at x: [ 1.57323029e-04 -2.97649785e-05]  gradient norm: 0.0001601139883027856\n",
            "iter: 937381  x: [ 3.9999596 15.9996768]  f(x): 1.6322200339937272e-09  grad at x: [ 7.68004118e-05 -1.96998499e-05]  gradient norm: 7.928674126371042e-05\n",
            "iter: 937382  x: [ 3.9999596 15.9996768]  f(x): 1.6321720442540407e-09  grad at x: [-2.46324547e-06 -9.79208562e-06]  gradient norm: 1.0097154006339979e-05\n",
            "iter: 937383  x: [ 3.9999596  15.99967681]  f(x): 1.6321204757966693e-09  grad at x: [ 7.68501869e-05 -1.97057634e-05]  gradient norm: 7.933642506718176e-05\n",
            "iter: 937384  x: [ 3.9999596  15.99967681]  f(x): 1.6320724269303245e-09  grad at x: [-2.46396653e-06 -9.79168726e-06]  gradient norm: 1.0096943622671164e-05\n",
            "iter: 937385  x: [ 3.9999596  15.99967681]  f(x): 1.6320209223602547e-09  grad at x: [ 7.68988123e-05 -1.97115332e-05]  gradient norm: 7.938496004760742e-05\n",
            "iter: 937386  x: [ 3.9999596  15.99967682]  f(x): 1.6319728156791053e-09  grad at x: [-2.46470223e-06 -9.79128708e-06]  gradient norm: 1.0096735108323034e-05\n",
            "iter: 937387  x: [ 3.99995961 15.99967682]  f(x): 1.6319213761428965e-09  grad at x: [ 7.69483690e-05 -1.97174195e-05]  gradient norm: 7.943442657794201e-05\n",
            "iter: 937388  x: [ 3.9999596  15.99967683]  f(x): 1.6318732105174982e-09  grad at x: [-2.46543800e-06 -9.79088691e-06]  gradient norm: 1.009652667778883e-05\n",
            "iter: 937389  x: [ 3.99995961 15.99967683]  f(x): 1.6318218360179982e-09  grad at x: [ 7.69978965e-05 -1.97233021e-05]  gradient norm: 7.948386448447818e-05\n",
            "iter: 937390  x: [ 3.99995961 15.99967683]  f(x): 1.631773611427833e-09  grad at x: [-2.46618840e-06 -9.79048491e-06]  gradient norm: 1.0096320121296109e-05\n",
            "iter: 937391  x: [ 3.99995961 15.99967684]  f(x): 1.6317223031828038e-09  grad at x: [ 7.70484135e-05 -1.97293084e-05]  gradient norm: 7.953429216909964e-05\n",
            "iter: 937392  x: [ 3.99995961 15.99967684]  f(x): 1.631674018408737e-09  grad at x: [-2.46692432e-06 -9.79008473e-06]  gradient norm: 1.0096111858756962e-05\n",
            "iter: 937393  x: [ 3.99995961 15.99967685]  f(x): 1.6316227753444573e-09  grad at x: [ 7.70979845e-05 -1.97351965e-05]  gradient norm: 7.958377467900507e-05\n",
            "iter: 937394  x: [ 3.99995961 15.99967685]  f(x): 1.6315744314795137e-09  grad at x: [-2.46768942e-06 -9.78968092e-06]  gradient norm: 1.0095907266118369e-05\n",
            "iter: 937395  x: [ 3.99995961 15.99967686]  f(x): 1.631523255825493e-09  grad at x: [ 7.71494035e-05 -1.97413156e-05]  gradient norm: 7.963510537250395e-05\n",
            "iter: 937396  x: [ 3.99995961 15.99967686]  f(x): 1.6314748506203034e-09  grad at x: [-2.46844005e-06 -9.78927892e-06]  gradient norm: 1.0095700967694595e-05\n",
            "iter: 937397  x: [ 3.99995961 15.99967687]  f(x): 1.631423741336242e-09  grad at x: [ 7.71999203e-05 -1.97473219e-05]  gradient norm: 7.968553453451983e-05\n",
            "iter: 937398  x: [ 3.99995961 15.99967687]  f(x): 1.6313752758493132e-09  grad at x: [-2.46919074e-06 -9.78887692e-06]  gradient norm: 1.0095494755120823e-05\n",
            "iter: 937399  x: [ 3.99995961 15.99967688]  f(x): 1.6313242329737173e-09  grad at x: [ 7.72504370e-05 -1.97533282e-05]  gradient norm: 7.97359641875755e-05\n",
            "iter: 937400  x: [ 3.99995961 15.99967688]  f(x): 1.6312757071488758e-09  grad at x: [-2.46995607e-06 -9.78847311e-06]  gradient norm: 1.009529042525189e-05\n",
            "iter: 937401  x: [ 3.99995961 15.99967689]  f(x): 1.6312247318361818e-09  grad at x: [ 7.73018849e-05 -1.97594509e-05]  gradient norm: 7.978732548926357e-05\n",
            "iter: 937402  x: [ 3.99995961 15.99967689]  f(x): 1.6311761445361016e-09  grad at x: [-2.47072147e-06 -9.78806929e-06]  gradient norm: 1.0095086183898152e-05\n",
            "iter: 937403  x: [ 3.99995962 15.9996769 ]  f(x): 1.631125236791152e-09  grad at x: [ 7.73533182e-05 -1.97655718e-05]  gradient norm: 7.983867275052828e-05\n",
            "iter: 937404  x: [ 3.99995961 15.9996769 ]  f(x): 1.6310765879922275e-09  grad at x: [-2.4714724e-06 -9.7876673e-06]  gradient norm: 1.0094880231824079e-05\n",
            "iter: 937405  x: [ 3.99995962 15.99967691]  f(x): 1.6310257467726878e-09  grad at x: [ 7.74038347e-05 -1.97715781e-05]  gradient norm: 7.988910388811345e-05\n",
            "iter: 937406  x: [ 3.99995962 15.99967691]  f(x): 1.6309770375180732e-09  grad at x: [-2.47223795e-06 -9.78726348e-06]  gradient norm: 1.0094676166138063e-05\n",
            "iter: 937407  x: [ 3.99995962 15.99967692]  f(x): 1.6309262640149545e-09  grad at x: [ 7.74553115e-05 -1.97777044e-05]  gradient norm: 7.994049580010976e-05\n",
            "iter: 937408  x: [ 3.99995962 15.99967692]  f(x): 1.6308774931296489e-09  grad at x: [-2.47297447e-06 -9.78686330e-06]  gradient norm: 1.0094468586165176e-05\n",
            "iter: 937409  x: [ 3.99995962 15.99967693]  f(x): 1.6308267851108681e-09  grad at x: [ 7.75048964e-05 -1.97835943e-05]  gradient norm: 7.998999672009106e-05\n",
            "iter: 937410  x: [ 3.99995962 15.99967693]  f(x): 1.6307779548103882e-09  grad at x: [-2.47372562e-06 -9.78646131e-06]  gradient norm: 1.009426289240693e-05\n",
            "iter: 937411  x: [ 3.99995962 15.99967694]  f(x): 1.6307273134670008e-09  grad at x: [ 7.75554418e-05 -1.97896043e-05]  gradient norm: 8.004045841297473e-05\n",
            "iter: 937412  x: [ 3.99995962 15.99967694]  f(x): 1.630678422577398e-09  grad at x: [-2.47447685e-06 -9.78605931e-06]  gradient norm: 1.0094057284870619e-05\n",
            "iter: 937413  x: [ 3.99995962 15.99967695]  f(x): 1.6306278479479542e-09  grad at x: [ 7.76059870e-05 -1.97956142e-05]  gradient norm: 8.009092059001825e-05\n",
            "iter: 937414  x: [ 3.99995962 15.99967695]  f(x): 1.6305788964119172e-09  grad at x: [-2.47521360e-06 -9.78565913e-06]  gradient norm: 1.0093849958598681e-05\n",
            "iter: 937415  x: [ 3.99995962 15.99967696]  f(x): 1.6305283874140045e-09  grad at x: [ 7.76556008e-05 -1.98015077e-05]  gradient norm: 8.014045202086303e-05\n",
            "iter: 937416  x: [ 3.99995962 15.99967696]  f(x): 1.6304793763147673e-09  grad at x: [-2.47596497e-06 -9.78525713e-06]  gradient norm: 1.0093644522162308e-05\n",
            "iter: 937417  x: [ 3.99995962 15.99967697]  f(x): 1.6304289341416916e-09  grad at x: [ 7.77061750e-05 -1.98075213e-05]  gradient norm: 8.019094425221878e-05\n",
            "iter: 937418  x: [ 3.99995962 15.99967697]  f(x): 1.6303798623030525e-09  grad at x: [-2.47671643e-06 -9.78485514e-06]  gradient norm: 1.0093439172013964e-05\n",
            "iter: 937419  x: [ 3.99995963 15.99967698]  f(x): 1.6303294869588768e-09  grad at x: [ 7.77567201e-05 -1.98135313e-05]  gradient norm: 8.024140786427173e-05\n",
            "iter: 937420  x: [ 3.99995962 15.99967698]  f(x): 1.630280354359113e-09  grad at x: [-2.47748251e-06 -9.78445132e-06]  gradient norm: 1.0093235716951197e-05\n",
            "iter: 937421  x: [ 3.99995963 15.99967699]  f(x): 1.6302300470400594e-09  grad at x: [ 7.78082255e-05 -1.98196612e-05]  gradient norm: 8.029283231430816e-05\n",
            "iter: 937422  x: [ 3.99995963 15.99967699]  f(x): 1.6301808524815721e-09  grad at x: [-2.47823411e-06 -9.78404933e-06]  gradient norm: 1.0093030540420143e-05\n",
            "iter: 937423  x: [ 3.99995963 15.999677  ]  f(x): 1.6301306120692594e-09  grad at x: [ 7.78587703e-05 -1.98256712e-05]  gradient norm: 8.034329689525189e-05\n",
            "iter: 937424  x: [ 3.99995963 15.999677  ]  f(x): 1.630081356688631e-09  grad at x: [-2.47898578e-06 -9.78364733e-06]  gradient norm: 1.009282545024351e-05\n",
            "iter: 937425  x: [ 3.99995963 15.99967701]  f(x): 1.630031183256208e-09  grad at x: [ 7.79093442e-05 -1.98316848e-05]  gradient norm: 8.039379105418219e-05\n",
            "iter: 937426  x: [ 3.99995963 15.99967701]  f(x): 1.629981866962633e-09  grad at x: [-2.47975209e-06 -9.78324351e-06]  gradient norm: 1.0092622258600818e-05\n",
            "iter: 937427  x: [ 3.99995963 15.99967702]  f(x): 1.6299317617086004e-09  grad at x: [ 7.79608785e-05 -1.98378184e-05]  gradient norm: 8.044524608039141e-05\n",
            "iter: 937428  x: [ 3.99995963 15.99967702]  f(x): 1.629882383302199e-09  grad at x: [-2.48050392e-06 -9.78284152e-06]  gradient norm: 1.0092417342392706e-05\n",
            "iter: 937429  x: [ 3.99995963 15.99967703]  f(x): 1.6298323451059866e-09  grad at x: [ 7.80114523e-05 -1.98438320e-05]  gradient norm: 8.049574120135791e-05\n",
            "iter: 937430  x: [ 3.99995963 15.99967703]  f(x): 1.6297829057255304e-09  grad at x: [-2.48125582e-06 -9.78243952e-06]  gradient norm: 1.009221251238719e-05\n",
            "iter: 937431  x: [ 3.99995963 15.99967704]  f(x): 1.6297329346257312e-09  grad at x: [ 7.80620259e-05 -1.98498456e-05]  gradient norm: 8.054623679937854e-05\n",
            "iter: 937432  x: [ 3.99995963 15.99967704]  f(x): 1.6296834342149715e-09  grad at x: [-2.48202235e-06 -9.78203570e-06]  gradient norm: 1.0092009584583276e-05\n",
            "iter: 937433  x: [ 3.99995963 15.99967705]  f(x): 1.6296335314123217e-09  grad at x: [ 7.81135600e-05 -1.98559792e-05]  gradient norm: 8.05976932880557e-05\n",
            "iter: 937434  x: [ 3.99995963 15.99967705]  f(x): 1.6295839687691432e-09  grad at x: [-2.48277440e-06 -9.78163371e-06]  gradient norm: 1.0091804928461011e-05\n",
            "iter: 937435  x: [ 3.99995963 15.99967706]  f(x): 1.6295341331755487e-09  grad at x: [ 7.81641626e-05 -1.98619964e-05]  gradient norm: 8.064821894688634e-05\n",
            "iter: 937436  x: [ 3.99995963 15.99967706]  f(x): 1.6294845094062455e-09  grad at x: [-2.48352653e-06 -9.78123171e-06]  gradient norm: 1.0091600359044561e-05\n",
            "iter: 937437  x: [ 3.99995964 15.99967707]  f(x): 1.629434741060344e-09  grad at x: [ 7.82147652e-05 -1.98680136e-05]  gradient norm: 8.069874507509161e-05\n",
            "iter: 937438  x: [ 3.99995963 15.99967707]  f(x): 1.6293850561086244e-09  grad at x: [-2.48429329e-06 -9.78082790e-06]  gradient norm: 1.0091397695280147e-05\n",
            "iter: 937439  x: [ 3.99995964 15.99967708]  f(x): 1.6293477687521844e-09  grad at x: [ 3.78909956e-05 -1.48274867e-05]  gradient norm: 4.068884252412671e-05\n",
            "iter: 937440  x: [ 3.99995964 15.99967708]  f(x): 1.6293345582202724e-09  grad at x: [-1.85381963e-06 -9.85947918e-06]  gradient norm: 1.0032246851972064e-05\n",
            "iter: 937441  x: [ 3.99995964 15.99967712]  f(x): 1.6291345101924092e-09  grad at x: [ 1.57228765e-04 -2.97431925e-05]  gradient norm: 0.0001600173180878238\n",
            "iter: 937442  x: [ 3.99995964 15.99967712]  f(x): 1.628988563512521e-09  grad at x: [ 7.67546356e-05 -1.96841247e-05]  gradient norm: 7.923849346086107e-05\n",
            "iter: 937443  x: [ 3.99995964 15.99967712]  f(x): 1.6289406327556412e-09  grad at x: [-2.46127676e-06 -9.78232856e-06]  gradient norm: 1.008721147746714e-05\n",
            "iter: 937444  x: [ 3.99995964 15.99967713]  f(x): 1.6288892023099146e-09  grad at x: [ 7.68042336e-05 -1.96900164e-05]  gradient norm: 7.928800064470103e-05\n",
            "iter: 937445  x: [ 3.99995964 15.99967713]  f(x): 1.6288412126520764e-09  grad at x: [-2.46201483e-06 -9.78192838e-06]  gradient norm: 1.0087003514993684e-05\n",
            "iter: 937446  x: [ 3.99995964 15.99967714]  f(x): 1.6287898473270784e-09  grad at x: [ 7.68539334e-05 -1.96959209e-05]  gradient norm: 7.933761014285463e-05\n",
            "iter: 937447  x: [ 3.99995964 15.99967714]  f(x): 1.6287417986119875e-09  grad at x: [-2.46276752e-06 -9.78152639e-06]  gradient norm: 1.0086797425340108e-05\n",
            "iter: 937448  x: [ 3.99995965 15.99967714]  f(x): 1.6286904995552486e-09  grad at x: [ 7.69045645e-05 -1.97019417e-05]  gradient norm: 7.9388151217771e-05\n",
            "iter: 937449  x: [ 3.99995964 15.99967715]  f(x): 1.6286423906524726e-09  grad at x: [-2.46352028e-06 -9.78112439e-06]  gradient norm: 1.0086591422103602e-05\n",
            "iter: 937450  x: [ 3.99995965 15.99967715]  f(x): 1.6285911579026762e-09  grad at x: [ 7.69551956e-05 -1.97079626e-05]  gradient norm: 7.943869278968149e-05\n",
            "iter: 937451  x: [ 3.99995965 15.99967716]  f(x): 1.6285429887547846e-09  grad at x: [-2.46425857e-06 -9.78072421e-06]  gradient norm: 1.0086383713905745e-05\n",
            "iter: 937452  x: [ 3.99995965 15.99967716]  f(x): 1.6284918212731053e-09  grad at x: [ 7.70049243e-05 -1.97138706e-05]  gradient norm: 7.948833284081736e-05\n",
            "iter: 937453  x: [ 3.99995965 15.99967716]  f(x): 1.6284435929197396e-09  grad at x: [-2.46501148e-06 -9.78032222e-06]  gradient norm: 1.0086177882157576e-05\n",
            "iter: 937454  x: [ 3.99995965 15.99967717]  f(x): 1.6283924918558958e-09  grad at x: [ 7.70555842e-05 -1.97198951e-05]  gradient norm: 7.953890449432365e-05\n",
            "iter: 937455  x: [ 3.99995965 15.99967717]  f(x): 1.6283442031470619e-09  grad at x: [-2.46577903e-06 -9.77991840e-06]  gradient norm: 1.0085973930684213e-05\n",
            "iter: 937456  x: [ 3.99995965 15.99967718]  f(x): 1.628293169618685e-09  grad at x: [ 7.71071464e-05 -1.97260324e-05]  gradient norm: 7.959037868165547e-05\n",
            "iter: 937457  x: [ 3.99995965 15.99967718]  f(x): 1.6282448194527507e-09  grad at x: [-2.46651754e-06 -9.77951822e-06]  gradient norm: 1.0085766478133591e-05\n",
            "iter: 937458  x: [ 3.99995965 15.99967719]  f(x): 1.6281938513064976e-09  grad at x: [ 7.71568749e-05 -1.97319405e-05]  gradient norm: 7.964002018903381e-05\n",
            "iter: 937459  x: [ 3.99995965 15.99967719]  f(x): 1.6281454418202506e-09  grad at x: [-2.46727068e-06 -9.77911623e-06]  gradient norm: 1.0085560905684901e-05\n",
            "iter: 937460  x: [ 3.99995965 15.9996772 ]  f(x): 1.6280945402422835e-09  grad at x: [ 7.72075637e-05 -1.97379686e-05]  gradient norm: 7.969062242527635e-05\n",
            "iter: 937461  x: [ 3.99995965 15.9996772 ]  f(x): 1.6280460702492848e-09  grad at x: [-2.46803845e-06 -9.77871241e-06]  gradient norm: 1.008535721716475e-05\n",
            "iter: 937462  x: [ 3.99995965 15.99967721]  f(x): 1.627995236359371e-09  grad at x: [ 7.72591548e-05 -1.97441095e-05]  gradient norm: 7.974212721987432e-05\n",
            "iter: 937463  x: [ 3.99995965 15.99967721]  f(x): 1.6279467047384805e-09  grad at x: [-2.46879174e-06 -9.77831041e-06]  gradient norm: 1.0085151819034008e-05\n",
            "iter: 937464  x: [ 3.99995966 15.99967722]  f(x): 1.6278959374607636e-09  grad at x: [ 7.73098144e-05 -1.97501340e-05]  gradient norm: 7.979270135112926e-05\n",
            "iter: 937465  x: [ 3.99995965 15.99967722]  f(x): 1.6278473453060254e-09  grad at x: [-2.46954511e-06 -9.77790842e-06]  gradient norm: 1.008494650728018e-05\n",
            "iter: 937466  x: [ 3.99995966 15.99967723]  f(x): 1.6277966447135882e-09  grad at x: [ 7.73605030e-05 -1.97561621e-05]  gradient norm: 7.984330507202792e-05\n",
            "iter: 937467  x: [ 3.99995966 15.99967723]  f(x): 1.6277479919342724e-09  grad at x: [-2.4703131e-06 -9.7775046e-06]  gradient norm: 1.008474308313106e-05\n",
            "iter: 937468  x: [ 3.99995966 15.99967724]  f(x): 1.6276973591833636e-09  grad at x: [ 7.74121229e-05 -1.97623067e-05]  gradient norm: 7.989484047793758e-05\n",
            "iter: 937469  x: [ 3.99995966 15.99967724]  f(x): 1.6276486446218477e-09  grad at x: [-2.47106662e-06 -9.77710260e-06]  gradient norm: 1.0084537945828852e-05\n",
            "iter: 937470  x: [ 3.99995966 15.99967725]  f(x): 1.6275980786344842e-09  grad at x: [ 7.74628114e-05 -1.97683348e-05]  gradient norm: 7.99454451862833e-05\n",
            "iter: 937471  x: [ 3.99995966 15.99967725]  f(x): 1.627549303386938e-09  grad at x: [-2.47182021e-06 -9.77670061e-06]  gradient norm: 1.008433289496997e-05\n",
            "iter: 937472  x: [ 3.99995966 15.99967726]  f(x): 1.6274988041667648e-09  grad at x: [ 7.75134852e-05 -1.97743611e-05]  gradient norm: 7.999603583098451e-05\n",
            "iter: 937473  x: [ 3.99995966 15.99967726]  f(x): 1.6274499682108001e-09  grad at x: [-2.47255933e-06 -9.77630043e-06]  gradient norm: 1.0084126126216139e-05\n",
            "iter: 937474  x: [ 3.99995966 15.99967727]  f(x): 1.6273995347120715e-09  grad at x: [ 7.75632422e-05 -1.97802729e-05]  gradient norm: 8.004571028816665e-05\n",
            "iter: 937475  x: [ 3.99995966 15.99967727]  f(x): 1.6273506390942547e-09  grad at x: [-2.47331307e-06 -9.77589843e-06]  gradient norm: 1.0083921247330945e-05\n",
            "iter: 937476  x: [ 3.99995966 15.99967728]  f(x): 1.627300272509126e-09  grad at x: [ 7.76139596e-05 -1.97863046e-05]  gradient norm: 8.009634554800163e-05\n",
            "iter: 937477  x: [ 3.99995966 15.99967728]  f(x): 1.6272513160359268e-09  grad at x: [-2.47405233e-06 -9.77549826e-06]  gradient norm: 1.0083714648222027e-05\n",
            "iter: 937478  x: [ 3.99995966 15.99967729]  f(x): 1.6272010152821538e-09  grad at x: [ 7.76637455e-05 -1.97922200e-05]  gradient norm: 8.014605004789491e-05\n",
            "iter: 937479  x: [ 3.99995966 15.99967729]  f(x): 1.6271519990366373e-09  grad at x: [-2.47480623e-06 -9.77509626e-06]  gradient norm: 1.0083509941398386e-05\n",
            "iter: 937480  x: [ 3.99995967 15.9996773 ]  f(x): 1.6271017652388656e-09  grad at x: [ 7.77144336e-05 -1.97982481e-05]  gradient norm: 8.019665716328202e-05\n",
            "iter: 937481  x: [ 3.99995966 15.9996773 ]  f(x): 1.6270526880961095e-09  grad at x: [-2.47557475e-06 -9.77469244e-06]  gradient norm: 1.0083307130691601e-05\n",
            "iter: 937482  x: [ 3.99995967 15.99967731]  f(x): 1.627002522450147e-09  grad at x: [ 7.77660821e-05 -1.98043963e-05]  gradient norm: 8.02482251294902e-05\n",
            "iter: 937483  x: [ 3.99995967 15.99967731]  f(x): 1.6269533832303301e-09  grad at x: [-2.47631424e-06 -9.77429227e-06]  gradient norm: 1.0083100788087516e-05\n",
            "iter: 937484  x: [ 3.99995967 15.99967732]  f(x): 1.626903283564549e-09  grad at x: [ 7.78158969e-05 -1.98103153e-05]  gradient norm: 8.029796014994388e-05\n",
            "iter: 937485  x: [ 3.99995967 15.99967732]  f(x): 1.6268540844227569e-09  grad at x: [-2.47706835e-06 -9.77389027e-06]  gradient norm: 1.0082896341426527e-05\n",
            "iter: 937486  x: [ 3.99995967 15.99967733]  f(x): 1.6268040518639393e-09  grad at x: [ 7.78666139e-05 -1.98163470e-05]  gradient norm: 8.03485978134076e-05\n",
            "iter: 937487  x: [ 3.99995967 15.99967733]  f(x): 1.6267547916720135e-09  grad at x: [-2.47780800e-06 -9.77349009e-06]  gradient norm: 1.0082690168686205e-05\n",
            "iter: 937488  x: [ 3.99995967 15.99967734]  f(x): 1.6267048251343274e-09  grad at x: [ 7.79163995e-05 -1.98222624e-05]  gradient norm: 8.039830466323947e-05\n",
            "iter: 937489  x: [ 3.99995967 15.99967734]  f(x): 1.6266555049789226e-09  grad at x: [-2.47856226e-06 -9.77308810e-06]  gradient norm: 1.0082485894307045e-05\n",
            "iter: 937490  x: [ 3.99995967 15.99967735]  f(x): 1.6266056056597375e-09  grad at x: [ 7.79671454e-05 -1.98282978e-05]  gradient norm: 8.044897237905347e-05\n",
            "iter: 937491  x: [ 3.99995967 15.99967735]  f(x): 1.6265562243432075e-09  grad at x: [-2.47933116e-06 -9.77268428e-06]  gradient norm: 1.0082283522123105e-05\n",
            "iter: 937492  x: [ 3.99995967 15.99967736]  f(x): 1.6265063934427065e-09  grad at x: [ 7.80188372e-05 -1.98344515e-05]  gradient norm: 8.050058643652238e-05\n",
            "iter: 937493  x: [ 3.99995967 15.99967736]  f(x): 1.6264569497819505e-09  grad at x: [-2.48010013e-06 -9.77228046e-06]  gradient norm: 1.0082081239479278e-05\n",
            "iter: 937494  x: [ 3.99995967 15.99967737]  f(x): 1.6264071872699819e-09  grad at x: [ 7.80704997e-05 -1.98406015e-05]  gradient norm: 8.055217188817257e-05\n",
            "iter: 937495  x: [ 3.99995967 15.99967737]  f(x): 1.6263576812764133e-09  grad at x: [-2.48085462e-06 -9.77187847e-06]  gradient norm: 1.0081877227991143e-05\n",
            "iter: 937496  x: [ 3.99995967 15.99967738]  f(x): 1.6263079861009685e-09  grad at x: [ 7.81212455e-05 -1.98466369e-05]  gradient norm: 8.060284105458016e-05\n",
            "iter: 937497  x: [ 3.99995967 15.99967738]  f(x): 1.62625841882742e-09  grad at x: [-2.48162374e-06 -9.77147465e-06]  gradient norm: 1.008167512240197e-05\n",
            "iter: 937498  x: [ 3.99995967 15.99967739]  f(x): 1.626221197651124e-09  grad at x: [ 3.78456421e-05 -1.48121308e-05]  gradient norm: 4.064101180160665e-05\n",
            "iter: 937499  x: [ 3.99995967 15.99967739]  f(x): 1.6262080178272147e-09  grad at x: [-1.85187890e-06 -9.85003498e-06]  gradient norm: 1.0022606679701603e-05\n",
            "iter: 937500  x: [ 3.99995968 15.99967743]  f(x): 1.6260082528466506e-09  grad at x: [ 1.57036091e-04 -2.97094230e-05]  gradient norm: 0.0001598217251585574\n",
            "iter: 937501  x: [ 3.99995968 15.99967743]  f(x): 1.6258626626001398e-09  grad at x: [ 7.66603922e-05 -1.96626588e-05]  gradient norm: 7.914187187661335e-05\n",
            "iter: 937502  x: [ 3.99995968 15.99967743]  f(x): 1.6258148482570338e-09  grad at x: [-2.45860324e-06 -9.77297714e-06]  gradient norm: 1.0077490362490171e-05\n",
            "iter: 937503  x: [ 3.99995968 15.99967744]  f(x): 1.6257634928380714e-09  grad at x: [ 7.67106136e-05 -1.96686287e-05]  gradient norm: 7.919200211422508e-05\n",
            "iter: 937504  x: [ 3.99995968 15.99967744]  f(x): 1.6257156189369536e-09  grad at x: [-2.45935822e-06 -9.77257514e-06]  gradient norm: 1.0077284739350357e-05\n",
            "iter: 937505  x: [ 3.99995968 15.99967744]  f(x): 1.6256643298341402e-09  grad at x: [ 7.67613880e-05 -1.96746678e-05]  gradient norm: 7.924268567632263e-05\n",
            "iter: 937506  x: [ 3.99995968 15.99967745]  f(x): 1.6256163956705269e-09  grad at x: [-2.46009872e-06 -9.77217496e-06]  gradient norm: 1.0077077414454167e-05\n",
            "iter: 937507  x: [ 3.99995968 15.99967745]  f(x): 1.6255651718138292e-09  grad at x: [ 7.68112309e-05 -1.96805904e-05]  gradient norm: 7.929243864886475e-05\n",
            "iter: 937508  x: [ 3.99995968 15.99967746]  f(x): 1.6255171784759272e-09  grad at x: [-2.46083930e-06 -9.77177478e-06]  gradient norm: 1.0076870173820124e-05\n",
            "iter: 937509  x: [ 3.99995969 15.99967746]  f(x): 1.6254660199019855e-09  grad at x: [ 7.68610883e-05 -1.96865149e-05]  gradient norm: 7.934220665233152e-05\n",
            "iter: 937510  x: [ 3.99995968 15.99967746]  f(x): 1.625417967317068e-09  grad at x: [-2.46157995e-06 -9.77137461e-06]  gradient norm: 1.0076663017686844e-05\n",
            "iter: 937511  x: [ 3.99995969 15.99967747]  f(x): 1.6253668741333463e-09  grad at x: [ 7.69109747e-05 -1.96924429e-05]  gradient norm: 7.93920042344837e-05\n",
            "iter: 937512  x: [ 3.99995969 15.99967747]  f(x): 1.6253187622121237e-09  grad at x: [-2.46233523e-06 -9.77097261e-06]  gradient norm: 1.0076457737986149e-05\n",
            "iter: 937513  x: [ 3.99995969 15.99967748]  f(x): 1.6252677354980592e-09  grad at x: [ 7.69617487e-05 -1.96984820e-05]  gradient norm: 7.944268977226235e-05\n",
            "iter: 937514  x: [ 3.99995969 15.99967748]  f(x): 1.625219563160818e-09  grad at x: [-2.46310514e-06 -9.77056879e-06]  gradient norm: 1.0076254338773708e-05\n",
            "iter: 937515  x: [ 3.99995969 15.99967749]  f(x): 1.625168604101316e-09  grad at x: [ 7.70134831e-05 -1.97046411e-05]  gradient norm: 7.949433604172645e-05\n",
            "iter: 937516  x: [ 3.99995969 15.99967749]  f(x): 1.62512037016178e-09  grad at x: [-2.46386057e-06 -9.77016680e-06]  gradient norm: 1.0076049233924634e-05\n",
            "iter: 937517  x: [ 3.99995969 15.9996775 ]  f(x): 1.6250694777189388e-09  grad at x: [ 7.70643152e-05 -1.97106874e-05]  gradient norm: 7.954508078288196e-05\n",
            "iter: 937518  x: [ 3.99995969 15.9996775 ]  f(x): 1.6250211832158273e-09  grad at x: [-2.46463062e-06 -9.76976298e-06]  gradient norm: 1.0075846011812595e-05\n",
            "iter: 937519  x: [ 3.99995969 15.99967751]  f(x): 1.6249703585076501e-09  grad at x: [ 7.71160495e-05 -1.97168465e-05]  gradient norm: 7.959672807793034e-05\n",
            "iter: 937520  x: [ 3.99995969 15.99967751]  f(x): 1.624922002356296e-09  grad at x: [-2.46535710e-06 -9.76936462e-06]  gradient norm: 1.0075637488203458e-05\n",
            "iter: 937521  x: [ 3.99995969 15.99967752]  f(x): 1.6248712420804942e-09  grad at x: [ 7.71650042e-05 -1.97226582e-05]  gradient norm: 7.964559695073086e-05\n",
            "iter: 937522  x: [ 3.99995969 15.99967752]  f(x): 1.6248228275308452e-09  grad at x: [-2.46608365e-06 -9.76896627e-06]  gradient norm: 1.0075429046671518e-05\n",
            "iter: 937523  x: [ 3.99995969 15.99967753]  f(x): 1.6247721317243152e-09  grad at x: [ 7.72139442e-05 -1.97284680e-05]  gradient norm: 7.969445173114002e-05\n",
            "iter: 937524  x: [ 3.99995969 15.99967753]  f(x): 1.6247236587576466e-09  grad at x: [-2.46682483e-06 -9.76856609e-06]  gradient norm: 1.0075222486503653e-05\n",
            "iter: 937525  x: [ 3.9999597  15.99967754]  f(x): 1.6246730286412274e-09  grad at x: [ 7.72638592e-05 -1.97343998e-05]  gradient norm: 7.974428179604032e-05\n",
            "iter: 937526  x: [ 3.99995969 15.99967754]  f(x): 1.6246244960364242e-09  grad at x: [-2.46758064e-06 -9.76816409e-06]  gradient norm: 1.0075017811695437e-05\n",
            "iter: 937527  x: [ 3.9999597  15.99967755]  f(x): 1.6245739327287105e-09  grad at x: [ 7.73146910e-05 -1.97404461e-05]  gradient norm: 7.979502897842784e-05\n",
            "iter: 937528  x: [ 3.9999597  15.99967755]  f(x): 1.624525339366902e-09  grad at x: [-2.46835107e-06 -9.76776028e-06]  gradient norm: 1.0074815025436518e-05\n",
            "iter: 937529  x: [ 3.9999597  15.99967756]  f(x): 1.6244748440236976e-09  grad at x: [ 7.73664539e-05 -1.97466088e-05]  gradient norm: 7.984670785278e-05\n",
            "iter: 937530  x: [ 3.9999597  15.99967756]  f(x): 1.6244261887477064e-09  grad at x: [-2.46910703e-06 -9.76735828e-06]  gradient norm: 1.0074610525790964e-05\n",
            "iter: 937531  x: [ 3.9999597  15.99967757]  f(x): 1.6243757603263e-09  grad at x: [ 7.74173146e-05 -1.97526588e-05]  gradient norm: 7.989748512996856e-05\n",
            "iter: 937532  x: [ 3.9999597  15.99967757]  f(x): 1.6243270441970066e-09  grad at x: [-2.46986306e-06 -9.76695628e-06]  gradient norm: 1.0074406113050781e-05\n",
            "iter: 937533  x: [ 3.9999597  15.99967758]  f(x): 1.624276682666935e-09  grad at x: [ 7.74681315e-05 -1.97587033e-05]  gradient norm: 7.994821924511156e-05\n",
            "iter: 937534  x: [ 3.9999597  15.99967758]  f(x): 1.6242279056787296e-09  grad at x: [-2.47061916e-06 -9.76655429e-06]  gradient norm: 1.0074201787455877e-05\n",
            "iter: 937535  x: [ 3.9999597  15.99967759]  f(x): 1.6241776111485018e-09  grad at x: [ 7.75189921e-05 -1.97647532e-05]  gradient norm: 7.999899750213118e-05\n",
            "iter: 937536  x: [ 3.9999597  15.99967759]  f(x): 1.624128773209948e-09  grad at x: [-2.47136079e-06 -9.76615411e-06]  gradient norm: 1.0073995742099275e-05\n",
            "iter: 937537  x: [ 3.9999597 15.9996776]  f(x): 1.6240785445989066e-09  grad at x: [ 7.75689212e-05 -1.97706868e-05]  gradient norm: 8.004884500686503e-05\n",
            "iter: 937538  x: [ 3.9999597 15.9996776]  f(x): 1.624029646791482e-09  grad at x: [-2.47211705e-06 -9.76575211e-06]  gradient norm: 1.0073791589442093e-05\n",
            "iter: 937539  x: [ 3.9999597  15.99967761]  f(x): 1.6239794852927718e-09  grad at x: [ 7.76197961e-05 -1.97767386e-05]  gradient norm: 8.00996387823048e-05\n",
            "iter: 937540  x: [ 3.9999597  15.99967761]  f(x): 1.623930526423055e-09  grad at x: [-2.47288793e-06 -9.76534830e-06]  gradient norm: 1.0073589332675688e-05\n",
            "iter: 937541  x: [ 3.9999597  15.99967762]  f(x): 1.6238804331617372e-09  grad at x: [ 7.76715877e-05 -1.97829049e-05]  gradient norm: 8.015134975247852e-05\n",
            "iter: 937542  x: [ 3.9999597  15.99967762]  f(x): 1.6238314121206386e-09  grad at x: [-2.47362978e-06 -9.76494812e-06]  gradient norm: 1.0073383545349537e-05\n",
            "iter: 937543  x: [ 3.99995971 15.99967763]  f(x): 1.6237813848583162e-09  grad at x: [ 7.77215021e-05 -1.97888367e-05]  gradient norm: 8.020118413895894e-05\n",
            "iter: 937544  x: [ 3.99995971 15.99967763]  f(x): 1.623732303849263e-09  grad at x: [-2.47437171e-06 -9.76454794e-06]  gradient norm: 1.0073177842460464e-05\n",
            "iter: 937545  x: [ 3.99995971 15.99967764]  f(x): 1.6236823426932244e-09  grad at x: [ 7.77714600e-05 -1.97947738e-05]  gradient norm: 8.025106264210629e-05\n",
            "iter: 937546  x: [ 3.99995971 15.99967764]  f(x): 1.623633201627096e-09  grad at x: [-2.47512827e-06 -9.76414594e-06]  gradient norm: 1.0072974037145682e-05\n",
            "iter: 937547  x: [ 3.99995971 15.99967765]  f(x): 1.6235833077382754e-09  grad at x: [ 7.78223491e-05 -1.98008274e-05]  gradient norm: 8.030187290080587e-05\n",
            "iter: 937548  x: [ 3.99995971 15.99967765]  f(x): 1.623534105453861e-09  grad at x: [-2.47589945e-06 -9.76374213e-06]  gradient norm: 1.007277213259768e-05\n",
            "iter: 937549  x: [ 3.99995971 15.99967766]  f(x): 1.62348427999596e-09  grad at x: [ 7.78741550e-05 -1.98069956e-05]  gradient norm: 8.035360039019663e-05\n",
            "iter: 937550  x: [ 3.99995971 15.99967766]  f(x): 1.6234350153292824e-09  grad at x: [-2.47668526e-06 -9.76333649e-06]  gradient norm: 1.0072572132727458e-05\n",
            "iter: 937551  x: [ 3.99995971 15.99967767]  f(x): 1.6233852594669961e-09  grad at x: [ 7.79269067e-05 -1.98132821e-05]  gradient norm: 8.040627424118601e-05\n",
            "iter: 937552  x: [ 3.99995971 15.99967767]  f(x): 1.6233359312693258e-09  grad at x: [-2.47744205e-06 -9.76293450e-06]  gradient norm: 1.007236859277099e-05\n",
            "iter: 937553  x: [ 3.99995971 15.99967768]  f(x): 1.6232862427930863e-09  grad at x: [ 7.79778102e-05 -1.98193375e-05]  gradient norm: 8.045710052635653e-05\n",
            "iter: 937554  x: [ 3.99995971 15.99967768]  f(x): 1.6232368532390287e-09  grad at x: [-2.4781989e-06 -9.7625325e-06]  gradient norm: 1.0072165139745379e-05\n",
            "iter: 937555  x: [ 3.99995971 15.99967769]  f(x): 1.623187232188508e-09  grad at x: [ 7.80286991e-05 -1.98253911e-05]  gradient norm: 8.050791274051797e-05\n",
            "iter: 937556  x: [ 3.99995971 15.99967769]  f(x): 1.623137781256557e-09  grad at x: [-2.47897039e-06 -9.76212868e-06]  gradient norm: 1.007196359288656e-05\n",
            "iter: 937557  x: [ 3.99995971 15.9996777 ]  f(x): 1.623088228832461e-09  grad at x: [ 7.80805483e-05 -1.98315647e-05]  gradient norm: 8.055968587528932e-05\n",
            "iter: 937558  x: [ 3.99995971 15.9996777 ]  f(x): 1.6230510935836123e-09  grad at x: [ 3.78003959e-05 -1.47966439e-05]  gradient norm: 4.05932334468851e-05\n",
            "iter: 937559  x: [ 3.99995971 15.9996777 ]  f(x): 1.6230379444385465e-09  grad at x: [-1.84994721e-06 -9.84044527e-06]  gradient norm: 1.0012825168737738e-05\n",
            "iter: 937560  x: [ 3.99995972 15.99967774]  f(x): 1.622838490273745e-09  grad at x: [ 1.56850379e-04 -2.96763792e-05]  gradient norm: 0.00015963310718072\n",
            "iter: 937561  x: [ 3.99995972 15.99967774]  f(x): 1.6226932434139542e-09  grad at x: [ 7.65696176e-05 -1.96414821e-05]  gradient norm: 7.904868224793571e-05\n",
            "iter: 937562  x: [ 3.99995972 15.99967774]  f(x): 1.6226455412985625e-09  grad at x: [-2.45595346e-06 -9.76347837e-06]  gradient norm: 1.0067632162432877e-05\n",
            "iter: 937563  x: [ 3.99995972 15.99967775]  f(x): 1.6225942668072684e-09  grad at x: [ 7.66196620e-05 -1.96474302e-05]  gradient norm: 7.909863541471843e-05\n",
            "iter: 937564  x: [ 3.99995972 15.99967775]  f(x): 1.6225465054111545e-09  grad at x: [-2.45671084e-06 -9.76307638e-06]  gradient norm: 1.0067427104146694e-05\n",
            "iter: 937565  x: [ 3.99995972 15.99967776]  f(x): 1.6224952973233501e-09  grad at x: [ 7.66705795e-05 -1.96534875e-05]  gradient norm: 7.914946195696529e-05\n",
            "iter: 937566  x: [ 3.99995972 15.99967776]  f(x): 1.622447475585889e-09  grad at x: [-2.45743919e-06 -9.76267802e-06]  gradient norm: 1.0067218556694239e-05\n",
            "iter: 937567  x: [ 3.99995972 15.99967777]  f(x): 1.622396331759517e-09  grad at x: [ 7.67196633e-05 -1.96593155e-05]  gradient norm: 7.919845592583995e-05\n",
            "iter: 937568  x: [ 3.99995972 15.99967777]  f(x): 1.6223484517888953e-09  grad at x: [-2.45819672e-06 -9.76227602e-06]  gradient norm: 1.0067013670589348e-05\n",
            "iter: 937569  x: [ 3.99995972 15.99967778]  f(x): 1.622297374476942e-09  grad at x: [ 7.67706097e-05 -1.96653764e-05]  gradient norm: 7.924931255889101e-05\n",
            "iter: 937570  x: [ 3.99995972 15.99967778]  f(x): 1.6222494340361484e-09  grad at x: [-2.45893977e-06 -9.76187584e-06]  gradient norm: 1.0066807080776976e-05\n",
            "iter: 937571  x: [ 3.99995973 15.99967779]  f(x): 1.6221984221687317e-09  grad at x: [ 7.68206247e-05 -1.96713208e-05]  gradient norm: 7.929923858962629e-05\n",
            "iter: 937572  x: [ 3.99995972 15.99967779]  f(x): 1.622150422328463e-09  grad at x: [-2.45969745e-06 -9.76147385e-06]  gradient norm: 1.0066602367928896e-05\n",
            "iter: 937573  x: [ 3.99995973 15.9996778 ]  f(x): 1.6220994770530892e-09  grad at x: [ 7.68715709e-05 -1.96773817e-05]  gradient norm: 7.935009622388901e-05\n",
            "iter: 937574  x: [ 3.99995973 15.9996778 ]  f(x): 1.6220514166818093e-09  grad at x: [-2.46042610e-06 -9.76107549e-06]  gradient norm: 1.0066394156278613e-05\n",
            "iter: 937575  x: [ 3.99995973 15.99967781]  f(x): 1.6220005358166868e-09  grad at x: [ 7.69206544e-05 -1.96832098e-05]  gradient norm: 7.939909210190613e-05\n",
            "iter: 937576  x: [ 3.99995973 15.99967781]  f(x): 1.6219524170623243e-09  grad at x: [-2.46118393e-06 -9.76067349e-06]  gradient norm: 1.0066189615354156e-05\n",
            "iter: 937577  x: [ 3.99995973 15.99967782]  f(x): 1.621901602900328e-09  grad at x: [ 7.69716297e-05 -1.96892743e-05]  gradient norm: 7.944997982049327e-05\n",
            "iter: 937578  x: [ 3.99995973 15.99967782]  f(x): 1.6218534234686403e-09  grad at x: [-2.46194184e-06 -9.76027150e-06]  gradient norm: 1.0065985161846316e-05\n",
            "iter: 937579  x: [ 3.99995973 15.99967783]  f(x): 1.6218026760147845e-09  grad at x: [ 7.70225757e-05 -1.96953351e-05]  gradient norm: 7.950083894367304e-05\n",
            "iter: 937580  x: [ 3.99995973 15.99967783]  f(x): 1.621754435918913e-09  grad at x: [-2.46271437e-06 -9.75986768e-06]  gradient norm: 1.0065782592142675e-05\n",
            "iter: 937581  x: [ 3.99995973 15.99967784]  f(x): 1.621703756359245e-09  grad at x: [ 7.70744821e-05 -1.97015161e-05]  gradient norm: 7.955265882410668e-05\n",
            "iter: 937582  x: [ 3.99995973 15.99967784]  f(x): 1.621655454429109e-09  grad at x: [-2.46345787e-06 -9.75946750e-06]  gradient norm: 1.0065576516735258e-05\n",
            "iter: 937583  x: [ 3.99995973 15.99967785]  f(x): 1.6216048405775535e-09  grad at x: [ 7.71245257e-05 -1.97074642e-05]  gradient norm: 7.960261688454795e-05\n",
            "iter: 937584  x: [ 3.99995973 15.99967785]  f(x): 1.6215564789653713e-09  grad at x: [-2.46423055e-06 -9.75906369e-06]  gradient norm: 1.0065374124169237e-05\n",
            "iter: 937585  x: [ 3.99995973 15.99967786]  f(x): 1.6215059330878875e-09  grad at x: [ 7.71764320e-05 -1.97136451e-05]  gradient norm: 7.9654437784292e-05\n",
            "iter: 937586  x: [ 3.99995973 15.99967786]  f(x): 1.6214575095436666e-09  grad at x: [-2.46498876e-06 -9.75866169e-06]  gradient norm: 1.0065170021321677e-05\n",
            "iter: 937587  x: [ 3.99995974 15.99967787]  f(x): 1.621407030600399e-09  grad at x: [ 7.72274359e-05 -1.97197132e-05]  gradient norm: 7.970535711104327e-05\n",
            "iter: 937588  x: [ 3.99995973 15.99967787]  f(x): 1.6213585461810519e-09  grad at x: [-2.46571793e-06 -9.75826333e-06]  gradient norm: 1.0064962402998964e-05\n",
            "iter: 937589  x: [ 3.99995974 15.99967788]  f(x): 1.6213081319108342e-09  grad at x: [ 7.72765335e-05 -1.97255431e-05]  gradient norm: 7.975437088820355e-05\n",
            "iter: 937590  x: [ 3.99995974 15.99967788]  f(x): 1.6212595888425808e-09  grad at x: [-2.46644718e-06 -9.75786497e-06]  gradient norm: 1.0064754867270995e-05\n",
            "iter: 937591  x: [ 3.99995974 15.99967789]  f(x): 1.6212092393862094e-09  grad at x: [ 7.73256891e-05 -1.97313802e-05]  gradient norm: 7.980344331960147e-05\n",
            "iter: 937592  x: [ 3.99995974 15.99967789]  f(x): 1.6211606375464067e-09  grad at x: [-2.46719106e-06 -9.75746480e-06]  gradient norm: 1.0064549217868711e-05\n",
            "iter: 937593  x: [ 3.99995974 15.9996779 ]  f(x): 1.6211103540221845e-09  grad at x: [ 7.73757615e-05 -1.97373320e-05]  gradient norm: 7.985343287668467e-05\n",
            "iter: 937594  x: [ 3.99995974 15.9996779 ]  f(x): 1.6210616922922532e-09  grad at x: [-2.46794957e-06 -9.75706280e-06]  gradient norm: 1.0064345458803552e-05\n",
            "iter: 937595  x: [ 3.99995974 15.99967791]  f(x): 1.6210114758212702e-09  grad at x: [ 7.74267360e-05 -1.97433965e-05]  gradient norm: 7.990432503526484e-05\n",
            "iter: 937596  x: [ 3.99995974 15.99967791]  f(x): 1.6209627530960795e-09  grad at x: [-2.46867904e-06 -9.75666444e-06]  gradient norm: 1.0064138174915453e-05\n",
            "iter: 937597  x: [ 3.99995974 15.99967792]  f(x): 1.6209126015145556e-09  grad at x: [ 7.74758915e-05 -1.97492336e-05]  gradient norm: 7.995339886202786e-05\n",
            "iter: 937598  x: [ 3.99995974 15.99967792]  f(x): 1.6208638199056145e-09  grad at x: [-2.46942314e-06 -9.75626426e-06]  gradient norm: 1.0063932780754738e-05\n",
            "iter: 937599  x: [ 3.99995974 15.99967793]  f(x): 1.6208137344048048e-09  grad at x: [ 7.75259782e-05 -1.97551872e-05]  gradient norm: 8.000340439055824e-05\n",
            "iter: 937600  x: [ 3.99995974 15.99967793]  f(x): 1.6207648927563424e-09  grad at x: [-2.47018187e-06 -9.75586227e-06]  gradient norm: 1.0063729280552334e-05\n",
            "iter: 937601  x: [ 3.99995974 15.99967794]  f(x): 1.6207148744587716e-09  grad at x: [ 7.75769816e-05 -1.97612553e-05]  gradient norm: 8.005432709651826e-05\n",
            "iter: 937602  x: [ 3.99995974 15.99967794]  f(x): 1.620665971665315e-09  grad at x: [-2.47094068e-06 -9.75546027e-06]  gradient norm: 1.0063525868033338e-05\n",
            "iter: 937603  x: [ 3.99995975 15.99967795]  f(x): 1.6206160206096054e-09  grad at x: [ 7.76279995e-05 -1.97673253e-05]  gradient norm: 8.010526484331452e-05\n",
            "iter: 937604  x: [ 3.99995974 15.99967795]  f(x): 1.6205670565965007e-09  grad at x: [-2.47169956e-06 -9.75505827e-06]  gradient norm: 1.0063322542783843e-05\n",
            "iter: 937605  x: [ 3.99995975 15.99967796]  f(x): 1.6205171728921877e-09  grad at x: [ 7.76790464e-05 -1.97733989e-05]  gradient norm: 8.015623217952263e-05\n",
            "iter: 937606  x: [ 3.99995975 15.99967796]  f(x): 1.6204681475680498e-09  grad at x: [-2.47247307e-06 -9.75465446e-06]  gradient norm: 1.0063121117592174e-05\n",
            "iter: 937607  x: [ 3.99995975 15.99967797]  f(x): 1.6204183323412932e-09  grad at x: [ 7.77310101e-05 -1.97795871e-05]  gradient norm: 8.020811674084022e-05\n",
            "iter: 937608  x: [ 3.99995975 15.99967797]  f(x): 1.620369244595915e-09  grad at x: [-2.47321754e-06 -9.75425428e-06]  gradient norm: 1.0062916155490982e-05\n",
            "iter: 937609  x: [ 3.99995975 15.99967798]  f(x): 1.6203194956069408e-09  grad at x: [ 7.77810964e-05 -1.97855406e-05]  gradient norm: 8.02581246654469e-05\n",
            "iter: 937610  x: [ 3.99995975 15.99967798]  f(x): 1.6202703476278385e-09  grad at x: [-2.47397665e-06 -9.75385228e-06]  gradient norm: 1.0062713093274048e-05\n",
            "iter: 937611  x: [ 3.99995975 15.99967799]  f(x): 1.6202206660730575e-09  grad at x: [ 7.78321285e-05 -1.97916124e-05]  gradient norm: 8.030907891312818e-05\n",
            "iter: 937612  x: [ 3.99995975 15.99967799]  f(x): 1.620171456699297e-09  grad at x: [-2.47475038e-06 -9.75344847e-06]  gradient norm: 1.006251193436639e-05\n",
            "iter: 937613  x: [ 3.99995975 15.999678  ]  f(x): 1.6201218438119118e-09  grad at x: [ 7.78841356e-05 -1.97978061e-05]  gradient norm: 8.03610086172476e-05\n",
            "iter: 937614  x: [ 3.99995975 15.999678  ]  f(x): 1.6200725718273394e-09  grad at x: [-2.47552419e-06 -9.75304465e-06]  gradient norm: 1.0062310865930106e-05\n",
            "iter: 937615  x: [ 3.99995975 15.99967801]  f(x): 1.6200230275432163e-09  grad at x: [ 7.79360844e-05 -1.98039925e-05]  gradient norm: 8.041288061766843e-05\n",
            "iter: 937616  x: [ 3.99995975 15.99967801]  f(x): 1.6199736929748408e-09  grad at x: [-2.47626896e-06 -9.75264447e-06]  gradient norm: 1.0062106250755808e-05\n",
            "iter: 937617  x: [ 3.99995975 15.99967802]  f(x): 1.6199242151533318e-09  grad at x: [ 7.79862141e-05 -1.98099515e-05]  gradient norm: 8.046293410536407e-05\n",
            "iter: 937618  x: [ 3.99995975 15.99967802]  f(x): 1.6198748201610476e-09  grad at x: [-2.47702837e-06 -9.75224248e-06]  gradient norm: 1.0061903540623135e-05\n",
            "iter: 937619  x: [ 3.99995975 15.99967802]  f(x): 1.619837750367137e-09  grad at x: [ 3.77801233e-05 -1.47841347e-05]  gradient norm: 4.0569796114283117e-05\n",
            "iter: 937620  x: [ 3.99995975 15.99967802]  f(x): 1.6198246170155675e-09  grad at x: [-1.84839193e-06 -9.83066457e-06]  gradient norm: 1.0002925500059538e-05\n",
            "iter: 937621  x: [ 3.99995976 15.99967806]  f(x): 1.6196257305593107e-09  grad at x: [ 1.56766738e-04 -2.96559501e-05]  gradient norm: 0.00015954712610104005\n",
            "iter: 937622  x: [ 3.99995976 15.99967806]  f(x): 1.6194806403463302e-09  grad at x: [ 7.65290937e-05 -1.96264427e-05]  gradient norm: 7.90056923932741e-05\n",
            "iter: 937623  x: [ 3.99995976 15.99967806]  f(x): 1.6194329907915287e-09  grad at x: [-2.45408768e-06 -9.75373769e-06]  gradient norm: 1.0057730619196835e-05\n",
            "iter: 937624  x: [ 3.99995976 15.99967807]  f(x): 1.6193818608469524e-09  grad at x: [ 7.65800379e-05 -1.96325036e-05]  gradient norm: 7.905654556048806e-05\n",
            "iter: 937625  x: [ 3.99995976 15.99967807]  f(x): 1.619334150973342e-09  grad at x: [-2.45483295e-06 -9.75333751e-06]  gradient norm: 1.0057524414437452e-05\n",
            "iter: 937626  x: [ 3.99995976 15.99967808]  f(x): 1.6192830864866706e-09  grad at x: [ 7.66301962e-05 -1.96384663e-05]  gradient norm: 7.910661363433268e-05\n",
            "iter: 937627  x: [ 3.99995976 15.99967808]  f(x): 1.6192353171909787e-09  grad at x: [-2.45556373e-06 -9.75293915e-06]  gradient norm: 1.0057316505791442e-05\n",
            "iter: 937628  x: [ 3.99995976 15.99967809]  f(x): 1.6191843171280343e-09  grad at x: [ 7.66794376e-05 -1.96443143e-05]  gradient norm: 7.915576564868121e-05\n",
            "iter: 937629  x: [ 3.99995976 15.99967809]  f(x): 1.6191364894625761e-09  grad at x: [-2.45629459e-06 -9.75254079e-06]  gradient norm: 1.0057108680166212e-05\n",
            "iter: 937630  x: [ 3.99995976 15.9996781 ]  f(x): 1.619085553790116e-09  grad at x: [ 7.67286499e-05 -1.96501587e-05]  gradient norm: 7.920488903886036e-05\n",
            "iter: 937631  x: [ 3.99995976 15.9996781 ]  f(x): 1.6190376677347955e-09  grad at x: [-2.45704008e-06 -9.75214061e-06]  gradient norm: 1.0056902728505339e-05\n",
            "iter: 937632  x: [ 3.99995977 15.99967811]  f(x): 1.6189867976326964e-09  grad at x: [ 7.67788079e-05 -1.96561214e-05]  gradient norm: 7.925495856125088e-05\n",
            "iter: 937633  x: [ 3.99995976 15.99967811]  f(x): 1.6189388520431002e-09  grad at x: [-2.45780019e-06 -9.75173862e-06]  gradient norm: 1.0056698655044814e-05\n",
            "iter: 937634  x: [ 3.99995977 15.99967812]  f(x): 1.6188880487275247e-09  grad at x: [ 7.68299409e-05 -1.96622059e-05]  gradient norm: 7.930600334393432e-05\n",
            "iter: 937635  x: [ 3.99995977 15.99967812]  f(x): 1.6188400424045364e-09  grad at x: [-2.45856038e-06 -9.75133662e-06]  gradient norm: 1.0056494669421957e-05\n",
            "iter: 937636  x: [ 3.99995977 15.99967813]  f(x): 1.6187893058109284e-09  grad at x: [ 7.68810157e-05 -1.96682831e-05]  gradient norm: 7.935699043613426e-05\n",
            "iter: 937637  x: [ 3.99995977 15.99967813]  f(x): 1.6187412387830917e-09  grad at x: [-2.45932065e-06 -9.75093462e-06]  gradient norm: 1.0056290771224815e-05\n",
            "iter: 937638  x: [ 3.99995977 15.99967814]  f(x): 1.618690569019942e-09  grad at x: [ 7.69321340e-05 -1.96743658e-05]  gradient norm: 7.940802168384594e-05\n",
            "iter: 937639  x: [ 3.99995977 15.99967814]  f(x): 1.618642441195812e-09  grad at x: [-2.46006644e-06 -9.75053445e-06]  gradient norm: 1.005608516471743e-05\n",
            "iter: 937640  x: [ 3.99995977 15.99967815]  f(x): 1.6185918371912286e-09  grad at x: [ 7.69823209e-05 -1.96803321e-05]  gradient norm: 7.945812227823529e-05\n",
            "iter: 937641  x: [ 3.99995977 15.99967815]  f(x): 1.6185436496251002e-09  grad at x: [-2.46081230e-06 -9.75013427e-06]  gradient norm: 1.0055879643499531e-05\n",
            "iter: 937642  x: [ 3.99995977 15.99967816]  f(x): 1.6184931114170878e-09  grad at x: [ 7.70325077e-05 -1.96862984e-05]  gradient norm: 7.950822335861208e-05\n",
            "iter: 937643  x: [ 3.99995977 15.99967816]  f(x): 1.6184448640890937e-09  grad at x: [-2.46157279e-06 -9.74973227e-06]  gradient norm: 1.0055676006162526e-05\n",
            "iter: 937644  x: [ 3.99995977 15.99967817]  f(x): 1.6183943928626464e-09  grad at x: [ 7.70836548e-05 -1.96923847e-05]  gradient norm: 7.955928519572386e-05\n",
            "iter: 937645  x: [ 3.99995977 15.99967817]  f(x): 1.6183460846037417e-09  grad at x: [-2.46230425e-06 -9.74933391e-06]  gradient norm: 1.0055468857237016e-05\n",
            "iter: 937646  x: [ 3.99995977 15.99967818]  f(x): 1.6182956781371345e-09  grad at x: [ 7.71329102e-05 -1.96982346e-05]  gradient norm: 7.960845606348152e-05\n",
            "iter: 937647  x: [ 3.99995977 15.99967818]  f(x): 1.6182473111179055e-09  grad at x: [-2.46307944e-06 -9.74893010e-06]  gradient norm: 1.0055267194369147e-05\n",
            "iter: 937648  x: [ 3.99995978 15.99967819]  f(x): 1.61819697282456e-09  grad at x: [ 7.71849885e-05 -1.97044374e-05]  gradient norm: 7.966045007904869e-05\n",
            "iter: 937649  x: [ 3.99995977 15.99967819]  f(x): 1.6181485436821709e-09  grad at x: [-2.46382560e-06 -9.74852992e-06]  gradient norm: 1.0055062017341006e-05\n",
            "iter: 937650  x: [ 3.99995978 15.9996782 ]  f(x): 1.6180982713731777e-09  grad at x: [ 7.72352041e-05 -1.97104073e-05]  gradient norm: 7.971058220401234e-05\n",
            "iter: 937651  x: [ 3.99995978 15.9996782 ]  f(x): 1.6180497822616258e-09  grad at x: [-2.46457184e-06 -9.74812974e-06]  gradient norm: 1.0054856925712083e-05\n",
            "iter: 937652  x: [ 3.99995978 15.99967821]  f(x): 1.6179995759750338e-09  grad at x: [ 7.72854197e-05 -1.97163772e-05]  gradient norm: 7.976071480856002e-05\n",
            "iter: 937653  x: [ 3.99995978 15.99967821]  f(x): 1.6179510268744063e-09  grad at x: [-2.46533270e-06 -9.74772774e-06]  gradient norm: 1.005465372406095e-05\n",
            "iter: 937654  x: [ 3.99995978 15.99967822]  f(x): 1.6179008877646108e-09  grad at x: [ 7.73365665e-05 -1.97224635e-05]  gradient norm: 7.981177911577065e-05\n",
            "iter: 937655  x: [ 3.99995978 15.99967822]  f(x): 1.6178522775191406e-09  grad at x: [-2.46607909e-06 -9.74732757e-06]  gradient norm: 1.0054448804703254e-05\n",
            "iter: 937656  x: [ 3.99995978 15.99967823]  f(x): 1.617802204508553e-09  grad at x: [ 7.73867819e-05 -1.97284335e-05]  gradient norm: 7.986191268608497e-05\n",
            "iter: 937657  x: [ 3.99995978 15.99967823]  f(x): 1.617753534179334e-09  grad at x: [-2.46685465e-06 -9.74692375e-06]  gradient norm: 1.0054247584745243e-05\n",
            "iter: 937658  x: [ 3.99995978 15.99967824]  f(x): 1.6177035295759813e-09  grad at x: [ 7.74388890e-05 -1.97346399e-05]  gradient norm: 7.991393832131963e-05\n",
            "iter: 937659  x: [ 3.99995978 15.99967824]  f(x): 1.617654796888243e-09  grad at x: [-2.46760119e-06 -9.74652357e-06]  gradient norm: 1.0054042838936836e-05\n",
            "iter: 937660  x: [ 3.99995978 15.99967825]  f(x): 1.617604858426573e-09  grad at x: [ 7.74890897e-05 -1.97406080e-05]  gradient norm: 7.996405831087175e-05\n",
            "iter: 937661  x: [ 3.99995978 15.99967825]  f(x): 1.6175560655936517e-09  grad at x: [-2.46836235e-06 -9.74612158e-06]  gradient norm: 1.0053839988016054e-05\n",
            "iter: 937662  x: [ 3.99995978 15.99967826]  f(x): 1.6175061945355216e-09  grad at x: [ 7.75402798e-05 -1.97466998e-05]  gradient norm: 8.001516824251314e-05\n",
            "iter: 937663  x: [ 3.99995978 15.99967826]  f(x): 1.6174573403310065e-09  grad at x: [-2.46913814e-06 -9.74571776e-06]  gradient norm: 1.0053639035637927e-05\n",
            "iter: 937664  x: [ 3.99995979 15.99967827]  f(x): 1.6174075378008617e-09  grad at x: [ 7.75923867e-05 -1.97529062e-05]  gradient norm: 8.006719539215567e-05\n",
            "iter: 937665  x: [ 3.99995978 15.99967827]  f(x): 1.617358621116247e-09  grad at x: [-2.46988490e-06 -9.74531758e-06]  gradient norm: 1.0053434550211038e-05\n",
            "iter: 937666  x: [ 3.99995979 15.99967828]  f(x): 1.617308884913655e-09  grad at x: [ 7.76426308e-05 -1.97588797e-05]  gradient norm: 8.01173604837496e-05\n",
            "iter: 937667  x: [ 3.99995979 15.99967828]  f(x): 1.617259907914473e-09  grad at x: [-2.47063174e-06 -9.74491741e-06]  gradient norm: 1.005323015035937e-05\n",
            "iter: 937668  x: [ 3.99995979 15.99967828]  f(x): 1.6172102381120286e-09  grad at x: [ 7.76929040e-05 -1.97648569e-05]  gradient norm: 8.016755514949505e-05\n",
            "iter: 937669  x: [ 3.99995979 15.99967829]  f(x): 1.617161200743817e-09  grad at x: [-2.47139320e-06 -9.74451541e-06]  gradient norm: 1.0053027650525651e-05\n",
            "iter: 937670  x: [ 3.99995979 15.99967829]  f(x): 1.6171115984321434e-09  grad at x: [ 7.77440647e-05 -1.97709451e-05]  gradient norm: 8.02186379351064e-05\n",
            "iter: 937671  x: [ 3.99995979 15.99967829]  f(x): 1.6170624995855963e-09  grad at x: [-2.47215474e-06 -9.74411341e-06]  gradient norm: 1.0052825238494765e-05\n",
            "iter: 937672  x: [ 3.99995979 15.9996783 ]  f(x): 1.6170129649090141e-09  grad at x: [ 7.77952836e-05 -1.97770405e-05]  gradient norm: 8.026977941543852e-05\n",
            "iter: 937673  x: [ 3.99995979 15.9996783 ]  f(x): 1.6169638044752507e-09  grad at x: [-2.47291636e-06 -9.74371142e-06]  gradient norm: 1.0052622914944235e-05\n",
            "iter: 937674  x: [ 3.99995979 15.99967831]  f(x): 1.616914337403072e-09  grad at x: [ 7.78464734e-05 -1.97831323e-05]  gradient norm: 8.032089228141136e-05\n",
            "iter: 937675  x: [ 3.99995979 15.99967831]  f(x): 1.6168651153583833e-09  grad at x: [-2.47366349e-06 -9.74331124e-06]  gradient norm: 1.0052418861403242e-05\n",
            "iter: 937676  x: [ 3.99995979 15.99967832]  f(x): 1.616815714876154e-09  grad at x: [ 7.78967608e-05 -1.97891113e-05]  gradient norm: 8.037110340647829e-05\n",
            "iter: 937677  x: [ 3.99995979 15.99967832]  f(x): 1.6167664322715314e-09  grad at x: [-2.47442525e-06 -9.74290924e-06]  gradient norm: 1.0052216712794741e-05\n",
            "iter: 937678  x: [ 3.99995979 15.99967833]  f(x): 1.616729429381114e-09  grad at x: [ 3.77367552e-05 -1.47690553e-05]  gradient norm: 4.052391503683762e-05\n",
            "iter: 937679  x: [ 3.99995979 15.99967833]  f(x): 1.6167163254637907e-09  grad at x: [-1.84650307e-06 -9.82124220e-06]  gradient norm: 9.993316364663603e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTACcFmS3bLW",
        "outputId": "c1227c1b-6b50-4d4f-a988-d4fc5e3079bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3.99995979 15.99967833]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 1:\n",
        "\n",
        "Minimizer : [4,16]\n",
        "Minimum Function Value : 0\n",
        "\n",
        "#Ans 2:\n",
        "\n",
        "Closed form expression cannot be found because it cannot be represented in the required matrix equation form.\n",
        "\n",
        "Since computing taking too much time, only backtracking line search performed for $\\alpha = 0$."
      ],
      "metadata": {
        "id": "MdhL-7LbzjOD"
      }
    }
  ]
}