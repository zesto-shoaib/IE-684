{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190012_IE684_Lab7_Ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b_M0qJ_tTF7C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "np.random.seed(1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 200\n",
        "ds = [1000, 5000, 10000, 20000, 25000, 50000, 100000, 200000, 500000, 1000000]\n",
        "lambda_reg = 0.001\n",
        "eps = np.random.randn(N,1)"
      ],
      "metadata": {
        "id": "wyiUITd3TNtj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalf_l(x, lambd):\n",
        "  res = np.multiply(lambd/2,np.matmul(x.transpose(),x))+((np.linalg.norm(np.subtract(np.matmul(A,x),y)))**2)/2\n",
        "  return res"
      ],
      "metadata": {
        "id": "JmJNvLeaT66s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg_l(x, lambd):\n",
        "  n = x.shape[0]\n",
        "  arr = np.zeros(n)\n",
        "  err = np.subtract(np.matmul(A,x),y)\n",
        "  for i in range(n):\n",
        "    arr[i] = lambd*x[i] + np.matmul(err.transpose(),A[:,i])\n",
        "  return arr.reshape(n,1)"
      ],
      "metadata": {
        "id": "NRoMFwjcT-xM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalh_l(x, lambd):\n",
        "  n = x.shape[0]\n",
        "  hes = np.zeros((n,n))\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      hes[i][j] = np.matmul(A[:,i],A[:,j])\n",
        "      if i == j:\n",
        "        hes[i][j] += lambd\n",
        "  return hes"
      ],
      "metadata": {
        "id": "GH8FU4UGT_Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_backtracking_scaled_direction(x, p, gradf, alpha_start, rho, gamma, d_k, lambd):\n",
        "  #assert type(x) is np.ndarray and len(x) == 2\n",
        "  #assert type(gradf) is np.ndarray and len(gradf) == 2\n",
        "  \n",
        "  alpha = alpha_start\n",
        "\n",
        "  while evalf_l(x+alpha*np.matmul(d_k,p), lambd) > evalf_l(x, lambd) + gamma*alpha*(np.matmul(gradf.transpose(),np.matmul(d_k,p))):\n",
        "    alpha = rho*alpha\n",
        "\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "Gq_jVFVGUsN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Newton_l(n, tol, lambd, *args):\n",
        "  xlist = []\n",
        "  x = np.zeros(n).reshape(n,1)\n",
        "  xlist.append(x)\n",
        "  grad_f = evalg_l(x, lambd)\n",
        "\n",
        "  alpha = args[0]\n",
        "  rho = args[1]\n",
        "  gamma = args[2]\n",
        "\n",
        "  hes_f = evalh_l(x, lambd)\n",
        "\n",
        "  k = 0\n",
        "\n",
        "  while np.linalg.norm(grad_f) > tol and k < 10000:\n",
        "    p = -grad_f\n",
        "    d = np.linalg.inv(hes_f)\n",
        "    step_length = compute_steplength_backtracking_scaled_direction(x, p, grad_f, alpha, rho, gamma, d, lambd)\n",
        "    x = np.add(x, np.multiply(step_length, np.matmul(d,p)))\n",
        "    xlist.append(x)\n",
        "    k += 1 \n",
        "    grad_f = evalg_l(x, lambd) \n",
        "    hes_f = evalh_l(x, lambd)\n",
        "  return x"
      ],
      "metadata": {
        "id": "YvGi6fgDUtF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(np.size(ds)):\n",
        "  d=ds[i]\n",
        "  A = np.random.randn(N,d)\n",
        "  for j in range(A.shape[1]):\n",
        "    A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "    \n",
        "  xorig = np.ones((d,1))\n",
        "  y = np.dot(A,xorig) + eps\n",
        "\n",
        "  start = timeit.default_timer()\n",
        "  x_opt = Newton_l(d, 1e-5, lambda_reg, 1, 0.5, 0.5)\n",
        "  newtontime = timeit.default_timer() - start\n",
        "  print('For',d,': Time taken :',newtontime,'\\n||Ax* - y||^2 =',(np.linalg.norm(np.subtract(np.matmul(A,x_opt),y)))**2,'\\n||x*-xorig||^2 =',(np.linalg.norm(np.subtract(x_opt,xorig)))**2,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUub1J72TPpw",
        "outputId": "e7392bba-b594-4f4f-d9a1-9a7b5192e84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 1000 : Time taken : 9.93499467200013 \n",
            "||Ax* - y||^2 = 6.0108776056799973e-05 \n",
            "||x*-xorig||^2 = 875.8122987367859 \n",
            "\n",
            "For 5000 : Time taken : 139.44050470799993 \n",
            "||Ax* - y||^2 = 8.63961256789895e-06 \n",
            "||x*-xorig||^2 = 4817.355553683237 \n",
            "\n",
            "For 10000 : Time taken : 599.9326577649999 \n",
            "||Ax* - y||^2 = 4.05446978527579e-06 \n",
            "||x*-xorig||^2 = 9815.561161563599 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 1:\n",
        "\n",
        "For Newton's method:\n",
        "\n",
        "For 1000 : Time taken : 9.93499467200013 \n",
        "\n",
        "$||Ax^* - y||^2$ = 6.0108776056799973e-05 \n",
        "\n",
        "$||x^*-x_{orig}||^2$ = 875.8122987367859 \n",
        "\n",
        "\n",
        "For 5000 : Time taken : 139.44050470799993 \n",
        "\n",
        "$||Ax^* - y||^2$ = 8.63961256789895e-06 \n",
        "\n",
        "$||x^*-x_{orig}||^2$ = 4817.355553683237 \n",
        "\n",
        "\n",
        "For 10000 : Time taken : 599.9326577649999 \n",
        "\n",
        "$||Ax^* - y||^2$ = 4.05446978527579e-06 \n",
        "\n",
        "$||x^*-x_{orig}||^2$ = 9815.561161563599\n",
        "\n",
        "For 20000, the runtime exceeds 20 minutes, so we declare it as a failure dimension.\n"
      ],
      "metadata": {
        "id": "OvT81MWr_XtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_steplength_backtracking(x, gradf, B, alpha_start, rho, gamma, lambd):\n",
        "  #assert type(x) is np.ndarray and len(x) == 2\n",
        "  #assert type(gradf) is np.ndarray and len(gradf) == 2\n",
        "  \n",
        "  alpha = alpha_start\n",
        "\n",
        "  while evalf_l(x+alpha*-np.matmul(B,gradf), lambd) > evalf_l(x, lambd) + gamma*alpha*np.matmul(gradf.transpose(),-np.matmul(B,gradf)):\n",
        "    alpha = rho*alpha\n",
        "\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "8VMiyJUaVhuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BFGS_l(n, tol, lambd, *args):\n",
        "  xlist = []\n",
        "  x1 = np.zeros(n).reshape(n,1)\n",
        "  xlist.append(x1)\n",
        "  grad_f = evalg_l(x1, lambd)\n",
        "\n",
        "  alpha_start = args[0]\n",
        "  rho = args[1]\n",
        "  gamma = args[2]\n",
        "\n",
        "  I = np.identity(n)\n",
        "\n",
        "  B = I\n",
        "\n",
        "  k = 0\n",
        "\n",
        "  while np.linalg.norm(grad_f) > tol and k < 3000:\n",
        "    alpha = compute_steplength_backtracking(x1, grad_f, B, alpha_start, rho, gamma, lambd)\n",
        "    x2 = np.add(x1, np.multiply(alpha,np.matmul(B,-grad_f)))\n",
        "    s = x2 - x1\n",
        "    y = evalg_l(x2, lambd) - evalg_l(x1, lambd)\n",
        "    mu = 1/np.matmul(y.transpose(),s)\n",
        "    #print(p,alpha,x2,s,y,mu)\n",
        "    B = np.add(np.matmul(np.matmul(np.subtract(I,np.matmul(np.multiply(mu,s),y.transpose())),B),np.subtract(I,np.matmul(np.multiply(mu,y),s.transpose()))),np.matmul(np.multiply(mu,s),s.transpose()))\n",
        "    x1 = x2\n",
        "    xlist.append(x1)\n",
        "    grad_f = evalg_l(x2, lambd)\n",
        "    k = k+1\n",
        "    #print(np.linalg.norm(grad_f))\n",
        "  return x1"
      ],
      "metadata": {
        "id": "IPTv7jiQgtQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(np.size(ds)):\n",
        "  d=ds[i]\n",
        "  A = np.random.randn(N,d)\n",
        "  for j in range(A.shape[1]):\n",
        "    A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "    \n",
        "  xorig = np.ones((d,1))\n",
        "  y = np.dot(A,xorig) + eps\n",
        "\n",
        "  start = timeit.default_timer()\n",
        "  x_opt = BFGS_l(d, 1e-5, lambda_reg, 1, 0.5, 0.5)\n",
        "  bfgstime = timeit.default_timer() - start\n",
        "  print('For',d,': Time taken :',bfgstime,'\\n||Ax* - y||^2 =',(np.linalg.norm(np.subtract(np.matmul(A,x_opt),y)))**2,'\\n||x*-xorig||^2 =',(np.linalg.norm(np.subtract(x_opt,xorig)))**2,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqvnzJydgyGx",
        "outputId": "0475ad5f-46d4-4f72-ead2-5182587dc224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 1000 : Time taken : 9.922479796999994 \n",
            "||Ax* - y||^2 = 5.672486123595797e-05 \n",
            "||x*-xorig||^2 = 865.3153037913714 \n",
            "\n",
            "For 5000 : Time taken : 686.8632253779999 \n",
            "||Ax* - y||^2 = 9.791829840368583e-06 \n",
            "||x*-xorig||^2 = 4783.681693162326 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 1:\n",
        "\n",
        "For BFGS method:\n",
        "\n",
        "For 1000 : Time taken : 9.922479796999994 \n",
        "\n",
        "$||Ax^* - y||^2$ = 5.672486123595797e-05 \n",
        "\n",
        "$||x^*-x_{orig}||^2$ = 865.3153037913714 \n",
        "\n",
        "\n",
        "For 5000 : Time taken : 686.8632253779999 \n",
        "\n",
        "$||Ax^* - y||^2$ = 9.791829840368583e-06 \n",
        "\n",
        "$||x^*-x_{orig}||^2$ = 4783.681693162326 \n",
        "\n",
        "For 10000, the runtime exceeds 20 minutes, so we declare it as a failure dimension."
      ],
      "metadata": {
        "id": "XsRgQq0l_9Xd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 2:\n",
        "\n",
        "Failure dimension for Newton's method: 20000\n",
        "\n",
        "Failure dimension for BFGS method: 10000"
      ],
      "metadata": {
        "id": "fzwzY_sfATlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fx_WsOx-hRO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}