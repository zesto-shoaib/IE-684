{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21i190012_IE684_Lab7_Ex3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 1:\n",
        "\n",
        "$f_i(x) = \\frac{\\lambda}{2N}x^Tx + \\frac{1}{2}||A_ix - y_i||_2^2$\n",
        "\n",
        "where $A_i$ denotes the ith row in the data matrix A and $y_i$ denotes the ith element in vector y."
      ],
      "metadata": {
        "id": "LseOcLlOegYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 2:\n",
        "\n",
        "$g_i(x) = \\frac{\\lambda}{N}x_i + (A_ix - y_i)A_i$"
      ],
      "metadata": {
        "id": "JuMPxc3_fML5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "7DRivZEOlrO8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "np.random.seed(1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 200\n",
        "d = 10000\n",
        "lambda_reg = 0.001\n",
        "eps = np.random.randn(N,1)"
      ],
      "metadata": {
        "id": "5uMxqn_YnUkQ"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.randn(N,int(d))"
      ],
      "metadata": {
        "id": "mfR2YfmgneLd"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(A.shape[1]):\n",
        "  A[:,j] = A[:,j]/np.linalg.norm(A[:,j])"
      ],
      "metadata": {
        "id": "9-YFfsKgngQl"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xorig = np.ones((int(d),1))\n",
        "y = np.dot(A,xorig) + eps"
      ],
      "metadata": {
        "id": "103KtajknrYJ"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((int(d),1))\n",
        "epochs = 1e4\n",
        "t = 1\n",
        "arr = np.arange(N)"
      ],
      "metadata": {
        "id": "eRUdMtKdnuBV"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg(x, lambd):\n",
        "  arr = np.zeros(64)\n",
        "  err = np.subtract(np.matmul(A,x),y)\n",
        "  for i in range(64):\n",
        "    arr[i] = lambd*x[i] + np.matmul(err.transpose(),A[:,i])\n",
        "  return arr.reshape(64,1)"
      ],
      "metadata": {
        "id": "Rl-A1U8Dy-cD"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalg_l(x, i, lambd):\n",
        "  err = np.subtract(np.matmul(A[i],x),y[i])\n",
        "  ar = np.add((lambd/N)*x[i],np.multiply(err[0],A[i]))\n",
        "  return ar.reshape((x.shape[0],1))"
      ],
      "metadata": {
        "id": "68-xqjw4pfSZ"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer() #start the timer\n",
        "for epoch in range(int(epochs)):\n",
        "  #print(epoch)\n",
        "  np.random.shuffle(arr) #shuffle every epoch\n",
        "  for i in np.nditer(arr):\n",
        "    #print(evalg_l(x, i, lambda_reg))\n",
        "    x = x - (1/t * evalg_l(x, i, lambda_reg))\n",
        "    #print(x.shape)\n",
        "    t = t+1\n",
        "    if t>1e4:\n",
        "      t = 1\n",
        "alglab7time = timeit.default_timer() - start #time is in seconds\n",
        "x_alglab7 = x\n",
        "\n",
        "print('time:',alglab7time)\n",
        "print('optimal gradient norm:',np.linalg.norm(evalg(x_alglab7, lambda_reg)))\n",
        "print((np.linalg.norm(np.subtract(np.matmul(A,x_alglab7),y)))**2)\n",
        "print((np.linalg.norm(np.subtract(x_alglab7,xorig)))**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAZOboxkn1WD",
        "outputId": "0e81ed96-baea-402a-beb0-4098e81b4463"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 130.52291859400066\n",
            "optimal gradient norm: 0.0010363844642636807\n",
            "3.898103464183208e-08\n",
            "9838.847456261916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 3:\n",
        "\n",
        "For dimension 10000,\n",
        "\n",
        "Time taken : 130.52 seconds\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0010363844642636807\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 3.898103464183208e-08\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 9838.847456261916\n",
        "\n",
        "For dimension 20000,\n",
        "\n",
        "Time taken : 317.23 seconds\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.000741488790987189\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 7.846033738594737e-09\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 19824.247821136378 "
      ],
      "metadata": {
        "id": "dWHuh-CEgqy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = [1e4, 5*1e4, 1e5]\n",
        "\n",
        "for k in epochs:\n",
        "  start = timeit.default_timer() #start the timer\n",
        "  for epoch in range(int(k)):\n",
        "    #print(epoch)\n",
        "    np.random.shuffle(arr) #shuffle every epoch\n",
        "    for i in np.nditer(arr):\n",
        "      #print(evalg_l(x, i, lambda_reg))\n",
        "      x = x - (1/t * evalg_l(x, i, lambda_reg))\n",
        "      #print(x.shape)\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "        t = 1\n",
        "  alglab7time = timeit.default_timer() - start #time is in seconds\n",
        "  x_alglab7 = x\n",
        "\n",
        "  print('epoch =',k)\n",
        "  print('time:',alglab7time)\n",
        "  print('optimal gradient norm:',np.linalg.norm(evalg(x_alglab7, lambda_reg)))\n",
        "  print('||Ax* - y||^2 =',(np.linalg.norm(np.subtract(np.matmul(A,x_alglab7),y)))**2)\n",
        "  print('||x*-xorig||^2 =',(np.linalg.norm(np.subtract(x_alglab7,xorig)))**2,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo1QRdrWgd9F",
        "outputId": "e3ccf8dc-417f-4777-b62c-af1cf1c68961"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 10000.0\n",
            "time: 128.2377099839996\n",
            "optimal gradient norm: 0.0010498801077334615\n",
            "||Ax* - y||^2 = 7.974511564562011e-09\n",
            "||x*-xorig||^2 = 9845.010811491862 \n",
            "\n",
            "epoch = 50000.0\n",
            "time: 652.5266416569993\n",
            "optimal gradient norm: 0.0010536545622100123\n",
            "||Ax* - y||^2 = 4.3321540850761296e-08\n",
            "||x*-xorig||^2 = 9872.291738488982 \n",
            "\n",
            "epoch = 100000.0\n",
            "time: 1324.3427896840003\n",
            "optimal gradient norm: 0.0010515805241716992\n",
            "||Ax* - y||^2 = 1.4337299772194933e-08\n",
            "||x*-xorig||^2 = 9924.49763942884 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lambdas = [1000, 100, 10, 1, 0.1, 1e-2, 1e-3]\n",
        "\n",
        "for k in lambdas:\n",
        "  start = timeit.default_timer() #start the timer\n",
        "  for epoch in range(int(1e4)):\n",
        "    #print(epoch)\n",
        "    np.random.shuffle(arr) #shuffle every epoch\n",
        "    for i in np.nditer(arr):\n",
        "      #print(evalg_l(x, i, lambda_reg))\n",
        "      x = x - (1/t * evalg_l(x, i, k))\n",
        "      #print(x.shape)\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "        t = 1\n",
        "  alglab7time = timeit.default_timer() - start #time is in seconds\n",
        "  x_alglab7 = x\n",
        "\n",
        "  print('lambda =',k)\n",
        "  print('time:',alglab7time)\n",
        "  print('optimal gradient norm:',np.linalg.norm(evalg(x_alglab7, lambda_reg)))\n",
        "  print('||Ax* - y||^2 =',(np.linalg.norm(np.subtract(np.matmul(A,x_alglab7),y)))**2)\n",
        "  print('||x*-xorig||^2 =',(np.linalg.norm(np.subtract(x_alglab7,xorig)))**2,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2OiYR6GlIV7",
        "outputId": "bc146639-8a7f-4849-e75d-e10312d6cf60"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lambda = 1000\n",
            "time: 132.2270335000012\n",
            "optimal gradient norm: 18.972286344711037\n",
            "||Ax* - y||^2 = 1804.1710838259148\n",
            "||x*-xorig||^2 = 10404.138641022742 \n",
            "\n",
            "lambda = 100\n",
            "time: 130.13892594000026\n",
            "optimal gradient norm: 2.558747927157985\n",
            "||Ax* - y||^2 = 24.149105813951127\n",
            "||x*-xorig||^2 = 10470.577258493173 \n",
            "\n",
            "lambda = 10\n",
            "time: 133.58179831500092\n",
            "optimal gradient norm: 0.359052566475746\n",
            "||Ax* - y||^2 = 0.4902254969565436\n",
            "||x*-xorig||^2 = 10528.236331047126 \n",
            "\n",
            "lambda = 1\n",
            "time: 133.8488884569997\n",
            "optimal gradient norm: 0.05737482995387158\n",
            "||Ax* - y||^2 = 0.012416071171366441\n",
            "||x*-xorig||^2 = 10472.512922389884 \n",
            "\n",
            "lambda = 0.1\n",
            "time: 127.85367920899989\n",
            "optimal gradient norm: 0.002530193292257295\n",
            "||Ax* - y||^2 = 1.5112054428170323e-05\n",
            "||x*-xorig||^2 = 10431.114418388244 \n",
            "\n",
            "lambda = 0.01\n",
            "time: 129.58886959200026\n",
            "optimal gradient norm: 0.0010410672951335497\n",
            "||Ax* - y||^2 = 3.016938553517417e-07\n",
            "||x*-xorig||^2 = 10433.507293673983 \n",
            "\n",
            "lambda = 0.001\n",
            "time: 129.25343775799956\n",
            "optimal gradient norm: 0.0010186131887792121\n",
            "||Ax* - y||^2 = 2.654744623840759e-09\n",
            "||x*-xorig||^2 = 10433.536835010902 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 200\n",
        "d = 20000\n",
        "lambda_reg = 0.001\n",
        "eps = np.random.randn(N,1)\n",
        "A = np.random.randn(N,int(d))\n",
        "for j in range(A.shape[1]):\n",
        "  A[:,j] = A[:,j]/np.linalg.norm(A[:,j])\n",
        "xorig = np.ones((int(d),1))\n",
        "y = np.dot(A,xorig) + eps\n",
        "x = np.zeros((int(d),1))\n",
        "epochs = 1e4\n",
        "t = 1\n",
        "arr = np.arange(N)"
      ],
      "metadata": {
        "id": "bTT7zMYbBhQ1"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = [1e4, 5*1e4, 1e5]\n",
        "\n",
        "for k in epochs:\n",
        "  start = timeit.default_timer() #start the timer\n",
        "  for epoch in range(int(k)):\n",
        "    #print(epoch)\n",
        "    np.random.shuffle(arr) #shuffle every epoch\n",
        "    for i in np.nditer(arr):\n",
        "      #print(evalg_l(x, i, lambda_reg))\n",
        "      x = x - (1/t * evalg_l(x, i, lambda_reg))\n",
        "      #print(x.shape)\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "        t = 1\n",
        "  alglab7time = timeit.default_timer() - start #time is in seconds\n",
        "  x_alglab7 = x\n",
        "\n",
        "  print('d=',d)\n",
        "  print('epoch =',k)\n",
        "  print('time:',alglab7time)\n",
        "  print('optimal gradient norm:',np.linalg.norm(evalg(x_alglab7, lambda_reg)))\n",
        "  print('||Ax* - y||^2 =',(np.linalg.norm(np.subtract(np.matmul(A,x_alglab7),y)))**2)\n",
        "  print('||x*-xorig||^2 =',(np.linalg.norm(np.subtract(x_alglab7,xorig)))**2,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHBrbH-auV2X",
        "outputId": "ff97ee7f-76ad-4f78-beb1-3b9ecab00ba1"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d= 20000\n",
            "epoch = 10000.0\n",
            "time: 317.2296431270006\n",
            "optimal gradient norm: 0.000741488790987189\n",
            "||Ax* - y||^2 = 7.846033738594737e-09\n",
            "||x*-xorig||^2 = 19824.247821136378 \n",
            "\n",
            "d= 20000\n",
            "epoch = 50000.0\n",
            "time: 1591.8587656910004\n",
            "optimal gradient norm: 0.0007160889791013773\n",
            "||Ax* - y||^2 = 2.7992275183683695e-09\n",
            "||x*-xorig||^2 = 19840.12558161412 \n",
            "\n",
            "d= 20000\n",
            "epoch = 100000.0\n",
            "time: 3193.5619911930007\n",
            "optimal gradient norm: 0.0007244234380072702\n",
            "||Ax* - y||^2 = 1.4640371870989295e-09\n",
            "||x*-xorig||^2 = 19869.84936113091 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lambdas = [1000, 100, 10, 1, 0.1, 1e-2, 1e-3]\n",
        "\n",
        "for k in lambdas:\n",
        "  start = timeit.default_timer() #start the timer\n",
        "  for epoch in range(int(1e4)):\n",
        "    #print(epoch)\n",
        "    np.random.shuffle(arr) #shuffle every epoch\n",
        "    for i in np.nditer(arr):\n",
        "      #print(evalg_l(x, i, lambda_reg))\n",
        "      x = x - (1/t * evalg_l(x, i, k))\n",
        "      #print(x.shape)\n",
        "      t = t+1\n",
        "      if t>1e4:\n",
        "        t = 1\n",
        "  alglab7time = timeit.default_timer() - start #time is in seconds\n",
        "  x_alglab7 = x\n",
        "\n",
        "  print('lambda =',k)\n",
        "  print('time:',alglab7time)\n",
        "  print('optimal gradient norm:',np.linalg.norm(evalg(x_alglab7, lambda_reg)))\n",
        "  print('||Ax* - y||^2 =',(np.linalg.norm(np.subtract(np.matmul(A,x_alglab7),y)))**2)\n",
        "  print('||x*-xorig||^2 =',(np.linalg.norm(np.subtract(x_alglab7,xorig)))**2,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrGCK091B6JX",
        "outputId": "6e6a7cd5-f57d-4c9a-e982-832902aa24eb"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lambda = 1000\n",
            "time: 321.937267502999\n",
            "optimal gradient norm: 52.078550955443156\n",
            "||Ax* - y||^2 = 9028.541478315108\n",
            "||x*-xorig||^2 = 20148.841727397616 \n",
            "\n",
            "lambda = 100\n",
            "time: 317.88425542700134\n",
            "optimal gradient norm: 5.050087299012066\n",
            "||Ax* - y||^2 = 72.1379895014913\n",
            "||x*-xorig||^2 = 20092.575147368454 \n",
            "\n",
            "lambda = 10\n",
            "time: 317.07445605200337\n",
            "optimal gradient norm: 0.12814282514193304\n",
            "||Ax* - y||^2 = 0.05055126874355229\n",
            "||x*-xorig||^2 = 20009.276019769448 \n",
            "\n",
            "lambda = 1\n",
            "time: 319.341281240002\n",
            "optimal gradient norm: 0.019772601057733194\n",
            "||Ax* - y||^2 = 0.0010423501051387723\n",
            "||x*-xorig||^2 = 20160.33069420957 \n",
            "\n",
            "lambda = 0.1\n",
            "time: 319.2264705790003\n",
            "optimal gradient norm: 0.0018407413913838946\n",
            "||Ax* - y||^2 = 1.131264503635859e-05\n",
            "||x*-xorig||^2 = 20134.919054877875 \n",
            "\n",
            "lambda = 0.01\n",
            "time: 318.2600023399973\n",
            "optimal gradient norm: 0.0007365408265413915\n",
            "||Ax* - y||^2 = 4.323728293206125e-08\n",
            "||x*-xorig||^2 = 20137.28394519603 \n",
            "\n",
            "lambda = 0.001\n",
            "time: 323.295242725002\n",
            "optimal gradient norm: 0.0007651265188281965\n",
            "||Ax* - y||^2 = 1.5224959819785493e-07\n",
            "||x*-xorig||^2 = 20137.171045621908 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 4:\n",
        "\n",
        "At $\\lambda$ = 0.001\n",
        "\n",
        "For dimension 10000,\n",
        "\n",
        "For 10000 epochs,\n",
        "\n",
        "Time taken : 128.2377099839996\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0010498801077334615\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 7.974511564562011e-09\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 9845.010811491862 \n",
        "\n",
        "For 50000 epochs,\n",
        "\n",
        "Time taken : 652.5266416569993\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0010536545622100123\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 4.3321540850761296e-08\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 9872.291738488982\n",
        "\n",
        "For 100000 epochs,\n",
        "\n",
        "Time taken : 1324.3427896840003\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0010515805241716992\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 1.4337299772194933e-08\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 9924.49763942884\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "For dimension 20000,\n",
        "\n",
        "For 10000 epochs,\n",
        "\n",
        "Time taken : 317.2296431270006\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.000741488790987189\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 7.846033738594737e-09\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 19824.247821136378 \n",
        "\n",
        "For 50000 epochs,\n",
        "\n",
        "Time taken : 1591.8587656910004\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0007160889791013773\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 2.7992275183683695e-09\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 19840.12558161412\n",
        "\n",
        "For 100000 epochs,\n",
        "\n",
        "Time taken : 3193.5619911930007\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0007244234380072702\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 1.4640371870989295e-09\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 19869.84936113091\n",
        "\n",
        "\n",
        "We can observe that for more no. of epochs, the time required increases rapidly, but no improvement is seen in the case of both failure dimensions."
      ],
      "metadata": {
        "id": "bXU6g6GojalH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 5:\n",
        "\n",
        "For 100000 epochs,\n",
        "\n",
        "For dimension 10000,\n",
        "\n",
        "For $\\lambda$ = 1000,\n",
        "\n",
        "Time taken : 132.2270335000012\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 18.972286344711037\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 1804.1710838259148\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 10404.138641022742 \n",
        "\n",
        "For $\\lambda$ = 100,\n",
        "\n",
        "Time taken : 130.13892594000026\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 2.558747927157985\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 24.149105813951127\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 10470.577258493173 \n",
        "\n",
        "For $\\lambda = 10$,\n",
        "\n",
        "Time taken : 133.58179831500092\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.359052566475746\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 0.4902254969565436\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 10528.236331047126\n",
        "\n",
        "For $\\lambda = 1$,\n",
        "\n",
        "Time taken : 133.8488884569997\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.05737482995387158\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 0.012416071171366441\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 10472.512922389884 \n",
        "\n",
        "For $\\lambda = 0.1$,\n",
        "\n",
        "Time taken : 127.85367920899989\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.002530193292257295\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 1.5112054428170323e-05\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 10431.114418388244\n",
        "\n",
        "For $\\lambda = 0.01$,\n",
        "\n",
        "Time taken : 129.58886959200026\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0010410672951335497\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 3.016938553517417e-07\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 10433.507293673983\n",
        "\n",
        "For $\\lambda = 0.001$,\n",
        "\n",
        "Time taken : 129.25343775799956\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0010186131887792121\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 2.654744623840759e-09\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 10433.536835010902\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "For dimension 20000,\n",
        "\n",
        "For $\\lambda$ = 1000,\n",
        "\n",
        "Time taken : 321.937267502999\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 52.078550955443156\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 9028.541478315108\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 20148.841727397616\n",
        "\n",
        "For $\\lambda$ = 100,\n",
        "\n",
        "Time taken : 317.88425542700134\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 5.050087299012066\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 72.1379895014913\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 20092.575147368454 \n",
        "\n",
        "For $\\lambda = 10$,\n",
        "\n",
        "Time taken : 317.07445605200337\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.12814282514193304\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 0.05055126874355229\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 20009.276019769448\n",
        "\n",
        "For $\\lambda = 1$,\n",
        "\n",
        "Time taken : 319.341281240002\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.019772601057733194\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 0.0010423501051387723\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 20160.33069420957\n",
        "\n",
        "For $\\lambda = 0.1$,\n",
        "\n",
        "Time taken : 319.2264705790003\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0018407413913838946\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 1.131264503635859e-05\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 20134.919054877875\n",
        "\n",
        "For $\\lambda = 0.01$,\n",
        "\n",
        "Time taken : 318.2600023399973\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0007365408265413915\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 4.323728293206125e-08\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 20137.28394519603 \n",
        "\n",
        "For $\\lambda = 0.001$,\n",
        "\n",
        "Time taken : 323.295242725002\n",
        "\n",
        "$||f_\\lambda(x^*)||$ = 0.0007651265188281965\n",
        "\n",
        "$||Ax^*-y||_2^2$ = 1.5224959819785493e-07\n",
        "\n",
        "$||x^*-x_{orig}||^2_2$ = 20137.171045621908\n",
        "\n",
        "We can observe that for both the failure dimensions for larger values of lambda, the value of $||Ax^*-y||^2_2$ is quite large and reduces quickly for smaller values of lambda. The time taken for all values of lambda is similar."
      ],
      "metadata": {
        "id": "1ronSJPokXtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 6:\n",
        "\n",
        "Yes, Alg-Lab 7 works for the failure dimensions as it gives the solution in way less time than in the previous exercise."
      ],
      "metadata": {
        "id": "E0m9xYDLntoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans 7:\n",
        "\n",
        "The algorithm runs for the no. of epochs defined, and shuffles the rows of the data matrix for every epoch.\n",
        "\n",
        "1/t acts as the step length and this algorithm performs well because no matrix inversion or matrix multiplication operation is needed to be performed and they can be computationally very expensive, only vector multiplications are required for the matrix in the gradient calculation."
      ],
      "metadata": {
        "id": "HDfA6VEcn8lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AukduVylVbUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}